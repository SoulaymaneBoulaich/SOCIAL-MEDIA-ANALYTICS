id,platform,title,text,score,num_comments,created_utc,author,url
1oy6wuf,reddit,Sunday Daily Thread: What's everyone working on this week?,"# Weekly Thread: What's Everyone Working On This Week? üõ†Ô∏è

Hello /r/Python! It's time to share what you've been working on! Whether it's a work-in-progress, a completed masterpiece, or just a rough idea, let us know what you're up to!

## How it Works:

1. **Show & Tell**: Share your current projects, completed works, or future ideas.
2. **Discuss**: Get feedback, find collaborators, or just chat about your project.
3. **Inspire**: Your project might inspire someone else, just as you might get inspired here.

## Guidelines:

* Feel free to include as many details as you'd like. Code snippets, screenshots, and links are all welcome.
* Whether it's your job, your hobby, or your passion project, all Python-related work is welcome here.

## Example Shares:

1. **Machine Learning Model**: Working on a ML model to predict stock prices. Just cracked a 90% accuracy rate!
2. **Web Scraping**: Built a script to scrape and analyze news articles. It's helped me understand media bias better.
3. **Automation**: Automated my home lighting with Python and Raspberry Pi. My life has never been easier!

Let's build and grow together! Share your journey and learn from others. Happy coding! üåü",6,1,2025-11-16 01:00:33,AutoModerator,https://www.reddit.com/r/Python/comments/1oy6wuf/sunday_daily_thread_whats_everyone_working_on/
1oz1c67,reddit,Monday Daily Thread: Project ideas!,"# Weekly Thread: Project Ideas üí°

Welcome to our weekly Project Ideas thread! Whether you're a newbie looking for a first project or an expert seeking a new challenge, this is the place for you.

## How it Works:

1. **Suggest a Project**: Comment your project idea‚Äîbe it beginner-friendly or advanced.
2. **Build & Share**: If you complete a project, reply to the original comment, share your experience, and attach your source code.
3. **Explore**: Looking for ideas? Check out Al Sweigart's [""The Big Book of Small Python Projects""](https://www.amazon.com/Big-Book-Small-Python-Programming/dp/1718501242) for inspiration.

## Guidelines:

* Clearly state the difficulty level.
* Provide a brief description and, if possible, outline the tech stack.
* Feel free to link to tutorials or resources that might help.

# Example Submissions:

## Project Idea: Chatbot

**Difficulty**: Intermediate

**Tech Stack**: Python, NLP, Flask/FastAPI/Litestar 

**Description**: Create a chatbot that can answer FAQs for a website.

**Resources**: [Building a Chatbot with Python](https://www.youtube.com/watch?v=a37BL0stIuM)

# Project Idea: Weather Dashboard

**Difficulty**: Beginner

**Tech Stack**: HTML, CSS, JavaScript, API

**Description**: Build a dashboard that displays real-time weather information using a weather API.

**Resources**: [Weather API Tutorial](https://www.youtube.com/watch?v=9P5MY_2i7K8)

## Project Idea: File Organizer

**Difficulty**: Beginner

**Tech Stack**: Python, File I/O

**Description**: Create a script that organizes files in a directory into sub-folders based on file type.

**Resources**: [Automate the Boring Stuff: Organizing Files](https://automatetheboringstuff.com/2e/chapter9/)

Let's help each other grow. Happy coding! üåü",6,0,2025-11-17 01:00:30,AutoModerator,https://www.reddit.com/r/Python/comments/1oz1c67/monday_daily_thread_project_ideas/
1oz4x0f,reddit,Ultra-strict Python template v2 (uv + ruff + basedpyright),"Some time ago I shared a strict Python project setup. I‚Äôve since reworked and simplified it, and this is the **new version**.

> **pystrict-strict-python** ‚Äì an ultra-strict Python project template using `uv`, `ruff`, and `basedpyright`, inspired by TypeScript‚Äôs `--strict` mode.

Compared to my previous post, this version:

- focuses on a single **pyproject.toml** as the source of truth,
- switches to `basedpyright` with a clearer strict configuration,
- tightens the ruff rules and coverage settings,
- and is easier to drop into new or existing projects.

**What it gives you**

- **Strict static typing** with `basedpyright` (TS `--strict` style rules):
  - No implicit `Any`
  - Optional/`None` usage must be explicit
  - Unused imports / variables / functions are treated as errors
- **Aggressive linting & formatting** with `ruff`:
  - pycodestyle, pyflakes, isort
  - bugbear, security checks, performance, annotations, async, etc.
- **Testing & coverage**:
  - `pytest` + `coverage` with 80% coverage enforced by default
- **Task runner via `poethepoet`**:
  - `poe format` ‚Üí format + lint + type check
  - `poe check` ‚Üí lint + type check (no auto-fix)
  - `poe metrics` ‚Üí dead code + complexity + maintainability
  - `poe quality` ‚Üí full quality pipeline
- **Single-source config**: everything is in **pyproject.toml**

**Use cases**

- **New projects**:  
  Copy the **pyproject.toml**, adjust the `[project]` metadata, create `src/your_package` + `tests/`, and install with:

  ```bash
  uv venv
  .venv\Scripts\activate  # Windows
  # or: source .venv/bin/activate

  uv pip install -e "".[dev]""
  ```

  Then your daily loop is basically:

  ```bash
  uv run ruff format .
  uv run ruff check . --fix
  uv run basedpyright
  uv run pytest
  ```

- **Existing projects**:  
  You don‚Äôt have to go ‚Äúall in‚Äù on day 1. You can cherry-pick:
  - the `ruff` config,
  - the `basedpyright` config,
  - the pytest/coverage sections,
  - and the dev dependencies,
  
  and progressively tighten things as you fix issues.

**Why I built this v2**

The first version worked, but it was a bit heavier and less focused. In this iteration I wanted:

- a cleaner, copy-pastable template,
- stricter typing rules by default,
- better defaults for dead code, complexity, and coverage,
- and a straightforward workflow that feels natural to run locally and in CI.

**Repo**

üëâ [GitHub link here](https://github.com/Ranteck/PyStrict-strict-python)

If you saw my previous post and tried that setup, I‚Äôd love to hear how this version compares. Feedback very welcome:

- Rules that feel too strict or too lax?
- Basedpyright / ruff settings you‚Äôd tweak?
- Ideas for a ‚Äúgradual adoption‚Äù profile for large legacy codebases?",100,30,2025-11-17 03:46:14,Ranteck,https://www.reddit.com/r/Python/comments/1oz4x0f/ultrastrict_python_template_v2_uv_ruff/
1ozdi7j,reddit,Created a complete Python 3.14 reference with hands-on examples (GitHub repo included),"I wanted to share a comprehensive resource I created covering all 8 major features in Python 3.14, with working code examples and side-by-side comparisons against Python 3.12.

**What's covered:**

* Deferred evaluation of annotations - import performance impact
* Subinterpreters with isolated GIL - true parallelism benchmarks
* Template strings and comparison with F Strings
* Simplified except/except\* syntax
* Control flow in finally blocks
* Free-threads - No GIL
* Enhanced error messages - debugging improvements
* Zstandard compression support - performance vs gzip

**What makes this different:**

* Side-by-side code comparisons (3.12 vs 3.14)
* Performance benchmarks for each feature
* All code available in GitHub repo with working examples

**Format:** 55-minute video with timestamps for each feature

**GitHub Repository:** [https://github.com/devnomial/video1\_python\_314](https://github.com/devnomial/video1_python_314)

**Video:** [https://www.youtube.com/watch?v=odhTr5UdYNc](https://www.youtube.com/watch?v=odhTr5UdYNc)

I've been working with Python for 12+ years and wanted to create a single comprehensive resource since most existing content only covers 2-3 features.

Happy to answer questions about any of the features or implementation details. Would especially appreciate feedback or if I missed any important edge cases.",15,1,2025-11-17 12:07:55,devnomial,https://www.reddit.com/r/Python/comments/1ozdi7j/created_a_complete_python_314_reference_with/
1oz3zqn,reddit,best way to avoid getting rusty with Python?,"I don‚Äôt code in Python daily, more like off and on for side projects or quick scripts. But every time I come back, it takes me a sec to get back in the groove. What do y‚Äôall do to keep your Python skills fresh? Any favorite mini projects, sites, or habits that actually help?",25,18,2025-11-17 03:02:50,Enlitenkanin,https://www.reddit.com/r/Python/comments/1oz3zqn/best_way_to_avoid_getting_rusty_with_python/
1oz5grb,reddit,"I made a fast, structured PDF extractor for RAG","**This project was made by a student participating in Hack Club & Hack Club Midnight:**  
[https://midnight.hackclub.com](https://midnight.hackclub.com/) & [https://hackclub.com](https://hackclub.com/)

**What My Project Does**  
A PDF extractor in C using MuPDF that outputs **structured JSON with partial Markdown**. It captures page-level structure‚Äîblocks, geometry, font metrics, figures‚Äîbut does **not** automatically extract tables or full Markdown.

All metadata is preserved so you can fully **customize downstream processing**. This makes it especially powerful for **RAG pipelines**: the deterministic, detailed structure allows for **precise chunking, consistent embeddings, and reliable retrieval**, eliminating the guesswork that often comes with raw PDF parsing.

**Anecdote / Personal Use**  
I genuinely used this library in one of my own projects, and the difference was clear: the chunks I got were **way better structured**, which made retrieval more accurate‚Äîand as a result, the model outputs were significantly improved. It‚Äôs one thing to have a PDF parser, but seeing the downstream impact in actual RAG workflows really confirmed the value.

**Performance matters**: optimized for in-memory limits, streaming to disk, and minimal buffering. It‚Äôs **much lighter and faster than PyMuPDF**, which can be slow, memory-heavy, and drift-prone.

The Python layer is a **minimal ctypes wrapper** with a convenience function‚Äîuse the bundled library or build the C extractor yourself.

**Repo:** [https://github.com/intercepted16/pymupdf4llm-C](https://github.com/intercepted16/pymupdf4llm-C)

**Target Audience**  
PDF ingestion, RAG pipelines, document analysis‚Äîpractical and performant, though early testers may find edge cases.

**Comparison**  
This project **trades automatic features for speed, deterministic structure, and full metadata**, making JSON output **highly adaptable for LLM workflows**. You get **control over parsing, chunking, and formatting**, which is invaluable when you need **consistent and precise data for downstream processing**.",16,3,2025-11-17 04:12:13,absqroot,https://www.reddit.com/r/Python/comments/1oz5grb/i_made_a_fast_structured_pdf_extractor_for_rag/
1ozfam2,reddit,Vocalance: Hands Free Computing,"# What My Project Does:

I built a new¬†**voice-based**¬†[interface](https://www.vocalance.com) to let you control your computer hands-free! It's an accessibility software that doubles as a productivity app, with customizable hot keys, the ability to dictate into any application and lots of smart/predictive features.

Vocalance is **currently open for beta testing**. Follow the instructions in the [README of my GitHub repository](https://github.com/rick12000/vocalance) to set it up on your machine (in future there will be a dedicated installer so anyone can use the application).

If this is something you'd consider using, **super keen to get user feedback**, so for any questions or comments reach out to [vocalance.contact@gmail.com](mailto:vocalance.contact@gmail.com) or join the subreddit at [https://www.reddit.com/r/Vocalance/](https://www.reddit.com/r/Vocalance/)

# Target Audience:

**Primary:** Users who struggle with hand use (disabled users with RSI, amputations, rheumatoid arthritis, neurological disorders, etc.).

**Secondary:** Users who want to optimize their coding or work with hotkeys, but can't be bothered to remember 20 key bindings. Or users who want to dictate straight into any AI chat or text editor with ease. Productivity features are not the priority for now, but they will be in future.

I personally map all my VSCode or Cursor hot keys to voice commands and then use those to navigate, review, scroll + dictate to the AI agents to code almost hands free.

# How does it work?

Vocalance uses an event driven architecture to coordinate speech recognition, sound recognition, grid overlays, etc. in a decentralized way.

For more information on design and architecture refer to the technical documentation here: [https://vocalance.readthedocs.io/en/latest/developer/introduction.html](https://vocalance.readthedocs.io/en/latest/developer/introduction.html)

# Comparison:

Built in accessibility features in Windows or Mac are ok, but not great. They're very latent and functionality is limited.

Community developed options like Talon Voice and Utterly Voice are better, but:

1. **Neither is open source**. Vocalance is 100% open source and free.
2. They're not as intuitive or UI based and lack many QOL features I've added in Vocalance. For a full comparison refer to the comparison table on the Vocalance landing page: [https://www.vocalance.com/index.html#comparison](https://www.vocalance.com/index.html#comparison)

# Want to learn more?

* Vocalance website: [https://www.vocalance.com](https://www.vocalance.com)
* Demo: [https://www.youtube.com/watch?v=Dm8m\_ApuiVU](https://www.youtube.com/watch?v=Dm8m_ApuiVU)
* Technical documentation: [https://vocalance.readthedocs.io](https://vocalance.readthedocs.io)
* GitHub: [https://github.com/rick12000/vocalance](https://github.com/rick12000/vocalance)",2,0,2025-11-17 13:44:37,RickCodes1200,https://www.reddit.com/r/Python/comments/1ozfam2/vocalance_hands_free_computing/
1ozf67i,reddit,[Project] virtualshell - keep a long-lived PowerShell session inside Python,"Hey everyone,

I‚Äôve been working on a small side project called **virtualshell** and wanted to share it here in case it‚Äôs useful to anyone mixing Python and PowerShell.

Repo (source + docs): [https://github.com/Chamoswor/virtualshell](https://github.com/Chamoswor/virtualshell)

PyPI: [https://pypi.org/project/virtualshell/](https://pypi.org/project/virtualshell/)

# What My Project Does

In short: **virtualshell lets Python talk to a persistent PowerShell process**, instead of spawning a new one for every command.

* You `pip install virtualshell` and work with a `Shell` class from Python.
* Under the hood, a C++ backend manages a long-lived PowerShell process.
* State is preserved between calls (variables, functions, imported modules, env vars, etc.).
* It also has an optional **zero-copy shared-memory bridge** on Windows for moving large blobs/objects without re-serializing over stdout.

Very minimal example:

    from virtualshell import Shell
    
    with Shell(timeout_seconds=5, set_UTF8=True) as sh:
        result = sh.run(""Get-Date"")
        print(result.out.strip(), result.exit_code)
    
        # State is kept between calls:
        sh.run(""$global:counter++"")
        print(sh.run(""$counter"").out.strip())

From the Python side you mainly get:

* `Shell.run()` / `run_async()` / `script()` / `script_async()` \- run commands or scripts, sync or async
* Structured result objects: `out`, `err`, `exit_code`, `ok`, `duration_ms`
* Config options for which host to use (`pwsh` vs `powershell.exe`), working directory, env, etc.
* Zero-copy helpers for sending/receiving big byte buffers or serialized PowerShell objects (Windows only for now)

# Target Audience

This is **not** meant as a big ‚Äúframework‚Äù, more like a glue tool for a fairly specific niche:

* People using **Python as the main orchestrator**, but who still rely on PowerShell for:
   * existing scripts/modules
   * Windows automation tasks
   * Dev/ops tooling that is already PowerShell-centric
* Long-running services, data pipelines, or test harnesses that:
   * don‚Äôt want to pay the cost of starting a new PowerShell process each time
   * want to keep session state alive across many calls
* Windows users who occasionally need to move **large amounts of data** between PowerShell and Python and care about overhead.

At this stage I still consider it a **serious side project / early-stage library**: it‚Äôs usable, but I fully expect rough edges and would not claim it‚Äôs ‚Äúbattle-tested in production‚Äù yet.

# Comparison (How It Differs From Existing Alternatives)

There are already several ways to use PowerShell from Python, so this is just another take on the problem:

* **vs. plain** `subprocess` **calls**
   * With `subprocess.run(""pwsh ‚Ä¶"")` you pay process start-up cost and lose state after each call.
   * virtualshell keeps a **single long-lived process** and tracks commands, timing, and exit codes in a higher-level API.
* **vs. using PowerShell only / no Python**
   * If your main logic/tooling is in Python (data processing, web services, tests), this lets you call into PowerShell where it makes sense without switching your whole stack.
* **vs. other interop solutions (e.g., COM, pythonnet, remoting libraries, etc.)**
   * Those are great for deep integration or remoting scenarios.
   * My focus here is a **simple, local, script-friendly API**: `Shell.run()`, structured results, and an optional performance path (shared memory) when you need to move bigger payloads.

Performance-wise, the zero-copy path is mainly there to avoid serializing tens of MB through stdout/stderr. It‚Äôs still early, so I‚Äôm very interested in real-world benchmarks from other machines and setups.

If anyone has feedback on:

* parts of the API that feel un-Pythonic,
* missing use cases I haven‚Äôt thought about, or
* things that would make it safer/easier to adopt in real projects,

I‚Äôd really appreciate it.

Again, the source and docs are here: [https://github.com/Chamoswor/virtualshell](https://github.com/Chamoswor/virtualshell)",2,0,2025-11-17 13:38:39,Chamoswor,https://www.reddit.com/r/Python/comments/1ozf67i/project_virtualshell_keep_a_longlived_powershell/
1oyriug,reddit,MkSlides: easily turn Markdown files into beautiful slides using a workflow similar to MkDocs!,"What my project does:

[MkSlides](https://pypi.org/project/mkslides/) ([Demo](https://martenbe.github.io/mkslides), [GitHub](https://github.com/MartenBE/mkslides)) is a static site generator that's geared towards building slideshows. Slideshow source files are written in Markdown, and configured with a single YAML configuration file. The workflow and commands are heavily inspired by [MkDocs](https://pypi.org/project/mkdocs/) and [reveal-md](https://github.com/webpro/reveal-md).

Features:

* Build static HTML slideshow files from Markdown files.
   * Turn a single Markdown file into a HTML slideshow.
   * Turn a folder with Markdown files into a collection of HTML slideshows.
* Publish your slideshow(s) anywhere that static files can be served.
   * Locally.
   * On a web server.
   * Deploy through CI/CD with GitHub/GitLab (like this repo!).
* Preview your site as you work, thanks to [python-livereload](https://pypi.org/project/livereload/).
* Use custom favicons, CSS themes, templates, ... if desired.
* Support for emojis like :smile: :tada: :rocket: :sparkles: thanks to [emoji](https://github.com/carpedm20/emoji/).
* Depends heavily on integration/unit tests to prevent regressions.
* And more!

Example:

Youtube: [https://youtu.be/RdyRe3JZC7Q](https://youtu.be/RdyRe3JZC7Q)

Want more examples? An [example repo](https://github.com/HoGentTIN/hogent-markdown-slides) with [slides](https://hogenttin.github.io/hogent-markdown-slides/) demonstrating all possibilities ([Mermaid.js](https://mermaid.js.org/) and [PlantUML](https://plantuml.com/) support, multi-column slides, image resizing, ...) using Reveal.js with the [HOGENT](https://hogent.be/) theme can be found at [https://github.com/HoGentTIN/hogent-markdown-slides](https://github.com/HoGentTIN/hogent-markdown-slides) .

Target audience:

Teachers, speakers on conferences, programmers, anyone who wants to use slide presentations, ... .

Comparison with other tools:

This tool is a single command and easy to integrate in CI/CD pipelines. It only needs Python. The workflow is also similar to MkDocs, which makes it easy to combine the two in a single GitHub/GitLab repo.",43,12,2025-11-16 18:25:41,MartenBE,https://www.reddit.com/r/Python/comments/1oyriug/mkslides_easily_turn_markdown_files_into/
1ozbx8b,reddit,"I built MemLayer, a Python package that gives LLMs persistent long-term memory (open-source)","# What My Project Does

MemLayer is an open-source **Python package** that adds persistent, long-term memory to LLM-based applications.

LLMs are stateless. Every request starts from zero, which makes it hard to build assistants or agents that stay consistent over time.

MemLayer provides a lightweight memory layer that:

* captures key information from conversations
* stores it persistently using vector + graph memory
* retrieves relevant context automatically on future calls

The basic workflow:  
you send a message ‚Üí MemLayer stores what matters ‚Üí later, when you ask a related question, the model answers correctly because the memory layer retrieved the earlier information.

This all happens behind the scenes while you continue using your LLM client normally.

# Target Audience

MemLayer is intended for:

* Python developers building **LLM apps, assistants, or agents**
* Anyone who needs **long-term recall** or **session persistence**
* People who want memory but **don‚Äôt want to build vector retrieval pipelines**
* Researchers exploring memory architectures
* Small applications that want a simple, local, import-only solution

It‚Äôs lightweight, works offline, and doesn‚Äôt require any external services.

# Comparison With Existing Alternatives

Some frameworks include memory features (LangChain, LlamaIndex), but MemLayer differs:

* **Focused:** It does one thing, memory for LLMs, without forcing you into a broader framework.
* **Pure Python + open-source:** Simple codebase, no external services.
* **Structured memory:** Uses both vector search and optional graph memory.
* **Noise-aware:** Includes an optional ML-based ‚Äúis this worth saving?‚Äù gate to prevent memory bloat.
* **Infrastructure-free:** Runs locally, no servers or orchestration needed.

The goal is to drop a memory layer into your existing Python codebase without adopting an entire ecosystem.



If anyone has feedback or architectural suggestions, I‚Äôd love to hear it.

**GitHub:** [https://github.com/divagr18/memlayer](https://github.com/divagr18/memlayer)  
**PyPI:** `pip install memlayer`",0,0,2025-11-17 10:29:32,MoreMouseBites,https://www.reddit.com/r/Python/comments/1ozbx8b/i_built_memlayer_a_python_package_that_gives_llms/
1oz0auo,reddit,Hack Review - A PR Review tool for Hack Clubbers,"Hi,  
I recently made a Pull Request review tool like [code rabbit](https://www.coderabbit.ai/) but for [Hack Clubbers](http://hackclub.com).  
All the source code is [here](https://github.com/DragonSenseiGuy/hack-review), this is a project for [Midnight](http://midnight.hackclub.com), a hackathon.

**What My Project Does:** Reviews Pull Requests on Github  
**Target Audience:** Hack Clubbers  
**Comparison:** This is specifically for Hack Clubbers

The project uses a [free API for hack Clubbers](http://ai.hackclub.com). I have not yet made the app public as I probably need permission from Hack Club to make it public and need Slack Verification to verify that you are a hack clubber.

Any feedback is welcome, if it is big I would appreciate it if you made an [issue](https://github.com/DragonSenseiGuy/hack-review/issues) and left a comment here that you made an issue.",4,0,2025-11-17 00:14:06,Rare_Koala_6567,https://www.reddit.com/r/Python/comments/1oz0auo/hack_review_a_pr_review_tool_for_hack_clubbers/
1ozbkas,reddit,üì¶ mcp-cookie-cutter: Generate MCP Servers from OpenAPI/Swagger Specs,"Creating MCP servers usually requires setting up models, routing, authentication, and project structure manually. **mcp-cookie-cutter** provides a way to generate this scaffolding directly from an OpenAPI/Swagger specification.

**Features:**

* Generates **MCP** server projects (local STDIO or remote HTTP)
* Builds **Pydantic** models from API schemas
* Creates tool stubs for each endpoint
* Supports optional authentication modules
* Includes prompts, tests, Dockerfile, and structured layout

**Usage:**

    pip install mcp-cookie-cutter
    mcp-cookie-cutter

Automated mode:

    mcp-cookie-cutter --no-input project_name=""MyAPI"" \
      openapi_spec_path=""https://example.com/openapi.json""

**Links:**  
PyPI: [https://pypi.org/project/mcp-cookie-cutter/](https://pypi.org/project/mcp-cookie-cutter/)  
GitHub: [https://github.com/maheshmahadevan/mcp-cookie-cutter](https://github.com/maheshmahadevan/mcp-cookie-cutter)

Feedback is welcome.",0,0,2025-11-17 10:05:41,Agitated_Option_8555,https://www.reddit.com/r/Python/comments/1ozbkas/mcpcookiecutter_generate_mcp_servers_from/
1oyngqx,reddit,SmartRSS- A new was to consume RSS,"I recently built a RSS reader and parser using python for [Midnight](https://midnight.hackclub.com/) a hackathon from [Hack Club](http://hackclub.com) All the source code is [here](https://github.com/DragonSenseiGuy/smart-RSS)

**What My Project Does:** Parses RSS XML feed and shows it in a Hacker News Themed website.

**Target Audience:** People looking for an RSS reader, other than that it's a Project I made for [Midnight](http://Midnight.hackclub.com).

**Comparison:** It offers a fully customizable Reader which has Hacker News colors by default. The layout is also like HN

You can leave feedback if you want to so I can improve it.  
Upvotes are helpful, please upvote if you think this is a good project",12,10,2025-11-16 15:44:13,Rare_Koala_6567,https://www.reddit.com/r/Python/comments/1oyngqx/smartrss_a_new_was_to_consume_rss/
1oxypjo,reddit,I made a CLI tool that deletes half your files,"GitHub link: https://github.com/soldatov-ss/thanos


So I built a little Python CLI tool called ""thanos-cli"".
It does exactly what you think it does: it deletes half of the files in any directory you point it at.

",281,89,2025-11-15 19:15:10,Ok_Researcher_6962,https://www.reddit.com/r/Python/comments/1oxypjo/i_made_a_cli_tool_that_deletes_half_your_files/
1oz8942,reddit,How to integrate Rust into Django project properly?,"I'm looking at spinning up a new Django project at work and need some help architecting it so that Rust integration is considered from day one. It's pretty calculation heavy and correctness is important to us, so Rust is a big help with all its static analysis. Unfortunately our company is already running on a Django stack so I can't make a purely Rust-based project. That would require a whole new repo/microservice as it'd be entirely disconnected from the rest of our product. If I'm making a new app, what steps can I take to make sure Rust integration is easier as we need it? An idiomatic way to do something like keeping type definitions in Rust while having Django hook into them for proper migrations support would be great. All tips and advice are appreciated.  
Thanks",0,5,2025-11-17 06:37:31,auric_gremlin,https://www.reddit.com/r/Python/comments/1oz8942/how_to_integrate_rust_into_django_project_properly/
1oyezcq,reddit,Python list append time complexity ‚Äî unexpected discrete levels?,"I ran a small experiment to visualize the time it takes to append elements to a Python list and to detect when memory reallocations happen.

    import sys
    import time
    
    import pandas as pd
    from matplotlib import pyplot as plt
    import seaborn as sns
    
    n_iters = 10_000_000
    
    sizes = []
    times = []
    
    sizes_realloc = []
    times_realloc = []
    
    prev_cap = sys.getsizeof(sizes)
    
    for i in range(n_iters):
        t = time.perf_counter_ns()
        sizes.append(i)
        elapsed = time.perf_counter_ns() - t
        times.append(elapsed)
    
        cap = sys.getsizeof(sizes)
        if cap != prev_cap:
            sizes_realloc.append(i)
            times_realloc.append(elapsed)
            prev_cap = cap
    
    df = pd.DataFrame({'sizes': sizes, 'times': times})
    df['is_realloc'] = df.sizes.isin(sizes_realloc)
    
    f = plt.figure(figsize=(15, 10))
    
    # --- Plot 1: all non-realloc appends ---
    ax = f.add_subplot(211)
    sns.scatterplot(df.query('~is_realloc'), x='sizes', y='times', ax=ax)
    ax.set_yscale('log')
    ax.set_title(""Append times (non-reallocation events)"")
    ax.set_xlabel(""List size"")
    ax.set_ylabel(""Append time (ns)"")
    ax.grid()
    
    # --- Plot 2: only reallocation events ---
    ax = f.add_subplot(223)
    sns.scatterplot(df.query('is_realloc'), x='sizes', y='times', ax=ax)
    ax.set_title(""Append times during reallocation"")
    ax.set_xlabel(""List size"")
    ax.set_ylabel(""Append time (ns)"")
    ax.grid()
    
    # --- Plot 3: zoomed-in reallocations ---
    ax = f.add_subplot(224)
    sns.scatterplot(
        df[:1_000_000].query('is_realloc').query('times < 2000'),
        x='sizes', y='times', ax=ax
    )
    ax.set_title(""Reallocation events (zoomed, < 1M size, < 2000 ns)"")
    ax.set_xlabel(""List size"")
    ax.set_ylabel(""Append time (ns)"")
    ax.grid()
    
    plt.tight_layout()
    plt.show()

[Results](https://postimg.cc/64c7W6Xv)

# Questions

1. **Why do we see discrete ‚Äúlevels‚Äù in the append times instead of a flat constant-time distribution?** I expected noise, but not distinct horizontal bands.
2. **Why does the noticeable linear-time effect from memory reallocation appear only after \~2 million elements?** Is this due to the internal growth strategy (`list_resize`) or something else (e.g., allocator behavior, OS page faults)?
3. Why do we see this 500 000 ns peak around the 3-4K thousand elements? It is persistent and occurs every time I ran it.

I'm on macOS 15.6.1 24G90 arm64 with Apple M4 Pro.",11,3,2025-11-16 07:55:50,atercygnus123,https://www.reddit.com/r/Python/comments/1oyezcq/python_list_append_time_complexity_unexpected/
1oz5s47,reddit,Guys! Any suggestions on learning the GO language?,"I mostly work with Python, Django, Flask and a little bit of JavaScript and Typescript. Is it worth it to learn GO? Any project suggestions?",0,5,2025-11-17 04:27:31,Beginning-Scholar105,https://www.reddit.com/r/Python/comments/1oz5s47/guys_any_suggestions_on_learning_the_go_language/
1oxw0gf,reddit,Added python support for my VSCode extension to see your code on an infinite canvas,"I'm building a VSCode extension that helps with understanding your codebase, particularly at a higher level where you need to figure out complex relationships between multiple files and modules.

It helps you quickly get an overview of the area of the codebase you're interested in, and lets you see how files and folders relate to each other based on dependency.

Kinda like a dependency graph, but it's the actual code files as the nodes, so you can see the actual code, you can ctrl+click on tokens like functions and variables to see their dependencies throughout the codebase, you can see the diffs for the local changes, and much more.

Python support was the most requested feature so far and I just recently added it to the extension.

I'm not a python dev, so I'm still learning how the language works, and would love any feedback from actual python devs if this type of visualisation is useful for you or if something else would be better. I'm using it for JS and I think it's really useful to see relationships between imports/exports, function usage and be able to follow props being passed down multiple levels, or a complex non-linear flow between multiple files.

You can get it on the vscode marketplace by looking for 'code canvas app'.

Or get it from this link [https://marketplace.visualstudio.com/items?itemName=alex-c.code-canvas-app](https://marketplace.visualstudio.com/items?itemName=alex-c.code-canvas-app)

It uses VSCode's LSP for creating the edges between tokens so you need to have the python/pylance vscode extension installed as well.

For the imports/exports edges and symbol outlines in the files when zooming out it uses ast-grep, which was just added recently and I've had a lot of issues with it, especially getting it to work on windows, but I think it should be fine now. Let me know if you encounter any issues.",55,10,2025-11-15 17:29:15,Standard_Ant4378,https://www.reddit.com/r/Python/comments/1oxw0gf/added_python_support_for_my_vscode_extension_to/
1oz0jnb,reddit,Python create doc,"Give me some example how to create a documentation for python, feels like a prompt question, lol. Just btw I‚Äôm using notion but feels little bit sus too find keywords easily ",0,4,2025-11-17 00:24:17,No-Implement5982,https://www.reddit.com/r/Python/comments/1oz0jnb/python_create_doc/
1oy83pa,reddit,SmartRSS-RSS parser and Reader in Python,"I recently built a RSS reader and parser using python for [Midnight](https://midnight.hackclub.com/) a hackathon from [Hack Club](http://hackclub.com) All the source code is [here](https://github.com/DragonSenseiGuy/smart-RSS)

**What My Project Does:** Parses RSS XML feed and shows it in a Hacker News Themed website.

**Target Audience:** People looking for an RSS reader, other than that it's a Project I made for [Midnight](http://Midnight.hackclub.com).

**Comparison:** It offers a fully customizable Reader which has Hacker News colors by default. The layout is also like HN

You can leave feedback if you want to so I can improve it.",11,7,2025-11-16 01:54:31,Rare_Koala_6567,https://www.reddit.com/r/Python/comments/1oy83pa/smartrssrss_parser_and_reader_in_python/
1oxhjj7,reddit,"The great leap forward: Python 2.7 -> 3.12, Django 1.11 -> 5.2","Original post: [A Python 2.7 to 3.14 Conversion: Existential Angst](https://www.reddit.com/r/Python/comments/1ouihlq/a_python_27_to_314_conversion_existential_angst/)

I would like to thank everyone who gave great advice on doing this upgrade. In the event, it took me about seven hours, with no recourse to AI coding required. The Python 3 version hasn't been pushed into production yet, but I'd estimate it's probably 90% of the way there.

I decided to go for the big push, and I think that worked out. I did take the advice to not go all the way to 3.14. Once I am convinced everything is fully operational, I'll go to 3.13, but I'll hold off on 3.14 for a bit more package support.

Switching package management to `uv` helped, as did the small-but-surprisingly-good test suite.

In rough order, the main problems I encountered were:

* bytes and strings. Literals themselves were OK (the code was already all unicode\_literals), but things like hash functions that take bytes were a bit tedious.
* Django API changes. I have to say, love Django to death, but the project's tendency to make ""this looks better"" breaking changes is not my favorite part of it.
* Django bugs. Well, bug: the `atomic` decorator can swallow exceptions. I spent some time tracking down a bytes/string issue because the exception was just \`bad thing happened\` by the time it reached the surface.
* Packages. This was not as horrible as I thought it would be. There were a few packages that were obsolete and had to be replaced, and a few whose APIs were entirely different. Using `pipdeps` and `uv` to separate out requested packages vs dependencies was extremely helpful here.

Most of the changes could be done with global search and replaces.

Things that weren't a problem:

* Python language features. There were no real issues about the language itself that `futurize` didn't take care of (in fact, I had to pull out a few of the `list` casts that it dropped in).
* Standard library changes. Almost none. Very happy!

Weird stuff:

* The code has a lot of raw SQL queries, often with regexes. The stricter checking in Python 3 made a lot of noise about ""bad escape sequences."" Turning the query text to a raw string fixed that, so I guess that's the new idiom.
* There were some subtle changes to the way Django renders certain values in templates, and apparently some types' string conversions are now more like `repr`.

One more thing that helped:

* A lot of the problematic code (from a conversion point of view) was moribund, and was hanging around from when this system replaced its predecessor (which was written in PHP), and had a lot of really crufty stuff to convert the old data structures to Python ones. That could all just be dropped in the trash.

Thanks again for all the amazing advice! I am sure it would have taken 10x longer if I hadn't had the guidance.",305,51,2025-11-15 04:43:17,MisterHarvest,https://www.reddit.com/r/Python/comments/1oxhjj7/the_great_leap_forward_python_27_312_django_111_52/
1oyyd1d,reddit,is bro code python 12 hour video a good first to start at ?,exactly what the question is ? is that the  best spot to start at with python  ? i downloaded the things he said to download and now at chapter 2 realised i should ask here first if thats the best place you would reccomend to start at too if u just started ,0,9,2025-11-16 22:54:13,TacoBullet,https://www.reddit.com/r/Python/comments/1oyyd1d/is_bro_code_python_12_hour_video_a_good_first_to/
1oydb0t,reddit,Pycharm plugin for colorizing string prefixes,"I've made a plugin for Pycharm that lets you customize the color of the string prefixes (for example, the f in f""abc"").

The plugin has a page in Color Scheme, named Custom, and in it you can customize the color.

The name of the plugin is Python String Prefix Color, and you can get it from the marketplace: [https://plugins.jetbrains.com/plugin/29002-python-string-prefix-color](https://plugins.jetbrains.com/plugin/29002-python-string-prefix-color)

You can find the source of it in here:

[https://github.com/mtnjustme/Python-String-Prefix-Color/tree/main](https://github.com/mtnjustme/Python-String-Prefix-Color/tree/main)

Any feedback is appreciated.",1,5,2025-11-16 06:18:05,mtnjustme,https://www.reddit.com/r/Python/comments/1oydb0t/pycharm_plugin_for_colorizing_string_prefixes/
1ox9cct,reddit,Pydantic and the path to enlightenment,"*TLDR: Until recently, I did not know about pydantic. I started using it - it is great. Just dropping this here in case anyone else benefits :)*

I maintain a Python program called [*Spectre*](https://github.com/jcfitzpatrick12/spectre), a program for recording signals from supported software-defined radios. Users create configs describing what data to record, and the program uses those configs to do so. This wasn't simple off the bat - we wanted a solution with...

* Parameter safety (Individual parameters in the config have to make sense. For example,¬†`X`¬†must always be a non-negative integer, or \`Y\` must be one of some defined options).
* Relationship safety (Arbitrary relationships between parameters must hold. For example,¬†`X`¬†must be divisible by some other parameter,¬†`Y`).
* Flexibility (The system supports different radios with varying hardware constraints. How do we provide developers the means to impose arbitrary constraints in the configs under the same framework?).
* Uniformity (Ideally, we'd have a uniform API for users to create any config, and for developers to template them).
* Explicit (It should be clear where the configurable parameters are used within the program).
* Shared parameters, different defaults (Different radios share configurable parameters, but require different defaults. If I've got ten different configs, I don't want to maintain ten copies of the same parameter just to update one value!).
* Statically typed (Always a bonus!).

Initially, with some difficulty, I made a custom implementation which was servicable but cumbersome. Over the past year, I had a nagging feeling I was reinventing the wheel. I was correct.

I recently merged [a PR](https://github.com/jcfitzpatrick12/spectre-core/pull/62) which replaced my custom implementation with one which used pydantic. Enlightenment! It satisfied all the requirements:

* We now define a model which templates the config right next to where those configurable parameters are used in the program (see [here](https://github.com/jcfitzpatrick12/spectre-core/blob/main/src/spectre_core/flowgraphs/_signal_generator.py#L15-L51)).
* Arbitrary relationships between parameters are enforced in the same way for every config with the validator decorator pattern (see [here](https://github.com/jcfitzpatrick12/spectre-core/blob/main/src/spectre_core/models/_signal_generator.py#L14-L49)). 
* We can share pydantic fields between configs, and update the defaults as required using the annotated pattern (see [here](https://github.com/jcfitzpatrick12/spectre-core/blob/main/src/spectre_core/fields/_fields.py)).
* The same framework is used for templating all the configs in the program, and it's all statically typed!

Anyway, check out *Spectre* [on GitHub](https://github.com/jcfitzpatrick12/spectre) if you're interested.",112,25,2025-11-14 22:37:10,jcfitzpatrick12,https://www.reddit.com/r/Python/comments/1ox9cct/pydantic_and_the_path_to_enlightenment/
1oyhies,reddit,"I built a program that predicts League game outcomes from drafts with 56% accuracy, thoughts on what","I've built a program on python that uses all pro League of Legends games from 2020 to now to calculate which pro team has the better winning odds from the draft.

It uses factors like counter matchups, synergies, champion's strength levels each patch based on their winrate and how often they are picked or banned and some more stuff, and with hundreds of thousands of simulations on past years I've chosen the best ""settings"" (eg. how much does mid-lane matchups weigh in vs the rest) for optimal prediction based on drafts.

I've made a discord server called Draft Edge Beta to put theory into practice, and coded a bot to signal when there is a ""draft gap"", which means the ROI of betting on a certain team is positive. The bot tells you what team to bet on, how many units to bet and the breakeven odds (let's say from my program T1 has a 50% chance to win the game, T1's breakeven odds is 2.00, which means you should bet on T1 if the but is above 2).

Right now since the end of July after 240 games, we are up 30 units and have a 56.25% win rate on bets since July while only tracking about 75% of the games (I'm human lol), which syncs with the numbers from the simulations where we were making about 60 units per year.

I know I'm sitting on a lottery ticket because all the math adds up: I've been perfecting the program for a while now and running hundreds of thousands of simulations to assure that, now I'm just wondering what to do with it, which is why I came here.

I could make a website with data from pro games ressembling opgg, or I could also just launch Draft Edge as another subscription-based discord server for the upcoming season, but to do so I would have to make a better front-end and probably hire 1-2 people so we don't miss any games.

I'm also wondering how much people would be willing to pay per month with a 40% referall system on whop, and basically what you guys think of it.

Feel free to ask any question or give any thoughts, would be much appreciated

Here's the link to the discord (the beta):¬†[https://discord.gg/mnQ7DfXs](https://discord.gg/mnQ7DfXs)  
Here's the link to the twitter page:¬†[https://x.com/draftedgelol?s=11](https://x.com/draftedgelol?s=11)",0,3,2025-11-16 10:33:33,Top-Share-4511,https://www.reddit.com/r/Python/comments/1oyhies/i_built_a_program_that_predicts_league_game/
1oyaxe8,reddit,"Fresh to Python, Made a Basic Number Game","Made a basic number-guessing game that tells you how close you are to the random number, 1-100. Link to code: [https://github.com/decoder181/Number-Guessing-Game](https://github.com/decoder181/Number-Guessing-Game) tell me if it's half decent for starters!",0,12,2025-11-16 04:12:36,Bananasarecoolascrap,https://www.reddit.com/r/Python/comments/1oyaxe8/fresh_to_python_made_a_basic_number_game/
1oyf7ep,reddit,Transforming a pair of lists into a dictionary in Python,"For given input lists ""keys and ""values"", create a dictionary from two input lists #python #list #dictionary #cogianova #zip_function

https://youtu.be/uZVWVOJ1WSU",0,0,2025-11-16 08:09:09,CogIANova,https://www.reddit.com/r/Python/comments/1oyf7ep/transforming_a_pair_of_lists_into_a_dictionary_in/
1oxeb6l,reddit,Kroma: a powerful and simple module for terminal output in Python,"*Looking for some feedback on Kroma, my new Python module! Kroma (based on the word ""chroma"" meaning color) is a modern alternative to libraries like `colorama` and `rich`.*


# What My Project Does

Kroma is a lightweight and powerful library for terminal output in Python. It allows you to set colors, text formatting, and more with ease!

# Target Audience

- Developers wanting to add color to their Python projects' terminal output

# Links

PyPI: https://pypi.org/project/kroma/  
Docs: https://www.powerpcfan.xyz/docs/kroma/v2/  
GitHub: https://github.com/PowerPCFan/kroma  

# Comparison

***""So, why should I give Kroma a try?""***

Kroma has significant advantages over libraries like `colorama`, and Kroma even has features that the very popular and powerful module `rich` lacks, such as:

- Dynamic color manipulation
- Powerful gradient generation
- Built-in color palettes
- Global terminal color scheme management (via palettes)
- Simple, intuitive, lightweight, and focused API

...and more!


# Kroma Showcase

Here are some code snippets showcasing Kroma's features (these snippets‚Äîand more‚Äîcan be found on the docs):

## Complex Multi-Stop Gradients:

You can use Kroma to create complex gradients with multiple color stops.

```python
import kroma

print(kroma.gradient(
    ""This is a rainbow gradient across the text!"",
    stops=(
        kroma.HTMLColors.RED,
        kroma.HTMLColors.ORANGE, 
        kroma.HTMLColors.YELLOW,
        kroma.HTMLColors.GREEN,
        kroma.HTMLColors.BLUE,
        kroma.HTMLColors.PURPLE
    )
))
```

## True Color support + HTML color names

Kroma provides access to all of the standard HTML color names through the `HTMLColors` enum. You can use these named colors with the `style()` function to set foreground and background colors.

```python
import kroma

print(kroma.style(
    ""This is black text on a spring green background."",
    background=kroma.HTMLColors.SPRINGGREEN,
    foreground=kroma.HTMLColors.BLACK
))
```

### HEX Color Support

The `style()` function also accepts custom HEX color codes:

```python
import kroma

print(kroma.style(
    ""This is text with a custom background and foreground."",
    background=""#000094"",
    foreground=""#8CFF7F""
))
```

## Palettes

Kroma supports color palettes, such as Gruvbox, Solarized, and Bootstrap, which are perfect if you want a nice-looking terminal output without having to pick individual colors.

```python
import kroma

palette = kroma.palettes.Solarized  # or your preferred palette

# IMPORTANT: you must enable the palette to set the proper background and foreground colors.
palette.enable()

# with alias:
print(palette.debug(""This is a debug message in the Solarized palette""))
print(palette.error(""This is an error message in the Solarized palette""))

```

## Text Formatting

The `style()` function supports text formatting options:

```python
import kroma

# All formatting options combined
print(kroma.style(
    ""This is bold, italic, underlined, and strikethrough text."",
    bold=True,
    italic=True,
    underline=True,
    strikethrough=True
))

# Individual formatting options
print(kroma.style(""This is bold text."", bold=True))
print(kroma.style(""This is underlined text."", underline=True))
print(kroma.style(
    ""This is italic and strikethrough text."",
    italic=True,
    strikethrough=True
))
```

Check out my other examples on the Kroma docs.


Let me know what you think!  
\- PowerPCFan, Kroma Developer",14,5,2025-11-15 02:07:11,PowerPCFan,https://www.reddit.com/r/Python/comments/1oxeb6l/kroma_a_powerful_and_simple_module_for_terminal/
1oy1qrv,reddit,can 390 pages plain text book be 39MB,"I was just trying to download book on pandas which has approx 390 pages ,it a plain text book which was free to download in some chinese university website url,midway during downloading I realised the pdf file size is 39MB fearing for any unknown executables hidden in pdf I cancelled the download,can a 400 some pdf be 39MB ,can we hide any executable code in pdf",0,8,2025-11-15 21:16:33,couriouscosmic,https://www.reddit.com/r/Python/comments/1oy1qrv/can_390_pages_plain_text_book_be_39mb/
1oxnmeq,reddit,TS/Go --> Python,"So I have been familiar with Go & Typescript, Now the thing is in my new job I have to use python and am not profecient in it. It's not like I can't go general programming in python but rather the complete environment for developing robust applications. Any good resource, content creators to check out for understanding the environment?",0,17,2025-11-15 10:39:21,ThreadStarver,https://www.reddit.com/r/Python/comments/1oxnmeq/tsgo_python/
1oxcssf,reddit,Saturday Daily Thread: Resource Request and Sharing! Daily Thread,"# Weekly Thread: Resource Request and Sharing üìö

Stumbled upon a useful Python resource? Or are you looking for a guide on a specific topic? Welcome to the Resource Request and Sharing thread!

## How it Works:

1. **Request**: Can't find a resource on a particular topic? Ask here!
2. **Share**: Found something useful? Share it with the community.
3. **Review**: Give or get opinions on Python resources you've used.

## Guidelines:

* Please include the type of resource (e.g., book, video, article) and the topic.
* Always be respectful when reviewing someone else's shared resource.

## Example Shares:

1. **Book**: [""Fluent Python""](https://www.amazon.com/Fluent-Python-Concise-Effective-Programming/dp/1491946008) \- Great for understanding Pythonic idioms.
2. **Video**: [Python Data Structures](https://www.youtube.com/watch?v=pkYVOmU3MgA) \- Excellent overview of Python's built-in data structures.
3. **Article**: [Understanding Python Decorators](https://realpython.com/primer-on-python-decorators/) \- A deep dive into decorators.

## Example Requests:

1. **Looking for**: Video tutorials on web scraping with Python.
2. **Need**: Book recommendations for Python machine learning.

Share the knowledge, enrich the community. Happy learning! üåü",5,0,2025-11-15 01:00:37,AutoModerator,https://www.reddit.com/r/Python/comments/1oxcssf/saturday_daily_thread_resource_request_and/
1oxbf12,reddit,"pixmatch: VisiPics didn't have features I wanted, so I re-wrote it in Python and added them!","[Source](https://github.com/rheard/pixmatch)¬†and [PyPI ](https://pypi.org/project/pixmatch/)(includes screenshot)

# What My Project Does

PixMatch is a modern, cross-platform duplicate-image finder inspired by VisiPics, built with PySide6.

PixMatch scans folders (and ZIP archives) for visually similar images, groups matches, and lets you quickly keep, ignore, move, or delete files from a clean GUI. Rotated, mirrored or recompressed imgaes are no match for PixMatch! PixMatch can even detect visually similar GIFs and animated WebP files. Files inside ZIPs are treated as read-only ‚Äúsources of truth‚Äù ‚Äînever deleted‚Äîso you can safely compare against archived libraries.

# Comparison

Features pixmatch has that VisiPics does not:

* Namely ZIP support
* Better support for rotations and mirrorings
* Proper GIF and webp support
* Better selection controls

# Usage

PixMatch is a standard Python app (GUI via PySide6).

Install:¬†`python -m pip install pixmatch[gui]`

Running:¬†`python -m pixmatch`

# Target Audience

Anyone with duplicate images!

This is my first public project release, let me know if there are any issues or feedback!",1,0,2025-11-15 00:00:40,CraigChrist8239,https://www.reddit.com/r/Python/comments/1oxbf12/pixmatch_visipics_didnt_have_features_i_wanted_so/
1oxhljr,reddit,Python Editor I Developed,"**This a text editor aimed at coders,**

**specifically Python coders.**

**It can check for syntax errors using Ruff and Pyright.**

**It can run your scripts in a terminal.**

**It can compare 2 different scripts and highlight differences.**

**It can sort of handle encoding issues.**

**Note: Don't use wordwrap when coding.**

**You need PyQt6 and Ruff and Pyright. Also any dependencies for scripts you wish to run in the console.**

[Editor of Death](https://github.com/maggotspawn/Network-Tools/blob/Python-Editor/editor_of_death_win..py)",0,19,2025-11-15 04:46:09,Ok-Paramedic-6169,https://www.reddit.com/r/Python/comments/1oxhljr/python_editor_i_developed/
1owedv4,reddit,Accounting + Python,"Any accounts here use Python to successfully help/automate their jobs? If so how?

My next question is: do you have to install and IDE on your work computer to have it work? If so, what are the use cases I can sell to my boss to let me install?",27,52,2025-11-13 22:59:54,Cool-Business-2393,https://www.reddit.com/r/Python/comments/1owedv4/accounting_python/
1ow4shz,reddit,Keecas: Dict-based symbolic math for Jupyter with units support and automatic LaTeX rendering,"As a structural engineer I always aimed to reduce the friction between doing the calculation and writing the report. I've been taught symbolic math with units, but the field is dominated by Word and Excel, neither of which is a good fit. Thanks to Quarto I've been able to break the shackle of Office and write reproducible documents (BONUS: plain text is a *bliss*).

# What My Project Does

Keecas is a Python package for symbolic and units-aware calculations in Jupyter notebooks, specifically designed for Quarto-rendered documents (PDF/HTML). It minimizes boilerplate by using Python **dicts** and **dict comprehension** as main equations containers: keys represent left-hand side symbols, values represent right-hand side expressions.

The package combines SymPy (symbolic math), Pint (units), and functional programming patterns to provide automatic LaTeX rendering with equation numbering, unit conversion, and cross-referencing.

# Target Audience

* **Engineers** writing calculation reports and technical documentation
* **Scientists** creating reproducible notebooks with units
* **Academics** preparing papers with mathematical content (likely not mathematicians though, those pesky folk have no use for units; or numbers)
* **Anyone** using Jupyter + Quarto for technical documents requiring LaTeX output

>NOTE: while `keecas` includes features aimed at Quarto, it can be used just as easily with Jupyter notebooks alone.

`keecas` is available on [PyPI](https://pypi.org/project/keecas/), with tests, CI, and full [API documentation](https://kompre.github.io/keecas/), generated with Quarto and [quartodoc](https://github.com/machow/quartodoc).

# Comparison

**vs. SymPy (alone):** Keecas wraps SymPy with dict-based containers and automatic formatting. Less boilerplate for repeated calculation patterns in notebooks.

**vs. handcalcs:** handcalcs converts Python code to LaTeX with jupyter magic. Keecas just uses Python to write symbolic sympy expressions with unit support and is built specifically for the Jupyter + Quarto workflow.

**vs. Manual LaTeX:** Eliminates manual equation writing. Calculations are executable Python code that generates LaTeX automatically (`amsmath`).

**Quick example:**

    from keecas import symbols, u, pc, show_eqn, generate_unique_label
    
    # Define symbols with LaTeX notation
    F_d, A_load, sigma = symbols(r""F_{d}, A_{load}, \sigma"")
    
    # Parameters with units
    _p = {
        F_d: 10 * u.kN,
        A_load: 50 * u.cm**2,
    }
    
    # Expressions
    _e = {
        sigma: ""F_d / A_load"" | pc.parse_expr
    }
    
    # Evaluate
    _v = {
        k: v | pc.subs(_e | _p) | pc.convert_to([u.MPa]) | pc.N
        for k, v in _e.items()
    }
    
    # Description
    _d = {
        F_d: ""design force"",
        A_load: ""loaded area"",
        sigma: ""normal stress"",
    }
    
    # Label (Quarto only)
    _l = generate_unique_label(_d)
    
    # Display
    show_eqn(
        [_p | _e, _v, _d],  # list of dict as main input
        label=_l  # a dict of labels (key matching)
    )

This generates an IPython LaTeX object with properly formatted LaTeX equations with automatic numbering (`amsmath`), cross-references, and unit conversion.

**Generated LaTeX output:**

    \begin{align}
        F_{d} & = 10{\,}\text{kN} &   & \quad\text{design force}  \label{eq-1kv2lsa6}  \\[8pt]
        A_{load} & = 50{\,}\text{cm}^{2} &   & \quad\text{loaded area}  \label{eq-1qnugots}  \\[8pt]
        \sigma & = \dfrac{F_{d}}{A_{load}} & = 2.0{\,}\text{MPa} & \quad\text{normal stress}  \label{eq-27myzkyp}
    \end{align}

# Try it for yourself

If you have `uv` (or `pipx`) already in your system, give it a quick try by running:

    uvx keecas edit --temp --template quickstart

`keecas` will spawn a temporary JupyterLab session with the `quickstart` template loaded.

# Examples

Want to see more? Check out:

* [**hello\_world.ipynb**](https://github.com/kompre/keecas/blob/main/examples/hello_world.ipynb)
* [**full quarto example (folder with source ipynb file and different output)**](https://github.com/kompre/keecas/tree/main/examples/quarto_example)

# Links

* **Documentation:** [https://kompre.github.io/keecas/](https://kompre.github.io/keecas/)
* **Source Code:** [https://github.com/kompre/keecas](https://github.com/kompre/keecas)
* **PyPI:** [https://pypi.org/project/keecas/](https://pypi.org/project/keecas/)

# Feedback

Feedback is welcome! I've been using earlier versions professionally for over a year, but it's been tested within a somewhat limited scope of structural engineering. New blood would be welcome!",21,6,2025-11-13 16:58:20,komprexior,https://www.reddit.com/r/Python/comments/1ow4shz/keecas_dictbased_symbolic_math_for_jupyter_with/
1ox19lr,reddit,What is the best way for you to learn how to use Python?,"Personally, studying at university, I see that the lessons, despite the explanations, are too ""rhetorical"" and as much as I understand certain things it is difficult for me to apply them, however when I see and do the exercises or go online for checks I find myself much better and it is stimulating.",0,17,2025-11-14 17:32:00,HyenaTricky9315,https://www.reddit.com/r/Python/comments/1ox19lr/what_is_the_best_way_for_you_to_learn_how_to_use/
1ox8yr9,reddit,New Pytest Language Server üî•,"So I just built [pytest-language-server](https://github.com/bellini666/pytest-language-server) \- a blazingly fast LSP implementation for pytest, written in Rust. And by ""built"" I mean I literally vibed it into existence in a single AI-assisted coding session. No template. No boilerplate. Just pure vibes. ü§ñ‚ú®

**Why?** As a Neovim user, I've wanted a way to jump to pytest fixture definitions for *years*. You know that feeling when you see ‚Å†def test\_something(my\_fixture): and you're like ""where the hell is this fixture defined?"" But I never found the time to actually build something.

So I thought... what if I just try to vibe it? Worst case, I waste an afternoon. Best case, I get my fixture navigation.

Turns out it worked *way* better than I was expecting.

**What it does:**

* üéØ **Go to Definition** \- Jump directly to fixture definitions from anywhere they're used
* üîç **Find References** \- Find all usages of a fixture across your entire test suite
* üìö **Hover Documentation** \- View fixture information on hover
* ‚ö°Ô∏è **Blazingly fast** \- Built with Rust for maximum performance

**The best part?** It properly handles pytest's fixture shadowing rules, automatically discovers fixtures from popular plugins (pytest-django, pytest-asyncio, etc.), and works with your virtual environments out of the box.

**Installation:**

\# PyPI (easiest)

uv tool install pytest-language-server

\# Homebrew

brew install bellini666/tap/pytest-language-server

\# Cargo

cargo install pytest-language-server



Works with Neovim, Zed, VS Code, or any editor with LSP support.

This whole thing was an experiment in AI-assisted development. The entire LSP implementation, CI/CD, security audits, Homebrew formula - all vibed into reality. Even this Reddit post was written by AI because why stop the vibe train now? üöÇ

Check it out and let me know what you think! MIT licensed and ready to use.

**GitHub:** [https://github.com/bellini666/pytest-language-server](https://github.com/bellini666/pytest-language-server)",0,3,2025-11-14 22:22:13,hackedbellini,https://www.reddit.com/r/Python/comments/1ox8yr9/new_pytest_language_server/
1ow6mtj,reddit,Finqual: analyze stock data and comps with a Python package + web app built entirely in Python,"Hey everyone,

I‚Äôm excited to share a project I‚Äôve been working on: a combination of a **Python package (`finqual`)** and an **interactive web app built entirely in Python using [Reflex](https://reflex.dev)** for financial analysis.

---

# What My Project Does

**Finqual** is designed to simplify fundamental equity analysis by making it easy to retrieve, normalize, and analyze financial statements.  

Key features include:

- Pull **income statements, balance sheets, and cash flow data** directly from SEC filings  
- Provide **annual and quarterly financials** for most U.S. companies  
- Compute **liquidity, profitability, and valuation ratios** in one line of code  
- Retrieve **comparable companies** based on SIC codes  
- Offer **fast API calls** (up to 10 req/sec) with **no rate limits**  
- Interactive web app lets users search tickers, view financials and ratios, compare companies, and see AI-generated news summaries ‚Äî all without writing code  

**Install:**  
`pip install finqual`

**PyPI:** [https://pypi.org/project/finqual/](https://pypi.org/project/finqual/)  
**GitHub:** [https://github.com/harryy-he/finqual](https://github.com/harryy-he/finqual)  
**Live Web App:** [https://app-lime-apple.reflex.run/](https://app-lime-apple.reflex.run/)

---

# Target Audience

This project is aimed at:

- **Python developers** who want programmatic access to company financials for research or analysis  
- **Finance professionals** and enthusiasts who want quick access to financial statements and key metrics without coding  
- Anyone who wants to explore company data interactively without opening an IDE or dealing with API restrictions  

It‚Äôs suitable for production analysis, research, learning, and prototyping ‚Äî though the data may occasionally be imperfect due to SEC taxonomy inconsistencies.

---

# Comparison

Most free financial APIs have **rate limits** or inconsistent data formats across companies.  

- **SEC EDGAR** provides raw data but requires handling different taxonomies for each company, which is cumbersome  
- **Other free Python packages** often have restrictions or limited coverage  

**Finqual differs by:**

- Normalizing line items across companies to allow consistent ratio calculation  
- Removing API call restrictions ‚Äî you can fetch data freely  
- Providing both a **Python package** and a **fully Python-built web app** for instant exploration  

---

# Why I Built This

I wanted to perform fundamental analysis without dealing with API limits or inconsistent SEC taxonomies.  

The **Python package** allows programmatic access for developers and analysts, while the **Reflex web app** makes it easy for anyone to quickly explore financials and ratios without writing code. Everything, including the frontend, is written entirely in Python.

---

# Open to Collaboration

It‚Äôs still evolving ‚Äî especially the taxonomy logic and UI.  
Feedback, suggestions, or contributions are very welcome ‚Äî feel free to open an issue or reach out via GitHub.

---

# Disclaimer

Some values may not perfectly match official filings due to taxonomy inconsistencies. I‚Äôve done my best to normalize this across companies, but refinements are ongoing.

---

**TL;DR**

- `finqual`: Python library for financial statement + ratio analysis  
- Web app: Built entirely in Python with Reflex ‚Äî no JavaScript required  
- Goal: Simplify equity research and comparable company analysis ‚Äî no API limits, no setup hassle
",7,1,2025-11-13 18:07:15,Myztika,https://www.reddit.com/r/Python/comments/1ow6mtj/finqual_analyze_stock_data_and_comps_with_a/
1ovw9rd,reddit,"PyOctoMap, Sparse Octrees 3D mapping in Python using OctoMap","Hello r/Python,

I built **pyoctomap** to simplify 3D occupancy mapping in Python by wrapping the popular C++ OctoMap library.

# What My Project Does

**pyoctomap** provides a ""Pythonic"" API for OctoMap, allowing you to create, update, and query 3D probabilistic maps.

* **NumPy-friendly:** Integrates directly with NumPy arrays for point clouds and queries.
* **Vectorized:** Supports fast, vectorized operations (e.g., checking occupancy for many points at once).
* **Easy Install:** `pip install pyoctomap` (pre-built wheels for Linux/WSL).
* Beta ROS support.

# Target Audience

This library is for **robotics/3D perception researchers and engineers** who want to use OctoMap's capabilities within a standard Python (NumPy/SciPy/Torch/Open3D) environment.

# Comparison

The main alternative is building your own `pybind11` or `ctypes` wrapper, which is complex and time-consuming.

The project is open-source, and I'm sharing it here to get technical feedback and answer any questions.

**GitHub Repo:** [`https://github.com/Spinkoo/pyoctomap`](https://github.com/Spinkoo/pyoctomap)",19,0,2025-11-13 09:58:04,Spinkoo,https://www.reddit.com/r/Python/comments/1ovw9rd/pyoctomap_sparse_octrees_3d_mapping_in_python/
1owhaba,reddit,Friday Daily Thread: r/Python Meta and Free-Talk Fridays,"# Weekly Thread: Meta Discussions and Free Talk Friday üéôÔ∏è

Welcome to Free Talk Friday on /r/Python! This is the place to discuss the r/Python community (meta discussions), Python news, projects, or anything else Python-related!

## How it Works:

1. **Open Mic**: Share your thoughts, questions, or anything you'd like related to Python or the community.
2. **Community Pulse**: Discuss what you feel is working well or what could be improved in the /r/python community.
3. **News & Updates**: Keep up-to-date with the latest in Python and share any news you find interesting.

## Guidelines:

* All topics should be related to Python or the /r/python community.
* Be respectful and follow Reddit's [Code of Conduct](https://www.redditinc.com/policies/content-policy).

## Example Topics:

1. **New Python Release**: What do you think about the new features in Python 3.11?
2. **Community Events**: Any Python meetups or webinars coming up?
3. **Learning Resources**: Found a great Python tutorial? Share it here!
4. **Job Market**: How has Python impacted your career?
5. **Hot Takes**: Got a controversial Python opinion? Let's hear it!
6. **Community Ideas**: Something you'd like to see us do? tell us.

Let's keep the conversation going. Happy discussing! üåü",1,0,2025-11-14 01:00:50,AutoModerator,https://www.reddit.com/r/Python/comments/1owhaba/friday_daily_thread_rpython_meta_and_freetalk/
1owtcai,reddit,Python projects,"Can anyone suggest some cool Python projects that involve APIs, automation, or data analysis? I want something practical that I can add to my portfolio.",0,10,2025-11-14 11:51:17,Ok_Zebra_927,https://www.reddit.com/r/Python/comments/1owtcai/python_projects/
1ovivvs,reddit,MyPy vs Pyright,"What's the preferred tool in industry? 

For the whole workflow: IDE, precommit, CI/CD.

I searched and cannot find what's standard. I'm also working with unannotated libraries.",83,93,2025-11-12 22:58:24,LeCholax,https://www.reddit.com/r/Python/comments/1ovivvs/mypy_vs_pyright/
1owoqna,reddit,Whats the best IDE for python,"I still use vs code to code in python to this day, but after all this time coding i think vs code is' nt the way to go with. And now i search for a better alternative. ",0,49,2025-11-14 07:03:48,Acceptable_Nature563,https://www.reddit.com/r/Python/comments/1owoqna/whats_the_best_ide_for_python/
1owg12b,reddit,MCP Microsoft SQL Server Developed with Python!,"I released my first MCP.

It's a SQL Server MCP that can be integrated via Claude Code.

You can communicate with your database using natural language.

Check it out here, and if you like it, give it a star üåü

[https://github.com/lorenzouriel/mssql-mcp-python](https://github.com/lorenzouriel/mssql-mcp-python)",0,3,2025-11-14 00:06:49,Cylogus,https://www.reddit.com/r/Python/comments/1owg12b/mcp_microsoft_sql_server_developed_with_python/
1owb7f8,reddit,A1: Agent-to-Code JIT compiler for optimizing faster & safer AI,"Most all agent frameworks run a static while loop program. **Comparison** Agent compilers are different: each agent input results in an optimized program that can be as simple as a single tool call or as complex as a network router command script.

It's https://github.com/stanford-mast/a1 easy to install: just pip install a1-compiler and start compiling agents.

**What my project does** A1 presents an interface that makes optimization possible: every agent has tools and skills. Tools are dead simple to construct: e.g. just pass in an OpenAPI document for a REST API. Skills define how to use Python libraries.

The compiler can make a number of optimizations transparently:

Replace LLM calls with regex/code (while guaranteeing type-safety)

Replace extreme classification LLM queries with a fused embedding-model-language model pipeline.

Etc

**Target audience** If you build AI agents, check it out and let me know what you think :)

https://github.com/stanford-mast/a1",0,0,2025-11-13 20:57:17,calebwin,https://www.reddit.com/r/Python/comments/1owb7f8/a1_agenttocode_jit_compiler_for_optimizing_faster/
1owakdy,reddit,twitter client mcp server,"Hey since twitter doesnt provide mcp server for client, I created my own so anyone could connect Al to X.

Reading Tools
get_tweets - Retrieve the latest tweets from a specific user
get_profile - Access profile details of a user
search_tweets - Find tweets based on hashtags or keywords

Interaction Tools
like_tweet - Like or unlike a tweet
retweet - Retweet or undo retweet
post_tweet - Publish a new tweet, with optional media attachments

Timeline Tools
get_timeline - Fetch tweets from various timeline types
get_trends - Retrieve currently trending topics

User Management Tools
follow_user - Follow or unfollow another user

I would really appriciate you starring the [project](https://github.com/touchmeangel/twitter-mcp-server)",0,0,2025-11-13 20:32:59,touchmeangel,https://www.reddit.com/r/Python/comments/1owakdy/twitter_client_mcp_server/
1ow74i0,reddit,Qwerty Auto Player,I made this QWERTY auto player for games like roblox. [https://github.com/Coolythecoder/QWERTY\_Auto\_Player](https://github.com/Coolythecoder/QWERTY_Auto_Player),0,0,2025-11-13 18:25:41,Intrepid-Carpet-3005,https://www.reddit.com/r/Python/comments/1ow74i0/qwerty_auto_player/
1ovxy6l,reddit,TweetCapturePlus: Open Source Python-Based Tweet Capture,"**What My Project Does**

Easily take screenshots of¬†**tweets**,¬†**mentions**, and¬†**full threads**

**Target Audience**

Production Use

**Comparison**

* Take screenshots of long Tweets (that require scrolling to capture)
* Some settings are default now: overwrite, Dim mode, Capture full threads

**Download here:**

GitHub:¬†[abdallahheidar/tweetcaptureplus](https://github.com/abdallahheidar/tweetcaptureplus)

PyPI:¬†[tweetcaptureplus v0.3.4](https://pypi.org/project/tweetcaptureplus/)

",0,4,2025-11-13 11:46:13,AbdallahHeidar,https://www.reddit.com/r/Python/comments/1ovxy6l/tweetcaptureplus_open_source_pythonbased_tweet/
1ow7alr,reddit,Install a python library,How to install a python library (selenium/ matplotlib etc.)  in a computer if internet connection is not there ?. But I can download libraries from python.org and copy through pendrive. I could not find any setup files inside the python library downloaded. Can anyone teach how to do it ?,0,1,2025-11-13 18:31:51,friendtoearth,https://www.reddit.com/r/Python/comments/1ow7alr/install_a_python_library/
1ovlxtw,reddit,"Thursday Daily Thread: Python Careers, Courses, and Furthering Education!","# Weekly Thread: Professional Use, Jobs, and Education üè¢

Welcome to this week's discussion on Python in the professional world! This is your spot to talk about job hunting, career growth, and educational resources in Python. Please note, this thread is **not for recruitment**.

---

## How it Works:

1. **Career Talk**: Discuss using Python in your job, or the job market for Python roles.
2. **Education Q&A**: Ask or answer questions about Python courses, certifications, and educational resources.
3. **Workplace Chat**: Share your experiences, challenges, or success stories about using Python professionally.

---

## Guidelines:

- This thread is **not for recruitment**. For job postings, please see r/PythonJobs or the recruitment thread in the sidebar.
- Keep discussions relevant to Python in the professional and educational context.
  
---

## Example Topics:

1. **Career Paths**: What kinds of roles are out there for Python developers?
2. **Certifications**: Are Python certifications worth it?
3. **Course Recommendations**: Any good advanced Python courses to recommend?
4. **Workplace Tools**: What Python libraries are indispensable in your professional work?
5. **Interview Tips**: What types of Python questions are commonly asked in interviews?

---

Let's help each other grow in our careers and education. Happy discussing! üåü",3,0,2025-11-13 01:00:31,AutoModerator,https://www.reddit.com/r/Python/comments/1ovlxtw/thursday_daily_thread_python_careers_courses_and/
1ovc9mh,reddit,"""Slippery ZIPs and Sticky tar-pits"" from Python's Security Dev Seth Larson","The Python Software Foundation Security Developer-in-Residence, Seth Larson, published a new white paper with Alpha-Omega titled ""Slippery ZIPs and Sticky tar-pits: Security & Archives"" about work to remediate 10 vulnerabilities affecting common archive format implementations such as ZIP and tar for critical Python projects.

PDF link: https://alpha-omega.dev/wp-content/uploads/sites/22/2025/10/ao_wp_102725a.pdf

PSF Blog: https://pyfound.blogspot.com/2025/10/slippery-zips-and-sticky-tar-pits-security-and-archives-white-paper.html

Alpha-Omega.dev: https://alpha-omega.dev/blog/slippery-zips-and-sticky-tar-pits-security-and-archives-white-paper-by-seth-larson-python-software-foundation/",8,0,2025-11-12 18:56:32,AlSweigart,https://www.reddit.com/r/Python/comments/1ovc9mh/slippery_zips_and_sticky_tarpits_from_pythons/
1ouxq8q,reddit,"Simple Resume: Generate PDF, HTML, and LaTeX resumes from a simple YAML config file","Github: [https://github.com/athola/simple-resume](https://github.com/athola/simple-resume)

This is a solved problem but I figured I'd implement a resume generation tool with a bit more flexibility and customization available vs the makefile/shell options I found and the out-of-date python projects available in the same realm. It would be awesome to get some other users to check it out and provide critical feedback to improve the tool for the open source community to make simple and elegant resumes without having to pay for it through a resume generation site.

What My Project Does:

This is a CLI tool which allows for defining resume content in a single YAML file and then generating PDF, HTML, or LaTeX rendered resumes from it. The idea is to write the configuration once, then be able to render it in a variety of different iterations.

Target Audience:

Jobseekers, students, academia

Comparison:

pyresume generates latex, has not been updated in 8 years

resume-parser appears to be out of date as well, 5 years since most recent update

resume-markdown has been recently updated and closely matches the goals of this project; there are some differentiators between resume-markdown and this project from a ease of use perspective where the default CSS/HTML doesn't require much modification to output a nice looking resume out of the box. I'd like to support more default style themes to expand upon this.

Some key details:

It comes with a few templates and color schemes that you can customize.

For academic use, the LaTeX output gives you precise typesetting control.

There's a Python API if you want to generate resumes programmatically. It's designed to have a limited surface area to not expose inner workings, only the necessary structures as building blocks.

The codebase has over 90% test coverage and is fully type-hinted. I adhered to a functional core, imperative shell architecture.

Example YAML:

      template: resume_base
      full_name: Jane Doe
      job_title: Software Engineer
      email: jane@example.com
      config:
        color_scheme: ""Professional Blue""
    
      body:
        experience:
          - title: Senior Engineer
            company: TechCorp
            start: 2022
            end: Present
            description: |
              - Led microservices architecture serving 1M+ users
              - Improved performance by 40% through optimization

Generate:

      uv run simple-resume generate --format pdf --open",67,21,2025-11-12 07:20:24,uhgrippa,https://www.reddit.com/r/Python/comments/1ouxq8q/simple_resume_generate_pdf_html_and_latex_resumes/
1ovgdzp,reddit,Keylogger and Full stack API security scanner (FastAPI - React TS),"Showcasing these more so as learning resources since they're part of a larger GitHub repo where I'm building 60 cybersecurity projects for people to clone, learn from, or customize.

So far I've completed:

* **Keylogger** (Pure Python with pynput)
* **Full Stack API Security Scanner** (FastAPI backend + React TypeScript frontend & Nginx + Docker)

Both are fully functional but designed as templates you can study or clone and build upon. The code is commented and structured to be educational.

Let me know what you think of the implementations and if you have suggestions for improvements to make them better learning resources.

[https://github.com/CarterPerez-dev/Cybersecurity-Projects/tree/main/PROJECTS](https://github.com/CarterPerez-dev/Cybersecurity-Projects/tree/main/PROJECTS)",5,0,2025-11-12 21:24:54,Hopeful_Beat7161,https://www.reddit.com/r/Python/comments/1ovgdzp/keylogger_and_full_stack_api_security_scanner/
1ouihlq,reddit,A Python 2.7 to 3.14 conversion. Existential angst.,"A bit of very large technical debt has just reached its balloon payment.

An absolutely 100% mission-critical, it's-where-the-money-comes-in Django backend is still on Python 2.7, and that's become unacceptable. It falls to me to convert it to running on Python 3.14 (along with the various package upgrades required).

At last count, it's about 32,000 lines of code.

I know much of what I must do, but I am looking for any suggestions to help make the process somewhat less painful. Anyone been through this kind of conversion have any interesting tips? (I know it's going to be painful, but the less the better.)

(For the results of the conversion, you can [see this post](https://www.reddit.com/r/Python/comments/1oxhjj7/the_great_leap_forward_python_27_312_django_111_52/).)",460,281,2025-11-11 20:12:18,MisterHarvest,https://www.reddit.com/r/Python/comments/1ouihlq/a_python_27_to_314_conversion_existential_angst/
1ovxuif,reddit,should I use AWS Lambda or a web framework like FASTAPI for my background job?,"I have a series of Python codes that process files (determining if they are images, videos, or PDFs), extract their contents, chunk the contents, embed them, and save them to a vector database. Now I am wondering if I should just deploy the pure Python function or wrap it around simple frameworks like FastAPI and deploy it.",0,13,2025-11-13 11:39:56,tolbou,https://www.reddit.com/r/Python/comments/1ovxuif/should_i_use_aws_lambda_or_a_web_framework_like/
1ouwa42,reddit,Webcam Rubik's Cube Solver GUI App [PySide6 / OpenGL / OpenCV],"# Background

This toy-project started as a self-challenge to see if I could build an application that uses the webcam and some foundational computer vision techniques to detect the state of a scrambled Rubik's cube and then show the solution steps to the user.

# Target Audience

As it is a toy-project it is mainly meant for casual use by those who are curious or it serves as an example project for students trying to learn computer vision and/or graphics programming.

# Comparison

I have seen a few projects on GitHub that implement a Rubik's cube facelet detection pipeline but they seem to fall short of actually solving the cube and show the solution to the user. I have also seen a few android solver apps but those don't seem to have a way to auto detect the state of the cube using your phone camera and you need to manually set the state.

# Installation and Usage

    git clone https://github.com/pdadhikary/rubiksolver.git
    
    cd rubiksolver
    
    uv sync
    
    uv run rubiksolver

When scanning their Rubik's cube the user should hold up each face of the cube to the webcam. By convention we assume that the white face is UP and the yellow face is DOWN. When scanning the white face, the red face is DOWN and it should be UP when scanning the yellow face.

Once the scan is complete press the `Play` button to animate the solution steps. You can also step through each of the moves using the `Previous` and `Next` buttons.

# Repository and Demo

A demo of the project can be [viewed on YouTube](https://www.youtube.com/watch?v=abj7ubu9g8o)

The code repository is [available on GitHub](https://github.com/pdadhikary/rubiksolver)

Any and all feedback are welcome! ",12,0,2025-11-12 05:59:54,Deepta_512,https://www.reddit.com/r/Python/comments/1ouwa42/webcam_rubiks_cube_solver_gui_app_pyside6_opengl/
1oumucr,reddit,How JAX makes high-performance economics accessible,Recent post on Google's open source blog has the story of how John Stachurski of  QuantEcon used JAX as part of their solution for the Central Bank of Chile and a computational bottleneck with one of their core models. [https://opensource.googleblog.com/2025/11/how-jax-makes-high-performance-economics-accessible.html](https://opensource.googleblog.com/2025/11/how-jax-makes-high-performance-economics-accessible.html),33,7,2025-11-11 22:56:27,darylducharme,https://www.reddit.com/r/Python/comments/1oumucr/how_jax_makes_highperformance_economics_accessible/
1ovay0m,reddit,I built a small project bookmarking CLI: recall,"What My Project Does: Recall-ingenious

Recall is a command line interface (CLI) tool for windows designed to bookmark project directories.

I have bunch of folder in my laptop and they are somewhat organized, and when I have to work on some project I just create a project in the directory that I am currently in not necessarily the directory where that project should be.

This was a problem cause if I have to work on it the next day or couple of days later I didn't know where I had saved it.

I had to then search through all the directory where I might've this directory so to solve this I have created a cli tool using python\[typer\] for windows¬†(***recall)***¬†that let's you save the directory along with project name and you can simply type the name of the project  and it will open the directory for you in the explorer.



GitHub: [https://github.com/ingenious452/recall/tree/main/recall](https://github.com/ingenious452/recall/tree/main/recall)

TestPyPI: ¬†[https://test.pypi.org/project/recall-ingenious/](https://test.pypi.org/project/recall-ingenious/)

please check the latest version



Recall can be used by developer and students who:

* Work on multiple small, disparate projects across various directories.
* Frequently use the Windows command line or integrated terminal (like in VS Code).
* Need a **fast, zero-setup** utility to quickly jump back into a project without digging through file structures.

I have been using this for about a year now and it's been really helpful for me personally, so I was thinking of improving it and publishing this to pypi

I would love to hears all of your suggestion :)",0,2,2025-11-12 18:09:15,PuzzleheadedSpace349,https://www.reddit.com/r/Python/comments/1ovay0m/i_built_a_small_project_bookmarking_cli_recall/
1ouv1l3,reddit,basic_colormath 1.1,"# What My Project Does

Everything I wanted to salvage from the (abandoned?) python-colormath library ... with no numpy dependency and 14x speed.

* Perceptual (DeltaE CIE 2000) and Euclidean distance between colors
* Conversion between RGB, HSV, HSL, Lab, and 8-bit hex colors
* Some convenience functions for RGB tuples and 8-bit hex color strings
* Vectorized functions for numpy arrays
* Proximity and cross-proximity (rectangular) matrices for numpy arrays

Version 1.1 adds (vectorized) Lab to RGB conversion, mostly for interest / exploratory purposes. Intentionally does not check for out-of-gamut values.

# Target Audience

Stable and appropriate for production.

# Comparison

* Quite a bit of overlap with [python-colormath](https://github.com/gtaylor/python-colormath/tree/master), but faster and with vectorized functions and (cross-)proximity matrices.
* Small overlap with `colorsys` in the Python standard library, with the addition of Lab conversion and distance.

# link to source

[https://github.com/ShayHill/basic\_colormath](https://github.com/ShayHill/basic_colormath)",10,3,2025-11-12 04:55:47,Shay-Hill,https://www.reddit.com/r/Python/comments/1ouv1l3/basic_colormath_11/
1oubbk3,reddit,Decorators are great!,"After a long, long time trying to wrap my head around decorators, I am using them more and more. I'm not suggesting I fully grasp metaprogramming in principle, but I'm really digging on decorators, and I'm finding them especially useful with UI callbacks.

I know a lot of folks don't like using decorators; for me, they've always been difficult to understand. Do you use decorators? If you understand how they work but don't, why not?",100,84,2025-11-11 15:48:21,Icy_Mulberry_3962,https://www.reddit.com/r/Python/comments/1oubbk3/decorators_are_great/
1our6fw,reddit,Can I create PDF infographics/reports using Python?,"I have a python script that does data scrapping and whatnot to output data into a CSV file. I'd love to know which packages I can use to printout professional graphics and charts and output the data into nice layouts to export it as a PDF on my computer. Any suggestions? I used ChatGPT and it used the basic Matplotlib, but I am wondering what is the best way I can go about creating something like this:

[https://cdn.venngage.com/template/thumbnail/small/f7c94e39-a01c-4bba-934c-52bd9330525a.webp](https://cdn.venngage.com/template/thumbnail/small/f7c94e39-a01c-4bba-934c-52bd9330525a.webp)



  


[https://cdn.venngage.com/template/thumbnail/small/f7c94e39-a01c-4bba-934c-52bd9330525a.webp](https://cdn.venngage.com/template/thumbnail/small/f7c94e39-a01c-4bba-934c-52bd9330525a.webp)",8,17,2025-11-12 01:56:29,Over-Half-8801,https://www.reddit.com/r/Python/comments/1our6fw/can_i_create_pdf_infographicsreports_using_python/
1ou5ry0,reddit,"New Python module: thermocouples, voltage-temperature conversion and Seebeck data","Hey everyone,

I recently released a Python module called thermocouples, designed to make working with thermocouple data straightforward in Python.

What it does:

* Convert temperature (¬∞C) to thermoelectric voltage (V)
* Convert voltage (V) to temperature (¬∞C)
* Get the Seebeck coefficient (¬µV/K) at any temperature
* Calculate dSeebeck/dT (nV/K¬≤) for advanced analysis
* Built-in method for reference junction temperature compensation
* Voltage calculations for positive and negative legs separately
* Seebeck coefficient calculations for positive and negative legs separately
* Based on NIST Monograph 175 polynomial coefficients
* Supports B, E, J, K, N, R, S, and T type thermocouples
* No external dependencies required

Check it out

PyPI: [thermocouples](https://pypi.org/project/thermocouples/?utm_source=chatgpt.com)

GitHub: [RogerGdot/thermocouples](https://github.com/RogerGdot/thermocouples)

Why I built it:

I work in a research/measurement environment and got tired of copy-pasting tables or reinventing conversion formulas. This module provides a clean, well-documented solution that‚Äôs ready to use in any project.

Cheers

RogerGdot",13,2,2025-11-11 11:12:21,Successful-Stomach12,https://www.reddit.com/r/Python/comments/1ou5ry0/new_python_module_thermocouples/
1otx8aa,reddit,"A collection of type-safe, async friendly, and unopinionated enhancements to SQLAlchemy Core","Project link: https://github.com/sayanarijit/sqla-fancy-core

## Why?

- ORMs are magical, but it's not always a feature. Sometimes, we crave for familiar.
- SQLAlchemy Core is powerful but `table.c.column` breaks static type checking and has runtime overhead. This library provides a better way to define tables while keeping all of SQLAlchemy's flexibility. See [Table Builder](https://github.com/sayanarijit/sqla-fancy-core#table-builder).
- The idea of sessions can feel too magical and opinionated. This library removes the magic and opinions and takes you to back to familiar transactions's territory, providing multiple un-opinionated APIs to deal with it. See [Wrappers](https://github.com/sayanarijit/sqla-fancy-core#fancy-engine-wrappers) and [Decorators](https://github.com/sayanarijit/sqla-fancy-core#decorators-inject-connect-transact).

## Demos:

- [FastAPI - sqla-fancy-core example app](https://github.com/sayanarijit/fastapi-sqla-fancy-core-example-app).

## Target audience

Production. For folks who prefer query maker over ORM, looking for a robust sync/async driver integration, wanting to keep code readable and secure.

## Comparison with other projects:

**Peewee**: No type hints. Also, no official async support.

**Piccolo**: Tight integration with drivers. Very opinionated. Not as flexible or mature as sqlalchemy core.

**Pypika**: Doesn‚Äôt prevent sql injection by default. Hence, can be considered insecure.",55,22,2025-11-11 03:07:29,codecratfer,https://www.reddit.com/r/Python/comments/1otx8aa/a_collection_of_typesafe_async_friendly_and/
1ou9cb7,reddit,pywinselect - Get Selected Files and Folders in Windows,"## What My Project Does

`pywinselect` returns the absolute paths of files and folders selected in Windows File Explorer or on the Desktop. If nothing is selected, it returns an empty list. It works across all File Explorer windows and the Desktop, using official Windows Shell COM APIs

## Target Audience

This library is designed for Python developers building Windows automation and productivity tools. It is production-ready and particularly useful for creating Stream Deck plugins, keyboard macro applications, custom context menu handlers, and batch processing utilities that need to operate on user-selected files.

## Comparison

Existing solutions for getting selected files in Windows typically involve clipboard manipulation (copying selections with Ctrl+C and parsing clipboard data) or writing extensive win32 API code manually. Clipboard-based approaches are unreliable, destructive to user workflows, and fail on the Desktop. Manual win32 implementations require 100+ lines of code, separate handling for File Explorer and Desktop, and complex debugging.

`pywinselect` provides a single-function interface

## Installation

```bash
pip install git+https://github.com/offerrall/pywinselect
```

## The Problem It Solves

When building automation scripts, you often need to know what the user has selected. Without this library, implementing this functionality requires writing over 100 lines of win32 API code, handling File Explorer and Desktop separately, managing clipboard backup and restore operations, and debugging platform-specific edge cases.

`pywinselect` reduces this complexity to a single function call.

## Practical Applications

This library is designed for developers building:

- Stream Deck automation scripts that operate on selected files
- Keyboard macro tools for repetitive file operations
- Custom context menu extensions
- Productivity applications requiring quick actions on user selections
- Batch processing tools that work with current selections

## Usage

```python
from pywinselect import get_selected

# Get all selected items
files = get_selected()
if files:
    print(f""Selected: {files[0]}"")

# Filter by type
only_files = get_selected(filter_type=""files"")
only_folders = get_selected(filter_type=""folders"")
```

## Technical Implementation

The library uses official Windows Shell COM APIs, specifically `IShellView` and `IDataObject` interfaces. These are the same interfaces that Windows Explorer uses internally for selection management.

**Safety guarantees:**

- Read-only operations - no system modifications
- No keyboard event simulation
- No clipboard interference
- No persistent system state changes

## Requirements

- Python 3.10 or higher
- Windows operating system
- pywin32 dependency

## Repository

Source code available at: https://github.com/offerrall/pywinselect

## License

Released under the MIT License.",4,3,2025-11-11 14:23:41,drboom9,https://www.reddit.com/r/Python/comments/1ou9cb7/pywinselect_get_selected_files_and_folders_in/
1otjuu4,reddit,I just published my first ever Python library on PyPI....,"After days of experimenting, and debugging, I‚Äôve officially released¬†numeth - a library focused on¬†core Numerical Methods¬†used in engineering and applied mathematics.

- ¬†What My Project Does

Numeth helps you quickly solve tough mathematical problems - like equations, integration, and differentiation - using accurate and efficient numerical methods.

 It covers essential methods like:

1. Root finding (Newton‚ÄìRaphson, Bisection, etc.)
2. Numerical integration and differentiation
3. Interpolation, optimization, and linear algebra

- ¬†Target Audience

I built this from scratch with a single goal:
Make fundamental numerical algorithms ready to use for students and developers alike.

- Comparison

Most Python libraries, like NumPy and SciPy, are designed to use numerical methods, not *understand* them. Their implementations are optimized in C or Fortran, which makes them incredibly fast but opaque to anyone trying to learn how these algorithms actually work.

'numeth' takes a completely different approach.  
It reimplements the core algorithms of numerical computing in pure, readable Python, structured into clear, modular functions.

The goal isn‚Äôt raw performance. It‚Äôs helping students, educators, and developers trace each computation step by step, experiment with the logic, and build a stronger mathematical intuition before diving into heavier frameworks.

If you‚Äôre into numerical computing or just curious to see what it‚Äôs about, you can check it out here:

üîó¬†https://pypi.org/project/numeth/

or run 'pip install numeth'

The GitHub link to numeth:

üîó¬†https://github.com/AbhisumatK/numeth-Numerical-Methods-Library

Would love feedback, ideas, or even bug reports.",152,36,2025-11-10 18:22:32,Prestigious_Bear5424,https://www.reddit.com/r/Python/comments/1otjuu4/i_just_published_my_first_ever_python_library_on/
1ouix5a,reddit,Making an Interpreter- Need Assistance,"I am planning in making a programming language called Pebble, and I made a discord server. Anyone can join, and are welcome to contribute to the GitHub page. My plan is this becomes a learning opportunity for everyone involved, including me.

  
[https://discord.gg/R38EY2J7e](https://discord.gg/R38EY2J7e)",0,1,2025-11-11 20:28:11,StrikingClub3866,https://www.reddit.com/r/Python/comments/1ouix5a/making_an_interpreter_need_assistance/
1outon5,reddit,Why is nobody doing this??,"Why does it seem like there‚Äôs still no straightforward, free way to view financial statements directly from SEC filings?

I‚Äôve been working on something myself at FreeFinancials.com, and the more I dig into XBRL data, the more surprised I am that nobody else is offering a clean, accessible solution. The SEC already makes all the structured data available ‚Äî it just needs to be parsed and presented clearly.

It makes me wonder: if the data is public and the process is manageable with the right approach, why hasn‚Äôt anyone else built a simple, free platform around it?",0,9,2025-11-12 03:50:43,Ok-Access5317,https://www.reddit.com/r/Python/comments/1outon5/why_is_nobody_doing_this/
1otmvti,reddit,My second Python video Game is released on Steam !,"Hi, am 18 and I am French developper coding in Python. Today, I have the pleasure to tell you that I am releasing a full made python Video Game that is available now on the Platform steam through the link : https://store.steampowered.com/app/4025860/Kesselgrad/ It was few years ago when I was 15 where I received all kind of Nice messages Coming from this Community to congrate me for my First Video Game. I have to thank Everyone who were here to support me to continue coding in Python Which I did until today. I would be thrilled to Talk with you directly in the comments or through my email : contact@kesselgrad.com",39,11,2025-11-10 20:10:43,krabott_le_crabe,https://www.reddit.com/r/Python/comments/1otmvti/my_second_python_video_game_is_released_on_steam/
1ouyetw,reddit,"I just inherited a repo with 150k lines.  It's absolutely infested with ""master"" and ""slave"".",Among many other issues.  Should I expend the effort (both in power capital and intellectual work) in removing these words?,0,82,2025-11-12 08:01:31,fistular,https://www.reddit.com/r/Python/comments/1ouyetw/i_just_inherited_a_repo_with_150k_lines_its/
1otwhaj,reddit,"Python for AEC (AutoCAD, Revit, Civil 3D) - Seeking knowledgeable individuals","  
Hello everyone!

I am interested in integrating Python and AEC software such as Revit, AutoCAD, Civil 3D, etc. 

If you have experience using Python in the AEC environment, I would like to connect with you and perhaps discuss this further. I am willing to compensate the right individual who has the proven knowledge. 

Look forward to hearing from you.

  
Chris





",6,2,2025-11-11 02:33:07,FreedomPlus8846,https://www.reddit.com/r/Python/comments/1otwhaj/python_for_aec_autocad_revit_civil_3d_seeking/
1ou66xa,reddit,Building a Python version of Spring Batch ‚Äî need opinions on Easier-Batch architecture,"Hey everyone,

I developed this small project on GitHub called [**Easier-Batch**](https://github.com/Daftyon/Easier-Batch?utm_source=chatgpt.com).  
It tries to bring the same philosophy as **Spring Batch** into Python ‚Äî using the familiar **Reader ‚Üí Processor ‚Üí Writer** model, job metadata tables, retries, skip logic, and checkpointing.

I‚Äôm currently designing something similar myself ‚Äî a **Python batch processing framework inspired by Spring Batch**, built to handle large-scale ETL and data jobs.

Before I go too far, I‚Äôd like to get some opinions on the **architecture** and design approach.

* Do you think this kind of structured batch framework makes sense in Python, or is it better to stick to existing tools like Airflow / Luigi / Prefect?
* How would you improve the design philosophy to make it more ""Pythonic"" while keeping the robustness of Spring Batch?
* Any suggestions for managing metadata, retries, and job states efficiently in a Python environment?

Here‚Äôs the repo again if you want to take a look:  
üëâ [https://github.com/Daftyon/Easier-Batch](https://github.com/Daftyon/Easier-Batch?utm_source=chatgpt.com)Would love to hear your thoughts, especially from people who have worked with both Spring Batch and Python ETL frameworks.  
",1,4,2025-11-11 11:37:28,Several-Revolution59,https://www.reddit.com/r/Python/comments/1ou66xa/building_a_python_version_of_spring_batch_need/
1otg5az,reddit,Looking for Best GUI reccomendation,"Just launched my first open-source [project](https://42zero.org/just-got-a-new-usb-mic-heres-how-to-test-it-live-without-the-hassle/) and im looking for GUI that fits my project

Any tips or ideas to improve it are welcome


about the project:

If you just got a new USB mic and want to test it live without the hassle, check out my Live Mic Audio Visualizer (Basic):

 - See your voice in real-time waveform
 - Hear it with instant reverb effects
 - Adjust Gain, Smoothing, Sample Rate, and Block Size ",25,28,2025-11-10 16:05:23,420_rottie,https://www.reddit.com/r/Python/comments/1otg5az/looking_for_best_gui_reccomendation/
1oue9x9,reddit,I made a number-guessing game‚Ä¶ but it lies to you.,"# What My Project Does

This project is a simple Python number-guessing game with an unusual twist: the program occasionally provides incorrect hints. Using weighted randomness, the game decides whether to tell the truth or intentionally mislead the player. The player has a fixed number of attempts to guess the secret number, making the game both unpredictable and challenging.

**Project link:**  
[https://github.com/itsleenzy/deceptive-guessing-game/tree/main](https://github.com/itsleenzy/deceptive-guessing-game/tree/main?utm_source=chatgpt.com)

# Target Audience

This is a small, non-production, beginner-friendly project intended for:

* learners who want to practice Python fundamentals
* anyone exploring randomness and probability weighting
* people experimenting with small toy projects It‚Äôs not meant for real-world deployment ‚Äî it‚Äôs mainly for learning and fun.

# Comparison

Most number-guessing games give accurate ‚Äúhigher‚Äù or ‚Äúlower‚Äù hints. This project is different because it introduces intentional misinformation through weighted probabilities. Instead of being a straightforward logic puzzle, it becomes a playful, unpredictable challenge where the hints cannot be fully trusted.",0,3,2025-11-11 17:40:01,leenzy-leen,https://www.reddit.com/r/Python/comments/1oue9x9/i_made_a_numberguessing_game_but_it_lies_to_you/
1oujmsk,reddit,"""–ü–æ–∫–æ–ª–µ–Ω–∏–µ Python"": –∫—É—Ä—Å –¥–ª—è –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª–æ–≤ —Å–ª–∏–≤","–ü—Ä–æ—à–µ–ª –±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ –∫—É—Ä—Å—ã ""–ü–æ–∫–æ–ª–µ–Ω–∏–µ Python"" , –æ—á–µ–Ω—å –ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å, –∑–∞–¥–∞—á–∏ –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–µ. –ö —Å–æ–∂–∞–ª–µ–Ω–∏—é –Ω–µ –∏–º–µ—é —Å—Ç–æ–ª—å–∫–æ –¥–µ–Ω–µ–≥, —á—Ç–æ –±—ã –∫—É–ø–∏—Ç—å –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ, –Ω–æ –æ—á–µ–Ω—å —Ö–æ—á—É –ø—Ä–æ–π—Ç–∏ —ç—Ç–æ—Ç –∫—É—Ä—Å. –ú–æ–∂–µ—Ç –∫—Ç–æ-—Ç–æ –ø–æ–º–æ—á—å –∏ —Å–∫–∏–Ω—É—Ç—å —Å–ª–∏–≤ —ç—Ç–æ–≥–æ –∫—É—Ä—Å–∞ –∏–ª–∏ —Å—Å—ã–ª–∫—É –Ω–∞ —Ä–µ—Å—É—Ä—Å –≥–¥–µ –º–æ–∂–Ω–æ –ø—Ä–∏–æ–±—Ä–µ—Å—Ç–∏ –¥–µ—à–µ–≤–ª–µ",0,0,2025-11-11 20:55:09,Simple_Building3088,https://www.reddit.com/r/Python/comments/1oujmsk/–ø–æ–∫–æ–ª–µ–Ω–∏–µ_python_–∫—É—Ä—Å_–¥–ª—è_–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª–æ–≤_—Å–ª–∏–≤/
1otrupf,reddit,"Feedback request: API Key library update (scopes, cache, env, library and docs online, diagram)","Hello,

A few weeks ago, I made a [feedback request](https://www.reddit.com/r/Python/comments/1o3s3yj/feedback_request_for_api_key_management_library) on my first version of a reusable API key system for FastAPI. It has evolved significantly since then, and I would like to have another round of comments before finalizing it.

**Project:** [https://github.com/Athroniaeth/fastapi-api-key](https://github.com/Athroniaeth/fastapi-api-key)  
**Docs:** [https://athroniaeth.github.io/fastapi-api-key/](https://athroniaeth.github.io/fastapi-api-key/)  
**PyPI:** [https://pypi.org/project/fastapi-api-key/](https://pypi.org/project/fastapi-api-key/)

**What‚Äôs new since the last post**

* **The documentation is now online** with quickstarts, guides and examples.
* **The package is now online**, previously, the project had to be installed locally, but this is no longer the case.
* **Scopes support** for fine-grained access control.
* **Caching layer** to speed up verification (remove Argon2 hashing) and reduce database load.
* **Environment-based config** If you just need to use an API key in your `.env` without worrying about persistence and API key management

For those interested, in the [README](https://github.com/Athroniaeth/fastapi-api-key/tree/main?tab=readme-ov-file#schema-validation) you will find a diagram representing the logic of API key verification (which is the most important section of code).

If you have already created/operated API key systems, I would greatly appreciate your opinion on security and user experience. Contributions are also welcome, even minor ones.

Thank you in advance.",5,0,2025-11-10 23:17:45,__secondary__,https://www.reddit.com/r/Python/comments/1otrupf/feedback_request_api_key_library_update_scopes/
1otue4f,reddit,Tuesday Daily Thread: Advanced questions,"# Weekly Wednesday Thread: Advanced Questions üêç

Dive deep into Python with our Advanced Questions thread! This space is reserved for questions about more advanced Python topics, frameworks, and best practices.

## How it Works:

1. **Ask Away**: Post your advanced Python questions here.
2. **Expert Insights**: Get answers from experienced developers.
3. **Resource Pool**: Share or discover tutorials, articles, and tips.

## Guidelines:

* This thread is for **advanced questions only**. Beginner questions are welcome in our [Daily Beginner Thread](#daily-beginner-thread-link) every Thursday.
* Questions that are not advanced may be removed and redirected to the appropriate thread.

## Recommended Resources:

* If you don't receive a response, consider exploring r/LearnPython or join the [Python Discord Server](https://discord.gg/python) for quicker assistance.

## Example Questions:

1. **How can you implement a custom memory allocator in Python?**
2. **What are the best practices for optimizing Cython code for heavy numerical computations?**
3. **How do you set up a multi-threaded architecture using Python's Global Interpreter Lock (GIL)?**
4. **Can you explain the intricacies of metaclasses and how they influence object-oriented design in Python?**
5. **How would you go about implementing a distributed task queue using Celery and RabbitMQ?**
6. **What are some advanced use-cases for Python's decorators?**
7. **How can you achieve real-time data streaming in Python with WebSockets?**
8. **What are the performance implications of using native Python data structures vs NumPy arrays for large-scale data?**
9. **Best practices for securing a Flask (or similar) REST API with OAuth 2.0?**
10. **What are the best practices for using Python in a microservices architecture? (..and more generally, should I even use microservices?)**

Let's deepen our Python knowledge together. Happy coding! üåü",2,1,2025-11-11 01:00:32,AutoModerator,https://www.reddit.com/r/Python/comments/1otue4f/tuesday_daily_thread_advanced_questions/
1ougmfu,reddit,For anyone with the skills,"I‚Äôll just get right into the thick of in, not need to dilly dally.

I‚Äôm looking to develop an educational platform for meme coins, perps, spot, lending, nfts, prediction markets‚Ä¶.. everything crypto.

The platform will encompass levels of education on all relevant sectors.

From the basics to fully functional signal and alert systems and technical analysis, blockchain development and defi applications.

Kyc, opsec, telegram functions the whole 9 yards..

I can‚Äôt achieve this alone, I need intellectual or if all els dedicated individuals with a passion for crypto and a genuine heart towards the betterment of the space as a whole.

My goal is to be a beacon of truth and clarity in the space apposed to the vulturous tendency crypto leads people.

It‚Äôs much needed in this space, the main focus as per my interest will be trading to start, tools bots, resources but my vision is that it will evolve into a larger thing encompassing all areas and interests crypto has to offer.

If you are interested in speaking about this or have skills in web 3 development or any other skills you feel might be valuable to the building of this idea please contact me.

https://x.com/inertia__tm?s=21",0,14,2025-11-11 19:05:20,Brief-Perception5682,https://www.reddit.com/r/Python/comments/1ougmfu/for_anyone_with_the_skills/
1oucxxq,reddit,From n8n to Python: How we scale a workflow 10x without limitationsÔªø‚ö†Ô∏è,"üö® I just finished some work on a project where the client tried  
automate a process with n8n.  
  
The problem?  
‚Ä¢ Complex integration between multiple systems  
‚Ä¢ Custom logic that n8n simply does not support  
‚Ä¢ Volume of data causing the tool to slow down  
  
[Make.com](http://Make.com) couldn't either. Zapier? Forget it.  
  
Result: 3 weeks of development in Python + FastAPI. Now the process  
It handles 10x what n8n could handle without limitations or slowdowns.  
  
The lesson? No-code tools are great for simple workflows.  
  
But when you need:  
‚úì Real integrations with complex systems  
‚úì Logic that goes beyond predefined blocks  
‚úì Performance and scale  
‚úì Specific cases of your business  
  
...You need code.  
  
ü§î Question: How many of you have run into limitations of  
no-code tools in your processes?  
  
What was the limit they found?  
  
Tell me in comments üëá",0,5,2025-11-11 16:50:58,AntonioJose-Dev,https://www.reddit.com/r/Python/comments/1oucxxq/from_n8n_to_python_how_we_scale_a_workflow_10x/
1ot86md,reddit,Python dependencies states managed via uv(illustrated),"A transition graph showing how to move from one deps state to another using \`uv\` commands.

at [https://valarmorghulis.io/tech/202511-python-dependencies-states-managed-via-uv/](https://valarmorghulis.io/tech/202511-python-dependencies-states-managed-via-uv/)",19,5,2025-11-10 09:09:03,socrateslee,https://www.reddit.com/r/Python/comments/1ot86md/python_dependencies_states_managed_via/
1ou3w26,reddit,Running a python app on a tablet or phone,"Hey there!  
I recently created a python app with a tkinter GUI, that can read outputs form the TCD1304 linear CCD, control exposure times and plot graphs. Since the CCD is part of a spectrometer which is mounted on a telescope it isn¬¥t always possible to hook it up to a computer for controlling it. Therefore I wanted to run the software on a mobile device which is connected to the spectrometer, either via a cable or via a hC-05 bluetooth module (Im not sure how i would power the stm32 then). Is there any way to do so, without much coding necessary. Note that I am not an expert by any means.   
The project can be found here: [https://github.com/iqnite/pyccd-spectrometer](https://github.com/iqnite/pyccd-spectrometer)",0,2,2025-11-11 09:10:33,NoFox1670,https://www.reddit.com/r/Python/comments/1ou3w26/running_a_python_app_on_a_tablet_or_phone/
1ost6e1,reddit,I wrote up a Python app and GUI for my mini thermal printer,"Hey everyone, it's Mel :) Long time reader, first time poster (I think)

I bought a mini thermal printer a few weeks back after spotting it at my local Walmart. I was hoping to use it out of the box with my PC to print shopping lists, to-do lists, notes and whatnot - no luck! So my friends and I got together and reverse-engineered the comms between the printer and our smartphones, wrote Python code to connect to and print from our PCs, and I made a GUI for the whole thing.

* **What My Project Does:** Lets computers connect to the CPT500 series of thermal printers by Core Innovation Products, and print text and images to the printer from the comfort of your desktop computer!
* **Target Audience:** Just a personal project for now, but I'm thinking of going back into the code when I have more time to really polish it and make it available more widely.
* **Comparison:** I couldn't really find anything that directly compares. There is a project out there that works for the same printer, but it's meant to be hosted on online server instances (mine is local). Other similar programs don't work for that printer, either.

You can find [the write-up for the whole project on my website](https://thirtythreedown.com/2025/11/02/pc-app-for-walmart-thermal-printer/). The Python app and some templates [are on GitHub for free](https://github.com/thirtythreedown/CTP500PrinterApp).

Enjoy!",55,3,2025-11-09 21:02:42,Bookmore,https://www.reddit.com/r/Python/comments/1ost6e1/i_wrote_up_a_python_app_and_gui_for_my_mini/
1osve44,reddit,"Selectively download videos, channels, playlists (YouTube and more)","[YT Channel Downloader 0.5.5](https://github.com/hyperfield/yt-channel-downloader/) is a cross-platform open source desktop application built to simplify downloading YouTube and non-YouTube video and audio content. It has [yt-dlp](https://github.com/yt-dlp/yt-dlp) under the hood, paired with an easy-to-use interface (Qt6 GUI). This tool aims to offer you a seamless experience to get your favorite video and audio content offline. You can selectively or fully download channels, playlists, or individual videos from multiple platforms, opt for audio-only tracks, download the associated thumbnails, and specify the quality and format for your video or audio to download.

Target audience: anyone who wants to save a video or an audio for later (e.g. for use in an offline situation).

This app is different from similar apps in the sense that it allows to get not just single videos, but selectively or fully get an entire channel or playlist, and customize the audio/video quality to one's liking with an easy clickable GUI, progress indicators, download fallbacks, and heuristics to ensure proper core function.

Easy run in two steps with `pip`:

```
pip install yt-channel-downloader
yt-channel-downloader
```

Source code on [GitHub](https://github.com/hyperfield/yt-channel-downloader).

The binary releases for Windows, macOS, and Linux (Debian-compatible) are available from the Releases section.

Suggestions for new features, bug reports, and ideas for improvements are welcome :)

You can see some screenshots on GitHub [here](https://github.com/hyperfield/yt-channel-downloader).

Disclaimer:

Please note that one should not download videos for any other purpose than personal (for example, for watching a video while on a trip with limited or non-existent internet connectivity) to avoid any copyright issues. Also, downloading videos from Youtube is not in accord with Youtube's Terms of Service, which has been a widely discussed controversial issue (see, for example, [this](https://www.digitalmusicnews.com/2021/07/13/is-it-legal-to-download-youtube-videos/)). So, if you have agreed to Youtube ToS, you might go against it by downloading a video, even if it's your own video!",16,3,2025-11-09 22:30:48,ph0tone,https://www.reddit.com/r/Python/comments/1osve44/selectively_download_videos_channels_playlists/
1osxjsk,reddit,I made a GUI framework for Python!,"Hai!!

I made a small program called SmolPyGUI, it's a GUI framework based in pygame.

* **What My Project Does:**¬†It's a module that allows for easier creation of GUIs, I've also found that it works well for visual novel-style games.
* **Target Audience:**¬†Anyone that wants to make a GUI-based project but doesnt feel like writing it all from scratch.
* **Comparison:**¬†Best comparison I can think of is Tkinter, which is definitely significantly more complex and has more features but SmolPyGUI allows for more customization of looks and can be implemented on top of any pygame project, it can also do things other than just GUI, like easier event handling.

You can install it from PyPI (`pip install smolpygui`) and more information is present both in the [PyPI project page](http://pypi.org/project/SmolPyGUI/) and the [GitHub repo](http://github.com/thebroskialex/SmolPyGUI/). Update suggestions are welcome as I am still updating and improving the project, any suggestions can be commented below this post, thanks in advance!

I hope everyone enjoys it!",12,13,2025-11-09 23:58:13,Massive-Tale-7527,https://www.reddit.com/r/Python/comments/1osxjsk/i_made_a_gui_framework_for_python/
1osh41c,reddit,PyCalc Pro v2.0.2 - A Math and Physics Engine With Optional GPU Acceleration For AI Integration,"**PyCalc Pro** has now evolved from just being your average CLI-Python Calculator to a fast and safe engine for AI integration. This engine supports both mathematical and physics functions combining **NumPy, Numba, SciPy, CuPy, and a C++ core** for maximum performance.

**Why it‚Äôs different:**

* Automatically chooses the **fastest execution mode**:
   * GPU via CuPy if available
   * C++ fallback if GPU is unavailable
   * NumPy/Numba fallback if neither is available
* Benchmarks show that in some situations it can even outperform **PyTorch**.

**Target Audience:**

* Python developers, AI/ML researchers, and anyone needing a high-performance math/physics engine.

**Installation:**  
CPU-only version:

    pip install pycalc-pro
    pycalc

Optional GPU acceleration (requires CUDA and CuPy):

    pip install pycalc-pro[gpu]
    pycalc

**Links:**

* GitHub: [https://github.com/lw-xiong/pycalc-pro](https://github.com/lw-xiong/pycalc-pro)
* PyPI: [https://pypi.org/project/pycalc-pro/2.0.2/](https://pypi.org/project/pycalc-pro/2.0.2/)

Feedback, suggestions, and contributions are welcome. I‚Äôd love to hear what the community thinks and how PyCalc Pro can be improved!

Edit:  
If you'd like to check out my github repo for this project please click the link down below:   
[https://github.com/lw-xiong/pycalc-pro](https://github.com/lw-xiong/pycalc-pro)",42,17,2025-11-09 12:31:33,lwx_dev,https://www.reddit.com/r/Python/comments/1osh41c/pycalc_pro_v202_a_math_and_physics_engine_with/
1osyz5r,reddit,Monday Daily Thread: Project ideas!,"# Weekly Thread: Project Ideas üí°

Welcome to our weekly Project Ideas thread! Whether you're a newbie looking for a first project or an expert seeking a new challenge, this is the place for you.

## How it Works:

1. **Suggest a Project**: Comment your project idea‚Äîbe it beginner-friendly or advanced.
2. **Build & Share**: If you complete a project, reply to the original comment, share your experience, and attach your source code.
3. **Explore**: Looking for ideas? Check out Al Sweigart's [""The Big Book of Small Python Projects""](https://www.amazon.com/Big-Book-Small-Python-Programming/dp/1718501242) for inspiration.

## Guidelines:

* Clearly state the difficulty level.
* Provide a brief description and, if possible, outline the tech stack.
* Feel free to link to tutorials or resources that might help.

# Example Submissions:

## Project Idea: Chatbot

**Difficulty**: Intermediate

**Tech Stack**: Python, NLP, Flask/FastAPI/Litestar 

**Description**: Create a chatbot that can answer FAQs for a website.

**Resources**: [Building a Chatbot with Python](https://www.youtube.com/watch?v=a37BL0stIuM)

# Project Idea: Weather Dashboard

**Difficulty**: Beginner

**Tech Stack**: HTML, CSS, JavaScript, API

**Description**: Build a dashboard that displays real-time weather information using a weather API.

**Resources**: [Weather API Tutorial](https://www.youtube.com/watch?v=9P5MY_2i7K8)

## Project Idea: File Organizer

**Difficulty**: Beginner

**Tech Stack**: Python, File I/O

**Description**: Create a script that organizes files in a directory into sub-folders based on file type.

**Resources**: [Automate the Boring Stuff: Organizing Files](https://automatetheboringstuff.com/2e/chapter9/)

Let's help each other grow. Happy coding! üåü",6,0,2025-11-10 01:00:35,AutoModerator,https://www.reddit.com/r/Python/comments/1osyz5r/monday_daily_thread_project_ideas/
1otp66a,reddit,python 3.14 !!!,"Some days before i saw that python 3.14 has released some mounths now,Then i got thinking python developers should have named this version ""Python œÄ"" because of the number œÄ= 3.14. Who is with me???",0,6,2025-11-10 21:34:55,kotsos_53,https://www.reddit.com/r/Python/comments/1otp66a/python_314/
1osjpd6,reddit,Display Your Live Spotify Track on Your GitHub Profile using Python/Flask!,"Hey fellow Python developers!

I wanted to share a small, open-source project I built: **Spotify-Live-Banner**.

### 1. What My Project Does ‚ùìÔ∏è
This project is a real-time web service powered by **Python** (Flask) that fetches the user's currently playing Spotify song and renders it as a dynamic, customizable SVG image. This image is primarily used for embedding directly into GitHub profile READMEs or personal websites.

### 2. Target Audience üó£
This is primarily a **side project / utility tool** meant for developers and enthusiasts who want to add a unique, dynamic element to their online profiles. It is stable and ready for use.

### 3. Comparison (Why use this?) üß≠
While there are other projects that display Spotify activity, this one focuses on:
* **Customization:** Offers extensive control over colors, animations (e.g., spinning CD), and themes.
* **Simple Deployment:** It is configured specifically for quick, free, one-click deployment on platforms like Vercel and Render.
* **Technology:** Built on the reliable **Python/Flask** stack, which may appeal to developers who prefer working within the Python ecosystem.

I'm keen to hear your feedback on the code and implementation.

**Check out the repo here:** https://github.com/SahooShuvranshu/Spotify-Live-Banner

**Live Demo:** https://spotify-live-banner.vercel.app

Let Me Know What You Think üí°",8,2,2025-11-09 14:43:15,MrCrystal_Exe,https://www.reddit.com/r/Python/comments/1osjpd6/display_your_live_spotify_track_on_your_github/
1ot7h4n,reddit,Linux chromedriver auto-downloader,"Good day everyone,

I built a Python script that automatically manages ChromeDriver installations using web scraping to fetch data from Google's official API.

**What My Project Does:** Automatically downloads and installs ChromeDriver by detecting your Chrome browser version and fetching the matching version from Google's official Chrome for Testing API.

**Target Audience:** Python developers doing web automation with Selenium.

**Comparison:** Other managers are outdated or don't handle version matching properly. This script uses the official Google API, auto-detects Chrome versions, and handles user/system installations with comprehensive error handling.

**Key Features:**
- Auto-detects Chrome browser version
- Downloads matching ChromeDriver from official Google API
- User (`~/.local/bin`) and system-wide (`/usr/local/bin`) installations
- Full CLI with `--help`, `--version`, `--chrome-version` flags

The script is fully tested and working.

**GitHub:** https://github.com/slyfox1186/script-repo/blob/main/Python3/Browsers/chromedriver_installer.py

Go fuck yourselves. ",0,15,2025-11-10 08:23:30,RiverRatt,https://www.reddit.com/r/Python/comments/1ot7h4n/linux_chromedriver_autodownloader/
1osuce8,reddit,Python course from scratch for Mac.,"Good evening everyone, sorry for the post, I'm looking for a Python programming course for a subject starting from scratch. I use Mac so it would be preferable on Macos (and even better in Italian) thanks for your time",0,6,2025-11-09 21:49:15,Scary-Instruction-22,https://www.reddit.com/r/Python/comments/1osuce8/python_course_from_scratch_for_mac/
1os4p38,reddit,Built pandas-smartcols: painless pandas column manipulation helper,"**What My Project Does**

A lightweight toolkit that provides consistent, validated helpers for manipulating DataFrame column order:

* Move columns (`move_after`, `move_before`, `move_to_front`, `move_to_end`)
* Swap columns
* Bulk operations (move multiple columns at once)
* Programmatic sorting of columns (by correlation, variance, mean, NaN-ratio, custom key)
* Column grouping utilities (by dtype, regex, metadata mapping, custom logic)
* Functions to save/restore column order

The goal is to remove boilerplate around column list manipulation while staying fully pandas-native.

**Target Audience**

* Data analysts and data engineers who frequently reshape and reorder wide DataFrames.
* Users who want predictable, reusable column-order utilities rather than writing the same reindex patterns repeatedly.
* Suitable for production workflows; it‚Äôs lightweight, dependency-minimal, and does not alter pandas objects beyond column order.

**Comparison**

**vs pure pandas**:  
You can already reorder columns by manually manipulating `df.columns`. This library wraps those patterns with input validation, bulk operations, and a unified API. It reduces repeated list-editing code but does not replace any pandas features.

**vs polars**:  
Polars uses expressions and doesn‚Äôt emphasize column-order manipulation the same way; this library focuses specifically on pandas workflows where column order often matters for reports, exports, and manual inspection.

Use `pandas-smartcols` when you want clean, reusable column-order utilities. For simple one-offs, vanilla pandas is enough.

  
**Install**

`pip install pandas-smartcols`

  
**Repo & Feedback**

[https://github.com/Dinis-Esteves/pandas-smartcols](https://github.com/Dinis-Esteves/pandas-smartcols)

If you try it, I‚Äôd appreciate feedback, suggestions, or PRs.",20,6,2025-11-09 01:08:13,RedHulk05,https://www.reddit.com/r/Python/comments/1os4p38/built_pandassmartcols_painless_pandas_column/
1orsvie,reddit,ArgMan ‚Äî Lightweight CLI argument manager,"Hey everyone ‚Äî I built ArgMan because I wanted something lighter than argparse with easier customization of error/help messages.

**What My Project Does**
   - Lightweight command-line argument parser for small scripts and utilities.
   - Supports positional and optional args, short & long aliases (e.g., -v / --verbose).
   - Customizable error and help messages, plus type conversion and validation hooks.
   - Includes a comprehensive unit test suite.

**Target Audience**
   - Developers writing small to medium CLI tools who want less overhead than argparse or click.
   - Projects that need simple, customizable parsing and error/help formatting rather than a full-featured framework.
   - Intended for production use in lightweight utilities and scripts (not a full replacement for complex CLI apps).

**Comparison**
   - vs argparse: Far smaller, simpler API and easier to customize error/help text; fewer built-in features.
   - vs click / typer: Less opinionated and lighter weight ‚Äî no dependency on decorators/context; fewer higher-level features (no command groups, automatic prompting).
   - Use ArgMan when you need minimal footprint and custom messaging; use click/typer for complex multi-command CLIs.

**Install**
```
pip install argman
```
**Repo & Feedback**
https://github.com/smjt2000/argman

If you try it, I‚Äôd appreciate feedback or feature suggestions!",34,9,2025-11-08 16:55:41,Smjt2000,https://www.reddit.com/r/Python/comments/1orsvie/argman_lightweight_cli_argument_manager/
1osup55,reddit,üìä klyne.dev - python package usage stats (for maintaners),"I'm a python project maintanter, and I always have problems with data and not really sure what features my users use.  
  
**What My Project Does**  
[klyne.dev](http://klyne.dev)¬†is a website that helps you understand how many people use your Python package library and how they use it

üÜì Free for the first package üÜì

**Target**  
Mainly Python package maintaners.

**Comparison**  
There are different tools like  
\-¬†[pepy.tech](http://pepy.tech), which is a package download stats  
\- sentry that is to monitor errors

But there is no Google Analytics or similar for python package stats.

What do you think?

GitHub repo: [https://github.com/psincraian/klyne](https://github.com/psincraian/klyne)",0,0,2025-11-09 22:03:11,psincraian,https://www.reddit.com/r/Python/comments/1osup55/klynedev_python_package_usage_stats_for_maintaners/
1oss6hu,reddit,Visually distinguishing between class and instance methods,"I understand why Python was designed to avoid a lot of symbols or requiring syntactic marking for subtle distinctions, but ‚Ä¶

I think that it would probably do more good than harm to reserve the ‚Äú.‚Äù for instance methods and variable and adopt something like ‚Äú::‚Äù for class methods and variables.

I suspect that this or something like it has been thoroughly discussed before somewhere, but my Google-fu was not up to the task of finding it. So I would welcome pointers to that. ",0,15,2025-11-09 20:24:19,jpgoldberg,https://www.reddit.com/r/Python/comments/1oss6hu/visually_distinguishing_between_class_and/
1osoys2,reddit,Where did go freepybox...,"**Freepybox is now a new mystery of the internet...**

I'm looking for this module freepybox because it has been extinct. The official link for the latest version is now deleted (github) and the other have 0.0.2, wich i cannot work on. Same thing for pip and PyPi : has only 0.0.2. So when we do `pip install freepybox` it says `Successfuly installed freepybox-0.0.2`... Pls find this module or it will be forever gone.",0,6,2025-11-09 18:19:36,-NotADog-,https://www.reddit.com/r/Python/comments/1osoys2/where_did_go_freepybox/
1os4iv3,reddit,Sunday Daily Thread: What's everyone working on this week?,"# Weekly Thread: What's Everyone Working On This Week? üõ†Ô∏è

Hello /r/Python! It's time to share what you've been working on! Whether it's a work-in-progress, a completed masterpiece, or just a rough idea, let us know what you're up to!

## How it Works:

1. **Show & Tell**: Share your current projects, completed works, or future ideas.
2. **Discuss**: Get feedback, find collaborators, or just chat about your project.
3. **Inspire**: Your project might inspire someone else, just as you might get inspired here.

## Guidelines:

* Feel free to include as many details as you'd like. Code snippets, screenshots, and links are all welcome.
* Whether it's your job, your hobby, or your passion project, all Python-related work is welcome here.

## Example Shares:

1. **Machine Learning Model**: Working on a ML model to predict stock prices. Just cracked a 90% accuracy rate!
2. **Web Scraping**: Built a script to scrape and analyze news articles. It's helped me understand media bias better.
3. **Automation**: Automated my home lighting with Python and Raspberry Pi. My life has never been easier!

Let's build and grow together! Share your journey and learn from others. Happy coding! üåü",2,3,2025-11-09 01:00:35,AutoModerator,https://www.reddit.com/r/Python/comments/1os4iv3/sunday_daily_thread_whats_everyone_working_on/
1ossqpv,reddit,Demande d‚Äôaide pour am√©lioration du Bot de trading,"Salut la team,

Apr√®s plusieurs mois de dev et de tests, le bot de trade crypto du Crypto Scalping Club tourne enfin correctement sur Binance Spot il g√®re les entr√©es/sorties via RSI, MACD, EMA, volume, et patterns japonais (Shooting Star, Engulfing, etc.).

üëâ Mais maintenant, je veux pousser l‚ÄôIA plus loin.
Objectif : affiner la logique d√©cisionnelle (buy/sell/hold), introduire une gestion dynamique du risque, et lui permettre d‚Äôadapter son comportement selon la volatilit√© et les performances pass√©es.

Je cherche donc :
	‚Ä¢	üîß Des devs Python (pandas, talib, websocket, threading, Decimal)
	‚Ä¢	üß© Des cerveaux IA / machine learning l√©ger (logique heuristique, scoring adaptatif, etc.)
	‚Ä¢	üí° Des traders techniques pour affiner les signaux et les ratios de prise de profit

üí¨ L‚Äôid√©e : am√©liorer ensemble la couche IA, √©changer sur les strat√©gies, et rendre le bot plus ‚Äúintelligent‚Äù sans le surcharger.
üí∏ Le bot est dispo pour les membres du Crypto Scalping Club (forfait symbolique de 50 ‚Ç¨ pour l‚Äôacc√®s complet + mise √† jour continue).

Si tu veux tester, contribuer, ou simplement brainstormer sur les optimisations IA, rejoins-nous ici :
üëâ r/CryptoScalpingClub700Ôøº

‚∏ª

üî• But final : un bot communautaire, √©volutif, et rentable √† long terme.
On code, on backteste, on scalpe, on s‚Äôam√©liore. Ensemble.",0,4,2025-11-09 20:45:52,clem-700,https://www.reddit.com/r/Python/comments/1ossqpv/demande_daide_pour_am√©lioration_du_bot_de_trading/
1ospjlw,reddit,OpenPorts ‚Äî Tiny Python package to instantly list open ports,"# üîé What My Project Does

**OpenPorts** is a tiny, no-fuss Python library + CLI that tells you which TCP ports are open on a target machine ‚Äî local or remote ‚Äî in one line of Python or a single command in the terminal.  
Think: `netstat` \+ a clean Python API, without the bloat.

Quick demo:

    pip install openports
    openports
    



# üéØ Target Audience

* **Developers** debugging services locally or in containers
* **DevOps** engineers who want quick checks in CI or deployment scripts
* **Students / Learners** exploring sockets and networking in Python
* **Self-hosters** who want an easy way to audit services on their machine

>

# ‚öñÔ∏è Comparison ‚Äî Why use OpenPorts?

* **Not Nmap** ‚Äî Nmap = powerful network scanner. OpenPorts = tiny, script-first port visibility.
* **Not netstat** ‚Äî netstat shows sockets but isn‚Äôt cleanly scriptable from Python. OpenPorts = programmatic and human-readable output (JSON-ready).
* **Benefits:**
   * Pure Python, zero heavy deps
   * Cross-platform: Windows / macOS / Linux
   * Designed to be embedded in scripts, CI, notebooks, or quick terminal checks

# ‚ú® Highlights & Features

* `pip install` and go ‚Äî no complex setup
* Returns clean, parseable results (easy to pipe to JSON)
* Small footprint, fast for local and small remote scans
* Friendly API for embedding in tools or monitoring scripts

# üîó Links

* **GitHub:** [https://github.com/yashmahamulkar/openports.git](https://github.com/yashmahamulkar/openports.git)
* **PyPI:** [https://pypi.org/project/openports/](https://pypi.org/project/openports/)

# ‚úÖ Call to Action

Love to hear your feedback ‚Äî star the repo if you like it, file issues for bugs, and tell me which feature you want next (UDP scanning, async mode, port filtering, or CI integration). I‚Äôll be watching this thread ‚Äî ask anything!",0,3,2025-11-09 18:42:17,Significant-Roll-520,https://www.reddit.com/r/Python/comments/1ospjlw/openports_tiny_python_package_to_instantly_list/
1osh77h,reddit,Create real-time Python web apps,"Hi all!

I'm creating a library + service to create Python web apps and I'm looking for some feedback and ideas. This is still in alpha so if something breaks, sorry!

# What my project does?

Create Python web apps:

* with 0 config
* with interactive UI
* using real-time websockets

Core features:

* Run anywhere: on a laptop, a Raspberry Pi or a server
* Pure Python: No Vue/React needed
* Full control on what to show, when and who

# Demo

Pip install [miniappi](https://pypi.org/project/miniappi/) and run this code:

    from miniappi import App, content
    
    app = App()
    
    @app.on_open()
    async def new_user():
        # This runs when a user joins
        # We will show them a simple card
        await content.v0.Title(
            text=""Hello World!""
        ).show()
    
    # Start the app
    app.run()

Go to the link this printed, ie.: [https://miniappi.com/apps/123456](https://miniappi.com/apps/de96cedf-2d33-4585-a8a1-b4437e1a3142)

This doesn't do much but here are some more complex examples you can just copy-paste and run:

* [Kahoot-like game](https://github.com/Miksus/miniappi-examples/blob/main/examples/kahoot-like-game.py)
* [Small chatroom](https://github.com/Miksus/miniappi-examples/blob/main/examples/chatroom.py)
* [poll/survey](https://github.com/Miksus/miniappi-examples/blob/main/examples/survey.py)

Here are some live demos (if they are unavailable, my computer went to sleep üò¥, or they crashed...):

* [A simple (fake) survey)](https://miniappi.com/apps/e657b439-2053-468b-bb0d-8269ffb87e6f)
* [A chatroom (don't want to moderate so...)](https://miniappi.com/apps/2635a3e8-ebfe-4173-849a-27fb7b22b82c)

# Potential Audience

* Home lab: create a UI for your locally run stuff without opening ports
* Prototypers: Test your idea fast and free
* De-googlers: Own your data. Why not self-host polls/surveys (instead of using Google Forms)
* Hobbyists: Create small web games/apps for you or your friends

# Comparison to others:

* Streamlit: Streamlit is focused on plotting data. It does not support nested components and is not meant for users interacting with each other.
* Web frameworks (ie. Flask/FastAPI): Much more effort but you can do much more. But I simplified a lot for you.
* Python to React/Vue (ie. ReactPy): You basically write React/Vue but in Python. Miniappi tries to be Python in Python and handles the complexity of Vue for you.

# What I'm possibly doing next?

* Bug fixing, optimizations, bug fixing...
* Create more UI components:
   * Graphs and plots
   * Game components: cards, avatars
   * Images, file uploads, media
   * More ideas?
* Named apps and permanent URLs
* Sessions: users can resume when closing browser
   * Inprove existing: Polls, surveys, chats, quiz etc.
   * Simple CRUD apps
   * Virtual board games
   * Ideas?
* Option for locally host the server (open source the server code)

Some links you might find useful:

* [The documentation](https://python-docs.miniappi.com/)
* [Library source code](https://github.com/Miksus/miniappi-python)

Any feedback, concerns or ideas? What do you think I should do next?",0,4,2025-11-09 12:36:40,Natural-Intelligence,https://www.reddit.com/r/Python/comments/1osh77h/create_realtime_python_web_apps/
1osknpl,reddit,MainyDB: MongoDB-style embedded database for Python,"# üß© What My Project Does

**MainyDB** is an embedded, file-based database for Python that brings the MongoDB experience into a single `.mdb` file.  
No external server, no setup, no dependencies.

It lets you store and query JSON-like documents with full **PyMongo syntax support**, or use its **own Pythonic syntax** for faster and simpler interaction.  
It‚Äôs ideal for devs who want to build apps, tools, or scripts with structured storage but without the overhead of installing or maintaining a full database system.

PyPI: [pypi.org/project/MainyDB](https://pypi.org/project/MainyDB/)  
GitHub: [github.com/dddevid/MainyDB](https://github.com/dddevid/MainyDB?utm_source=chatgpt.com)

# üß† Main Features

* **Single file storage** ‚Äì all your data lives inside one `.mdb` file
* **Two syntax modes**
   * *Own Syntax* ‚Üí simple Python-native commands
   * *PyMongo Compatibility* ‚Üí just change the import to switch from MongoDB to MainyDB
* **Aggregation pipelines** like `$match`, `$group`, `$lookup`, and more
* **Thread-safe** with **async writes** for good performance
* **Built-in media support** for images (auto base64 encoding)
* **Zero setup** ‚Äì works fully offline, perfect for local or portable projects

# üéØ Target Audience

MainyDB is meant for:

* üß† Developers prototyping apps or AI tools that need quick data storage
* üíª Desktop app devs who want local structured storage without running a database server
* ‚öôÔ∏è Automation and scripting projects that need persistence
* üß∞ Students and indie devs experimenting with database logic

It‚Äôs not made for massive-scale production or distributed environments yet. Its main goal is simplicity, portability, and zero setup.

# ‚öñÔ∏è Comparison

|Feature|MainyDB|MongoDB|TinyDB|SQLite|
|:-|:-|:-|:-|:-|
|Server required|‚ùå No|‚úÖ Yes|‚ùå No|‚ùå No|
|Mongo syntax|‚úÖ Yes|‚úÖ Yes|‚ùå No|‚ùå No|
|Aggregation pipeline|‚úÖ Yes|‚úÖ Yes|‚ùå No|‚ùå No|
|Binary / media support|‚úÖ Built-in|‚öôÔ∏è Manual|‚ùå No|‚ùå No|
|File-based|‚úÖ Single `.mdb`|‚ùå|‚úÖ|‚úÖ|
|Thread-safe + async|‚úÖ|‚úÖ|‚ö†Ô∏è Partial|‚öôÔ∏è Depends|

MainyDB sits between **MongoDB‚Äôs power** and **TinyDB‚Äôs simplicity**, combining both into a single embedded package.

# üí¨ Feedback Welcome

I‚Äôd love to hear your feedback: ideas, bug reports, performance tests, or feature requests (encryption, replication, maybe even cloud sync?).

Repo ‚Üí [github.com/dddevid/MainyDB](https://github.com/dddevid/MainyDB?utm_source=chatgpt.com)  
PyPI ‚Üí [pypi.org/project/MainyDB](https://pypi.org/project/MainyDB/)

Thanks for reading and happy coding ‚úåÔ∏è",0,14,2025-11-09 15:24:53,Theb1ffy_,https://www.reddit.com/r/Python/comments/1osknpl/mainydb_mongodbstyle_embedded_database_for_python/
1or564a,reddit,"httpmorph - HTTP client with Chrome 142 fingerprinting, HTTP/2, and async support","What My Project Does:
httpmorph is a Python HTTP client that mimics real browser TLS/HTTP fingerprints. It uses BoringSSL (the same TLS stack as Chrome) and nghttp2 to make your Python requests look exactly like Chrome 142 from a fingerprinting perspective - matching JA3N, JA4, and JA4_R fingerprints perfectly.

It includes HTTP/2 support, async/await with AsyncClient (using epoll/kqueue), proxy support with authentication, certificate compression for Cloudflare-protected sites, post-quantum cryptography (X25519MLKEM768), and connection pooling.

Target Audience:
* Developers testing how their web applications handle different browser fingerprints
* Researchers studying web tracking and fingerprinting mechanisms
* Anyone whose Python scripts are getting blocked despite setting correct User-Agent headers
* Projects that need to work with Cloudflare-protected sites that do deep fingerprint checks

This is a learning/educational project, not meant for production use yet.

Comparison:
The main alternative is curl_cffi, which is more mature, stable, and production-ready. If you need something reliable right now, use that.

httpmorph differs in that it's built from scratch as a learning project using BoringSSL and nghttp2 directly, with a requests-compatible API. It's not trying to compete - it's a passion project where I'm learning by implementing TLS, HTTP/2, and browser fingerprinting myself.

Unlike httpx or aiohttp (which prioritize speed), httpmorph prioritizes fingerprint accuracy over performance.

Current Status:
Still early development. API might change, documentation needs work, and there are probably bugs. This is version 0.2.x territory - use at your own risk and expect rough edges.

Links:
* PyPI: https://pypi.org/project/httpmorph/
* GitHub: https://github.com/arman-bd/httpmorph
* Docs: https://httpmorph.readthedocs.io

Feedback, bug reports, and criticism all are welcome. Thanks to everyone who gave feedback on my initial post 3 weeks ago. It made a real difference.
",110,22,2025-11-07 21:22:04,armanfixing,https://www.reddit.com/r/Python/comments/1or564a/httpmorph_http_client_with_chrome_142/
1or2vxm,reddit,"Alexy Khrabrov interviews Guido on AI, Functional Programming, and Vibe Coding","Alexy Khrabrov, the AI Community Architect at Neo4j, interviewed Guido at the 10th PyBay in San Francisco, where Guido gave a talk ""Structured RAG is better than RAG"".  The topics included 

* why Python has become the language of AI 
* what is it about Python that made it so adaptable to new developments 
* how does Functional Programming get into Python and was it a good idea 
* does Guido do vibe coding? 
* and more  

See [the full interview on DevReal AI](https://www.devreal.ai/guido-van-rossum-by-the-pybay/), the community blog for DevRel advocates in AI.",27,3,2025-11-07 19:54:56,setuporg,https://www.reddit.com/r/Python/comments/1or2vxm/alexy_khrabrov_interviews_guido_on_ai_functional/
1orzrcu,reddit,New here and confused about something.,"Hello, I'm here because I am curious about how Python can be used to program actual robots to move, pick things up, etc. I have only just started a GCSE course in computer science, so I'm very new to programming as a whole, but I am too impatient to wait and find out if I get to learn about robotics in the GCSE course (especially as I have doubts about whether I will).",0,8,2025-11-08 21:34:06,LegoBear135654,https://www.reddit.com/r/Python/comments/1orzrcu/new_here_and_confused_about_something/
1orajp0,reddit,Saturday Daily Thread: Resource Request and Sharing! Daily Thread,"# Weekly Thread: Resource Request and Sharing üìö

Stumbled upon a useful Python resource? Or are you looking for a guide on a specific topic? Welcome to the Resource Request and Sharing thread!

## How it Works:

1. **Request**: Can't find a resource on a particular topic? Ask here!
2. **Share**: Found something useful? Share it with the community.
3. **Review**: Give or get opinions on Python resources you've used.

## Guidelines:

* Please include the type of resource (e.g., book, video, article) and the topic.
* Always be respectful when reviewing someone else's shared resource.

## Example Shares:

1. **Book**: [""Fluent Python""](https://www.amazon.com/Fluent-Python-Concise-Effective-Programming/dp/1491946008) \- Great for understanding Pythonic idioms.
2. **Video**: [Python Data Structures](https://www.youtube.com/watch?v=pkYVOmU3MgA) \- Excellent overview of Python's built-in data structures.
3. **Article**: [Understanding Python Decorators](https://realpython.com/primer-on-python-decorators/) \- A deep dive into decorators.

## Example Requests:

1. **Looking for**: Video tutorials on web scraping with Python.
2. **Need**: Book recommendations for Python machine learning.

Share the knowledge, enrich the community. Happy learning! üåü",8,0,2025-11-08 01:00:38,AutoModerator,https://www.reddit.com/r/Python/comments/1orajp0/saturday_daily_thread_resource_request_and/
1oqn305,reddit,How Big is the GIL Update?,"So for intro, I am a student and my primary langauge was python. So for intro coding and DSA  I always used python.

Took some core courses like OS and OOPS to realise the differences in memory managament and internals of python vs languages say Java or C++. In my opinion one of the biggest drawbacks for python at a higher scale was GIL preventing true multi threading. From what i have understood, GIL only allows one thread to execute at a time, so true multi threading isnt achieved. Multi processing stays fine becauses each processor has its own GIL

But given the fact that GIL can now be disabled, isn't it a really big difference for python in the industry?   
I am asking this ignoring the fact that most current codebases for systems are not python so they wouldn't migrate. ",105,68,2025-11-07 07:26:26,Worldly-Duty4521,https://www.reddit.com/r/Python/comments/1oqn305/how_big_is_the_gil_update/
1oqytrv,reddit,How should linters treat constants and globals?,"As a followup to my previous [post](https://www.reddit.com/r/Python/comments/1oj4mcr/comment/nm6qgio/?sort=top), I'm working on an ask for Pylint to implement a more comprehensive strategy for constants and globals.

A little background. Pylint currently uses the following logic for variables defined at a module root.

* Variables assigned once are considered constants
   * If the value is a literal, then it is expected to be UPPER\_CASE (const-rgx)
   * If the value is not a literal, is can use either UPPER\_CASE (const-rgx) or snake\_case (variable-rgx)
      * There is no mechanism to enforce one regex or the other, so both styles can exist next to each other
* Variables assigned more than once are considered ""module-level variables""
   * Expected to be snake\_case (variable-rgx)
* No distinction is made for variables inside a dunder name block

I'd like to propose the following behavior, but would like community input to see if there is support or alternatives before creating the issue.

* Variables assigned exclusively inside the dunder main block are treated as regular variables
   * Expected to be snake\_case (variable-rgx)
* Any variable reassigned via the global keyword is treated as a global
   * Expected to be snake\_case (variable-rgx)
   * Per PEP8, these should start with an underscore unless `__all__` is defined and the variable is excluded
* All other module-level variables not guarded by the dunder name clause are constants
   * If the value is a literal, then it is expected to be UPPER\_CASE (const-rgx)
   * If the value is not a literal, a regex or setting determines how it should be treated
      * By default snake\_case or UPPER\_CASE are valid, but can be configured to UPPER\_CASE only or snake\_case only
* Warn if any variable in a module root is assigned more than once
   * Exception in the case where **all** assignments are inside the dunder main block

What are your thoughts?",11,25,2025-11-07 17:22:22,avylove,https://www.reddit.com/r/Python/comments/1oqytrv/how_should_linters_treat_constants_and_globals/
1orv8e4,reddit,Clean execution of python by chatgpt,"Hello everyone.

I created a custom chatbot on chatgpt. It is used to narrate interactive adventures.

The problem is that there is a character creation phase, and for this phase, so that he doesn't invent anything, I have planned ready-made sentences.

But when he quotes my sentences he systematically reformulates them. But by reformulating, he disrupts this creation phase because he invents options.

So I thought about making it ‚Äúspit out ready-made python blocks of text‚Äù. But here again he distorts them.

I've spent many, many hours on it, I can't get it to cite the VERBATIM content. The LLM engine systematically reformulates. It behaves like a chatbot, not a code executor.

Here are the security measures that I have put in place, but it is not enough.

Does anyone have an idea?

Thanks in advance:

* **Output post-filter**¬†`fences_only_zwsp`¬†Extracts only¬†`‚Ä¶`¬†blocks from captured stdout and keeps¬†**only**¬†those whose inner content starts with U+200B (zero-width space). Everything else (including any outside-fence text) is discarded. If nothing remains: return empty (silence).
* **Output gate (self-check) before sending**¬†Verifies the final response equals¬†`fences_only_zwsp(captured_stdout)`¬†and that nothing outside fences slipped in. Otherwise, returns silence.
* **Strict 1:1 relay channel**¬†The bot forwards¬†**only**¬†the engine‚Äôs fenced blocks, in the same order, with the original language labels (e.g.,¬†`text`). No headers, no commentary, no ‚Äúsmart‚Äù typography, no block merging/splitting.
* **Engine-side signed fences**¬†Every emitted block is wrapped as a \`\`\`text fence whose body is¬†**prefixed with U+200B**¬†(the signature) and never empty; optional SHA-256 hash line can be enabled via env var.
* **Backtick neutralization (anti-injection)**¬†Before emission, the engine rewrites sequences of backticks in content lines to prevent accidental fence injection from inner text.
* **Minimal, safe**¬†`{{TOKEN}}`¬†**substitution gated by phase**¬†Placeholders like¬†`{{ARME_1}}`,¬†`{{DOOR_TITLE}}`, etc. are replaced via a tight regex and a phase policy so only allowed tokens are expanded at a given step‚Äîno structure rewriting.
* **Auto-boot on first turn (stdout capture)**¬†On T1, the orchestration imports¬†`A1_ENGINE`, captures its stdout, applies the post-filter, and returns¬†**only**¬†the resulting fences (typically the INTRO). No¬†`run()`¬†call on T1 if auto-boot is active.
* **Forced INTRO until consent**¬†While in A1A, if the INTRO hasn‚Äôt been shown yet, user input is ignored and the INTRO is re-emitted; progression is locked until the player answers ‚Äúyes/1‚Äù.
* **No fallback, controlled silence**¬†While creation isn‚Äôt finished: every user input is passed verbatim to the engine; the reply is¬†**strictly**¬†the captured fences after post-filter. If the engine emits nothing: silence. On exceptions in the orchestrator: current behavior is silence (no leak).
* **Phase-guarded progression + structural checks**¬†Advance to A1B only if a¬†**valid**¬†`foundation`¬†exists; to A1C only if a¬†**valid**¬†`persona`¬†exists; to A1D only if¬†`door`¬†is¬†**valid**; pipeline ends when A1D has exported a¬†`.dlv`¬†path.
* **Final output comes from A1D (no JSON capsule)**¬†The visible end of the pipeline is A1D‚Äôs short player message +¬†`.dlv`¬†download link. We removed the old JSON ‚Äúcapsule‚Äù to avoid any non-verbatim wrapper.
* **Registry + phase token policy**¬†Annexes register with the engine; a phase policy dictates which annex tokens are collectable for safe placeholder expansion (A1A‚ÜíA1D).
* **Stable source corpus in A1A**¬†The full prompt text and flow (INTRO‚Üí‚Ä¶‚ÜíHALT), including immediate fiche after name and the ‚ÄúPersona‚Äù handoff trigger, live in¬†`A1A_PROFILS.py`; the engine never paraphrases them.
* **Meta/backstage input filter**¬†Even if the user types engine/dev keywords (A1\_ENGINE, annexes, stdout, etc.), we still pass the message to the engine and only relay fenced output; if none, silence.
* **Typography & label preservation**¬†Do not normalize punctuation/quotes, do not add headers, keep the emitted fence labels and the leading U+200B as-is.",0,15,2025-11-08 18:30:51,Standard_Count_7581,https://www.reddit.com/r/Python/comments/1orv8e4/clean_execution_of_python_by_chatgpt/
1or7ybp,reddit,Quick Python Project to Build a Private AI News Agent in Minutes on NPU/GPU/CPU,"I built a small Python project that runs a fully local AI agent directly on the Qualcomm NPU using Nexa SDK and Gradio UI ‚Äî no API keys or server.

# What My Project Does

The agent reads the latest AI news and saves it into a local notebook file. It‚Äôs a simple example project to help you quickly get started building an AI agent that runs entirely on a local model and NPU.

It can be easily extended for tasks like scraping and organizing research, summarizing emails into to-do lists, or integrating RAG to create a personal offline research assistant.

This demo runs Granite-4-Micro (NPU version) ‚Äî a new small model from IBM that demonstrates surprisingly strong reasoning and tool-use performance for its size. This model only runs on Qualcomm NPU, but you can switch to other models easily to run on macOS or Windows CPU/GPU.

# Comparison

It also demonstrates a local AI workflow running directly on the NPU for faster, cooler, and more battery-efficient performance, while the Python binding provides full control over the entire workflow.  
While other runtimes have limited support on the latest models on NPU.

# Target Audience

* Learners who want hands-on experience with local AI agents and privacy-first workflows
* Developers looking to build their own local AI agent using a quick-start Python template
* Anyone with a Snapdragon laptop who wants to try or utilize the built-in NPU for faster, cooler, and energy-efficient AI execution

# Links

**Video Demo:** [https://youtu.be/AqXmGYR0wqM?si=5GZLsdvKHFR2mzP1](https://youtu.be/AqXmGYR0wqM?si=5GZLsdvKHFR2mzP1)

**Repo:** [github.com/NexaAI/nexa-sdk/tree/main/demos/Agent-Granite](https://github.com/NexaAI/nexa-sdk/tree/main/demos/Agent-Granite)

Happy to hear from others exploring local AI app development with Python!",1,0,2025-11-07 23:12:28,Different-Effect-724,https://www.reddit.com/r/Python/comments/1or7ybp/quick_python_project_to_build_a_private_ai_news/
1oqbwtg,reddit,Best books to be a good Python Dev?,Got a new offer where I will be doing Python for backend work. I wanted to know what good books there are good for making good Python code and more advance concepts?,83,42,2025-11-06 22:42:53,Juanx68737,https://www.reddit.com/r/Python/comments/1oqbwtg/best_books_to_be_a_good_python_dev/
1oqldnq,reddit,Best Python package to convert doc files to HTML?,"Hey everyone,

I‚Äôm looking for a Python package that can convert doc files (.docx, .pdf, ...etc) into an **HTML representation** ‚Äî ideally with **all the document‚Äôs styles preserved** and **CSS included** in the output.

I‚Äôve seen some tools like **python-docx** and **mammoth**, but I‚Äôm not sure which one provides the best results for full styling and clean HTML/CSS output.

What‚Äôs the best or most reliable approach you‚Äôve used for this kind of task?

Thanks in advance!",8,10,2025-11-07 05:50:45,Bitter_Comfort9280,https://www.reddit.com/r/Python/comments/1oqldnq/best_python_package_to_convert_doc_files_to_html/
1oqp1xi,reddit,"zlmdb v25.10.1 Released: LMDB for Python with PyPy Support, Binary Wheels, and Vendored Dependencies","Hey r/Python! I'm excited to share **zlmdb v25.10.1** - a complete LMDB database solution for Python that's been completely overhauled with production-ready builds.

## What is zlmdb?

zlmdb provides two APIs in one package:

1. **Low-level py-lmdb compatible API** - Drop-in replacement for py-lmdb with the same interface
2. **High-level ORM API** - Type-safe persistent objects with automatic serialization

## Why this release is interesting

**üîã Batteries Included - Zero Dependencies**
- Vendored LMDB (no system installation needed)
- Vendored Flatbuffers (high-performance serialization built-in)
- Just `pip install zlmdb` and you're ready to go!

**üêç PyPy Support**
- Built with CFFI (not CPyExt) so it works perfectly with PyPy
- Near-C performance with JIT compilation
- py-lmdb doesn't work on PyPy due to CPyExt dependency

**üì¶ Binary Wheels for Everything**
- CPython 3.11, 3.12, 3.13, 3.14 (including free-threaded 3.14t)
- PyPy 3.11
- Linux (x86_64, aarch64), macOS (Intel, Apple Silicon), Windows (x64)
- No compilation required on any platform

**‚ö° Performance Features**
- Memory-mapped I/O (LMDB's legendary speed)
- Zero-copy operations where possible
- Multiple serializers: JSON, CBOR, Pickle, Flatbuffers
- Integration with Numpy, Pandas, and Apache Arrow

## Quick Example

```python
# Low-level API (py-lmdb compatible)
from zlmdb import lmdb

env = lmdb.open('/tmp/mydb')
with env.begin(write=True) as txn:
    txn.put(b'key', b'value')

# High-level ORM API
from zlmdb import zlmdb

class User(zlmdb.Schema):
    oid: int
    name: str
    email: str

db = zlmdb.Database('/tmp/userdb')
with db.begin(write=True) as txn:
    user = User(oid=1, name='Alice', email='alice@example.com')
    txn.store(user)
```

## Links

- **üì¶ PyPI:** https://pypi.org/project/zlmdb/25.10.1/
- **üìñ Docs:** https://zlmdb.readthedocs.io/en/latest/
- **üíª GitHub:** https://github.com/crossbario/zlmdb
- **üìã Full Announcement:** https://github.com/crossbario/zlmdb/discussions/73

## When to use zlmdb?

- ‚úÖ Need PyPy support (py-lmdb won't work)
- ‚úÖ Want zero external dependencies
- ‚úÖ Building for multiple platforms (we provide all wheels)
- ‚úÖ Want both low-level control AND high-level ORM
- ‚úÖ Need high-performance embedded database

zlmdb is part of the [WAMP project family](https://wamp-proto.org/) and used in production by [Crossbar.io](https://crossbar.io/).

Happy to answer any questions!",4,3,2025-11-07 09:31:34,Traditional-You-8175,https://www.reddit.com/r/Python/comments/1oqp1xi/zlmdb_v25101_released_lmdb_for_python_with_pypy/
1oqbg2q,reddit,This week Everybody Codes has started (challange similar to Advent Of Code),"Hi everybody!

This week Everybody Codes has started (challenge similar to Advent Of Code). You can practice Python solving algorithmic puzzles. This is also good warm-up before AoC ;)

This is second edition of EC. It consists of twenty days (three parts of puzzles each day).

Web: [Everybody.codes](http://Everybody.codes)  \- there is also reddit forum for EC problems.

**I encourage everyone to participatre and compete!**",28,2,2025-11-06 22:25:09,Repsol_Honda_PL,https://www.reddit.com/r/Python/comments/1oqbg2q/this_week_everybody_codes_has_started_challange/
1oqp65c,reddit,Autobahn v25.10.2 Released: WebSocket & WAMP for Python with Critical Fixes and Enhanced CI/CD,"Hey r/Python! Just released **Autobahn|Python v25.10.2** with important fixes and major CI/CD improvements.

## What is Autobahn|Python?

Autobahn|Python is the leading Python implementation of:
- **WebSocket** (RFC 6455) - Both client and server
- **WAMP** (Web Application Messaging Protocol) - RPC and PubSub for microservices

Works on both **Twisted** and **asyncio** with the same API.

## Key Features of This Release

**üîß Critical Fixes**
- Fixed source distribution integrity issues
- Resolved CPU architecture detection (NVX support)
- Improved reliability of sdist builds

**üîê Cryptographic Chain-of-Custody**
- All build artifacts include SHA256 checksums
- Verification before GitHub Release creation
- Automated integrity checks in CI/CD pipeline

**üèóÔ∏è Production-Ready CI/CD**
- Automated tag-triggered releases (`git push tag vX.Y.Z`)
- GitHub Actions workflows with full test coverage
- Publishes to PyPI with trusted publishing (OIDC)
- Comprehensive wheel builds for all platforms

**üì¶ Binary Wheels**
- CPython 3.11, 3.12, 3.13, 3.14
- PyPy 3.10, 3.11
- Linux (x86_64, aarch64), macOS (Intel, Apple Silicon), Windows (x64)

## Why Autobahn?

**For WebSocket:**
- Production-proven implementation (used by thousands)
- Full RFC 6455 compliance
- Excellent performance and stability
- Compression, TLS, and all extensions

**For Microservices (WAMP):**
- Remote Procedure Calls (RPC) with routed calls
- Publish & Subscribe with pattern matching
- Works across languages (Python, JavaScript, Java, C++)
- Battle-tested in production environments

## Quick Example

```python
# WebSocket Client (asyncio)
from autobahn.asyncio.websocket import WebSocketClientProtocol
from autobahn.asyncio.websocket import WebSocketClientFactory

class MyClientProtocol(WebSocketClientProtocol):
    def onConnect(self, response):
        print(""Connected: {}"".format(response.peer))

    def onMessage(self, payload, isBinary):
        print(""Received: {}"".format(payload.decode('utf8')))

# WAMP Component (asyncio)
from autobahn.asyncio.wamp import ApplicationSession

class MyComponent(ApplicationSession):
    async def onJoin(self, details):
        # Subscribe to topic
        def on_event(msg):
            print(f""Received: {msg}"")
        await self.subscribe(on_event, 'com.example.topic')

        # Call RPC
        result = await self.call('com.example.add', 2, 3)
        print(f""Result: {result}"")
```

## Links

- **üì¶ PyPI:** https://pypi.org/project/autobahn/25.10.2/
- **üìñ Docs:** https://autobahn.readthedocs.io/
- **üíª GitHub:** https://github.com/crossbario/autobahn-python
- **üìã Full Announcement:** https://github.com/crossbario/autobahn-python/discussions/1755
- **üåê WAMP Protocol:** https://wamp-proto.org/

## Related Projects

Autobahn is part of the WAMP ecosystem:
- **Crossbar.io** - WAMP router/broker for production deployments
- **Autobahn|JS** - WAMP for browsers and Node.js
- **zlmdb** - High-performance embedded database (just released v25.10.1!)

Autobahn|Python is used in production worldwide for real-time communication, IoT, microservices, and distributed applications.

Questions welcome!",3,0,2025-11-07 09:39:13,Traditional-You-8175,https://www.reddit.com/r/Python/comments/1oqp65c/autobahn_v25102_released_websocket_wamp_for/
1or92do,reddit,venv-rs: Virtual Environment Manager TUI,"Hello everyone. I'd like to showcase my project for community feedback.

# Project Rationale

Keeping virtual environments in a hidden folder in `$HOME` became a habit of mine and I find it very convenient for most of my DS/AI/ML projects or quick scripting needs. But I have a few issues with this:

* I can't see what packages I have in a venv without activating it.
* I can't easily browse my virtual environments even though they are collected in a single place.
* Typing the activation command is annoying.
* I can't easily see disk space usage.

So I developed [venv-rs](https://github.com/Ardnys/venv-rs) to address my needs. It's finally usable enough to share it.

# What my project does

Currently it has most features I wanted in the first place. Mainly:

* a config file to specify the location of the folder where I put my venvs.
* shows venvs, its packages, some basic info about the venv and packages.
* copies activation command to clipboard.
* searches for virtual environments recursively

Check out the [README.md](https://github.com/Ardnys/venv-rs/blob/main/README.md) in the repo for usage gifs and commands.

# Target audience

Anyone who's workflow & needs align with mine above (see Project Rationale).

# Comparison

There are similar venv manager projects, but venv-rs is a TUI and not a CLI. I think TUIs are a lot more in**TUI**tive and fast to use for this kind of management tools, though currently lacking some functionality.

|Feature|venv-rs|virtualenvwrapper|venv-manager|uv|pip|
|:-|:-|:-|:-|:-|:-|
|TUI|‚úÖ|‚ùå|‚ùå|‚ùå|‚ùå|
|list virtual environments|‚úÖ|‚úÖ|‚úÖ|‚ùå|‚ùå|
|show size of virtual environments|‚úÖ|?|‚ùå|‚ùå|‚ùå|
|easy shell activation|‚úÖ|‚úÖ|‚úÖ|depends|‚ùå|
|search for venvs|‚úÖ|‚ùå|‚ùå|‚ùå|‚ùå|
|creating virtual environment|‚ùå|‚úÖ|‚úÖ|‚úÖ|‚úÖ|
|cloning, deleting venvs|‚ùå|‚úÖ|‚úÖ|‚ùå|‚ùå|

*To be honest, I didn't check if there were venv managers before starting. Isn't it funny that there are least 2 of them already? CLI is too clunky to provide the effortless browsing and activating I want. It had to be TUI.* 

# Feedback

If this tool/project interests you, or you have a similar workflow, I'd love to hear your feedback and suggestions.

I wrote it in Rust because I am familiar with TUI library Ratatui. Rust seems to be a popular choice for writing Python tooling, so I hope it's not too out of place here.

# uv

I know that uv exists and more and more people are adopting it. uv manages the venv itself so the workflow above doesn't make sense with uv. I got mixed results with uv so I can't fully ditch my regular workflow. Sometimes I find it more convenient to activate the venv and start working. Maybe my boi could peacefully coexist with uv, I don't know.

# Known issues, limitations

* MAC is not supported for the lack of macs in my possession.
* First startup takes some time if you have a lot of venvs and packages. Once they are cached, it's quick.
* Searching could take a lot of time.
* It's still in development and there are rough edges.

# Source code and binaries

Repo: [https://github.com/Ardnys/venv-rs](https://github.com/Ardnys/venv-rs)

Thanks for checking it out! Let me know what you think!",0,7,2025-11-07 23:57:40,gingerbread475,https://www.reddit.com/r/Python/comments/1or92do/venvrs_virtual_environment_manager_tui/
1or5327,reddit,multi_Threading in python,"in python why GIL limits true parallel execution i.e, only one thread can run python bytecode at a time why,please explain................................................",0,13,2025-11-07 21:18:46,couriouscosmic,https://www.reddit.com/r/Python/comments/1or5327/multi_threading_in_python/
1oqfalr,reddit,Friday Daily Thread: r/Python Meta and Free-Talk Fridays,"# Weekly Thread: Meta Discussions and Free Talk Friday üéôÔ∏è

Welcome to Free Talk Friday on /r/Python! This is the place to discuss the r/Python community (meta discussions), Python news, projects, or anything else Python-related!

## How it Works:

1. **Open Mic**: Share your thoughts, questions, or anything you'd like related to Python or the community.
2. **Community Pulse**: Discuss what you feel is working well or what could be improved in the /r/python community.
3. **News & Updates**: Keep up-to-date with the latest in Python and share any news you find interesting.

## Guidelines:

* All topics should be related to Python or the /r/python community.
* Be respectful and follow Reddit's [Code of Conduct](https://www.redditinc.com/policies/content-policy).

## Example Topics:

1. **New Python Release**: What do you think about the new features in Python 3.11?
2. **Community Events**: Any Python meetups or webinars coming up?
3. **Learning Resources**: Found a great Python tutorial? Share it here!
4. **Job Market**: How has Python impacted your career?
5. **Hot Takes**: Got a controversial Python opinion? Let's hear it!
6. **Community Ideas**: Something you'd like to see us do? tell us.

Let's keep the conversation going. Happy discussing! üåü",2,0,2025-11-07 01:00:47,AutoModerator,https://www.reddit.com/r/Python/comments/1oqfalr/friday_daily_thread_rpython_meta_and_freetalk/
1oqvfb5,reddit,A discussion on Python patterns for building reliable LLM-powered systems.,"Hey guys,

I've been working on integrating LLMs into larger Python applications, and I'm finding that the real challenge isn't the API call itself, but building a resilient, production-ready system¬†around¬†it. The tutorials get you a prototype, but reliability is another beast entirely.

I've started to standardize on a few core patterns, and I'm sharing them here to start a discussion. I'm curious to hear what other approaches you all are using.

My current ""stack"" for reliability includes:

1. **Pydantic for everything.**¬†I've stopped treating LLM outputs as strings. Every tool-using call is now bound to a Pydantic model. It either returns a valid, structured object, or it raises an exception that I can catch and handle.
2. **Graph-based logic over simple loops.**¬†For any multi-step process, I'm now using a library like LangGraph to model the flow as a state machine. This makes it much easier to build in explicit error-handling paths and self-correction loops.
3. **""Constitutional"" System Prompts.**¬†Instead of a simple persona, I'm using a very detailed system prompt that acts like a ""constitution"" for the agent, defining its exact scope, rules, and refusal protocols.

I'm interested to hear what other Python-native patterns or libraries you've all found effective for making LLM applications less brittle.



For context, I'm formalizing these patterns into a hands-on course. I'm looking for a handful of experienced Python developers to join a private beta and pressure-test the material.

It's a simple exchange: your deep feedback for free, lifetime access. If that sounds interesting and you're a builder who lives these kinds of architectural problems,¬†**please send me a DM.**",0,2,2025-11-07 15:11:02,petburiraja,https://www.reddit.com/r/Python/comments/1oqvfb5/a_discussion_on_python_patterns_for_building/
1oq1hvw,reddit,"edge-tts suddenly stopped working on Ubuntu (NoAudioReceived error), but works fine on Windows","Hey everyone,

I‚Äôve been using the **edge-tts** Python library for text-to-speech for a while, and it has always worked fine. However, it has recently stopped working on **Ubuntu** machines ‚Äî while it still works perfectly on **Windows,** using the same code, voices, and parameters.

Here‚Äôs the traceback I‚Äôm getting on Ubuntu:

    NoAudioReceived                           Traceback (most recent call last)
     /tmp/ipython-input-1654461638.py in <cell line: 0>()
         13 
         14 if __name__ == ""__main__"":
    ---> 15     main()
    
    10 frames
    /usr/local/lib/python3.12/dist-packages/edge_tts/communicate.py in __stream(self)
        539 
        540             if not audio_was_received:
    --> 541                 raise NoAudioReceived(
        542                     ""No audio was received. Please verify that your parameters are correct.""
        543                 )
    
    NoAudioReceived: No audio was received. Please verify that your parameters are correct.

All parameters are valid ‚Äî I‚Äôve confirmed the voice model exists and is available.

I‚Äôve tried:

* Reinstalling `edge-tts`
* Running in a clean virtual environment
* Using different Python versions (3.10‚Äì3.12)
* Switching between voices and output formats

Still the same issue.

Has anyone else experienced this recently on Ubuntu or Linux?  
Could this be related to a backend change from Microsoft‚Äôs side or some SSL/websocket compatibility issue on Linux?

Any ideas or workarounds would be super appreciated üôè  


code example to test:

    import edge_tts
    
    
    TEXT = ""Hello World!""
    VOICE = ""en-GB-SoniaNeural""
    OUTPUT_FILE = ""test.mp3""
    
    
    
    def main() -> None:
    ¬† ¬† """"""Main function""""""
    ¬† ¬† communicate = edge_tts.Communicate(TEXT, VOICE)
    ¬† ¬† communicate.save_sync(OUTPUT_FILE)
    
    
    
    if __name__ == ""__main__"":
    ¬† ¬† main()",9,4,2025-11-06 16:12:37,Majestic_Side_8488,https://www.reddit.com/r/Python/comments/1oq1hvw/edgetts_suddenly_stopped_working_on_ubuntu/
1opwbhi,reddit,"Single-stock analysis tool with Python, including ratios, news analysis, Ollama and LSTM forecast","Good morning everyone,

I am currently a MSc Fintech student at Aston University (Birmingham, UK) and Audencia Business School (Nantes, France). Alongside my studies, I've started to develop a few personal Python projects.

My first big open-source project: A single-stock analysis tool that uses both market and financial statements informations. It also integrates news sentiment analysis (FinBert and Pygooglenews), as well as LSTM forecast for the stock price. You can also enable Ollama to get information complements using a local LLM.

**What my project (FinAPy) does:**

* Prologue: Ticker input collection and essential functions and data: *In this part, the program gets in input a ticker from the user, and asks wether or not he wants to enable the AI analysis. Then, it generates a short summary about the company fetching information from Yahoo Finance, so the user has something to read while the next step proceeds. It also fetches the main financial metrics and computes additional ones.*



* Step 1: Events and news fetching: *This part fetches stock events from Yahoo Finance and news from Google RSS feed. It also generates a sentiment analysis about the articles fetched using FinBERT.*

¬†

* Step 2: Forecast using Machine Learning LSTM: *This part creates a baseline scenario from a LSTM forecast. The forecast covers 60 days and is trained from 100 last values of close/ high/low prices. It is a quantiative model only. An optimistic and pessimistic scenario are then created by tweaking the main baseline to give a window of prediction. They do not integrate macroeconomic factors, specific metric variations nor Monte Carlo simulations for the moment.*

¬†

* Step 3: Market data restitution: *This part is dedicated to restitute graphically the previously computed data. It also computes CFA classical metrics (histogram of returns, skewness, kurtosis) and their explanation. The part concludes with an Ollama AI commentary of the analysis.*

¬†

* Step 4: Financial statement analysis: *This part is dedicated to the generation of the main ratios from the financial statements of the last 3 years of the company. Each part concludes with an Ollama AI commentary on the ratios. The analysis includes an overview of the variation, and highlights in color wether the change is positive or negative. Each ratio is commented so you can understand what they represent/ how they are calculated. The ratios include:*
   * Profitability ratios:¬†Profit margin, ROA, ROCE, ROE,...
   * Asset related ratios:¬†Asset turnover, working capital.
   * Liquidity ratios:¬†Current ratio, quick ratio, cash ratio.
   * Solvency ratios:¬†debt to assets, debt to capital, financial leverage, coverage ratios,...
   * Operational ratios (cashflow related):¬†CFI/ CFF/ CFO ratios, cash return on assets,...
   * Bankrupcy and financial health scores: Altman Z-score/ Ohlson O-score.



* Appendix: Financial statements: *A summary of the financial statements scaled for better readability in case you want to push the manual analysis further.*

**Target audience:** Students, researchers,... For educational and research purpose only. However, it illustrates how local LLMs could be integrated into industry practices and workflows.

**Comparison:** The project enables both a market and statement analysis perspective, and showcases how a local LLM can run in a financial context while showing to which extent it can bring something to analysts.

At this point, I'm considering starting to work on industry metrics (for comparability of ratios) and portfolio construction. Thank you in advance for your insights, I‚Äôm keen to refine this further with input from the community!

The repository: [gruquilla/FinAPy: Single-stock analysis using Python and local machine learning/ AI tools (Ollama, LSTM).](https://github.com/gruquilla/FinAPy)

Thanks!",13,4,2025-11-06 12:21:12,gruquilla,https://www.reddit.com/r/Python/comments/1opwbhi/singlestock_analysis_tool_with_python_including/
1oqqjhv,reddit,SystemCtl - Simplifying Linux Service Management,"# What my Project Does

I created **SystemCtl**, a small Python module that wraps the Linux systemctl command in a clean, object-oriented API. Basically, it lets you manage systemd services from Python - no more parsing shell output!

```python
from systemctl import SystemCtl

monerod = SystemCtl(""monerod"")
if not monerod.running():
    monerod.start()
print(f""Monerod PID: {monerod.pid()}"")
```

# Target Audience

I realized it was useful in all sorts of contexts, dashboards, automation scripts, deployment tools... So I‚Äôve created a PyPI package to make it generally available.

# Source Code and Docs

- [GitHub repo](https://github.com/NadimGhaznavi/systemctl)
- [Project website](https://systemctl.osoyalce.com)
- [PyPI package](https://pypi.org/project/systemctl/)
- Sphinx documentation on [ReadTheDocs](https://systemctl.readthedocs.io/en/latest/)

# Comparison

The [psystemd](https://github.com/systemd/pystemd) module provides similar functionality.

Feature	 | pystemd | SystemCtl
---------|---------|-----------
Direct D-Bus interface	| ‚úÖ Yes | ‚ùå No
Shell systemctl wrapper	| ‚ùå No | ‚úÖ Yes
Dependencies | Cython, libsystemd | stdlib
Tested for service management workflows | ‚úÖ Yes | ‚úÖ Yes",0,5,2025-11-07 11:06:06,Nadim-Daniel,https://www.reddit.com/r/Python/comments/1oqqjhv/systemctl_simplifying_linux_service_management/
1oq1isg,reddit,Support for Python OCC,"I have been trying to get accustomed to Python OCC, but it seems so complicated and feels like I am  building my own library on top of that.

I have been trying to figure out and convert my CAD Step files into meaningful information like z
Counterbores, Fillets, etc. Even if I try to do it using the faces, cylinders, edges and other stuff I am not sure what I am doing is right or not.


Anybody over here, have any experience with Python OCC?",5,7,2025-11-06 16:13:35,Weekly-One-848,https://www.reddit.com/r/Python/comments/1oq1isg/support_for_python_occ/
1oqmh8s,reddit,Tutorial on Creating and Configuring the venv environment on Linux and Windows Sytems,"Just wrote a tutorial on learning to create a venv (Python Virtual Environment ) on Linux and Windows systems aimed at Beginners.

* Tested on Ubuntu 24.04 LTS and Ubuntu 25.04
* Tested on Windows 11

The tutorial teaches you

* How to Create a venv environment on Linux and Windows Systems
* How to solve ensurepip is not available error on Linux
* How to Solve the Power shell Activate.ps1 cannot be loaded error on Windows
* Structure of Python Virtual Environment (venv) on Linux
* Structure of Python Virtual Environment (venv) on Windows and How it differs from Linux 
* How the Venv Activate modifies the Python Path to use the local Python interpreter
* How to install the packages locally using pip and run your source codes

Here is the link to the Article

* [Introduction to Python venv Environment on Linux and Windows  for Absolute Beginners](https://www.xanthium.in/configuring-python-virtual-environment-venv-tutorial-on-windows-linux-os)",0,4,2025-11-07 06:51:37,xanthium_in,https://www.reddit.com/r/Python/comments/1oqmh8s/tutorial_on_creating_and_configuring_the_venv/
1op2dut,reddit,"FastAPI‚Äôs creator on the framework‚Äôs popularity, FastAPI Cloud, self-taught developers, and more","Hi there! I‚Äôm a huge fan of FastAPI for its focus on developer experience. This year it became [the most popular Python framework](https://blog.jetbrains.com/pycharm/2025/08/the-state-of-python-2025/), which comes as no surprise.

Recently I had the chance to chat with Sebasti√°n Ram√≠rez, the creator of FastAPI. We talked about why it became so popular since [its launch seven years ago](https://www.reddit.com/r/Python/comments/b0zxa9/introducing_fastapi/), what‚Äôs next on the roadmap, FastAPI Cloud, the impact of the faster CPython initiative, and being a self-taught developer (yes, he‚Äôs self-taught!). We also talked about [that famous tweet about companies asking for more years of experience with a framework than it‚Äôs even existed](https://x.com/tiangolo/status/1281946592459853830).

Sebasti√°n was super nice, kind and humble. I didn't expect someone so popular to be so down-to-earth.

I think there are some useful takeaways here for other devs in this community, so I'm sharing the link below. I welcome any feedback for how I can make these interviews better.

[https://youtu.be/iaDRYUQ0OMM](https://youtu.be/iaDRYUQ0OMM)",206,7,2025-11-05 14:08:47,miabajic,https://www.reddit.com/r/Python/comments/1op2dut/fastapis_creator_on_the_frameworks_popularity/
1ooy326,reddit,Optimizing filtered vector queries from tens of seconds to single-digit milliseconds in PostgreSQL,"We actively use pgvector in a production setting for maintaining and querying HNSW vector indexes used to power our recommendation algorithms. A couple of weeks ago, however, as we were adding many more candidates into our database, we suddenly noticed our query times increasing linearly with the number of profiles, which turned out to be a result of incorrectly structured and overly complicated SQL queries.

Turns out that I hadn't fully internalized how filtering vector queries really worked. I knew vector indexes were fundamentally different from B-trees, hash maps, GIN indexes, etc., but I had not understood that they were essentially incompatible with more standard filtering approaches in the way that they are typically executed.

I searched through google until page 10 and beyond with various different searches, but struggled to find thorough examples addressing the issues I was facing in real production scenarios that I could use to ground my expectations and guide my implementation.

Now, I wrote a blog post about some of the best practices I learned for filtering vector queries using pgvector with PostgreSQL based on all the information I could find, thoroughly tried and tested, and currently in deployed in production use. In it I try to provide:

\- Reference points to target when optimizing vector queries' performance  
\- Clarity about your options for different approaches, such as pre-filtering, post-filtering and integrated filtering with pgvector  
\- Examples of optimized query structures using both Python + SQLAlchemy and raw SQL, as well as approaches to dynamically building more complex queries using SQLAlchemy  
\- Tips and tricks for constructing both indexes and queries as well as for understanding them  
\- Directions for even further optimizations and learning

Hopefully it helps, whether you're building standard RAG systems, fully agentic AI applications or good old semantic search!

[https://www.clarvo.ai/blog/optimizing-filtered-vector-queries-from-tens-of-seconds-to-single-digit-milliseconds-in-postgresql](https://www.clarvo.ai/blog/optimizing-filtered-vector-queries-from-tens-of-seconds-to-single-digit-milliseconds-in-postgresql)

Let me know if there is anything I missed or if you have come up with better strategies!",145,15,2025-11-05 10:07:47,m1r0k3,https://www.reddit.com/r/Python/comments/1ooy326/optimizing_filtered_vector_queries_from_tens_of/
1ooysmw,reddit,Nuttiest 1 Line of Code You have Seen?,"Quality over quantity with chained methods, but yeah I'm interested in the maximum set up for the most concise pull of the trigger that you've encountered",78,106,2025-11-05 10:54:32,Inside_Character_892,https://www.reddit.com/r/Python/comments/1ooysmw/nuttiest_1_line_of_code_you_have_seen/
1op8a30,reddit,# Agentic RAG: From Zero to Hero with Python + LangGraph + Ollama,"## What My Project Does

After spending several months building agents and experimenting with RAG systems, I decided to publish a GitHub repository to help those who are approaching agents and RAG for the first time.

I created an **agentic RAG** with an educational purpose, aiming to provide a clear and practical reference. When I started, I struggled to find a single, structured place where all the key concepts were explained. I had to gather information from many different sources‚Äîand that‚Äôs exactly why I wanted to build something more accessible and beginner-friendly.

## Target Audience

Anyone like me who's curious about **how agentic RAG actually works**.

This is a complete educational project that helps you understand how reasoning, retrieval, query rewriting, and memory connect together in a real agent system.

## Comparison

Most RAG tutorials are scattered across Medium posts and YouTube.

This one is a **complete end-to-end implementation** ‚Äî no API keys, no cloud services.

Just you, your machine, and Python doing some real agent magic ‚ú®

## What You'll Learn

- PDF ‚Üí Markdown conversion
- Hierarchical chunking (parent/child)
- Hybrid embeddings (dense + sparse)
- Vector storage with Qdrant
- Parallel multi-query handling
- Query rewriting & human-in-the-loop
- Context management with summarization
- Fully working agentic RAG with LangGraph
- Simple Gradio chatbot interface

## GitHub

[GitHub Repo](https://github.com/GiovanniPasq/agentic-rag-for-dummies)

Let me know what you guys think!",16,6,2025-11-05 17:56:35,CapitalShake3085,https://www.reddit.com/r/Python/comments/1op8a30/agentic_rag_from_zero_to_hero_with_python/
1opdok1,reddit,Cleanest way to handle a dummy or no-op async call with the return value already known?,"Since there doesn't appear to be an async lambda, what's the cleanest way you've found to handle a batch of async calls where the number of calls are variable?

An example use case is that I have a variable passed into a function and if it's true, then I do an additional database look-up.

Real world code:

    ¬† ¬† ¬† ¬† emails, confirmed = await asyncio.gather(
    ¬† ¬† ¬† ¬† ¬† ¬† self._get_emails_for_notifications(),
    ¬† ¬† ¬† ¬† ¬† ¬† (
    ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† self._get_notification_email_confirmed()
    ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† if exclude_unconfirmed_email
    ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† else asyncio.sleep(0, True)
    ¬† ¬† ¬† ¬† ¬† ¬† ),
    ¬† ¬† ¬† ¬† )
    ¬† ¬† ¬† ¬† if not emails or not confirmed:
    ¬† ¬† ¬† ¬† ¬† ¬† raise NoPrimaryNotificationEmailError(self.user_id)
    ¬† ¬† ¬† ¬† return emails[0]

Using a sleep feels icky. Is this really the best approach?",10,13,2025-11-05 21:09:07,JamesHutchisonReal,https://www.reddit.com/r/Python/comments/1opdok1/cleanest_way_to_handle_a_dummy_or_noop_async_call/
1opjo5c,reddit,"Thursday Daily Thread: Python Careers, Courses, and Furthering Education!","# Weekly Thread: Professional Use, Jobs, and Education üè¢

Welcome to this week's discussion on Python in the professional world! This is your spot to talk about job hunting, career growth, and educational resources in Python. Please note, this thread is **not for recruitment**.

---

## How it Works:

1. **Career Talk**: Discuss using Python in your job, or the job market for Python roles.
2. **Education Q&A**: Ask or answer questions about Python courses, certifications, and educational resources.
3. **Workplace Chat**: Share your experiences, challenges, or success stories about using Python professionally.

---

## Guidelines:

- This thread is **not for recruitment**. For job postings, please see r/PythonJobs or the recruitment thread in the sidebar.
- Keep discussions relevant to Python in the professional and educational context.
  
---

## Example Topics:

1. **Career Paths**: What kinds of roles are out there for Python developers?
2. **Certifications**: Are Python certifications worth it?
3. **Course Recommendations**: Any good advanced Python courses to recommend?
4. **Workplace Tools**: What Python libraries are indispensable in your professional work?
5. **Interview Tips**: What types of Python questions are commonly asked in interviews?

---

Let's help each other grow in our careers and education. Happy discussing! üåü",3,0,2025-11-06 01:00:32,AutoModerator,https://www.reddit.com/r/Python/comments/1opjo5c/thursday_daily_thread_python_careers_courses_and/
1op1ghd,reddit,Free Introductory Python Book (amongst others),"I recently discovered the wonderful collection of free textbooks made available by the openstax organisation (https://openstax.org/). There are many books available covering a wide range of disciplines but there‚Äôs one in particular that may be of interest to redditors here, namely Introduction to Python Programming: https://openstax.org/details/books/introduction-python-programming

Another notable example is Principles of Data Science: https://openstax.org/details/books/principles-data-science

There are many others including texts on mathematics and computer science.",22,3,2025-11-05 13:26:25,Timberfist,https://www.reddit.com/r/Python/comments/1op1ghd/free_introductory_python_book_amongst_others/
1oq3332,reddit,python streamlit ideas,"hey guys im working on a streamlit project and im using it to show my co2 valuse and temprature values on the website can anyone give me ideas to make it more nice?    
 i will drop down a google drive link so u people can get the file and make some changes or say make it more nice : [https://drive.google.com/drive/folders/1RlxOmJCWgoYeXnKDqlp6zrNL-Ovcmho\_?usp=drive\_link](https://drive.google.com/drive/folders/1RlxOmJCWgoYeXnKDqlp6zrNL-Ovcmho_?usp=drive_link)",0,4,2025-11-06 17:11:43,Last-Road-93,https://www.reddit.com/r/Python/comments/1oq3332/python_streamlit_ideas/
1opvbpd,reddit,Looking for a Machine Learning / Deep Learning Practice Partner or Group ü§ù,"Hey everyone üëã

I‚Äôm looking for someone (or even a small group) who‚Äôs seriously interested in **Machine Learning, Deep Learning, and AI Agents** ‚Äî to learn and practice together daily.

My idea is simple:
‚úÖ Practice multiple ML/DL algorithms daily with live implementation.
‚úÖ If more people join, we can make a small study group or do regular meetups.
‚úÖ Join **Kaggle competitions** as a team and grow our skills together.
‚úÖ Explore and understand how big models work ‚Äî like **GPT architecture, DeepSeek, Gemini, Perplexity, Comet Browser, Gibliart, Nano Banana, VEO2, VEO3**, etc.
‚úÖ Discuss the **algorithms, datasets, fine-tuning methods, RAG concepts, MCP**, and all the latest things happening in AI agents.
‚úÖ Learn **3D model creation in AI, prompt engineering, NLP, and Computer Vision**.
‚úÖ Read **AI research papers** together and try to implement small projects with AI agents.

Main goal: **consistency + exploration + real projects** üöÄ

If you‚Äôre interested, **DM me** and we can start learning together. Let‚Äôs build our AI journey step by step üí™
",0,1,2025-11-06 11:22:58,ChampionshipWest947,https://www.reddit.com/r/Python/comments/1opvbpd/looking_for_a_machine_learning_deep_learning/
1opcius,reddit,[Showcase] RobotraceSim ‚Äî A Line-Follower Robot Simulator for Fair Controller Benchmarking,"Hi everyone üëã

I‚Äôve built [**RobotraceSim**](https://github.com/Koyoman/robotrace_Sim) ‚Äî an **open-source simulator for line-following robots**, made for running **reproducible, fair comparisons** between different robot designs and Python controllers.

It‚Äôs built entirely in **Python + PySide6**, and everything runs locally with no external dependencies.

# üß© What My Project Does

RobotraceSim lets you:

* üß≠ **Design line tracks** (straights, arcs, start/finish markers) in a visual editor.
* ü§ñ **Model your robot geometry and sensor array** (wheelbase, number and placement of sensors).
* üß† **Plug in your own Python control logic** via a `control_step(state)` function, which runs every simulation tick.
* üìä **Record CSV/JSON logs** to compare performance metrics like lap time, off-track counts, or RMS error.

Essentially, you can **prototype, tune, and benchmark** your control algorithms without touching a physical robot.

# Target Audience

* **Students** learning control systems, robotics, or mechatronics.
* **Hobbyists** who want to experiment with line-following robots or test PID controllers.
* **Researchers / educators** who need a repeatable simulation environment for teaching or demonstrations.
* **Anyone writing robot controllers in Python** and looking for a lightweight visual sandbox.

# Comparison

Most existing robot simulators (like Gazebo or Webots) are **powerful but heavy**‚Äîthey require complex setup, 3D models, and physics tuning.  
**RobotraceSim** focuses on the *2D line-follower niche*: lightweight, fast to iterate, and easy to understand for small-scale experiments.  
It‚Äôs ideal for **teaching, competitions, and algorithm testing**, not for production robotics.

# üí¨ Feedback Welcome

If you write a cool controller (PID, fuzzy logic, etc.) or design a challenging track, please share it ‚Äî I‚Äôd love to feature community experiments on the repo!

üëâ **GitHub:** [https://github.com/Koyoman/robotrace\_Sim](https://github.com/Koyoman/robotrace_Sim)",3,0,2025-11-05 20:26:52,Logical_Lettuce_1630,https://www.reddit.com/r/Python/comments/1opcius/showcase_robotracesim_a_linefollower_robot/
1ooe0g4,reddit,How often does Python allocate?,"Recently a tweet blew up that was along the lines of 'I will never forgive Rust for making me think to myself ‚ÄúI wonder if this is allocating‚Äù whenever I‚Äôm writing Python now' to which almost everyone jokingly responded with ""it's Python, of course it's allocating""

I wanted to see how true this was, so I did some digging into the CPython source and [wrote a blog post about my findings](https://zackoverflow.dev/writing/how-often-does-python-allocate), I focused specifically on allocations of the \`PyLongObject\` struct which is the object that is created for every integer.

I noticed some interesting things:

1. There were a lot of allocations
2. CPython was actually reusing a lot of memory from a freelist
3. Even if it \_did\_ allocate, the underlying memory allocator was a pool allocator backed by an arena, meaning there were actually very few calls to the OS to reserve memory

Feel free to [check out the blog post](https://zackoverflow.dev/writing/how-often-does-python-allocate) and let me know your thoughts!",188,41,2025-11-04 18:50:14,agriculturez,https://www.reddit.com/r/Python/comments/1ooe0g4/how_often_does_python_allocate/
1oolq4o,reddit,"Type safe, coroutine based, purely functional algebraic effects in Python.","Hi gang. I'm a huge statically typed functional programming fan, and I have been working on a functional effect system for python for some years in multiple different projects.

With the latest release of my project https://github.com/suned/stateless, I've added direct integration with asyncio, which has been a major goal since I first started the project. Happy to take feedback and questions. Also, let me know if you want to try it out, either professionally or in your own projects!

**What My Project Does**

Enables type safe, functional effects in python, without monads.

**Target Audience**

Functional Python Enthusiasts.",73,21,2025-11-04 23:38:51,Due_Shine_7199,https://www.reddit.com/r/Python/comments/1oolq4o/type_safe_coroutine_based_purely_functional/
1opbomz,reddit,I built routing system for langchain,"# What My Project Does

I built a Python package called `langchain-fused-model` that allows you to register multiple LangChain `ChatModel` instances (OpenAI, Anthropic, etc.) and route requests across them automatically.

It supports:

* Routing strategies: priority, cost-aware, round-robin, least-used
* Per-model rate limit handling (RPM, RPS, cooldown)
* Fallback when a model times out or fails
* Structured output via Pydantic ‚Äî even when the model doesn‚Äôt support it natively
* Full compatibility with LangChain chains and agents (`BaseChatModel`, `Runnable`)

# Target Audience

This package is for developers building **production-grade LangChain-based LLM applications**. It's especially useful for:

* Handling API limits across multiple providers
* Improving fault tolerance and availability
* Reducing operational costs via cost-aware routing
* Getting structured outputs reliably from any model

# Comparison

LangChain doesn‚Äôt natively support combining multiple chat models into a single managed interface. Many devs create one-off wrappers, but they‚Äôre often limited in scope.

`langchain-fused-model` is:

* Modular and extensible
* Cleanly integrated with LangChain's core abstractions
* Designed for intelligent model orchestration and real-world usage scenarios

# Installation

    pip install langchain-fused-model

# Links

* **GitHub**: [https://github.com/sezer-muhammed/langchain-fused-model](https://github.com/sezer-muhammed/langchain-fused-models)
* **PyPI**: [https://pypi.org/project/langchain-fused-model/](https://pypi.org/project/langchain-fused-model/)

Feedback and contributions are welcome.",0,3,2025-11-05 19:56:39,KalZaxSea,https://www.reddit.com/r/Python/comments/1opbomz/i_built_routing_system_for_langchain/
1oolpva,reddit,Real time execution?,"Hello my wonderful reddit pythonists!

I have for you a question:  
Is there any existing solution that effectively achieve real-time output of every line as I type?

Some background:  
I am a mechanical engineer (well a student, final year) and often do many different calculations and modelling of systems in software. I find that ""calculators"" often don't quite hit the level of flexibility id like to see; think Qalculate for example. Essentially, what I desire is a calculator where I can define variables, write equations, display plots, etc and be able to change a earlier variable having everything below it update in real-time.  
Note: I am NOT new to python/programming. Talk dirty (technical) to me if you must.

What I have already explored:  
Jupyter - Cell based, fine for some calculations where there may be a long running step (think meshing or heavy iteration). Doesn't output all results, only the last without a bunch of print() statements. Requires re-running all cells if a early variable is updated.

Marimo - Closer then Jupyter. Still cell based but updates dynamically. This is pretty close but still not there as it only seems to update dynamically with Marimo ui elements (like scroll bars) but not if I change a raw variable definition, this requires re-running similar to Jupyter.

Homebrewed solution - Here I wrote a script that essentially watches a python file for changes so that upon each save, it will run the script and output based on the definitions (like variables vs comments vs function definitions, etc). Note here that every line gets some sort of output. I paired this script with a package I wrote, pyeng, which essentially provides matlab like function convenience with nice default outputs so that the console shows results quite nicely. pyeng, however, is very naive. pyeng was also for my learning as I progressed through my degree so often functions are naive and slow taking on algorithms similar to how id solve problems by hand. This means many edge cases are not handled, very slow at times, non-standard, and in some cases things are brute force with a custom arbitrary precision Float class to handle potentially non well behaved iterations. pyeng handles units and such as well but everything I have implemented is already covered by some package. This setup doesn't handle plotting very gracefully.

Smath Studio / Excel:  
GUI based, not great.  
SMath Studio is cool. Free but non-commercial (otherwise costs some coin) and has some quirks. Doesn't do symbolic stuff terribly well sometimes. Matrix support is basic. Otherwise, very capable in that it automatically handles units, updates in realtime, supports conditionals, etc.  
Excel simply doesn't do matrices in any nice way and just ain't it. Has its place but not for what I want. No units support either.

Essentially I'm looking for a professional version of my homebrew setup that's made by people smarter than I (if it exists) and if not, is this something that there could be a niche for? Could I have stumbled upon something that doesn't exist but should?

[I have a video showing my homebrew setup to give a better idea.](https://streamable.com/s1kyr3) Its not perfect but it works and its really quite nice.

Thanks folks and apologies for the longer read.",18,55,2025-11-04 23:38:33,Motox2019,https://www.reddit.com/r/Python/comments/1oolpva/real_time_execution/
1opel26,reddit,Reactive Pyside utility | Early Stage,"Hi everyone! üëã

I've been working on a small project‚Äì it's a lightweight pseudo-framework built on top of PySide that aims to bring reactivity and component decoupling into desktop app development.

# üß† What My Project Does

ReactivePySide lets you create connections between models and views that update when something changes. it's reactive programming, but adapted for PySide. The views use pyside signal functions to make events available, but models use custom python code with observer features.



# Alternatives

Currently you could build a desktop app in a traditional way or use some projects react framework  like to achieve reactivity.

# üîß Key Features

* üîÅ Model-to-model and view-to-model reactivity.
* üîå Bridge-based communication ‚Äì enables decoupled components.
* üß© Minimalistic logging utility ‚Äì track changes in your components.
* üß± Encourages separation of concerns ‚Äì build cleaner, modular Uis.

# ‚ö†Ô∏è Current Limitations / Challenges

* **View management is still manual** ‚Äì right now, creating and replacing views must be handled manually by the developer.

# üöÄ Getting Started

The project is small and lightweight ‚Äì only three core files you can drop into your own project and adding a config.json file for logging targets. No pip install (yet), just clone and use.

Here is an example To Do app:

GitHub: [https://github.com/perSuitter/reactiveQtPyside](https://github.com/perSuitter/reactiveQtPyside)

# üôå Who Might Find This Useful / Target Audience

If you're building desktop apps and want something lighter than full frameworks, but still crave reactivity and cleaner architecture, this might be for you.

I'm looking for:

* Anyone who wants to try it
* Feedback on design and structure

Thanks for reading",0,2,2025-11-05 21:42:47,Difficult_Alps4567,https://www.reddit.com/r/Python/comments/1opel26/reactive_pyside_utility_early_stage/
1ooyfas,reddit,Self-Hosting a Production Mobile Server: a Guide on How to Not Melt Your Phone,"I have gotten my prediction accuracy to a remarkable level, and was able to launch and sustain an animation rendering Discord bot with real time physics simulations and heavy cache operations and computational backend. My launcher successfully deferred operations before reaching throttle temperature, predicted thermal events before they happened, and during a stress test where I launched my bot quickly to overheat my phone, my launcher shut down my bot before it reached danger level temperature. 

UPDATE (Nov 5, 2025):

Performance Numbers (1 hour production test on Discord bot serving 645+ members):

============================================================
PREDICTION ACCURACY
============================================================
Total predictions: 21372
MAE:  1.82¬∞C
RMSE: 3.41¬∞C
Bias: -0.38¬∞C
Within ¬±1¬∞C: 57.0%
Within ¬±2¬∞C: 74.6%

Per-zone MAE:
  BATTERY     : 1.68¬∞C (3562 predictions)
  CHASSIS     : 1.77¬∞C (3562 predictions)
  CPU_BIG     : 1.82¬∞C (3562 predictions)
  CPU_LITTLE  : 2.11¬∞C (3562 predictions)
  GPU         : 1.82¬∞C (3562 predictions)
  MODEM       : 1.71¬∞C (3562 predictions)
============================================================

I don't know about everyone else, but I didn't want to pay for a server, and didn't want to host one on my computer. I have a flagship phone; an S25+ with Snapdragon 8 and 12 GB RAM. It's ridiculous. I wanted to run intense computational coding on my phone, and didn't have a solution to keep my phone from overheating. So. I built one. This is non-rooted using sys-reads and Termux (found on Google Play) and Termux API (found on F-Droid), so you can keep your warranty. üî•

Just for ease, the repo is also posted up here.

https://github.com/DaSettingsPNGN/S25_THERMAL-

What my project does: Monitors core temperatures using sys reads and Termux API. It models thermal activity using Newton's Law of Cooling to predict thermal events before they happen and prevent Samsung's aggressive performance throttling at 42¬∞ C. 

Target audience: Developers who want to run an intensive server on an S25+ without rooting or melting their phone. 

Comparison: I haven't seen other predictive thermal modeling used on a phone before. The hardware is concrete and physics can be very good at modeling phone behavior in relation to workload patterns. Samsung itself uses a reactive and throttling system rather than predicting thermal events. Heat is continuous and temperature isn't an isolated event. 

I didn't want to pay for a server, and I was also interested in the idea of mobile computing. As my workload increased, I noticed my phone would have temperature problems and performance would degrade quickly. I studied physics and realized that the cores in my phone and the hardware components were perfect candidates for modeling with physics. By using a ""thermal bank"" where you know how much heat is going to be generated by various workloads through machine learning, you can predict thermal events before they happen and defer operations so that the 42¬∞ C thermal throttle limit is never reached. At this limit, Samsung aggressively throttles performance by about 50%, which can cause performance problems, which can generate more heat, and the spiral can get out of hand quickly. 

My solution is simple: never reach 42¬∞ C

https://github.com/DaSettingsPNGN/S25_THERMAL-

Please take a look and give me feedback.

Thank you!",2,0,2025-11-05 10:30:15,DaSettingsPNGN,https://www.reddit.com/r/Python/comments/1ooyfas/selfhosting_a_production_mobile_server_a_guide_on/
1op5wmk,reddit,How to improve?,"I'm a beginner in python. My school's been teaching basic python for the past 2 years and I can now code basic sql commands (I know around 60 or so) and write small python programs and integrate python and MySQL. But this is the max my school syllabus teaches. Though I'm not a maths student so mostly python wouldn't be much of a use in my career, I'd like to learn more such simple programs and/or learn to write something actually useful. May I know how to approach this? ",0,17,2025-11-05 16:28:59,No_Kaleidoscope7162,https://www.reddit.com/r/Python/comments/1op5wmk/how_to_improve/
1op3ulx,reddit,Books for learning py,"Any tips on a good book to learn how to create analytical applications (crud) with py?
It can be in any language.
This is to help an old Delphi programmer get into the py world.",0,12,2025-11-05 15:09:07,Sufficient-Row2193,https://www.reddit.com/r/Python/comments/1op3ulx/books_for_learning_py/
1op58dz,reddit,üöÄ AERO-V10 ‚Äì Next-Gen Chat & Media Platform in Material Design,"Hey everyone! I‚Äôm excited to share my latest project: AERO-V10, a modern, interactive chat and media platform built with a futuristic material design aesthetic.

What is AERO-V10?
AERO-V10 is designed for seamless communication and media sharing with a focus on real-time chat, music streaming, and extendable plugins. It‚Äôs perfect for small communities, friends, or hobby projects that want a sleek, modern interface.

Key Features:

Real-time Chat: Smooth multi-user interaction with colorful, dynamic UI.

Music Streaming: Stream your favorite songs or radio stations with a dynamic queue.

Custom Plugins: Add commands and interactive tools for more functionality.

Interactive Landing Page: Material-inspired interface with floating shapes, animated feature cards, and carousel demos.

Responsive & Modern: Works on mobile and desktop, designed with futuristic gradients and motion effects.


Why You‚Äôll Love It:
AERO-V10 isn‚Äôt just functional‚Äîit‚Äôs a visually engaging experience. Every interaction is designed to feel smooth, responsive, and futuristic. Perfect for communities that want a chat platform that looks as good as it performs.

Check it out:
GitHub: https://github.com/YOCRRZ224/AERO-V10

I‚Äôd love feedback from the community‚Äîwhether it‚Äôs on features, design, or ideas for new plugins. Let me know what you think!",0,4,2025-11-05 16:03:32,Total-Rutabaga-8512,https://www.reddit.com/r/Python/comments/1op58dz/aerov10_nextgen_chat_media_platform_in_material/
1op3bk6,reddit,How does Python's Internal algorithm for MOD work?,"I am wanting to translate Python's algorithm for MOD over to Forth. Like so in order to get results like Python supplies as below.

        -7 %  26 =  19 (not -7)
        
         7 % -26 = -19 (not  7)

I don't know Python, nor have I Python installed. In an online Python emulator I got the result of 19 (not -7) as shown below.

    d = -7
    e = 26
    f = d % e
    print(f""{d} % {e} = {f}"") 
    -7 % 26 = 19

This agrees also with Perl, as below.

    perl -e "" print -7 % 26 ; ""
    19

So I'm wanting my Forth translation to work the same way. Who might know the algorithm by which that's accomplished?",0,9,2025-11-05 14:47:36,Alternative-Grade103,https://www.reddit.com/r/Python/comments/1op3bk6/how_does_pythons_internal_algorithm_for_mod_work/
1oo8fka,reddit,"[Showcase] trendspyg - Python library for Google Trends data (pytrends
  replacement)"," What My Project Does



  trendspyg retrieves real-time Google Trends data with two approaches:



  RSS Feed (0.2s) - Fast trends with news articles, images, and sources

  CSV Export (10s) - 480 trends with filtering (time periods, categories,

  regions)



  pip install trendspyg



  from trendspyg import download\_google\_trends\_rss



  \# Get trends with news context in <1 second

  trends = download\_google\_trends\_rss('US')



  print(f""{trends\[0\]\['trend'\]}: {trends\[0\]\['news\_articles'\]\[0\]\['headline'\]}"")

  \# Output: ""xrp: XRP Price Faces Death Cross Pattern""



  Key features:

  \- üì∞ News articles (3-5 per trend) with sources

  \- üì∏ Images with attribution

  \- üåç 114 countries + 51 US states

  \- üìä 4 output formats (dict, DataFrame, JSON, CSV)

  \- ‚ö° 188,000+ configuration options



  \---

  Target Audience



  Production-ready for:



  \- Data scientists: Multiple output formats, 24 automated tests, 92% RSS

  coverage

  \- Journalists: 0.2s response time for breaking news validation with credible

  sources

  \- SEO/Marketing: Free alternative saving $300-1,500/month vs commercial APIs

  \- Researchers: Mixed-methods ready (RSS = qualitative, CSV = quantitative)



  Stability: v0.2.0, tested on Python 3.8-3.12, CI/CD pipeline active



  \---

  Comparison



  vs. pytrends (archived April 2025)



  \- pytrends: Had 7M+ downloads, broke when Google changed APIs, now archived

  \- trendspyg: Uses official RSS + CSV exports (more reliable), adds news

  articles/images, actively maintained

  \- Trade-off: No historical data (pytrends had this), but much more stable



  vs. Commercial APIs (SerpAPI, DataForSEO)



  \- Cost: They charge $0.003-0.015 per call ($300-1,500/month) ‚Üí trendspyg is

  free

  \- Features: They have more data sources ‚Üí trendspyg has real-time + news

  context

  \- Use commercial when: You need historical data or enterprise support

  \- Use trendspyg when: Budget-conscious, need real-time trends, open source

  requirement



  vs. Manual Scraping



  \- DIY: 50+ lines of Selenium code, HTML parsing, error handling

  \- trendspyg: 2 lines, structured data, tested & validated

  \- Value: 900x faster than manual research (15min ‚Üí <1sec per trend)



  \---

  Why It's Valuable



  Real use case example:

  \# Journalist checking breaking trend

  trends = download\_google\_trends\_rss('US')

  trend = trends\[0\]



  \# One API call gets you:

  \# - Trending topic: trend\['trend'\]

  \# - News headline: trend\['news\_articles'\]\[0\]\['headline'\]

  \# - Credible source: trend\['news\_articles'\]\[0\]\['source'\]

  \# - Copyright-safe image: trend\['image'\]\['url'\]

  \# - Traffic estimate: trend\['traffic'\]



  \# 15 minutes of manual work ‚Üí 0.2 seconds automated



  Data structure value:

  \- News articles = qualitative context (not just keywords)

  \- Related searches = semantic network analysis

  \- Start/end timestamps = trend lifecycle studies

  \- Traffic volume = virality metrics



  ROI:

  \- Time: Save 2-3 hours daily for content creators

  \- Money: $3,600-18,000 saved annually vs commercial APIs

  \- Data: More comprehensive insights per API call



  \---

  Links



  \- GitHub: [https://github.com/flack0x/trendspyg](https://github.com/flack0x/trendspyg)

  \- PyPI: [https://pypi.org/project/trendspyg/](https://pypi.org/project/trendspyg/)

  \- Tests: 24 passing, 92% coverage -

  [https://github.com/flack0x/trendspyg/actions](https://github.com/flack0x/trendspyg/actions)



  License: MIT (free, commercial use allowed)



  \---

  Feedback Welcome



  1. Is the RSS vs CSV distinction clear?

  2. Would you want async support? (on roadmap)

  3. Any features from pytrends you miss?



  Contributions welcome - especially test coverage for CSV module and CLI tool

  (v0.3.0 roadmap).



  Thanks for reading! üöÄ",9,0,2025-11-04 15:22:29,flack0x,https://www.reddit.com/r/Python/comments/1oo8fka/showcase_trendspyg_python_library_for_google/
1oo8lpf,reddit,CoreSpecViewer: An open-source hyperspectral core scanning platform,"# [](https://www.reddit.com/r/Python/?f=flair_name%3A%22Showcase%22)[CoreSpecViewer](https://github.com/Russjas/CoreSpecViewer/tree/main)

This is my first serious python repo, where I have actually built something rather than just ""learn to code"" projects.

It is pretty niche, a gui for hyperspectral core scanning workflows, but I am pretty pleased with it.

I hope that I have set it up in such a way that I can add pages with extra functionality, additional instrument manufacturers.

If anyone is nerdy enough to want to play with it free data can be downloaded from:

Happy to recieve all comments and criticisms, particularly if anyone does try it on data and breaks it!

**What my project does:**

This is a platform for opening raw hyperspectral core scanning data, processing and performing necessary corrections and processing for interpretation. It also handles all loading and saving of data, including products

**Target Audience**

Principally geologist working with drill core, this data is becoming more and more available, but there is limited choice in commercial applications and most open-souce solution require command line or scripting

**Comparison**  
This is similar to many open-source python libraries, and uses them extensively, but is the only desktop based GUI platform ",6,0,2025-11-04 15:29:10,Russjass,https://www.reddit.com/r/Python/comments/1oo8lpf/corespecviewer_an_opensource_hyperspectral_core/
1ongpc9,reddit,Approved: PEP 798: Unpacking in Comprehensions & PEP 810: Explicit lazy imports,"Today, two PEPS were approved by the Steering Council:

- https://discuss.python.org/t/pep-798-unpacking-in-comprehensions/99435/60 
- https://discuss.python.org/t/pep-810-explicit-lazy-imports/104131/466",297,51,2025-11-03 17:41:00,Ninteendo19d0,https://www.reddit.com/r/Python/comments/1ongpc9/approved_pep_798_unpacking_in_comprehensions_pep/
1oohs41,reddit,"Weak Incentives (Py3.12+) ‚Äî typed, stdlib‚Äëonly agent toolkit","**What My Project Does**  
Weak Incentives is a lean, stdlib‚Äëfirst runtime for side‚Äëeffect‚Äëfree background agents in Python. It composes dataclass‚Äëbacked prompt trees that render deterministic Markdown, parses strict JSON, and records plans/tool calls/staged edits in a session ledger with reducers, rollback, a sandboxed VFS, planning tools, and optional Python‚Äëeval (via asteval). Adapters (OpenAI/LiteLLM) are optional and add structured output + tool orchestration.

**Target Audience**  
Python developers building LLM agents or automation who want reproducibility/auditability, typed I/O, and minimal dependencies (Python 3.12+).

**Comparison**  
Most frameworks emphasize graph schedulers/optimizers or pull in heavy deps. Weak Incentives centers deterministic prompt composition and fail‚Äëclosed structured outputs, with a built‚Äëin session/event model (reducers, rollback) and sandboxed VFS/planning; it works provider‚Äëfree for rendering/state and adds adapters only when you evaluate.

**Source Code:**  
[https://github.com/weakincentives/weakincentives](https://github.com/weakincentives/weakincentives)",1,1,2025-11-04 21:06:52,andreis,https://www.reddit.com/r/Python/comments/1oohs41/weak_incentives_py312_typed_stdlibonly_agent/
1oo4uuk,reddit,pyro-mysql v0.1.8: a fast MySQL client library,"* **What My Project Does**
   * **pyro-mysql** is a fast sync/async MySQL library backed by Rust
* **Repo**
   * [https://github.com/elbaro/pyro-mysql/](https://github.com/elbaro/pyro-mysql/)
* **Bench**
   * [https://github.com/elbaro/pyro-mysql/blob/main/BENCHMARK.md](https://github.com/elbaro/pyro-mysql/blob/main/BENCHMARK.md)
   * For small sync SELECT, `pyro-mysql` is 40% faster than `mysqlclient`
   * For small async SELECT, `pyro-mysql` is 30% faster than `aiomysql`
   * For large SELECT, `pyro-mysql (async)` is x3 faster than `aiomysql/asyncmy`
      * An experimental `wtx` backend (not included in v0.1.8) is x5 faster than `aiomysql`.
   * For sync INSERT, `pyro-mysql` is 50% faster than `mysqlclient`
   * For async INSERT, `pyro-mysql` is 20% slower than `aiomysql`
* **Target Audience**: the library aims to be production-ready
* **Comparison**: see [the previous post](https://www.reddit.com/r/Python/comments/1nxt42j/pyromysql_a_fast_mysql_client_library/)

v0.1.8 adds the sqlalchemy support with the following dialects:

* mysql+pyro\_mysql://
* mysql+pyro\_mysql\_async://
* mariadb+pyro\_mysql://
* mariadb+pyro\_mysql\_async://

It is tested against related test suites from the sqlalchemy repo.",6,2,2025-11-04 12:21:58,Sad_Tap_9191,https://www.reddit.com/r/Python/comments/1oo4uuk/pyromysql_v018_a_fast_mysql_client_library/
1oncd2l,reddit,Pyrefly: Type Checking 1.8 Million Lines of Python Per Second,"How do you type-check 1.8 million lines of Python per second? Neil Mitchell explains how Pyrefly (a new Python type checker) achieves this level of performance.

Python's optional type system has grown increasingly sophisticated since type annotations were introduced in 2014, now featuring generics, subtyping, flow types, inference, and field refinement. This talk explores how Pyrefly models and validates this complex type system, the architectural choices behind it, and the performance optimizations that make it blazingly fast. 

Full talk on Jane Street's youtube channel: https://www.youtube.com/watch?v=Q8YTLHwowcM

Learn more: https://pyrefly.org",239,62,2025-11-03 14:54:46,BeamMeUpBiscotti,https://www.reddit.com/r/Python/comments/1oncd2l/pyrefly_type_checking_18_million_lines_of_python/
1oo4bdj,reddit,Pipelex: DSL and Python runtime for declarative AI workflows with MCP support (MIT),"[https://github.com/Pipelex/pipelex](https://github.com/Pipelex/pipelex)

# What My Project Does

Pipelex is a domain-specific language and Python runtime that lets you write repeatable AI workflows as declarative scripts. Think of it like writing a Dockerfile or SQL query, but for multi-step LLM pipelines. You declare what needs to happen (extract PDF, analyze sentiment, generate report) and the runtime handles execution across any model or provider.

The core insight: instead of writing glue code between API calls, you write `.plx` files that capture your business logic in a structured format that both humans and LLMs can understand. Each step carries natural language context about its purpose and expected inputs/outputs, making workflows auditable and optimizable by AI agents.

Key capabilities:

* Multi-step pipelines with LLM calls, OCR/PDF extraction, image generation, custom Python steps
* Strongly typed structured output via Pydantic v2 schemas
* Conditional branching and parallel execution
* Composable pipes that can call other pipes
* MCP server for agent integration
* FastAPI server, Docker support, n8n node, VS Code extension
* Self-bootstrapping: includes a pipeline that generates new Pipelex workflows from natural language queries

# Target Audience

**Production-ready for specific use cases:** Teams building repeatable AI workflows who want version control, reproducibility, and the ability to share/reuse components. Particularly useful if you're tired of rewriting the same agentic patterns across projects.

**Early adopters welcome:** We're actively seeking feedback from developers building AI applications, especially those working with MCP (Model Context Protocol) or needing to integrate AI workflows into existing systems via n8n or APIs.

**Not yet suitable for:** Teams needing extensive pre-built app connectors (we focus on cognitive steps, not SaaS integrations) or hosted infrastructure (self-host only for now).

# Comparison

**vs. LangChain/LlamaIndex:** These are imperative Python frameworks where you write custom code to orchestrate AI calls. Pipelex is declarative: you describe the workflow in a DSL, and the runtime handles execution. This separation makes workflows portable, shareable, and understandable by both humans and AI agents without parsing Python code.

**vs. BAML:** BAML generates typed SDK clients for single LLM function calls that you orchestrate in your app code. Pipelex is a complete workflow orchestrator where non-LLM operations (OCR, PDF parsing, image generation) are first-class citizens alongside LLM steps. Both support structured outputs, but Pipelex handles the entire pipeline execution.

**vs. n8n/Zapier:** These are visual workflow builders with fixed node types. Pipelex workflows are text files (better for version control, diffs, code review) and every step includes semantic context that AI agents can understand and modify. Plus, Pipelex actually integrates with n8n as a node type for hybrid workflows.

**vs. Temporal/Airflow:** These orchestrate traditional code/containers. Pipelex orchestrates AI-native operations with built-in understanding of prompts, structured generation, and model selection, while maintaining deterministic execution.

**Links:**

* GitHub main repo: [https://github.com/Pipelex/pipelex](https://github.com/Pipelex/pipelex)
* Docs: [https://docs.pipelex.com](https://docs.pipelex.com/)
* Demo video: [https://go.pipelex.com/demo](https://go.pipelex.com/demo)
* Discord: [https://go.pipelex.com/discord](https://go.pipelex.com/discord)

Looking for contributors and feedback on the DSL design, MCP integration, and what pipes the community needs. Everything's MIT licensed.",3,0,2025-11-04 11:50:28,lchoquel,https://www.reddit.com/r/Python/comments/1oo4bdj/pipelex_dsl_and_python_runtime_for_declarative_ai/
1onnwlx,reddit,Intercom ‚Äî Open-Source WebRTC Audio & Video Intercom System in Python,"Hi Friends,

I just finished an open-source project called **Intercom**. It turns any computer with a **microphone**, **speakers**, and **webcam** into a remote intercom. You can **talk**, **listen**, and **watch** in real time through your browser using **WebRTC**.

**Repo:** [https://github.com/zemendaniel/intercom](https://github.com/zemendaniel/intercom)

# What My Project Does

Intercom allows a single user to remotely stream **video** and **audio** from a Linux machine to a browser. The user can monitor a space and communicate in real-time with anyone watching. It uses **WebRTC** for low-latency streaming and **Python/Quart** as the backend.

# Target Audience

* Hobbyists or developers who want a **self-hosted intercom system**
* People looking for a **lightweight, Python-based WebRTC solution**
* Small deployments where **1 user streams** and **1 viewer watches**

>

# Comparison

Unlike commercial tools like Zoom or Jitsi, Intercom is:

* **Self-hosted:** No third-party servers required for video/audio except for optional TURN relay.
* **Lightweight & Python-powered:** Easy to read, modify, and extend.
* **Open-source GPLv3 licensed:** Guarantees users can use, modify, and redistribute freely.

# Features

* üîä Two-way audio communication
* üé• Live video streaming
* üîê Password-protected single-user login
* ‚öôÔ∏è Built with **Python**, **Quart**, and **aiortc**
* üß© Uses **Coturn** for TURN/STUN relay support
* üñ•Ô∏è Easy deployment on Linux (Ubuntu/Debian)

# Tech Stack

* Python 3.11+
* Quart (async web framework)
* aiortc (WebRTC + media handling)
* Hypercorn (ASGI server)
* Coturn (TURN/STUN server)
* ALSA + PortAudio (sound I/O)

# TL;DR

Plug in a mic, speakers, and webcam to your Linux computer ‚Äî then talk, listen, and watch remotely in your browser. Open-source, Python-powered, and uses WebRTC.

‚úÖ Please feel free to open an issue if you find a bug. If you found this project useful, please ‚≠ê the repo. Contributions are welcome!",15,0,2025-11-03 22:01:45,Mr_Dani17,https://www.reddit.com/r/Python/comments/1onnwlx/intercom_opensource_webrtc_audio_video_intercom/
1oneky5,reddit,Best Python Notebooks out there,"Hey everyone!

I‚Äôm a programmer preparing to teach a Python training session. I already have a collection of Jupyter Notebooks from previous courses, but they often feel a bit dull and uninspiring.

The training will cover Python fundamentals (variables, core data structures, functions, classes) and move up to NumPy, Matplotlib, and file I/O.



I‚Äôd love to know: what are some of the best or most engaging Jupyter Notebooks you‚Äôve come across during your learning journey?



Thanks in advance!",23,30,2025-11-03 16:22:13,gstvschlz,https://www.reddit.com/r/Python/comments/1oneky5/best_python_notebooks_out_there/
1on9xtt,reddit,Debugging live code with CPython 3.14,"Debugging a live Python process just got incredibly easier in Python 3.14, but when I read the release notes I didn't pay much attention to PEP 768: Safe external debugger interface for CPython, not every PEP sparks enough interest to me to spend 1-2 days going pep-deep, and I was honestly eclipsed by the new Template strings and the Multiple interpreters in the standard library.

It was not until I saw ‚ô±‚ò†Ô∏éÔ∏é Pablo Galindo ìÉµ‚ô±, a core CPython and one of PEP's authors live at PyConES that I understood the importance of this, since it changes the way we will be debugging Python...

[https://surister.dev/blog/debugging-live-python-code](https://surister.dev/blog/debugging-live-python-code)",41,1,2025-11-03 13:04:28,surister,https://www.reddit.com/r/Python/comments/1on9xtt/debugging_live_code_with_cpython_314/
1oociik,reddit,Py ‚Üî Ipynb converter for folders/subfolders,"# What My Project Does

This Python script batch converts `.py` ‚Üî `.ipynb` files in folders and subfolders.  
It works recursively, skips unrelated files, and includes an interactive option to delete the original file after conversion.

# Target Audience

Python developers, data scientists, and anyone who frequently works with both scripts and Jupyter notebooks and wants to automate conversions for multiple files at once.

# Comparison

Most existing converters only handle single files and don‚Äôt offer folder recursion or the ability to selectively delete original files.  
This script solves those limitations in a simple, interactive way.

**Source Code:**  
[https://github.com/Excentrik0/py-ipynb-folder-converter](https://github.com/Excentrik0/py-ipynb-folder-converter)",0,5,2025-11-04 17:56:11,Excentrik0_,https://www.reddit.com/r/Python/comments/1oociik/py_ipynb_converter_for_folderssubfolders/
1onpsfk,reddit,üêç yaradb-client: The official Python client for YaraDB is here!,"*(Following up on my last post about the YaraDB server)*

## What It Does

Yaradb-client ‚Äî an official, lightweight client to make integration dead simple.

**Instead of this:**

```python
# Manual, error-prone, no helpers
import requests

resp = requests.post(
    ""http://localhost:8000/document/create"",
    json={""name"": ""user"", ""body"": {""..."": ""...""}}
)
doc_id = resp.json()[""_id""]
```

**You just do this:**

```python
# Clean, simple, and handles errors
from yaradb_client import YaraClient, YaraConflictError

client = YaraClient(""http://localhost:8000"")
doc = client.create(name=""user"", body={""..."": ""...""})
print(doc[""_id""])
```

It gives you:

- **Simple Pythonic API**: `client.create()`, `client.get()`, `client.update()`, `client.archive()`
- **Built-in OCC Handling**: The `client.update()` method requires the version, making optimistic locking easy
- **Clean Error Handling**: Raises custom exceptions like `YaraConflictError` or `YaraNotFoundError` instead of you checking status codes
- **Zero Config**: Just `pip install yaradb-client` and point it at your server

## Target Audience

For Python devs who saw my YaraDB (the server) and want to actually use it in their app, script, or side project without writing HTTP plumbing.

Unlike manually using requests, the client abstracts away all the URL endpoints, JSON payloads, and HTTP error checking. It lets you think in Python objects, not HTTP requests.

**Client Repo ‚Üí** [github.com/illusiOxd/yaradb-client-py](https://github.com/illusiOxd/yaradb-client-py)  
**Server Repo ‚Üí** [github.com/illusiOxd/yaradb](https://github.com/illusiOxd/yaradb)
**PyPI Package ‚Üí** [https://pypi.org/project/yaradb-client](https://pypi.org/project/yaradb-client/)",7,0,2025-11-03 23:13:07,illusiON_MLG1337,https://www.reddit.com/r/Python/comments/1onpsfk/yaradbclient_the_official_python_client_for/
1ond5hm,reddit,How does fastapi handles concurrency with websocket infinite loops?,I was trying to learn websockets and it's logic is soooo hard. I thought of a simple task as a test. there will be 3 clients the 1st 2 would be in private chat room and the 3rd would be in broadcast mode. It took me 5 hrs to write this simple logic because I was facing issues for not handling the disconnect states properly. This made me wonder how does web frameworks and browsers handles concurrency with infinite loops?,13,6,2025-11-03 15:26:51,exeNOS15,https://www.reddit.com/r/Python/comments/1ond5hm/how_does_fastapi_handles_concurrency_with/
1ond0j4,reddit,Title: TripWire - Python library for managing environment variables with validation,"I built TripWire to solve a problem I kept running into: environment variables failing silently or with cryptic errors in production.¬†

**What My Project Does**

TripWire provides:¬†- Type validation for environment variables¬†- Clear error messages when config is wrong¬†- Support for common types (int, bool, lists, URLs, etc.)¬†- Easy integration with existing projects¬†

GitHub: [https://github.com/Daily-Nerd/TripWire](https://github.com/Daily-Nerd/TripWire)

It's early but functional. Feedback welcome.",14,9,2025-11-03 15:21:18,Sea-Perception1619,https://www.reddit.com/r/Python/comments/1ond0j4/title_tripwire_python_library_for_managing/
1onsfns,reddit,Tuesday Daily Thread: Advanced questions,"# Weekly Wednesday Thread: Advanced Questions üêç

Dive deep into Python with our Advanced Questions thread! This space is reserved for questions about more advanced Python topics, frameworks, and best practices.

## How it Works:

1. **Ask Away**: Post your advanced Python questions here.
2. **Expert Insights**: Get answers from experienced developers.
3. **Resource Pool**: Share or discover tutorials, articles, and tips.

## Guidelines:

* This thread is for **advanced questions only**. Beginner questions are welcome in our [Daily Beginner Thread](#daily-beginner-thread-link) every Thursday.
* Questions that are not advanced may be removed and redirected to the appropriate thread.

## Recommended Resources:

* If you don't receive a response, consider exploring r/LearnPython or join the [Python Discord Server](https://discord.gg/python) for quicker assistance.

## Example Questions:

1. **How can you implement a custom memory allocator in Python?**
2. **What are the best practices for optimizing Cython code for heavy numerical computations?**
3. **How do you set up a multi-threaded architecture using Python's Global Interpreter Lock (GIL)?**
4. **Can you explain the intricacies of metaclasses and how they influence object-oriented design in Python?**
5. **How would you go about implementing a distributed task queue using Celery and RabbitMQ?**
6. **What are some advanced use-cases for Python's decorators?**
7. **How can you achieve real-time data streaming in Python with WebSockets?**
8. **What are the performance implications of using native Python data structures vs NumPy arrays for large-scale data?**
9. **Best practices for securing a Flask (or similar) REST API with OAuth 2.0?**
10. **What are the best practices for using Python in a microservices architecture? (..and more generally, should I even use microservices?)**

Let's deepen our Python knowledge together. Happy coding! üåü",2,0,2025-11-04 01:00:31,AutoModerator,https://www.reddit.com/r/Python/comments/1onsfns/tuesday_daily_thread_advanced_questions/
1on90sr,reddit,Non VS Code dev setups,"I like to experiment with other IDE's and most recently tried [Positron](https://positron.posit.co/) which feels very promising for a data science oriented workflow. Often however, I resort back to vs code due to pylance. I've yet to find a LSP which works as well out of the box. Based pyright / pyright feels sluggish and tends to be to strict in it's type checking capabilities. 

  
What I love about pylance is the goto-definition, fast file scanning and autocomplete. Works just as well for notebooks (which is common in my workflow).

  
I'm currently using

* vscode ( + pylance)
* uv
* ruff
* mypy

  
coding primarily on wsl ubuntu 



Any one else using other IDE with similar workflows and tools?",10,53,2025-11-03 12:14:30,_besten,https://www.reddit.com/r/Python/comments/1on90sr/non_vs_code_dev_setups/
1onsgqd,reddit,NextMCP - Production-grade MCP server toolkit with minimal boilerplate,"I just released NextMCP v0.1.0 on PyPI! It's a toolkit for building Model Context
  Protocol (MCP) servers with minimal boilerplate.

  **What My Project Does**

  NextMCP lets you build production-ready MCP servers in minutes instead of hours. It
  provides:

  Core Features:

  ‚Ä¢ Decorator-based tool registration (no boilerplate)

  ‚Ä¢ Global and tool-specific middleware system

  ‚Ä¢ Built-in monitoring with Prometheus & JSON exporters

  ‚Ä¢ WebSocket transport with async support

  ‚Ä¢ Plugin architecture for extending functionality

  ‚Ä¢ CLI with hot-reload during development

  Quick Example:

      from nextmcp import NextMCP

      app = NextMCP(""weather-bot"")

      @app.tool()
      async def get_weather(city: str) -> str:
          """"""Get current weather for a city""""""
          return f""Weather in {city}: Sunny, 72¬∞F""

      if __name__ == ""__main__"":
          app.run()

  That's it! You now have a fully functional MCP server with monitoring, error
  handling, and production-ready features.

  **Target Audience**

  This is for developers who:

  ‚Ä¢ Want to build MCP servers quickly without reinventing infrastructure

  ‚Ä¢ Need production features (monitoring, middleware, error handling) out of the box

  ‚Ä¢ Are building AI agents or tools that need MCP integration

  ‚Ä¢ Want a FastAPI-like developer experience for MCP

  **Comparison**

  vs Raw FastMCP:

  NextMCP builds on FastMCP but adds production essentials - built-in middleware
  system, monitoring & metrics out of the box, plugin architecture for extensibility,
  CLI with project scaffolding, and ready-to-use middleware for auth, rate limiting,
  and caching.

  vs Building from Scratch:

  10x faster development (no boilerplate), battle-tested patterns for common tasks,
  production features included (monitoring, error handling), and active development
  and community support.

  **Installation**

      pip install nextmcp

  **Links**

  GitHub: https://github.com/KeshavVarad/NextMCP

  PyPI: https://pypi.org/project/nextmcp/

  Documentation: See README for full examples

  **Why I Built This**

  I kept rebuilding the same infrastructure (middleware, monitoring, error handling)
  for every MCP project. NextMCP packages those patterns into a reusable toolkit so
  you can focus on your server's logic instead of plumbing.

  Would love feedback from the community! What features would make this more useful
  for your projects?

  ---",2,0,2025-11-04 01:01:39,PresentationMurky786,https://www.reddit.com/r/Python/comments/1onsgqd/nextmcp_productiongrade_mcp_server_toolkit_with/
1on3ta4,reddit,fastapi-async-storages: Async Cloud Storage Backends for FastAPI apps,"Hey everyone,

I've been working on an open-source package called¬†**fastapi-async-storages**¬†and would love to share it with you all!

# What My Project Does

fastapi-async-storages is a powerful, extensible, and async-ready cloud object storage backend for FastAPI. It makes integrating async file storage into your FastAPI apps seamless ‚Äì offering plug-and-play support for S3 and more, with a clean, consistent interface. It's designed to be easy for anyone building modern, performant web APIs with FastAPI.

**Key features:**

* Full async/await support throughout
* Drop-in S3 backend (aioboto3), pluggable design for more
* Compatible with both SQLAlchemy/SQLModel usage
* Clean docs and tested examples for real apps
* MIT-licensed and built to be extended for other storage providers

# Target Audience

This library targets Python developers building production-ready FastAPI applications requiring async file or object storage solutions. It is also suited for open-source contributors interested in backend storage integrations in async Python ecosystems.

# Comparison

Unlike traditional synchronous storage libraries or monolithic SDKs, fastapi-async-storages is designed from the ground up for async workflows, offering better scalability for concurrent applications. Its modular and extensible architecture allows easy addition of new storage backends, whereas many existing libraries are service-specific or lack async support.

If you're building something with FastAPI that needs async file or object storage, I hope this might save you time or inspire new approaches!

**Source code:**¬†[https://github.com/stabldev/fastapi-async-storages](https://github.com/stabldev/fastapi-async-storages)  
**Docs & Getting Started:**¬†[https://fastapi-async-storages.readthedocs.io/en/latest/](https://fastapi-async-storages.readthedocs.io/en/latest/)  
**PyPI:**¬†[https://pypi.org/project/fastapi-async-storages](https://pypi.org/project/fastapi-async-storages)

Would love feedback, ideas, or contributions. If you end up using it or running into any snags, please let me know. Thanks for checking it out!",8,2,2025-11-03 06:41:01,stabldev,https://www.reddit.com/r/Python/comments/1on3ta4/fastapiasyncstorages_async_cloud_storage_backends/
1onjhyo,reddit,"I made some Jupyter notebooks to run any AI models (Vision, LLM, Audio) locally ‚Äî CPU, GPU, or NPU","I‚Äôve been trying to make it easier to run real AI models from Python without needing to set up a full backend or mess with runtimes.

So I put together a few Jupyter notebooks that uses`nexa-sdk` ‚Äî you can load an LLM, a vision model, or speech model with a single line. Works on whatever backend you have: CPU, GPU (including Apple MLX)., or even NPU

They‚Äôre simple enough to learn from, but powerful enough to test real models like Qwen, Parakeet, or OmniNeural, etc.  
  
Repo‚Äôs here - choose your appropriate operating system.  
[https://github.com/NexaAI/nexa-sdk/tree/main/bindings/python/notebook](https://github.com/NexaAI/nexa-sdk/tree/main/bindings/python/notebook)

If you‚Äôve been wanting to mess with local inference without spinning up servers, this should save you some setup time. 

Let me know if you have any questions for running AI models. I'd love to share and discuss my learnings.",0,1,2025-11-03 19:20:16,AlanzhuLy,https://www.reddit.com/r/Python/comments/1onjhyo/i_made_some_jupyter_notebooks_to_run_any_ai/
1omy90e,reddit,What‚Äôs your dream scRNA-seq package?,"Curious question for the single-cell crowd here ‚Äî if you could snap your fingers and instantly have¬†*one brand-new R or Python package*¬†for scRNA-seq analysis, what would it do?

There are already so many great tools ‚Äî¬†*Scanpy, Seurat, scVI, CellRank, scvelo, monocle3, inferCNV, etc.*¬†‚Äî but it feels like there are still gaps no one‚Äôs filled cleanly yet.",7,5,2025-11-03 01:57:29,Top_Pomelo7996,https://www.reddit.com/r/Python/comments/1omy90e/whats_your_dream_scrnaseq_package/
1on6pz3,reddit,gibr - a plugin-based Python CLI to automate Git branch naming integrating with issue trackers,"# üß∞ What My Project Does

I originally built a Python tool at work called **jig** to help with our Jira + GitLab workflow. It made life much easier ‚Äî a simple command like:

    jig 123
    

would create a properly named branch (no need to specify Jira project key), push it, open a GitLab Merge Request with a pre-filled description, and move the Jira issue to *In Progress*.

It was very successful (still in use today), but after leaving that job I decided to rewrite it from scratch, this time making it flexible enough to work with **any issue tracker**.

The rewrite ‚Äî now called **gibr** ‚Äî provides the same convenience, but with a cleaner, plugin-based design.

# üß© Target Audience

gibr is meant for **developers who frequently work with Git-based repos connected to issue trackers** (like Jira, GitHub, GitLab, or Linear).  
It‚Äôs production-ready, but also lightweight enough for personal projects and teams that want to standardize their branch naming and automation workflows.

# ‚öôÔ∏è Comparison

There are other Git helper tools, but most are tied to one platform (e.g., GitHub CLI or GitLab CLI).  
gibr focuses on being **tracker-agnostic** and **extensible** ‚Äî you can easily add support for a new issue tracker by writing a small plugin class.

# ‚ú® Some Technical Details

* ‚å®Ô∏è**Built with Click** (I used to use argparse, but I‚Äôm loving Click).
* üß©**Plugin-based architecture** ‚Äî adding a new issue tracker just means writing a class.
* ü™∂**Optional dependencies and lazy loading** ‚Äî install only what you need.
* üß™**Tested with pytest (90%+ coverage)**.
* üßπ**Linted with ruff** for clean, consistent code.
* ‚öôÔ∏è**Easy setup** via an `init` command that creates a config file.

# üíª Example usage

    # List open issues
    $ gibr issues
    |   Issue | Type   | Title                                 | Assignee   |
    |---------|--------|---------------------------------------|------------|
    |     123 | issue  | Add support for OAuth2 / login (beta) | ytreister  |
    |      97 | issue  | Add support for gitlab                |            |
    
    # Start work on an issue
    $ gibr 123
    Generating branch name for issue #123: Add support for OAuth2 / login (beta)
    ‚úÖ  Created and Pushed branch 'ytreister/issue/123/add-support-for-oauth2-login-beta' to origin.
    

I just released **version 0.6.0** and would love feedback or ideas for future improvements.  
Please feel free to open a discussion or issue!

**Repo:** [github.com/ytreister/gibr](https://github.com/ytreister/gibr)",0,0,2025-11-03 09:48:53,Maximum-Geologist493,https://www.reddit.com/r/Python/comments/1on6pz3/gibr_a_pluginbased_python_cli_to_automate_git/
1omqcem,reddit,FTS-Tool: Fast Peer-to-Peer LAN File Transfers & Chat,"FTS-Tool is a lightweight CLI tool and GUI application for local-network file transfers and communication.

Key features:

* LAN chat
* Contacts & online users
* Intuitive file transfers with progress display
* Transfer history tracking

FTS-Tool uses¬†[Textual](https://textual.textualize.io/) for its GUI and a custom logger for clean CLI output.

**What My Project Does:**

This tool merges file transfer and chat messaging into one application for ease-of-use and works out the box after install. The behavior of FTS-Tool may be modified by changing the config files in .fts, located in the user directory. The tool is published to pypi and can be installed with the classic pip command: pip install fts-tool.

**Target Audience:**

FTS-Tool is developed for office environments to make communication and file sharing more straightforward. The tool is supposed to replace the need of uploading a temporary file to a network drive just to transfer to another computer on land. This could take longer than necessary and could clutter or stress the drive with downloading/uploading to a drive for a peer-to-peer transfer.

**Comparison:**

Fts-Tool is simplified and to the point. It is designed to be intuitive to anyone in the work place. Not just the tech savy employees. Unlike other chat tools, Fts-Tool does not require joining chat rooms and instead has a global chat for less required setup. It also is supposed to take out the middleman in file-transfers and work peer-to-peer. As a result, Fts-tool doesn't require WAN access as it runs primarly through LAN.

The GitHub repo contains more information and also includes documentation for the use of FTS-Tool in the command line. Any feedback on the gui, intuitiveness, any user inconvenience, or features absent from a tool like this would be greatly appreciated. Thank you for your time.

pypi:¬†[https://pypi.org/project/fts-tool](https://pypi.org/project/fts-tool)  
github:¬†[https://github.com/Terabase-Studios/fts](https://github.com/Terabase-Studios/fts)",12,14,2025-11-02 20:26:36,Ashamed_Theme9456,https://www.reddit.com/r/Python/comments/1omqcem/ftstool_fast_peertopeer_lan_file_transfers_chat/
1omoq1q,reddit,Demo link for a Python based and focused code visualizer,"Sorry for bothering you all with additional post noise, but I wanted to put this out here given the relevance to this sub in the hopes some of you might find it interesting. I developed a Python codebase visualizer which is still in the very early stages. I am assessing whether it is something worth further developing or just keeping it focused on what I specifically wanted out of it when I started. I think there is some value to it even though it is not in any way the first of it's kind. Just gauging interest and figuring out where to focus my energy going forward. The other post has additional information and a link to the demo video that I uploaded to youtube. Cheers.

[Original Post](https://www.reddit.com/r/SideProject/comments/1om7dzj/interactive_tool_for_visualizing_understanding/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)",7,2,2025-11-02 19:23:12,BaseDue9532,https://www.reddit.com/r/Python/comments/1omoq1q/demo_link_for_a_python_based_and_focused_code/
1oma4yc,reddit,pygitzen - a pure Python based Git client with terminal user interface inspired by LazyGit!,"I've been working on a side project for a while and finally decided to share it with the community. Checkout¬†[pygitzen](https://pypi.org/project/pygitzen/)¬†\- a terminal-based Git client built entirely in Python, inspired by LazyGit.



**What My Project Does**

pygitzen is a TUI (Terminal User Interface) for Git repositories that lets you navigate commits, view diffs, track file changes, and manage branches - all without leaving your terminal. Think of it as a Python-native LazyGit.

  
**Target Audience**

I'm a terminal-first developer and love tools like¬†`htop`,¬†`lazygit`, and¬†`fzf`. So this tool is made with such users in mind. Who loves TUI apps and wanted python solution for app like lazygit etc which can be used in times like where there is restriction to install any thing apart from python package or wanted something pure python based TUIs.

  
**Comparison**

Currently there is no pure python based TUI git client.

* Pure Python (no external git CLI needed)
* VSCode-style file status panels
* Branch-aware commit history
* Push status indicators
* Vim-style navigation (j/k, h/l)



**Try it out!**

If you're a terminal-first developer who loves TUIs, give it a shot:

    pip install pygitzen
    
    cd <your-git-repo>
    
    pygitzen

  
**Feedback welcome!**

This is my first PyPI package, so I'd love feedback on:

* What features are missing?
* What could be improved?
* Is the UI intuitive?
* Any bugs or issues?

**Repo**:

[https://github.com/SunnyTamang/pygitzen](https://github.com/SunnyTamang/pygitzen)

**PyPI installation**: 

[https://pypi.org/project/pygitzen/](https://pypi.org/project/pygitzen/)

Let me know what you think!",42,26,2025-11-02 07:18:56,Visual_Loquat_8242,https://www.reddit.com/r/Python/comments/1oma4yc/pygitzen_a_pure_python_based_git_client_with/
1omx03o,reddit,Monday Daily Thread: Project ideas!,"# Weekly Thread: Project Ideas üí°

Welcome to our weekly Project Ideas thread! Whether you're a newbie looking for a first project or an expert seeking a new challenge, this is the place for you.

## How it Works:

1. **Suggest a Project**: Comment your project idea‚Äîbe it beginner-friendly or advanced.
2. **Build & Share**: If you complete a project, reply to the original comment, share your experience, and attach your source code.
3. **Explore**: Looking for ideas? Check out Al Sweigart's [""The Big Book of Small Python Projects""](https://www.amazon.com/Big-Book-Small-Python-Programming/dp/1718501242) for inspiration.

## Guidelines:

* Clearly state the difficulty level.
* Provide a brief description and, if possible, outline the tech stack.
* Feel free to link to tutorials or resources that might help.

# Example Submissions:

## Project Idea: Chatbot

**Difficulty**: Intermediate

**Tech Stack**: Python, NLP, Flask/FastAPI/Litestar 

**Description**: Create a chatbot that can answer FAQs for a website.

**Resources**: [Building a Chatbot with Python](https://www.youtube.com/watch?v=a37BL0stIuM)

# Project Idea: Weather Dashboard

**Difficulty**: Beginner

**Tech Stack**: HTML, CSS, JavaScript, API

**Description**: Build a dashboard that displays real-time weather information using a weather API.

**Resources**: [Weather API Tutorial](https://www.youtube.com/watch?v=9P5MY_2i7K8)

## Project Idea: File Organizer

**Difficulty**: Beginner

**Tech Stack**: Python, File I/O

**Description**: Create a script that organizes files in a directory into sub-folders based on file type.

**Resources**: [Automate the Boring Stuff: Organizing Files](https://automatetheboringstuff.com/2e/chapter9/)

Let's help each other grow. Happy coding! üåü",1,1,2025-11-03 01:00:30,AutoModerator,https://www.reddit.com/r/Python/comments/1omx03o/monday_daily_thread_project_ideas/
1omv4m1,reddit,Need a transliteration library,"Go to bottom for actual question

I am doing a project for fun, an AI model that can recognize a word‚Äôs or a sentence‚Äôs language, and I have figured out everything important. The only thing I haven‚Äôt completely figured out is transliteration: if I kept words in their original script then 1. Well of course that word is from that language, the character only appears in it and 2. I can‚Äôt write a romanized word in and get the language it‚Äôs from, which is why I‚Äôm making it so that every time you interact with the model he doesn‚Äôt see what you input but a cleaned and romanized word (spaces are removed). The issue I‚Äôm having is with this: the library unidecode does what it should, but it does a terrible job at it: it removes vowels from Indic and Arabic languages (and Semitic too probably but I didn‚Äôt test it yet), and for the Arabic ones it also does a terrible job. Then I tried the library ‚Äúaksharamukha‚Äù, which does a wonderful job with Semitic languages but has no support for Asian ones whatsoever, and I also can‚Äôt just use a library that requires me to manually input the original script it‚Äôs in for each transliteration (since It would be a whole nother mess). 

In short: I need a transliteration library with coverage for all main (and not main) scripts that automatically detects them and makes them into Latin Script.

Sorry for the long post.",1,9,2025-11-02 23:38:04,Sufficient_Virus_322,https://www.reddit.com/r/Python/comments/1omv4m1/need_a_transliteration_library/
1olyidq,reddit,üåü Myfy: a modular Python framework with a built-in frontend,"**What It Does**

Tired of gluing FastAPI + Next.js together, I built [**Myfy**](https://github.com/psincraian/myfy) ‚Äî a **modular Python framework** that ships with a frontend by default.

Run:

    myfy frontend init

and you instantly get:

* üìù Jinja2 templates
* üé® DaisyUI 5 + Tailwind 4 + Vite + HMR
* üåó Dark mode
* üöÄ Zero config that works out of the box

**Target Audience**

For Python devs who love backend work but want a frontend without touching JS.  
Perfect for side projects, internal tools, or fast prototypes.

**Comparison**

Unlike FastAPI + Next.js or Flask + React, Myfy gives you a full-stack Python experience with plain HTML + modern CSS.

Repo ‚Üí [github.com/psincraian/myfy](https://github.com/psincraian/myfy)  
If it sounds cool, drop a ‚≠ê and tell me what you think!",83,25,2025-11-01 21:43:50,psincraian,https://www.reddit.com/r/Python/comments/1olyidq/myfy_a_modular_python_framework_with_a_builtin/
1on22u9,reddit,üÜï ttkbootstrap-icons 3.1 ‚Äî Stateful Icons at Your Fingertips üé®üí°,"Hey everyone ‚Äî I‚Äôm excited to announce **v3.1** of **[ttkbootstrap-icons](https://github.com/israel-dryer/ttkbootstrap-icons)** is bringing major enhancements to its icon system.

## üí´ What‚Äôs new

### Stateful icons

You can now map icons to widget states ‚Äî **hover**, **pressed**, **selected**, **disabled** ‚Äî without manually swapping images.

If you just want to map the icon to the themed button states... it's simple
```python

button = ttk.Button(root, text=""Home"")

# map the icon to the styled button states
BootstrapIcon(""house"").map(button)
```

> BTW... this works with vanilla styled Tkinter as well. :-)

If you want to get more fancy...

```python
import ttkbootstrap as ttk

root = ttk.Window(""Demo"", themename=""flatly"")

btn = ttk.Button(root, text=""Home"")
btn.pack(padx=20, pady=20)

icon = BootstrapIcon(""house"")

# swap icon on hover, and color change on pressed.
icon.map(btn, statespec=[(""hover"", ""#0af""), (""pressed"", {""name"": ""house-fill"", ""color"": ""green""})])

root.mainloop()
```

‚úÖ Icons automatically track your widget‚Äôs theme **foreground color** unless you explicitly override it.  
‚úÖ Fully supports all icon sets in [`ttkbootstrap-icons`](https://github.com/israel-dryer/ttkbootstrap-icons).  
‚úÖ Works seamlessly with existing ttkbootstrap themes and styles.

---

## ‚öôÔ∏è Under the hood

- Introduces **`StatefulIconMixin`**, integrated into the base `Icon` class.
- Uses `ttk.Style.map(..., image=...)` to apply per-state images dynamically.
- Automatically generates derived child styles like `house-house-fill-16.my.TButton` if you don‚Äôt specify a `subclass`.
- Falls back to the **original untinted icon** for unmatched states (the empty-state `''` entry).
- Default `mode=""merge""` allows incremental icon-state changes without overwriting existing style maps.

---

## üß© Other updates

- Improved **rendering cache performance** when using PIL or custom font providers.
- Updated documentation with **live examples** for stateful icons and custom theming.
- Minor bug fixes and compatibility refinements.

---

## üöÄ Upgrade

```bash
pip install -U ttkbootstrap
pip install -U ttkbootstrap-icons
```

---

## üó®Ô∏è Feedback welcome!

If you build **Tkinter apps** with custom toolbars, dark themes, or icon-heavy UIs, please give the new **stateful icons** a try.  
Share screenshots, report issues, or suggest new states on GitHub:

üëâ [github.com/israel-dryer/ttkbootstrap-icons](https://github.com/israel-dryer/ttkbootstrap-icons)

Thanks for supporting the project ‚Äî and happy theming! üß©‚ú®

‚Äî _Israel Dryer_
",0,5,2025-11-03 05:03:34,ProfessionOld,https://www.reddit.com/r/Python/comments/1on22u9/ttkbootstrapicons_31_stateful_icons_at_your/
1omacx3,reddit,üÜï ttkbootstrap-icons v3.0.0 ‚Äî More icon sets for Tkinter üé®,"[`ttkbootstrap-icons`](https://github.com/israel-dryer/ttkbootstrap-icons) v3.0.0 is here ‚Äî bringing **Typicons** and **Meteocons** to the growing collection of icon providers for **Tkinter** and **ttkbootstrap**.

# üöÄ What‚Äôs new

* Added **Typicons** and **Meteocons** providers
* Improved **icon browser** performance and search
* Refined **package structure** with cleaner glyphmaps
* Updated docs with per-provider pages

üìò Docs ‚Üí [https://israel-dryer.github.io/ttkbootstrap-icons](https://israel-dryer.github.io/ttkbootstrap-icons)

# üêç Install

    pip install ttkbootstrap-icons ttkbootstrap-icons-typicons ttkbootstrap-icons-meteocons

Everything still works seamlessly with **ttkbootstrap** and scales perfectly with your widgets.

All via a **simple, unified API**:

    from ttkbootstrap_icons_typicons import TypiconsIcon
    from ttkbootstrap_icons_meteocons import MeteoIcon
    
    btn = ttk.Button(root, text=""Down"", image=TypiconsIcon(""arrow-down-fill"", size=24), compound=""left"")

You can browse all icons visually with:

    ttkbootstrap-icons

‚ú® 15 Icon Packs, One Unified API

|Provider|Description|
|:-|:-|
|üÖ±Ô∏è **Bootstrap** *(built-in)*|Default ttkbootstrap icon set|
|‚≠ê **Font Awesome** (`ttkbootstrap-icons-fa`)|Solid, regular, and brand icons|
|üß≠ **Google Material Icons** (`ttkbootstrap-icons-gmi`)|Clean, modern system icons|
|‚ö° **Ionicons** (`ttkbootstrap-icons-ion`)|iOS-style outline and filled icons|
|üé® **Remix Icon** (`ttkbootstrap-icons-remix`)|2,500+ elegant line icons|
|ü™ü **Fluent System Icons** (`ttkbootstrap-icons-fluent`)|Microsoft‚Äôs Fluent UI icons|
|ü™∂ **Lucide** (`ttkbootstrap-icons-lucide`)|Feather-inspired minimalist set|
|üíª **Devicon** (`ttkbootstrap-icons-devicon`)|Developer tools & language logos|
|üß© **Simple Icons** (`ttkbootstrap-icons-simple`)|Brand & social logos|
|üå§Ô∏è **Weather Icons** (`ttkbootstrap-icons-weather`)|Conditions, forecasts & symbols|
|üí† **Material Design Icons (MDI)** (`ttkbootstrap-icons-mat`)|Extended Material set|
|üí´ **Eva Icons** (`ttkbootstrap-icons-eva`)|Elegant outline & filled designs|
|üî£ **Typicons** (`ttkbootstrap-icons-typicons`)|Lightweight typographic icons|
|üå¶Ô∏è **Meteocons** (`ttkbootstrap-icons-meteocons`)|Weather & atmosphere icons|
|‚öîÔ∏è **RPG Awesome** (`ttkbootstrap-icons-rpga`)|RPG / fantasy-themed icons|

**GitHub:** [israel-dryer/ttkbootstrap-icons](https://github.com/israel-dryer/ttkbootstrap-icons)  
**Docs:** [Project site](https://israel-dryer.github.io/ttkbootstrap-icons)",6,0,2025-11-02 07:32:56,ProfessionOld,https://www.reddit.com/r/Python/comments/1omacx3/ttkbootstrapicons_v300_more_icon_sets_for_tkinter/
1ols60g,reddit,Solvex - An open source FastAPI + SciPy API I'm building to learn optimization algorithms,"Hey,

I find the best way to understand a complex topic is to build something with it. To get a handle on optimization algorithms, I've started a new project called **Solvex**.

It's a REST API built with FastAPI + SciPy that solves linear programming problems. It's an early stage learning project, and I'd love to get your feedback.

**Repo Link:** [`https://github.com/pranavkp71/solvex`](https://github.com/pranavkp71/solvex)

Here are the details for the showcase:

**What My Project Does**

Solvex provides a simple REST API that wraps optimization solvers from the SciPy library. Currently, it focuses on solving linear programming problems: you send a JSON payload with your problem's objective, constraints, and bounds, and it returns the optimal solution.

It uses FastAPI, so it includes automatic interactive API documentation and has a full CI/CD pipeline with tests.

**Example Use Case (Portfolio Optimization):**

Python

    import requests
    
    payload = {
        ""objective"": [0.12, 0.15, 0.10],  # Maximize returns
        ""constraints_matrix"": [
            [1, 1, 1],    # Total investment <= 100k
            [1, 0, 0]     # Max in asset 1 <= 40k
        ],
        ""constraints_limits"": [100000, 40000],
        ""bounds"": [[0, None], [0, None], [0, None]] # No short selling
    }
    
    response = requests.post(""http://localhost:8000/solve/lp"", json=payload)
    print(response.json())

**Target Audience**

This is primarily a learning project. The target audience is:

* Students & Learners:  Anyone who wants to see a practical web application of optimization algorithms.
* Developers / Prototypers: Anyone who needs a simple, self-hostable endpoint for linear programming for a prototype without needing to build a full scientific Python backend themselves.
* FastAPI Users:  Developers interested in seeing how FastAPI can be used to create clean, validated APIs for scientific computing.

**Next Steps & Feedback**

I'm still learning, and my next steps are to add more solvers for:

* The Knapsack problem
* Integer programming
* Network flow algorithms

I am open to any and all feedback

* What optimization algorithms do you think would be most useful to add next?
* Any thoughts on improving the API structure?

If you find this project interesting, I'd be very grateful for a **star on GitHub** . It's open-source, and all **contributions are welcome**",56,14,2025-11-01 17:28:53,MainWild1290,https://www.reddit.com/r/Python/comments/1ols60g/solvex_an_open_source_fastapi_scipy_api_im/
1olvisc,reddit,Reduino v1.0.0: Write Arduino projects entirely in Python and run transpiled C++ directly on Arduino,"Hello¬†[r/python](https://www.reddit.com/r/python/) just wanted to share my new side project i call Reduino! Reduino is a python to arduino transpiler that let's you write code in python and then transpile it into arduino compatible c++ and if you want even upload it for you automatically.

**First Question that comes to mind: How is it different from PyFirmata or MicroPython**

* Unlike micropython Reduino is not actually running python on these MCUs, Reduino just transpiles to an equivalent C++, that can be deployed on all arduinos like Uno which is not possible with Micropython
* On the other hand Pyfirmata is a library that let's you communicate with the MCU via serial communication, the biggest con here is that you can't deploy your code on to the mcu
* Reduino aims to sit in the middle to be deployable on all hardware while giving users the comfort to code their projects in python

**How it works**

Reduino is based on Abstract Syntax Tree to transpile python code into arduino. Basically there are three main scripts that are doing the heavy lifting. Ast, Parser, Emitter

1. Ast: Defines *data structures* that describe everything Reduino knows how to transpile ‚Äî e.g. `LedDecl`, `LedOn`, `BuzzerPlayTone`, `IfStatement`, `WhileLoop`, etc.
2. Each node is just a structured record (a `dataclass`) representing one element of the Python DSL.
3. Parser: Walks through the user‚Äôs Python source code line by line, recognising patterns and extracting semantic meaning (variable declarations, loops, LED actions, etc.).
4. It builds a `Program` object populated with AST nodes.
5. Takes that `Program` (list of AST nodes) and **serialises it into valid Arduino-style C++**.
6. It injects global variables, generates `setup()` and `loop()` bodies, applies correct `pinMode()`, and inserts library includes or helper snippets when needed.

**Features / Things it can transpile**

My aim while writing Reduino was to support as much pythonic syntaxes as possible so here are the things that Reduino can transpile

* If / else / elif
* range loops
* Lists and list comprehension
* Automatic variable data type inference
* functions and break statements
* Serial Communication
* try / catch blocks
* the pythonic number swap¬†`a,b = b,a`

**Examples**

Get Started with:

`pip install Reduino`

if you would like to also directly upload code to your MCUs instead of only transpiling you must also install platformio

`pip install platformio`

    from Reduino import target
    from Reduino.Actuators import Buzzer
    from Reduino.Sensors import Button
    
    target(""COM4"")
    
    buzzer = Buzzer(pin=9)
    button = Button(pin=2)
    
    while True:
        if button.is_pressed():
            buzzer.melody(""success"")

This code detects for a button press and plays a nice success sound on the buzzer connected.

Anything under the¬†`While True:`¬†loop is basically mapped to being inside the¬†`void loop () {}`¬†function and anything outside it is in¬†`void setup()`¬†so overall it maintains the arduino script structure

This code transpiles to and uploads automatically the following cpp code

    #include <Arduino.h>
    
    bool __buzzer_state_buzzer = false;
    float __buzzer_current_buzzer = 0.0f;
    float __buzzer_last_buzzer = static_cast<float>(440.0);
    bool __redu_button_prev_button = false;
    bool __redu_button_value_button = false;
    
    void setup() {
      pinMode(9, OUTPUT);
      pinMode(2, INPUT_PULLUP);
      __redu_button_prev_button = (digitalRead(2) == HIGH);
      __redu_button_value_button = __redu_button_prev_button;
    }
    
    void loop() {
      bool __redu_button_next_button = (digitalRead(2) == HIGH);
      __redu_button_prev_button = __redu_button_next_button;
      __redu_button_value_button = __redu_button_next_button;
      if ((__redu_button_value_button ? 1 : 0)) {
        {
          float __redu_tempo = 240.0f;
          if (__redu_tempo <= 0.0f) { __redu_tempo = 240.0f; }
          float __redu_beat_ms = 60000.0f / __redu_tempo;
          const float __redu_freqs[] = {523.25f, 659.25f, 783.99f};
          const float __redu_beats[] = {0.5f, 0.5f, 1.0f};
          const size_t __redu_melody_len = sizeof(__redu_freqs) / sizeof(__redu_freqs[0]);
          for (size_t __redu_i = 0; __redu_i < __redu_melody_len; ++__redu_i) {
            float __redu_freq = __redu_freqs[__redu_i];
            float __redu_duration = __redu_beats[__redu_i] * __redu_beat_ms;
            if (__redu_freq <= 0.0f) {
              noTone(9);
              __buzzer_state_buzzer = false;
              __buzzer_current_buzzer = 0.0f;
              if (__redu_duration > 0.0f) { delay(static_cast<unsigned long>(__redu_duration)); }
              continue;
            }
            unsigned int __redu_tone = static_cast<unsigned int>(__redu_freq + 0.5f);
            tone(9, __redu_tone);
            __buzzer_state_buzzer = true;
            __buzzer_current_buzzer = __redu_freq;
            __buzzer_last_buzzer = __redu_freq;
            if (__redu_duration > 0.0f) { delay(static_cast<unsigned long>(__redu_duration)); }
            noTone(9);
            __buzzer_state_buzzer = false;
            __buzzer_current_buzzer = 0.0f;
          }
        }
      }
    }

Reduino offers extended functionality for some of the Actuators, for example for Led, you have the following avaliable

    from Reduino import target
    from Reduino.Actuators import Led
    
    print(target(""COM4"", upload=False))
    
    led = Led(pin=9)
    led.off()
    led.on()
    led.set_brightness(128)
    led.blink(duration_ms=500, times=3)
    led.fade_in(duration_ms=2000)
    led.fade_out(duration_ms=2000)
    led.toggle()
    led.flash_pattern([1, 1, 0, 1, 0, 1], delay_ms=150)

Or for the buzzer you have

    bz = Buzzer(pin=9)
    bz.play_tone(frequency=523.25, duration_ms=1000)
    bz.melody(""siren"")
    bz.sweep(400, 1200, duration_ms=2000, steps=20)
    bz.beep(frequency=880, on_ms=200, off_ms=200, times=5)
    bz.stop()

**Target Audience**

1. I believe at it's current infancy stage it is a really good rapid prototyping tool to quickly program cool projects!
2. Anyone who loves python but does not want to learn c++ to get into electronics this is  a really good way to start

**Limitations**

As Reduino is still really new, very less amount of actuators and sensors are supported, as for every single device / sensor /actuator / module i need to update the parser and emitter logic.

Because the library is so new if you try it out and find a bug please open an issue with your code example and prefferably an image of your hardware setup. I would be really grateful

**More info**

You can find more info on the¬†[Github](https://github.com/Jackhammer9/Reduino)¬†or on the¬†[PyPi Page](https://pypi.org/project/Reduino/)",34,6,2025-11-01 19:42:12,PreppyToast,https://www.reddit.com/r/Python/comments/1olvisc/reduino_v100_write_arduino_projects_entirely_in/
1om2nwm,reddit,Discogs Recommender API,"**What My Project Does**

I built a FastAPI application that recommends Discogs records based on similarity. You provide a Discogs URL or release ID, and it returns similar records using Spotify's Annoy library for fast approximate nearest neighbor search based on release metadata (styles, year, countries, prices, wants, haves, etc).

Beyond basic recommendations, it includes batch recommendations, user accounts with JWT authentication, favorites management, recommendation/search history, release filtering, and a feedback system. The whole thing runs locally with Docker.

**Target Audience**

Anyone interested in vinyl recommendations, music discovery, or exploring Discogs data. Also useful if you're learning about recommendation systems, FastAPI, or building ML-backed APIs. This is a toy/learning project - I'm a Data Engineer and wanted to explore some backend development in my spare time, so it's not designed for production yet.

**Comparison**

Honestly, I haven't found any other standalone Discogs recommendation systems out there, but if there are some I'd be curious to check them out.

**Repo:** [https://github.com/justinpakzad/discogs-rec-api](https://github.com/justinpakzad/discogs-rec-api)

Open to any feedback, suggestions, or contributions. Thanks.",10,2,2025-11-02 00:43:21,Resident-Loss8774,https://www.reddit.com/r/Python/comments/1om2nwm/discogs_recommender_api/
1omak5t,reddit,My first AI Agent Researcher with Python + LangChain + Ollama,"# What My Project Does

So I always wondered how AI agents actually work ‚Äî how do they decide what to do, what file to open, or how to run terminal commands like npm run build  
So I tried to learn the high-level stuff and built a small local research agent from scratch.

It runs fully offline, uses a local LLM through **Ollama**, connects tools via **LangChain**, and stores memory with **ChromaDB**.  
Basically it can search, summarize, do math, and even save markdown notes all in your terminal

# Target Audience

Anyone like me who‚Äôs curious about **how AI agents actually ‚Äúthink‚Äù**.  
It‚Äôs not for production or anything just a fun little learning project that helps you understand how reasoning, tools, and memory connect together.

# Comparison

Most AI assistants depend on APIs or the cloud.  
This one runs **completely local** ‚Äî no API keys, no servers.  
Just you, your machine, and Python doing some agent magic ‚ú®

# GitHub

[github.com/vedas-dixit/LocalAgent](https://github.com/vedas-dixit/LocalAgent)

Let me know what you guys think!",2,3,2025-11-02 07:45:44,FriendshipCreepy8045,https://www.reddit.com/r/Python/comments/1omak5t/my_first_ai_agent_researcher_with_python/
1ommzfg,reddit,I‚Äôm learning JavaScript at school and want to make my handwritten Python script more Pythonic.,"
import json
import os

todos = [];

def loadTasks():
    global todos;
    if os.path.exists(""todo.json""):
        f = open(""todo.json"", ""r"");
        try:
            todos = json.load(f);
        except:
            todos = [];
        f.close();
    else:
        todos = [];

def saveTasks():
    f = open(""todo.json"", ""w"");
    json.dump(todos, f);
    f.close();

def addTask(task):
    todos.append({""text"": task, ""done"": False});
    saveTasks();
    print(""Task added: "" + task);

def listTasks():
    print(""\nYour tasks:"");
    if len(todos) == 0:
        print(""No tasks yet!"");
    else:
        for i in range(0, len(todos)):
            t = todos[i];
            status = ""[x]"" if t[""done""] else ""[ ]"";
            print(str(i+1) + "". "" + status + "" "" + t[""text""]);

def removeTask(index):
    if index >= 0 and index < len(todos):
        print(""Removed: "" + todos[index][""text""]);
        del todos[index];
        saveTasks();
    else:
        print(""Invalid index"");

def markDone(index):
    if index >= 0 and index < len(todos):
        todos[index][""done""] = True;
        saveTasks();
        print(""Marked as done: "" + todos[index][""text""]);
    else:
        print(""Invalid index"");

loadTasks();

while True:
    print(""\n1) Add Task\n2) List Tasks\n3) Remove Task\n4) Mark Done\n5) Exit"");
    choice = input(""Choose: "");
    if choice == ""1"":
        t = input(""Enter task: "");
        addTask(t);
    elif choice == ""2"":
        listTasks();
    elif choice == ""3"":
        idx = int(input(""Task number to remove: "")) - 1;
        removeTask(idx);
    elif choice == ""4"":
        idx = int(input(""Task number to mark done: "")) - 1;
        markDone(idx);
    elif choice == ""5"":
        print(""Goodbye!"");
        break;
    else:
        print(""Invalid choice"");",0,10,2025-11-02 18:15:39,Educational_Use3842,https://www.reddit.com/r/Python/comments/1ommzfg/im_learning_javascript_at_school_and_want_to_make/
1om313b,reddit,Sunday Daily Thread: What's everyone working on this week?,"# Weekly Thread: What's Everyone Working On This Week? üõ†Ô∏è

Hello /r/Python! It's time to share what you've been working on! Whether it's a work-in-progress, a completed masterpiece, or just a rough idea, let us know what you're up to!

## How it Works:

1. **Show & Tell**: Share your current projects, completed works, or future ideas.
2. **Discuss**: Get feedback, find collaborators, or just chat about your project.
3. **Inspire**: Your project might inspire someone else, just as you might get inspired here.

## Guidelines:

* Feel free to include as many details as you'd like. Code snippets, screenshots, and links are all welcome.
* Whether it's your job, your hobby, or your passion project, all Python-related work is welcome here.

## Example Shares:

1. **Machine Learning Model**: Working on a ML model to predict stock prices. Just cracked a 90% accuracy rate!
2. **Web Scraping**: Built a script to scrape and analyze news articles. It's helped me understand media bias better.
3. **Automation**: Automated my home lighting with Python and Raspberry Pi. My life has never been easier!

Let's build and grow together! Share your journey and learn from others. Happy coding! üåü",0,12,2025-11-02 01:00:31,AutoModerator,https://www.reddit.com/r/Python/comments/1om313b/sunday_daily_thread_whats_everyone_working_on/
1ommty3,reddit,New Code obfuscator approach,"As you may have encountered it before. We want to protect our code while sharing to other users - a basic for security in corporate line of work.

There are tons of code obfuscators online which work halfway. They reveal the basic structure of code to other user and doesn't prevent any modification / redistribution.

Here's an idea - why not encrypt it ?

So encryption can be done in python itself. But the decryption is the best part - it's done in a binary. I could manage to make a rust executable which does exactly that. It decrypts the code in RAM and runs from it. No extra /temporary file created. In case of any issues, run the regular python file to debug, otherwise user gets a rust executable and encrypted python code- gibberish to look at.

What y'all think ?

  
Edit: This is a post on python code obfuscation. If you're not interested in this topic, please ignore this post. and not put opinions.",0,24,2025-11-02 18:09:39,Separate_Mirror2651,https://www.reddit.com/r/Python/comments/1ommty3/new_code_obfuscator_approach/
1om71r1,reddit,How to make a eptrichoid (for the rotary inside),Hello üëã I am kinda new to python and am currently trying to make my own replica of a mazada 13 g engine I am using free cad and want to make the internal rotor using python and it is a mathe mathematical figure ,0,2,2025-11-02 04:21:01,zenxoogabooga,https://www.reddit.com/r/Python/comments/1om71r1/how_to_make_a_eptrichoid_for_the_rotary_inside/
1okypr5,reddit,My type-safe asyncio lib and the fingerprinting guide it spawned,"I wanted to share a project that‚Äôs been my passion, a `asyncio`\-native automation library (pydoll). My main goal was to build a 100% type-safe API on top of the chaotic Chrome DevTools Protocol.

This meant engineering a type-safe core by mapping the entire CDP protocol using `TypedDict`s. This gives the user full IDE autocomplete for every command and event. I wrote about that design philosophy here: [`https://pydoll.tech/docs/deep-dive/fundamentals/typing-system/`](https://pydoll.tech/docs/deep-dive/fundamentals/typing-system/)

It also required deep research to build the advanced evasion features. I ended up going down the rabbit hole and writing a full manual on modern bot detection (TLS/JA3, Canvas, biometrics), which I'm also sharing: [`https://pydoll.tech/docs/deep-dive/fingerprinting/`](https://pydoll.tech/docs/deep-dive/fingerprinting/)

The project is OSS and was a massive deep-dive into `asyncio` and `typing`. I'd love your feedback on the architecture.",65,16,2025-10-31 17:08:57,thalissonvs,https://www.reddit.com/r/Python/comments/1okypr5/my_typesafe_asyncio_lib_and_the_fingerprinting/
1ol145x,reddit,State of Django 2025 from JetBrains,"A new set of survey results just dropped, this time in the form of Django-specific data gathered by JetBrains:

  
[Django Developers Survey 2025 Results](https://lp.jetbrains.com/django-developer-survey-2025/)

Some key takeaways:

* HTMX and Alpine.js are the fastest-growing JavaScript frameworks used with Django.
   * HTMX is fantastic - my personal take ;)
* 38% of developers use AI to learn Django.
* 3 out of 4 Django developers have 3+ years of professional coding experience.
* 63% already use type hints, and more plan to.
   * This is good. Type hints were a good idea.
* 76% use PostgreSQL as their database backend.",32,3,2025-10-31 18:40:17,monorepo,https://www.reddit.com/r/Python/comments/1ol145x/state_of_django_2025_from_jetbrains/
1olfmu9,reddit,Email processing project for work,"I would like to ask the community here for some ideas or guidance, especially if you have worked on an email automation/processing project before.

For a few weeks I've been working on a project, maybe about 20% of my time at work, I'm really happy with how it's going and it's been a great process to learn a lot of different things.

The project is building a tool that will pull emails from a mail server, scan all the content, headers, attachments for the presence of a particular type of 10 digit number used for internal projects, and to check the participants of the email for certain domains.

If one of these project identifiers is found, the email and it's attachments will be uploaded to a cloud storage system so that anyone in the company can see relevant documents and communications relevant to that project.

I'm wondering if anyone in the community has any ideas for an elegant way of setting this up to run long term.

My thinking at the moment is to have emails downloaded and stored in a staging folder, when an email is processed it will be moved to another temporary folder to then be picked up by the last step to be uploaded. I could leave them all in the same folder but I think it's best to separate them, but hey that's why I'm trying to have a discussion about this.

I think these components should happen asynchronously, but I'm wondering about how to best set that up. I have some experience with subprocess but I have also been looking into asyncio.

I'm hoping to have the email downloading service run with crontab, and then another service that will handle processing emails, uploading the files, and doing file system cleanup and some other API calls to update the original email message in the mail server with a tag to show it has been processed.

I would really appreciate any feedback or ideas, if anyone else has done this before, or has some ideas of how to best handle this kind of project implementation.

Thanks,
Bob

**edit to add:**

Here is what is already done:

* Downloading the emails
* Processing them with regex to find relevant items
* If the email is relevant (has a project identifier) the email is renamed {timestamp}_{subject} (since it comes from exchange api as the messageID.eml)
* Uploads the email and all attachments to a cloud storage system (not important which one since this is already working well)
* Sends another Microsoft Graph API request to apply a category to the email to denote that it has been added to cloud storage

What I'm looking for is some discussion around how to orchestrate this.",5,23,2025-11-01 06:04:30,Francobanco,https://www.reddit.com/r/Python/comments/1olfmu9/email_processing_project_for_work/
1ol96ne,reddit,TelegramCLIBot - Control your server via Telegram from anywhere,"I released **TelegramCLIBot v0.1.0**, a personal Telegram bot that turns your phone into a remote CLI for your self-hosted server.

# What it does

Execute shell commands on your server directly from Telegram. Perfect for when you're away from your desk and need to:

* Start/stop your home VPN when traveling
* Restart services
* Run any custom automation scripts remotely

# Key Features

* **Direct command execution** via `/run <command>`
* **Custom command shortcuts** \- Create aliases for frequently used commands (e.g., `/startvpn` ‚Üí `sudo wg-quick up wg0`)
* **User whitelist authentication** \- Only specified Telegram user IDs can control the bot

# Security Notice

This is designed **exclusively for personal/self-hosted use**. It executes arbitrary shell commands with the privileges of the user running the bot.

**Security measures:**

* User ID whitelist (configured in YAML)
* Recommended to run as non-root user
* 2FA required on Telegram account

# Why I Built This

I wanted a simple way to manage my home server from anywhere without opening SSH ports on my router or dealing with port forwarding/dynamic DNS.

**The Telegram approach:**

* No ports to open - the bot connects outbound to Telegram's servers
* Works from anywhere with internet (Telegram handles the routing)
* Clean mobile interface - just send a message
* Can start your VPN remotely when you need it, without already having VPN access

Basically, Telegram acts as a secure relay. Your bot polls Telegram's servers, so you never expose your home network directly to the internet.

# Repository

GitHub: [https://github.com/vincenzoarico/telegramclibot](https://github.com/vincenzoarico/telegramclibot)",3,1,2025-11-01 00:17:08,Enzo10091,https://www.reddit.com/r/Python/comments/1ol96ne/telegramclibot_control_your_server_via_telegram/
1ola3n2,reddit,Saturday Daily Thread: Resource Request and Sharing! Daily Thread,"# Weekly Thread: Resource Request and Sharing üìö

Stumbled upon a useful Python resource? Or are you looking for a guide on a specific topic? Welcome to the Resource Request and Sharing thread!

## How it Works:

1. **Request**: Can't find a resource on a particular topic? Ask here!
2. **Share**: Found something useful? Share it with the community.
3. **Review**: Give or get opinions on Python resources you've used.

## Guidelines:

* Please include the type of resource (e.g., book, video, article) and the topic.
* Always be respectful when reviewing someone else's shared resource.

## Example Shares:

1. **Book**: [""Fluent Python""](https://www.amazon.com/Fluent-Python-Concise-Effective-Programming/dp/1491946008) \- Great for understanding Pythonic idioms.
2. **Video**: [Python Data Structures](https://www.youtube.com/watch?v=pkYVOmU3MgA) \- Excellent overview of Python's built-in data structures.
3. **Article**: [Understanding Python Decorators](https://realpython.com/primer-on-python-decorators/) \- A deep dive into decorators.

## Example Requests:

1. **Looking for**: Video tutorials on web scraping with Python.
2. **Need**: Book recommendations for Python machine learning.

Share the knowledge, enrich the community. Happy learning! üåü",3,1,2025-11-01 01:01:02,AutoModerator,https://www.reddit.com/r/Python/comments/1ola3n2/saturday_daily_thread_resource_request_and/
1olqab2,reddit,Just launched CrossTray,"Hi Guys, I just created a new python library and I would like you to check it out and let me know what you guys think about it?

You can download it using

pip install crosstry

It is a lightweight Python library for creating system tray/menu bar icons across¬†**Windows, macOS & Linux** (Windows for now as MVP).

But for now it only supports the Windows as this is the MVP idea and I would like you guys to come and contribute. I would be happy to see issues and pull requests coming.

GitHub Link:¬†[https://github.com/UmanSheikh/crosstray](https://github.com/UmanSheikh/crosstray)",0,2,2025-11-01 16:12:49,umansheikh,https://www.reddit.com/r/Python/comments/1olqab2/just_launched_crosstray/
1olpew7,reddit,CVE scanner for requirements.txt and pyproject.toml,"Made a VS Code extension that scans Python dependencies for CVEs.



Checks requirements.txt and pyproject.toml against NVD and OSV databases.



Ask GitHub Copilot ""Check for security vulnerabilities"" and it runs the scan.



Also works with other languages (JavaScript, Java, Go, etc.)



GitHub: [https://github.com/abhishekrai43/VulScan-MCP](https://github.com/abhishekrai43/VulScan-MCP)

Marketplace: Search ""VulScan-MCP""",0,6,2025-11-01 15:36:55,FeelingResolution806,https://www.reddit.com/r/Python/comments/1olpew7/cve_scanner_for_requirementstxt_and_pyprojecttoml/
1olpxa7,reddit,Virus generando .exe con pyinstaller,"Hola, ayer intente hacer de nuevo un .exe con pyinstaller, es un codigo de python simple que lo unico que hace es trabajar con el archivo host de windows para cambiar el dns en local. eso hace mas facil las pruebas. La cosa es que instale python 3.14.0 y luego pyinstaller, y me sucedio algo que nunca habia pasado. Y es que ahora el .exe resultante windows lo dectecta como virus. Lo subi a virus total, y varios antivirus dieron alerta tambien. realmente no entiendo que pasa con pyinstaller, esto antes no pasaba. 

Estos son los antivirus que daban la alerta:

Arctic WolfUnsafe

Bkav ProW64.AIDetectMalware

DeepInstinctMALICIOUS

McAfee ScannerTi!4850EAC089E3

SecureAgeMalicious

SentinelOne (Static ML)Static AI - Suspicious PE

Skyhigh (SWG)BehavesLike.Win64.Generic.vc

Acronis (Static ML)



Alguien sabe porque ocurre esto?",0,4,2025-11-01 15:58:02,PollutionDue7541,https://www.reddit.com/r/Python/comments/1olpxa7/virus_generando_exe_con_pyinstaller/
1okojvr,reddit,For Streamlit'ers: Customize theme and components with st_yled to build unique apps,"With¬†[**st\_yled**](https://st-styled.evo-byte.com/)¬†you can simply style most Streamlit elements like button or containers - right from you app code. This helps you build unique UIs using your personal tone or brand.

Visit¬†[**st-yled studio**](https://styled-studio.streamlit.app/), the accompanying app, to test and configure layouts for your own apps.

Styled integrates naturally with your Streamlit dev workflow, just replace¬†`st.`¬†with¬†`st_yled.`¬†and activate elements for passing style parameters.

    # Use enhanced elements to style the (text) color and background of a single button
    st_yled.button(""Styled Button"", color=""white"", background_color=""blue"")
    
    # Or the color and size of the title
    st_yled.title(""Welcome!"", color=""#57cf1cff"", font_size=""24px"")
    

A quickstart can be found in the¬†[st\_yled docs](https://st-styled.evo-byte.com/).

You can configure elements globally for the whole app or for individual elements. With this you can include you branding style guides and re-use style sheets between apps.

What parts of Streamlit elements would you like to st\_yle? Leave a comment.",16,0,2025-10-31 08:54:03,QueasyVarieties,https://www.reddit.com/r/Python/comments/1okojvr/for_streamliters_customize_theme_and_components/
1okumdi,reddit,grasp-agents: a minimalist framework for working with LLMs.,"## What Our Project Does

[grasp-agents](https://github.com/grasp-technologies/grasp-agents) is a modular Python framework for building agentic AI pipelines and applications. It is meant to be minimalistic but functional, allowing for rapid experimentation while keeping full and granular low-level control over prompting, LLM handling, tool call loops, and inter-agent communication by avoiding excessive higher-level abstractions.

## Target Audience

Individuals and teams (especially research teams) looking for something minimalist whilst expressive.

## Comparisons

**grasp-agents** ‚Äî minimalist Python library for agent loops with low-level control over prompts/tool-calls, LiteLLM-based model support, static workflows + agents-as-tools, in‚Äëprocess A2A actor model, granular event streaming; no heavy graph/runtime.

**LangChain** ‚Äî broader LLM app framework with prebuilt agent architectures and rich integrations; faster ‚Äúgetting started‚Äù vs grasp-agent‚Äôs lower‚Äëlevel primitives.

**LangGraph** ‚Äî graph/state‚Äëmachine orchestration with persistence, memory, streaming, and human‚Äëin‚Äëthe‚Äëloop; grasp-agents doesn‚Äôt center on graphs/checkpointing.

**LlamaIndex** ‚Äî ‚Äúdata‚Äëfirst‚Äù RAG + agents over indexes/workflows; grasp-agents isn‚Äôt opinionated around indexes/RAG.

**smolagents** ‚Äî ultralight agents with a really good ""CodeAgent"" and secure sandboxed execution; grasp-agents doesn‚Äôt have a code‚Äëexecution sandbox.

**OpenAI Agents SDK** ‚Äî production orchestration tightly integrated with OpenAI (guardrails, tracing, sessions) and built‚Äëin tools via the new Responses API (web/file search, computer‚Äëuse, MCP); grasp-agents is provider‚Äëagnostic via LiteLLM (open-source) and doesn‚Äôt bundle hosted tools.",6,1,2025-10-31 14:28:55,kellyratio,https://www.reddit.com/r/Python/comments/1okumdi/graspagents_a_minimalist_framework_for_working/
1oljwh2,reddit,What's the best Python version to download if u want everything to run without any issues?,I've read that getting the latest version might not be too good because some pip packages may quit working because they arent really supported and that u need to download something like python 311 instead of 314. Bruh.,0,17,2025-11-01 10:51:48,aespaste,https://www.reddit.com/r/Python/comments/1oljwh2/whats_the_best_python_version_to_download_if_u/
1ok548a,reddit,Can you break our pickle sandbox? Blog + exploit challenge inside,"We‚Äôve applied the feedback, fixed the issues, and wrote a follow-up explaining what went wrong and what changed. üîó Blog: [https://iyehuda.substack.com/p/follow-up-what-200-researchers-taught](https://iyehuda.substack.com/p/follow-up-what-200-researchers-taught)  
Thanks to everyone who participated so far‚Äî this was fun and genuinely useful.  
\----  
I've been working on a different approach to pickle security with a friend.  
We wrote up a blog post about it and built a challenge to test if it actually holds up. The basic idea: we intercept and block the dangerous operations at the interpreter level during deserialization (RCE, file access, network calls, etc.). Still experimental, but we tested it against 32+ real vulnerabilities and got <0.8% performance overhead.  
Blog post with all the technical details: [https://iyehuda.substack.com/p/we-may-have-finally-fixed-pythons](https://iyehuda.substack.com/p/we-may-have-finally-fixed-pythons)  
Challenge site (try to escape): [https://pickleescape.xyz](https://pickleescape.xyz/)  
Curious what you all think - especially interested in feedback if you've dealt with pickle issues before or know of edge cases we might have missed.",61,24,2025-10-30 17:55:16,valmarelox,https://www.reddit.com/r/Python/comments/1ok548a/can_you_break_our_pickle_sandbox_blog_exploit/
1okcm3a,reddit,"[Python] Introducing Pyxe, a simple GUI for the PyInstaller module to compile your Python projects!","I found that PyInstaller, a module in Python that compiles scripts into executables, was a little rough to learn at the beginning. It is basically just CLI only, and figured I would try and widen the audience group to people who would prefer a GUI version.   


\*What my project does\*:  
[Pyxe](https://github.com/DutytoDevelop/Pyxe)¬†comes in with the simple goal is to make it easier for people to take a Python project and compile it into their own executable! Essentially, it's a GUI wrapper that interfaces with 'PyInstaller' which is the module that does the compiling once you provide it the various arguments, but it is CLI only.

\*Target Audience\*:  
My target audience are Python enthusiasts that have a Python project and want to be able to compile it into a running executable, whether on Linux, Mac, or Windows.  
  
\*Comparison\*:   
It does seem like there is an [alternative](https://github.com/inject3r/pyinstaller-gui) that seems better than my own project. I love to develop projects from the ground up so I do not simply copy projects and make it seem like I built them. The alternative I provided does seem to have more functionality. I am not afraid to post the alternative here, as it may better help the target audience. Pyxe uses Tkinter for the GUI while the alternative, [pyinstaller-gui](https://github.com/inject3r/pyinstaller-gui), uses PyQT. I doubt that whichever GUI is used really makes an impact, but if you are someone who wants to see how these projects are built using different GUI's, then most certainly dive in and check both of them out!  


\---  
\*\*It's still in the works\*\*, but I recently got it working with Linux and MacOS after learning that you may need to install some packages beforehand to allow Pyxe to run on your operating system. Skim over the ReadMe, or look at it with a detailed mind, before you start working with this project, since there are some caveats.  
\---

Since I cannot post images of the¬†[Pyxe Auto-Compiler](https://github.com/DutytoDevelop/Pyxe)¬†in action, I will instead provide a link to the GitHub sub-folder that provides screenshots of Pyxe to understand how it works.¬†[Here are where the screenshots are](https://github.com/DutytoDevelop/Pyxe/tree/main/build_folder)!

\---  
To-Do:  
Fix the ability to bundle data from multiple folders into the application. It is being odd and not populating the directories correctly.

\---  
Let me know what you all think.",22,9,2025-10-30 22:42:38,DutytoDevelop,https://www.reddit.com/r/Python/comments/1okcm3a/python_introducing_pyxe_a_simple_gui_for_the/
1ol3aop,reddit,Preference as a user: do your want your security tokens in keyring or in plain text?,"Working on a project and would love to hear people's opinion: to store sensitive configuration parameters - from a user perspective if you were to use such a tool: do you prefer if an app stored sensitive tokens (passwords,, API keys, etc.) in keyring or in plain text in configuration files?  
",0,13,2025-10-31 20:04:07,ayechat,https://www.reddit.com/r/Python/comments/1ol3aop/preference_as_a_user_do_your_want_your_security/
1okfus7,reddit,Friday Daily Thread: r/Python Meta and Free-Talk Fridays,"# Weekly Thread: Meta Discussions and Free Talk Friday üéôÔ∏è

Welcome to Free Talk Friday on /r/Python! This is the place to discuss the r/Python community (meta discussions), Python news, projects, or anything else Python-related!

## How it Works:

1. **Open Mic**: Share your thoughts, questions, or anything you'd like related to Python or the community.
2. **Community Pulse**: Discuss what you feel is working well or what could be improved in the /r/python community.
3. **News & Updates**: Keep up-to-date with the latest in Python and share any news you find interesting.

## Guidelines:

* All topics should be related to Python or the /r/python community.
* Be respectful and follow Reddit's [Code of Conduct](https://www.redditinc.com/policies/content-policy).

## Example Topics:

1. **New Python Release**: What do you think about the new features in Python 3.11?
2. **Community Events**: Any Python meetups or webinars coming up?
3. **Learning Resources**: Found a great Python tutorial? Share it here!
4. **Job Market**: How has Python impacted your career?
5. **Hot Takes**: Got a controversial Python opinion? Let's hear it!
6. **Community Ideas**: Something you'd like to see us do? tell us.

Let's keep the conversation going. Happy discussing! üåü",7,1,2025-10-31 01:00:49,AutoModerator,https://www.reddit.com/r/Python/comments/1okfus7/friday_daily_thread_rpython_meta_and_freetalk/
1okxuyj,reddit,Data Science Project,"Hey guys! I‚Äôm currently studying CS, and for my Data Science final project I need to build an app that uses algorithms and logic like graphs, stacks, etc. I was wondering if you guys have any cool ideas I could use. The presentation is on 11/19, so I‚Äôve got around 19 days to come up with an idea and grind it out. I‚Äôd love something creative that could also fit in my portfolio not the usual basic stuff like supermarket queues or bank ticket systems. ",0,6,2025-10-31 16:36:46,EntranceKey9696,https://www.reddit.com/r/Python/comments/1okxuyj/data_science_project/
1ojz871,reddit,PyCalc Pro v1.0 ‚Äì My Python CLI Calculator for Math Nerds,"PyCalc Pro v1.0 is a command-line Python calculator that handles advanced math (trig, logs, factorials), arithmetic & geometric sequences, and number theory functions like prime checks, GCD, and LCM. It features a modular menu system for easy navigation.

**Target Audience:**  
Students, hobbyists, and Python learners who want a CLI calculator to explore math concepts. It is designed as a learning and experimentation tool rather than for daily accounting.

**Comparison:**  
Unlike basic Python scripts or generic calculator apps, PyCalc Pro combines advanced math, sequences, and number theory functions in one modular interface, making it more feature-rich and educational than standard alternatives.

**Installation:**

1. `git clone` [`https://github.com/lw-xiong/pycalc-pro`](https://github.com/lw-xiong/pycalc-pro)
2. `pip install -r requirements.txt`
3. `python` [`main.py`](http://main.py)

Feedback and feature ideas are welcome.",23,21,2025-10-30 14:08:06,lwx_dev,https://www.reddit.com/r/Python/comments/1ojz871/pycalc_pro_v10_my_python_cli_calculator_for_math/
1oktdez,reddit,I built a Python debugging tool that uses Semantic Analysis to determine what and where the issue is,"I've built a Python tool that performs deep **semantic analysis** to detect inconsistencies that traditional linters and statistical AI models miss. It solves the problem of logical errors arising when a function's stated purpose doesn't match its actual implementation.

What this means: This tool can find **semantic bugs**‚Äîthe kind of logical contradictions that often lead to production errors and technical debt.

### What My Project Does (The Execution)

The **Python Code Harmonizer** is a standalone application designed to enforce **semantic consistency** across your entire codebase.

What it provides: The tool analyzes your Python functions and generates a **Semantic Disharmony Score**‚Äîa quantifiable metric that measures the logical distance between a promise and its fulfillment.

1.  **Parses Syntax:** It uses the Python **AST (Abstract Syntax Tree)** to extract function names, documentation, and the complete implementation logic.
2.  **Maps Semantics:** It maps both the **Intent** (from the name/docstring) and the **Execution** (from the code body) into a fixed, multi-dimensional **Conceptual Space**.
3.  **Measures Disharmony:** It calculates the **Euclidean distance** between the Intent Coordinate and the Execution Coordinate. A score closer to 0 is ""Harmonious""; a high score is a critical semantic bug.
4.  **Generates Report:** It produces a clear CLI report showing which functions have the largest Intent-Execution Gaps, ranked by severity.

**Example findings:**

* A function named `calculate_score()` that uses `db.fetch_cache()` (Intent: **Wisdom** vs. Execution: **Justice/Power**).
* A function named `validate_input()` that contains `os.remove()` calls (Intent: **Justice** vs. Execution: **Power/Force**).
* A `get_data()` method that uses highly destructive write/delete patterns.

### Why This Tool is Different (The Comparison)

This tool operates on a **Semantic Metric** that no current commercial or open-source solution uses.

| Tool | Focus | Why the Harmonizer is Different |
| :--- | :--- | :--- |
| **Linters (e.g., Pylint)** | **Syntax/Style.** Low-level structural consistency. | Does not understand *meaning* or *intent*. |
| **LLMs (e.g., CodePilot)** | **Statistical Likelihood.** Predicts the most *likely* next token. | Lacks a fixed, deterministic **metric** to critique the code it writes. |
| **Harmonizer** | **Semantic Integrity.** Uses a fixed, deterministic **Conceptual Space** to quantify the ethical/logical coherence of code. | It measures against an *ideal* (a fixed metric), not against a statistical average (data). |

### Target Audience & Use Cases

This project provides an objective metric for problems that are currently subjective (""This function *feels* wrong"").

| Benefit | Use Case |
| :--- | :--- |
| **Objective Code Review** | Provides a quantifiable metric for code review disputes, replacing ""I don't like this name"" with ""The I-E Disharmony Score is 0.72."" |
| **Technical Debt Measurement** | Track semantic consistency across versions. A rising average score indicates increasing architectural drift. |
| **Architectural Insights** | Spot high-level patterns where certain modules are consistently named for **Wisdom** but only ever execute **Power**. |
| **CI/CD Integration** | Simple CLI output allows for fail-fast integration, automatically flagging code if its Disharmony Score exceeds a set threshold. |
| **Onboarding** | Quickly assess a new developer's codebase integration by observing how tightly their code aligns with the established function Intent. |

If you are dealing with large, complex Python codebases or are interested in a deterministic, **quantifiable approach to code meaning**, I‚Äôd appreciate a look and any feedback on the underlying approach!

**üîó Repo:** https://github.com/BruinGrowly/Python-Code-Harmonizer 
**üì¶ Minimal Dependencies:** Pure Python (`ast`, `math`, `dataclasses`, `re`).
**üõ†Ô∏è Extensible:** The semantic engine is designed to be easily extended with new keywords and rules.",0,4,2025-10-31 13:35:42,TreacleMine9318,https://www.reddit.com/r/Python/comments/1oktdez/i_built_a_python_debugging_tool_that_uses/
1ok4i17,reddit,Fixing Pylance Compatibility on Cursor 2.0 (Temporary Solution),"If you are using Cursor 2.0, you may have noticed that Pylance stopped working or can no longer be installed.  
This happens because Cursor 2.0 currently runs on the VS Code engine version 1.99.x, while the latest Pylance builds (from 1.101.x onward) require VS Code 1.101.0 or higher.

There is also growing speculation that Microsoft might be enforcing stricter licensing and compatibility rules around Pylance, which is unfortunate since this extension is essential for Python developers using Cursor.

Pylance provides:

* Type checking and static analysis based on Pyright
* Intelligent autocomplete and IntelliSense
* In-editor diagnostics and hover information
* Code navigation and better overall performance for Python projects

Without Pylance, the Python development experience inside Cursor becomes significantly limited.

# Temporary Fix

After some testing, I found a specific version that works perfectly with Cursor 2.0:¬†**Pylance 2025.6.1**.

This version is fully compatible and stable with the current Cursor core.  
You can download it directly from the official Visual Studio Marketplace:

[https://marketplace.visualstudio.com/\_apis/public/gallery/publishers/ms-python/vsextensions/vscode-pylance/2025.6.1/vspackage](https://marketplace.visualstudio.com/_apis/public/gallery/publishers/ms-python/vsextensions/vscode-pylance/2025.6.1/vspackage)

# Installation Guide

1. Download the¬†`.vsix`¬†file to a folder, for example: `C:\Downloads`
2. Open your terminal or shell (it can be inside Cursor or your system terminal).
3. Run the following command to install it manually:

&#8203;

    cursor --install-extension ms-python.vscode-pylance-2025.6.1.vsix

Once the installation finishes, check that Pylance appears in your installed extensions list.

Restart Cursor to ensure the extension loads correctly.

# Final Notes

After restarting, all Pylance features such as IntelliSense, linting, and type checking should be working normally again.  
This fix will keep your Python environment functional until Cursor upgrades its VS Code core beyond version 1.101.x.

I hope this helps other developers who are facing the same issue.  
If it works for you, share it forward so more people can stay productive with Cursor.

Happy coding, and cheers from Brazil üáßüá∑üë®‚Äçüíª",4,1,2025-10-30 17:32:25,with-ia-is-low-code,https://www.reddit.com/r/Python/comments/1ok4i17/fixing_pylance_compatibility_on_cursor_20/
1ok5ng0,reddit,(Free & Unlimited) Image Enhancer / Background Remover / OCR / Colorizer,"**URL** https://github.com/d60/picwish Please read the readme.md for the usage details.

# What My Project Does
This library allows you to use image enhancer, background remover, OCR, Colorizer and Text-To-Image for free and unlimited. It runs online and no API key is required. You can install it easily via pip.

# Target Audience
Everyone

# Comparison
This package is easier to use than others.

**Install**:
```
pip install picwish
```

**Quick Example**:
```python
import asyncio
from picwish import PicWish

async def main():
    picwish = PicWish()

    # Enhance an image
    enhanced_image = await picwish.enhance('/path/to/input.jpg')
    await enhanced_image.download('enhanced_output.jpg')

asyncio.run(main())
```",2,5,2025-10-30 18:15:08,06ddd,https://www.reddit.com/r/Python/comments/1ok5ng0/free_unlimited_image_enhancer_background_remover/
1ojgqmr,reddit,PathQL: A Declarative SQL Like Layer For Pathlib,"üêç What PathQL Does

PathQL allows you to easily walk file systems and perform actions on the files that match ""simple"" query parameters, that don't require you to go into the depths of `os.stat_result`  and the `datetime` module to find file ages, sizes and attributes.

The tool supports query functions that are common when crawling folders, tools to aggregate information about those files and finally actions to perform on those files.  Out of the box it supports copy, move, delete, fast_copy and zip actions.

It is also VERY/sort-of easy to sub-class filters that can look into the contents of files to add data about the file itself (rather than the metadata), perhaps looking for ERROR lines in todays logs, or image files that have 24 bit color.  For these types of filters it can be important to use the built in multithreading for sharing the load of reading into all of those files. 

```python
from pathql import AgeDays, Size, Suffix, Query,ResultField

# Count, largest file size, and oldest file from the last 24 hours in the result set
query = Query(
    where_expr=(AgeDays() == 0) & (Size() > ""10 mb"") & Suffix(""log""),
    from_paths=""C:/logs"",
    threaded=True
)
result_set = query.select()

# Show stats from matches
print(f""Number of files to zip: {result_set.count_()}"")
print(f""Largest file size: {result_set.max(ResultField.SIZE)} bytes"")
print(f""Oldest file: {result_set.min(ResultField.MTIME)}"")
```

And a more complex example

```python
from pathql import Suffix, Size, AgeDays, Query, zip_move_files

# Define the root directory for relative paths in the zip archive
root_dir = ""C:/logs""

# Find all .log files larger than 5MB and modified > 7 days ago
query = Query(
    where_expr=(Suffix("".log"") & (Size() > ""5 mb"") & (AgeDays() > 7)),
    from_paths=root_dir
)
result_set = query.select()

# Zip all matching files into 'logs_archive.zip' (preserving structure under root)
# Then move them to 'C:/logs/archive'
zip_move_files(
    result_set,
    target_zip=""logs_archive.zip"",
    move_target=""C:/logs/archive"",
    root=root_dir,
    preserve_dir_structure=True
)

print(""Zipped and moved files:"", [str(f) for f in result_set])

```

Support for querying on `Age`, `File`, `Suffix`, `Stem`, `Read`/`Write`/`Exec`, modified/created/accessed, `Size`, `Year`/`Month`/`Day`/`HourFilter` with compact syntax as well as aggregation support for `count_`, `min`, `max`, `top_n`, `bot_n`, `median` functions that may be applied to standard `os.stat` fields.

GitHub:[https://github.com/hucker/pathql](https://github.com/hucker/pathql)

Test coverage on the `src` folder is 85% with 500+ tests.

üéØ Target Audience

Developers who make tools to manage processes that generate large numbers of files that need to be managed, and just generally hate dealing with `datetime`, `timestamp` and other `os.stat` ad-hackery.  


üéØ Comparison

I have not found something that does what `PathQL` does beyond directly using `pathlib` and `os` and hand rolling your own predicates using a `pathlib` `glob`/`rglob` crawler.",37,30,2025-10-29 22:10:25,HolidayEmphasis4345,https://www.reddit.com/r/Python/comments/1ojgqmr/pathql_a_declarative_sql_like_layer_for_pathlib/
1oju1vf,reddit,I used Python (w/ Unsloth & Colab) to fine-tune Llama 3.1 to speak my rare Spanish dialect,"Just wanted to share a fun project that shows how powerful (and fast!) the Python AI ecosystem has become.

I was tired of generic AI, so I used Python + Unsloth to fine-tune Llama 3.1 on a free Google Colab T4. As a test, I taught it to speak ""Aragonese,"" my local dialect (it's hilarious).

The workflow (all Python) is now incredibly simple and fast. I recorded a 5-minute tutorial for anyone who wants to try fine-tuning their own AI persona.

Link to the 5-min video: [https://youtu.be/Cqpcvc9P-lQ](https://youtu.be/Cqpcvc9P-lQ)

It's amazing what we can do with Python these days!",2,1,2025-10-30 09:21:45,jokiruiz,https://www.reddit.com/r/Python/comments/1oju1vf/i_used_python_w_unsloth_colab_to_finetune_llama/
1ojt083,reddit,Seeking advice on freelance roles I can explore,"Hey everyone

I have been freelancing as a Data Analyst for a while and now I am trying to expand my skill set and take on more diverse projects. I know Python, Flask, Git and GitHub, Docker, and REST APIs. I also have some experience with machine learning and have done a few freelance data analysis projects.

I am looking to branch out and get more work in tech. For those already freelancing, what kind of roles or projects could I explore with these skills? Any tips on how to position myself or where to find such gigs would mean a lot.

Thanks in advance!",5,5,2025-10-30 08:09:12,Designer-Mirror-8823,https://www.reddit.com/r/Python/comments/1ojt083/seeking_advice_on_freelance_roles_i_can_explore/
1ojkvx8,reddit,"Thursday Daily Thread: Python Careers, Courses, and Furthering Education!","# Weekly Thread: Professional Use, Jobs, and Education üè¢

Welcome to this week's discussion on Python in the professional world! This is your spot to talk about job hunting, career growth, and educational resources in Python. Please note, this thread is **not for recruitment**.

---

## How it Works:

1. **Career Talk**: Discuss using Python in your job, or the job market for Python roles.
2. **Education Q&A**: Ask or answer questions about Python courses, certifications, and educational resources.
3. **Workplace Chat**: Share your experiences, challenges, or success stories about using Python professionally.

---

## Guidelines:

- This thread is **not for recruitment**. For job postings, please see r/PythonJobs or the recruitment thread in the sidebar.
- Keep discussions relevant to Python in the professional and educational context.
  
---

## Example Topics:

1. **Career Paths**: What kinds of roles are out there for Python developers?
2. **Certifications**: Are Python certifications worth it?
3. **Course Recommendations**: Any good advanced Python courses to recommend?
4. **Workplace Tools**: What Python libraries are indispensable in your professional work?
5. **Interview Tips**: What types of Python questions are commonly asked in interviews?

---

Let's help each other grow in our careers and education. Happy discussing! üåü",10,1,2025-10-30 01:00:33,AutoModerator,https://www.reddit.com/r/Python/comments/1ojkvx8/thursday_daily_thread_python_careers_courses_and/
1oj0ogq,reddit,"Pyfory: Drop‚Äëin replacement serialization for pickle/cloudpickle ‚Äî faster, smaller, safer","**Pyfory**¬†is the Python implementation of¬†[Apache Fory‚Ñ¢](https://github.com/apache/fory/blob/main/python/README.md)¬†‚Äî a versatile serialization framework.

It works as a¬†**drop‚Äëin replacement for**¬†`pickle`\*\*/\*\*`cloudpickle`, but with major upgrades:

* **Features**: Circular/shared reference support, protocol‚Äë5 zero‚Äëcopy buffers for huge NumPy arrays and Pandas DataFrames.
* **Advanced hooks**: Full support for custom class serialization via¬†`__reduce__`,¬†`__reduce_ex__`, and¬†`__getstate__`.
* **Data size**: \~25% smaller than pickle, and 2‚Äì4√ó smaller than cloudpickle when serializing local functions/classes.
* **Compatibility**: Pure Python mode for dynamic objects (functions, lambdas, local classes), or cross‚Äëlanguage mode to share data with Java, Go, Rust, C++, JS.
* **Security**: Strict mode to block untrusted types, or fine‚Äëgrained¬†`DeserializationPolicy`¬†for controlled loading.",134,28,2025-10-29 11:16:22,Shawn-Yang25,https://www.reddit.com/r/Python/comments/1oj0ogq/pyfory_dropin_replacement_serialization_for/
1oiwxt5,reddit,Why doesn't for-loop have it's own scope?,"For the longest time I didn't know this but finally decided to ask, I get this is a thing and probably has been asked a lot but i genuinely want to know... why? What gain is there other than convenience in certain situations, i feel like this could cause more issue than anything even though i can't name them all right now.

I am also designing a language that works very similarly how python works, so maybe i get to learn something here.",175,282,2025-10-29 07:08:00,FUS3N,https://www.reddit.com/r/Python/comments/1oiwxt5/why_doesnt_forloop_have_its_own_scope/
1oj4mcr,reddit,Pylint 4 changes what's considered a constant. Does a use case exist?,"Pylint 4 changed their definition of constants. Previously, all variables at the root of a module were considered constants and expected to be in all caps. With Pylint 4, they are now checking to see if a variable is reassigned non-exclusively. If it is, then it's treated as a ""module-level variable"" and expected to be in snake case.

So this pattern, which used to be valid, now raises an invalid-name warning.

    SERIES_STD = ' ‚ñå‚ñà' if platform.system() == 'Windows' else ' ‚ñè‚ñé‚ñç‚ñå‚ñã‚ñä‚ñâ‚ñà'
    try:
        SERIES_STD.encode(sys.__stdout__.encoding)
    except UnicodeEncodeError:
        SERIES_STD = ' |'
    except (AttributeError, TypeError):
        pass

This could be re-written to match the new definition of a constant, but doing so reduces readability.

In my mind any runtime code is placed in classes, function or guarded with a dunder name clause. This only leaves code needed for module initialization. Within that, I see two categories of variables at the module root, constants and globals.

* Constants
   * After value is determine (like above example), it never changes
   * All caps
* Globals
   * After the value is determined, it can be changed within a function/method via the global keyword
   * snake case, but should also start with an underscore or `__all__` should be defined and exclude them (per [PEP8](https://peps.python.org/pep-0008/#global-variable-names))
   * rare, Pylint complains when the global keyword is used

Pylint 4 uses the following categories

* Constants
   * Value is assigned once, exclusively
   * All caps
* Module-level variables
   * Any variable that is assigned more than once, non-exclusively
   * snake case
   * Includes globals as defined above

A big distinction here is I do not think exclusive assignment should make a difference because it means the pattern of (assign, test, fallback) is invalid for a constant. I treat both assignment statements in the above example as part of determining the value of the constant.

I have been unable to see a real case where you'd change the value of a variable at the module root after it's initial value is determined and not violate some other good coding practice.

I've been looking for 4 days and haven't found any good examples that benefit from the new behavior in Pylint 4. Every example seems to have something scary in it, like parsing a config file as part of module initialization, and, once refactored to follow other good practices, the reassignment of module-level variables disappears.

Does someone have an example?",44,39,2025-10-29 14:31:59,avylove,https://www.reddit.com/r/Python/comments/1oj4mcr/pylint_4_changes_whats_considered_a_constant_does/
1ojv8h5,reddit,Reinventing the wheel?,"I‚Äôve been using Python for 2 years and I‚Äôm now doing some email outreach and other marketing activities that include website visitor tracking.

Is it a crazy idea to build a Python / Flask / Django app like some of the better known marketing automation apps? [single tenant not multi-tenant] 

Are there some building blocks or repositories that take me some or all of the way?

Interested in sending emails via Google mail with tracking of opens and clicks. Track website pages and landing pages. Assist with scoring visitors to identify engagement.

Crazy or a good challenge?
Appreciate a reality check.",2,11,2025-10-30 10:40:43,Intelligent-Cow341,https://www.reddit.com/r/Python/comments/1ojv8h5/reinventing_the_wheel/
1ok754r,reddit,Installing Xformers with UV not even works??,"i have been trying to install an unsloth but it does not installing with cuda enabled i have tired with pip and also uv and uv pip install not even installing cuda and xformers i don't know why i even added sources and index on uv and tried this [https://docs.astral.sh/uv/guides/integration/pytorch/#installing-pytorch](https://docs.astral.sh/uv/guides/integration/pytorch/#installing-pytorch) method and also unsloth install using pypi and also directly from github not working conflict always occur i am on windows so can any one give me any toml setup code referernce that works for any python version or cuda version?

btw! it always install cpu not cuda or else conflict plz suggest me any setup for cuda",0,5,2025-10-30 19:10:34,Complex_Height_1480,https://www.reddit.com/r/Python/comments/1ok754r/installing_xformers_with_uv_not_even_works/
1ojo90k,reddit,"Any one else got the email from a prominent contributor and ""REQUEST for Support"" ?","Not naming him because I'm not sure if it'd break any rules. If you've been around the community for just few years you'd know who I'm referring to.

It's really sad and heart-breaking that such well-known, skilled & talented person has been wrecked by mental illness and broken down to single-digit bank account balance.

Yes I have read about his ""attitude"". I think it has to do with his mental issues.

I'm going to help him.",3,12,2025-10-30 03:35:46,slowwolfcat,https://www.reddit.com/r/Python/comments/1ojo90k/any_one_else_got_the_email_from_a_prominent/
1oj294x,reddit,Best courses Python and Django X,"Hi all, 
I have a new role at work, which is kind of link between IT and the technical role (I am coming from the techical side).
I enjoy coding and have basic python and java script skills which I get by with for personal projects and AI.

For this role, my work have agreed to fund some development and i am looking for the best python and mainly django x framework courses/plans to gain bettet knowledge anf best practice to be more aid to the IT department. 

Wondered if anyone knew the best plan of action? Would likey need futher python training and then I am new to Django and offcial IT workflows and what not.

Tia ",15,8,2025-10-29 12:43:31,lsimcoates,https://www.reddit.com/r/Python/comments/1oj294x/best_courses_python_and_django_x/
1ojx3ws,reddit,Python performance: 3.14 vs 3.13 / 3.12 / 3.11 / 3.10,"I recently shared performance test results for **Python 3.14**, and compared them with previous version ‚Äî **3.13, 3.12, 3.11, and 3.10**. About **100 benchmark tests** were conducted using the [pyperformance 1.12.0](https://pyperformance.readthedocs.io/) on **Windows 11**, across two main hardware platforms:

* **AMD Ryzen 7000** desktop systems
* **Intel Core 13th-gen** laptops and mini PCs

All runs used **64-bit builds** of the following versions:

* [Python 3.14.0](https://www.python.org/downloads/release/python-3140/)
* [Python 3.13.9](https://www.python.org/downloads/release/python-3139/)
* [Python 3.12.10](https://www.python.org/downloads/release/python-31210/)
* [Python 3.11.9](https://www.python.org/downloads/release/python-3119/)
* [Python 3.10.11](https://www.python.org/downloads/release/python-31011/)

I found some noticeable trends, which made me curious how consistent these gains are across different setups. If you‚Äôre interested, the full benchmark summary and charts are available in the [article](https://en.lewoniewski.info/2025/python-314-vs-313-312-311-310-performance-testing-video/), [video](https://www.youtube.com/watch?v=Ft3odeBEST4) and [special project](https://python.lewoniewski.info/).

Can you recommend any **other reliable or interesting benchmark** comparisons for Python 3.14?  
If so, I‚Äôd love to see how their results line up with these findings.

",0,5,2025-10-30 12:28:35,Lewoniewski,https://www.reddit.com/r/Python/comments/1ojx3ws/python_performance_314_vs_313_312_311_310/
1ok1nqi,reddit,i am creating a basic python pkg is it worth it ??,"**problem :**

In machine learning projects, datasets are often scattered across multiple folders or drives usually in CSV files.  
Over time, this causes:

* Confusion about which version of the dataset is the latest.
* Duplicate or outdated files lying around the system.
* Difficulty in managing and loading consistent data during experiments.

**Solution :**

This package solves the **data chaos problem** by introducing a **centralized data management system** for ML workflows.

Here‚Äôs how it works:

1. When you **download or create a dataset**, you place it into **one dedicated folder** (managed by this package).
2. The package automatically tracks **versions** of each dataset  so you always know which one is the latest.
3. From **any location on your computer**, you can easily **load the current or a specific version** of a dataset through the package API.

**Limitations:**

Each dataset includes a **seed file** that stores key metadata such as its **nickname**, **dataset name**, **shape**, **column names**, and a **brief description** making it easier to identify and manage datasets.

The package supports **basic DataFrame operations** like:

* Mapping columns
* Dropping columns
* Renaming columns
* Performing simple text processing for cleaning and formatting data

It also offers **version management tools** that let you **delete** or **terminate** older dataset versions, helping maintain a clutter-free workspace.

Additionally, it provides handy **utility functions** for daily tasks such as:

* Reading and writing JSON files
* Reading and writing plain text files

Overall, this package acts as a **lightweight bridge between your data and your code**, keeping your datasets organized, versioned, and reusable  without relying on heavy tools like DVC or Git-LFS.

*(\*\*formated english with gpt with the content is mine\*\*)*",0,17,2025-10-30 15:45:28,InvestigatorEasy7673,https://www.reddit.com/r/Python/comments/1ok1nqi/i_am_creating_a_basic_python_pkg_is_it_worth_it/
1ojgkmz,reddit,What's this sub's opinion on panda3d/interrogate?,"[https://github.com/panda3d/interrogate](https://github.com/panda3d/interrogate)

  
I'm just curious how many people have even heard of it, and what people think of it.

Interrogate is a tool used by Panda3D to generate python bindings for its c++ code. it was spun into it's own repo a while back in the hopes that people outside the p3d community might use it.",3,1,2025-10-29 22:03:54,MycologistIcy7281,https://www.reddit.com/r/Python/comments/1ojgkmz/whats_this_subs_opinion_on_panda3dinterrogate/
1ojjnwu,reddit,üöÄ Released httptap 0.2.0 ‚Äî a Python CLI tool to debug HTTP requests (with skip TLS & proxy support),"Hey everyone!

A few days ago, I announced the first version of [httptap](https://www.reddit.com/r/Python/comments/1ogjjrl/i_built_a_python_tool_to_debug_http_request/) ‚Äî a small CLI tool I built to debug and inspect HTTP requests.

Got a lot of great feedback, and I‚Äôve just released **version 0.2.0** with several improvements suggested by the community.

üì¶ **PyPI:** [https://pypi.org/project/httptap/0.2.0/](https://pypi.org/project/httptap/0.2.0/)

üíª **GitHub:** [https://github.com/ozeranskii/httptap/releases/tag/v0.2.0](https://github.com/ozeranskii/httptap/releases/tag/v0.2.0)

üç∫ **Homebrew:** `brew install httptap`

# üß∞ What My Project Does

httptap is a lightweight command-line tool that lets you:

* Send HTTP/HTTPS requests
* View detailed request/response data (headers, timing, TLS info, etc.)
* Debug tricky networking issues or backend APIs

Think of it as a **more scriptable and transparent alternative to cURL** for developers who live in the terminal.

# üéØ Target Audience

* Developers debugging HTTP requests or APIs
* Backend engineers working with custom clients, webhooks, or payment integrations
* Anyone who needs to quickly reproduce or inspect HTTP traffic

# ‚öôÔ∏è What‚Äôs New in 0.2.0

* üîí **Optional TLS verification** ‚Äî not just skipping cert validation, but allowing reduced TLS security levels for deep debugging.
* üåê **Proxy support** ‚Äî you can now route outgoing requests through HTTP/S proxies.
* üç∫ **Now available via Homebrew** ‚Äî `brew install httptap`.

# üîç Comparison

httptap focuses on **transparency and debugging depth** ‚Äî showing full connection info, timings, and TLS details in one place, without UI overhead.

It‚Äôs ideal for scripting, CI, and quick diagnostics from the command line.

Would love feedback or feature suggestions ‚Äî especially around edge-case TLS testing or proxy behavior!

If you find it useful, I‚Äôd really appreciate a ‚≠ê on GitHub - it helps others discover the project.

üëâ¬†[https://github.com/ozeranskii/httptap](https://github.com/ozeranskii/httptap)",1,0,2025-10-30 00:08:35,ozeranskii,https://www.reddit.com/r/Python/comments/1ojjnwu/released_httptap_020_a_python_cli_tool_to_debug/
1ojuk8e,reddit,Curious to know how you guys think about this,"Just read this article about building AI agents in Java rather than Python. 

An excerpt from the article:
""You can build better agents in Java than in Python and the JVM is superior to Python for real-world generative Ai applications"" 

What do you guys think about this? 

Article link:
https://www.infoworld.com/article/4071159/java-or-python-for-building-agents.html",0,7,2025-10-30 09:56:36,Rawvik,https://www.reddit.com/r/Python/comments/1ojuk8e/curious_to_know_how_you_guys_think_about_this/
1oj8uxy,reddit,Python screenshot library,"In my old job as a software tester I recall using a pycreenshot library, but now I notice it's superceeded by Pillow.ImageGrab . I'm asking because I have an issue which the Pillow developers seem to be regularly closing as fixed/wontfix. Any alternatives to work around what does appear to be this problem, which is RDP session related I suspect. None of the suggestions in the threads [https://github.com/python-pillow/Pillow/issues/2631](https://github.com/python-pillow/Pillow/issues/2631) are actually solutions that are Robust. And due to no hard facts on what's the root cause or way for me to know what to look into to discover the root, am looking for alternatives?  


I'm going with trying a fallback to pyscreenshot, and will feedback if that works. I like that pyscreenshot does have some support 'linuxes support since I'm going to have to port for that at some point. Is there some explainer around the backend= arg, since for me speed is not a huge issue.",2,2,2025-10-29 17:16:06,zaphodikus,https://www.reddit.com/r/Python/comments/1oj8uxy/python_screenshot_library/
1oj420o,reddit,SHDL: A Minimal Hardware Description Language Built With ONLY Logic Gates - seeking contributors!,"Hi everyone ‚Äî I‚Äôm excited to share my new
project: SHDL (Simple Hardware Description Language). It‚Äôs a tiny yet expressive HDL that uses only basic logic gates to build combinational and sequential circuits. You can use it to describe components hierarchically, support vector signals, even generate C code for simulation. Check it out here:   
  

Link: https://github.com/rafa-rrayes/SHDL

## What My Project Does

SHDL (Simple Hardware Description Language) is a tiny, educational hardware description language that lets you design digital circuits using only logic gates. Despite its minimalism, you can build complex hierarchical components like adders, registers, and even CPUs ‚Äî all from the ground up.

The SHDL toolchain parses your code and compiles it down to C code for simulation, so you can test your designs easily without needing an FPGA or specialized hardware tools.

‚∏ª

## Target Audience
SHDL is primarily aimed at:
	‚Ä¢	Learners and hobbyists who want to understand how digital hardware works from first principles.
	‚Ä¢	Language and compiler enthusiasts curious about designing domain-specific languages for hardware.
	‚Ä¢	Educators who want a lightweight HDL for teaching digital logic, free from the complexity of VHDL or Verilog.

It‚Äôs not intended for production use ‚Äî think of it as a learning tool and experimental playground for exploring the building blocks of hardware description.

## Comparison 
Unlike Verilog, VHDL, or Chisel, SHDL takes a bottom-up, minimalist approach. There are no built-in arithmetic operators, types, or clock management systems ‚Äî only pure logic gates and hierarchical composition. You build everything else yourself.

This design choice makes SHDL:
	‚Ä¢	Simpler to grasp for newcomers ‚Äî you see exactly how complex logic is built from basics.
	‚Ä¢	More transparent ‚Äî no abstraction layers hiding what‚Äôs really happening.
	‚Ä¢	Portable and lightweight ‚Äî the compiler outputs simple C code, making it easy to integrate, simulate, and extend.

## How You Can help

I‚Äôd love your feedback and contributions! You can:
  
	‚Ä¢	Test SHDL and share suggestions on syntax and design.
  
	‚Ä¢	Build example circuits (ALUs, multiplexers, counters, etc.).
  
	‚Ä¢	Contribute to the compiler or add new output targets.
  
	‚Ä¢	Improve docs, examples, and tutorials.


This is still an early project, so your input can directly shape where SHDL goes next.

‚∏ª

### What I am going to focus on:

- The API for interacting with the circuit 
- Add support for compiling and running on embedded devices, using the pins as the actual interface for the circuit.
- Add constants to the circuits (yes i know, this shouldve been done already)
- Maybe make the c code more efficient, if anyone knows how. ",4,2,2025-10-29 14:08:06,rafa_rrayes,https://www.reddit.com/r/Python/comments/1oj420o/shdl_a_minimal_hardware_description_language/
1oiufp2,reddit,A new easy way on Windows to pip install GDAL and other tricky geospatial Python packages,"# What My Project Does

[geospatial-wheels-index](https://github.com/corbel-spatial/geospatial-wheels-index) is a pip-compatible 
[simple](https://packaging.python.org/en/latest/specifications/simple-repository-api/) index for the [cgohlke/geospatial-wheels](https://github.com/cgohlke/geospatial-wheels) repository. It's just a few static html files served on GitHub Pages, and all the .whl files are pulled directly from `cgohlke/geospatial-wheels`. All you need to do is add an `index` flag:

```
pip install --index https://gisidx.github.io/gwi gdal
```

In addition to GDAL, this index points to the other prebuilt packages in `geospatial-wheels`: cartopy, cftime, fiona, h5py, netcdf4, pygeos, pyogrio, pyproj, rasterio, rtree, and shapely.

Contributions are welcome!

# Target Audience

Mostly folks who straddle the traditional GIS and the developer/data science worlds, the people who would love to run Linux but are stuck on Windows for one reason or another. 

For myself, I'm tired of dealing with the lack of an easy way to install the GDAL binaries on Windows so that I can `pip install gdal`, especially in a `uv` virtual environment or a CI/CD context where using `conda` can be a headache.

# Comparison

Often you'll have to build these packages from source or rely on `conda` or another add-on package manager. For example, the official GDAL docs suggest [various ways](https://gdal.org/en/stable/download.html#windows) to install the binaries. This is often not possible or requires extra work.

The esteemed Christoph Gohlke has been providing prebuilt wheels for GDAL and other packages for a long time, and currently they can be found at his repository, [geospatial-wheels](https://github.com/cgohlke/geospatial-wheels). Awesome! But you have to manually find the one that matches your environment, download it somewhere, and then `pip install` the file... Still pretty annoying and difficult to automate. This index project simplifies the process down to the easy and portable `pip install`.

This project was partly inspired by [gdal-installer](https://pypi.org/project/gdal-installer/) which is also worth checking out.",16,0,2025-10-29 04:41:59,pvdp-corbel,https://www.reddit.com/r/Python/comments/1oiufp2/a_new_easy_way_on_windows_to_pip_install_gdal_and/
1oilkc1,reddit,The HTTP caching Python deserves,"# What My Project Does

[Hishel](https://hishel.com/1.0/) is an HTTP caching toolkit for python, which includes **sans-io** caching implementation, **storages** for effectively storing request/response for later use, and integration with your lovely HTTP tool in python such as HTTPX, requests, fastapi, asgi (for any asgi based library), graphql and more!!

Hishel uses **persistent storage** by default, so your cached responses survive program restarts.

After **2 years** and over **63 MILLION pip installs**, I released the first major version with tons of new features to simplify caching.

‚ú® Help Hishel grow! Give us a [star on GitHub](https://github.com/karpetrosyan/hishel) if you found it useful. ‚ú®

# Use Cases:

HTTP response caching is something you can use **almost everywhere** to:

* Improve the performance of your program
* Work without an internet connection (offline mode)
* Save money and stop wasting API calls‚Äîmake a single request and reuse it many times!
* Work even when your upstream server goes down
* Avoid unnecessary downloads when content hasn't changed (what I call ""free caching""‚Äîit's completely free and can be configured to always serve the freshest data without re-downloading if nothing changed, like the browser's 304 Not Modified response)

# QuickStart

First, download and install Hishel using pip:

pip: `pip install ""hishel[httpx, requests, fastapi, async]""==1.0.0`

We've installed several integrations just for demonstration‚Äîyou most likely won't need them all.

    from hishel.httpx import SyncCacheClient
    
    client = SyncCacheClient()
    
    # On first run of the program, this will store the response in the cache
    # On second run, it will retrieve it from the cache
    response = client.get(""https://hishel.com/"")
    
    
    print(response.extensions[""hishel_from_cache""])  # Additional info about the cache statusfrom hishel.httpx import SyncCacheClient
    
    client = SyncCacheClient()
    
    
    # On first run of the program, this will store the response in the cache
    # On second run, it will retrieve it from the cache
    response = client.get(""https://hishel.com/"")
    
    
    print(response.extensions[""hishel_from_cache""])  # Additional info about the cache status

or with requests:

    import requests
    from hishel.requests import CacheAdapter
    
    session = requests.Session()
    
    adapter = CacheAdapter()
    session.mount(""http://"", adapter)
    session.mount(""https://"", adapter)
    
    response = session.get(""https://hishel.com/"")
    
    print(response.headers[""x-hishel-from-cache""])

or with fastapi:

    from hishel.asgi import ASGICacheMiddleware
    from hishel.fastapi import cache
    
    app = FastAPI()
    
    processed_requests = 0
    
    .get(""/items/"", dependencies=[cache(max_age=5)])
    async def read_item():
        global processed_requests
        processed_requests += 1
        return {""created_at"": time.time(), ""processed_requests"": processed_requests}
    
    cached_app = ASGICacheMiddleware(app)

As mentioned before, Hishel has a core system that is entirely independent from any HTTP library, making it easy to integrate with any HTTP client you prefer.

# Caching Policies

**SpecificationPolicy** \- RFC 9111 compliant HTTP caching (default):

    from hishel import CacheOptions, SpecificationPolicy
    from hishel.httpx import SyncCacheClient
    
    client = SyncCacheClient(
        policy=SpecificationPolicy(
            cache_options=CacheOptions(
                shared=False,                              # Use as private cache (browser-like)
                supported_methods=[""GET"", ""HEAD"", ""POST""], # Cache GET, HEAD, and POST
                allow_stale=True                           # Allow serving stale responses
            )
        )
    )

**FilterPolicy** \- Custom filtering logic for fine-grained control:

    from hishel import FilterPolicy, BaseFilter, Request
    from hishel.httpx import AsyncCacheClient
    
    class CacheOnlyAPIRequests(BaseFilter[Request]):
        def needs_body(self) -> bool:
            return False
        
        def apply(self, item: Request, body: bytes | None) -> bool:
            return ""/api/"" in str(item.url)
    
    client = AsyncCacheClient(
        policy=FilterPolicy(
            request_filters=[CacheOnlyAPIRequests()] # also filter by body, status and etc.
        )
    )

# Storage Backend

Customize the storage backend behavior, set up global TTL (**note that TTL and most settings can also be configured at the per-request level**), choose whether to refresh TTL on access, and much more!

    from hishel import SyncSqliteStorage
    from hishel.httpx import SyncCacheClient
    
    storage = SyncSqliteStorage(
        database_path=""my_cache.db"",
        default_ttl=7200.0,           # Cache entries expire after 2 hours
        refresh_ttl_on_access=True    # Reset TTL when accessing cached entries
    )
    
    client = SyncCacheClient(storage=storage)

# Per-request settings

    from hishel.httpx import SyncCacheClient
    
    
    client = SyncCacheClient()
    
    client.get(
        ""https://hishel.com/"",
        headers={
            ""x-hishel-ttl"": ""3600"",  # invalidates cache after 1 hour, even if server says otherwise
        },
    )
    
    client.post(
        ""https://some-graphql-endpoint.com/"",
        json={""query"": ""{ users { id name } }""},
        headers={""x-hishel-body-key""},  # Include body in cache key
    )
    
    client.get(
        ""https://hishel.com/"", 
        headers={""x-hishel-refresh-ttl-on-access"": ""0""}  # do not refresh TTL on access
    )

# Target Audience

**Backend Developers** \- Building APIs with FastAPI/Django, making repeated HTTP requests to external APIs

**Data Engineers** \- Running ETL pipelines and batch jobs, fetching same data across multiple runs

**CLI Tool Builders** \- Creating command-line tools, need instant responses and offline support

**Web Scrapers** \- Building content crawlers, respect rate limits and need offline testing

**API Library Maintainers** \- Wrapping external APIs (GitHub, Stripe, OpenAI), need transparent caching

**GraphQL Developers** \- Need per-query caching with body-sensitive keys

**Also great for:** DevOps teams, performance-focused companies, enterprise users needing RFC 9111 compliance

‚≠ê GitHub: [https://github.com/karpetrosyan/hishelWhat](https://github.com/karpetrosyan/hishelWhat)",48,12,2025-10-28 22:09:35,karosis88,https://www.reddit.com/r/Python/comments/1oilkc1/the_http_caching_python_deserves/
1ojauq1,reddit,Bivariate analysis in python,"Student mental health dataset- tutorial of bivariate analysis techniques using python(pandas, seaborn,matplotlib) and SQL 


https://youtu.be/luO-iYHIqTg?si=UNecHrZpYsKmznBF",0,0,2025-10-29 18:29:22,Trinity_software,https://www.reddit.com/r/Python/comments/1ojauq1/bivariate_analysis_in_python/
1oj8s6y,reddit,New Release: cookiecutter-uv-gitlab - A Targeted Migration for GitLab,"Hey everyone,

A few days ago, I posted a [new gitlab ci component](https://www.reddit.com/r/Python/comments/1ocgcqh/new_uv_gitlab_component/) for uv inside gitlab, which I created with an intent.  
The intent to migrate a cookiecutter template.

Now, I've just released **cookiecutter-uv-gitlab**, a new project template built to fully embrace **GitLab's integrated features**.

This template represents a direct evolution and migration of the popular **fpgmass/cookiecutter-uv** template. While the original was excellent, this new version has been specifically updated to leverage GitLab's native tools, helping you consolidate your workflows and reduce dependency on external services.

**What my project does**

If you've been looking for a template that truly feels native to GitLab, this is it. We've made three major shifts to enhance the integrated experience:

1. **Fully Native GitLab CI/CD:** We've ditched generic CI setups for an opinionated, modern `.gitlab-ci.yml` designed to maximize efficiency with GitLab Runners and features.
2. **GitLab Coverage Reporting:** Coverage is now handled directly by **GitLab's native coverage reporting tools**, replacing the need for services like Codecov. Get your metrics right where your code lives.
3. **Package Publishing to GitLab Registry:** The template is pre-configured to handle seamless **package publishing (e.g., Python packages)** directly to your project's **GitLab Package Registry**, consolidating your dependency management and distribution.

This template saves you the effort of repeatedly setting up initial configuration, ensuring every new project on your team starts with a strong, highly-integrated foundation. Stop copying old config files and start coding faster.

The template is created with an upstream connection, so for most parts an equal result for both templates could be expected.

Check it out, give it a run, and let me know what you think!

**Template Link:**[https://gitlab.com/gitlab-uv-templates/cookiecutter-uv-gitlab](https://gitlab.com/gitlab-uv-templates/cookiecutter-uv-gitlab)

**Target Audience**

The project is created for open source python project owners, who intent to provide a solid base project structure and want to leverage the automations of gitlab-ci.

**Comparison**

This project is a downstream migration of the fpgmaas/cookiecutter-uv template, which utilizes github actions for automation. The main part of the migration includes the replacement of github actions against gitlab-ci, the replacment of codecov against gitlab coverage report and publishing against the gitlab registry.",1,0,2025-10-29 17:13:16,MaKaNuReddit,https://www.reddit.com/r/Python/comments/1oj8s6y/new_release_cookiecutteruvgitlab_a_targeted/
1oidpl8,reddit,Introducing Kanchi - Free Open Source Celery Monitoring,"I just shipped https://kanchi.io - a free open source celery monitoring tool (https://github.com/getkanchi/kanchi)

**What does it do**

Previously, I used flower, which most of you probably know. And it worked fine. It lacked some features like Slack webhook integration, retries, orphan detection, and a live mode.

I also wanted a polished, modern look and feel with additional UX enhancements like retrying tasks, hierarchical args and kwargs visualization, and some basic stats about our tasks.

It also stores task metadata in a Postgres (or SQLite) database, so you have historical data even if you restart the instance. It‚Äôs still in an early state.

**Comparison to alternatives**

Just like flower, Kanchi is free and open source. You can self-host it on your infra and it‚Äôs easy to setup via docker.

Unlike flower, it supports realtime task updates, has a workflow engine (where you can configure triggers, conditions and actions), has a great searching and filtering functionality, supports environment filtering (prod, staging etc) and retrying tasks manually. It has built in orphan task detection and comes with basic stats

**Target Audience**

Since by itself, it is just reading data from your message broker - and it‚Äôs working reliably, Kanchi can be used in production.

The next few releases will further target robustness and UX work.‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã

If anyone is looking for a new celery monitoring experience, this is for you! I‚Äôm happy about bug reports and general feedback! ",55,18,2025-10-28 17:15:15,imczyber,https://www.reddit.com/r/Python/comments/1oidpl8/introducing_kanchi_free_open_source_celery/
1ohh6v2,reddit,The PSF has withdrawn $1.5 million proposal to US government grant program,"In January 2025, the PSF submitted a proposal to the US government National Science Foundation under the [Safety, Security, and Privacy of Open Source Ecosystems program](https://www.nsf.gov/funding/opportunities/safe-ose-safety-security-privacy-open-source-ecosystems) to address structural vulnerabilities in Python and PyPI. It was the PSF‚Äôs first time applying for government funding, and navigating the intensive process was a steep learning curve for our small team to climb. Seth Larson, PSF Security Developer in Residence, serving as Principal Investigator (PI) with Loren Crary, PSF Deputy Executive Director, as co-PI, led the multi-round proposal writing process as well as the months-long vetting process. We invested our time and effort because we felt the PSF‚Äôs work is a strong fit for the program and that the benefit to the community if our proposal were accepted was considerable.¬†¬†

We were honored when, after many months of work, our proposal was recommended for funding, particularly as only [36% ](https://www.nsf.gov/funding/overview)of new NSF grant applicants are successful on their first attempt. We became concerned, however, when we were presented with the terms and conditions we would be required to agree to if we accepted the grant. These terms included affirming the statement that we ‚Äúdo not, and will not during the term of this financial assistance award, operate any programs that advance or promote DEI, or discriminatory equity ideology in violation of Federal anti-discrimination laws.‚Äù This restriction would apply not only to the security work directly funded by the grant, **but to any and all activity of the PSF as a whole**. Further, violation of this term gave the NSF the right to ‚Äúclaw back‚Äù previously approved and transferred funds. This would create a situation where money we‚Äôd already spent could be taken back, which would be an enormous, open-ended financial risk.¬† ¬†

Diversity, equity, and inclusion are core to the PSF‚Äôs values, as committed to in our [mission statement](https://www.python.org/psf/mission/):¬†

>*The mission of the Python Software Foundation is to promote, protect, and advance the Python programming language, and to support and facilitate the growth of* ***a diverse and international community*** *of Python programmers.*

Given the value of the grant to the community and the PSF, we did our utmost to get clarity on the terms and to find a way to move forward in concert with our values. We consulted our NSF contacts and reviewed decisions made by other organizations in similar circumstances, particularly [The Carpentries](https://carpentries.org/blog/2025/06/announcing-withdrawal-of-nsf-pose-proposal/).¬†¬†

In the end, however, the PSF simply can‚Äôt agree to a statement that we won‚Äôt operate any programs that ‚Äúadvance or promote‚Äù diversity, equity, and inclusion, as it would be a betrayal of our mission and our community.¬†

We‚Äôre disappointed to have been put in the position where we had to make this decision, because we believe our proposed project would offer invaluable advances to the Python and greater open source community, protecting millions of PyPI users from attempted supply-chain attacks. The proposed project would create new tools for automated proactive review of all packages uploaded to PyPI, rather than the current process of reactive-only review. These novel tools would rely on capability analysis, designed based on a dataset of known malware. Beyond just protecting PyPI users, the outputs of this work could be transferable for all open source software package registries, such as NPM and [Crates.io](http://Crates.io), improving security across multiple open source ecosystems.

In addition to the security benefits, the grant funds would have made a big difference to the PSF‚Äôs budget. The PSF is a relatively small organization, operating with an annual budget of around $5 million per year, with a staff of just 14. $1.5 million over two years would have been quite a lot of money for us, and easily the largest grant we‚Äôd ever received. Ultimately, however, the value of the work and the size of the grant were not more important than practicing our values and retaining the freedom to support every part of our community. The PSF Board voted unanimously to withdraw our application.¬†

Giving up the NSF grant opportunity‚Äîalong with inflation, lower sponsorship, economic pressure in the tech sector, and global/local uncertainty and conflict‚Äîmeans the PSF needs financial support now more than ever. We are incredibly grateful for any help you can offer. If you're already a PSF member or regular donor, you have our deep appreciation, and we urge you to share your story about why you support the PSF. Your stories make all the difference in spreading awareness about the mission and work of the PSF.¬†In January 2025, the PSF submitted a proposal to the US government National Science Foundation under the Safety, Security, and Privacy of Open Source Ecosystems program  
 to address structural vulnerabilities in Python and PyPI. It was the   
PSF‚Äôs first time applying for government funding, and navigating the   
intensive process was a steep learning curve for our small team to   
climb. Seth Larson, PSF Security Developer in Residence, serving as   
Principal Investigator (PI) with Loren Crary, PSF Deputy Executive   
Director, as co-PI, led the multi-round proposal writing process as well  
 as the months-long vetting process. We invested our time and effort   
because we felt the PSF‚Äôs work is a strong fit for the program and that   
the benefit to the community if our proposal were accepted was   
considerable.¬†¬†We were honored when, after many months of work, our proposal was recommended for funding, particularly as only 36% of  
 new NSF grant applicants are successful on their first attempt. We   
became concerned, however, when we were presented with the terms and   
conditions we would be required to agree to if we accepted the grant.   
These terms included affirming the statement that we ‚Äúdo not, and will   
not during the term of this financial assistance award, operate any   
programs that advance or promote DEI, or discriminatory equity ideology   
in violation of Federal anti-discrimination laws.‚Äù This restriction   
would apply not only to the security work directly funded by the grant, but to any and all activity of the PSF as a whole.  
 Further, violation of this term gave the NSF the right to ‚Äúclaw back‚Äù   
previously approved and transferred funds. This would create a situation  
 where money we‚Äôd already spent could be taken back, which would be an   
enormous, open-ended financial risk.¬† ¬†  
Diversity, equity, and inclusion are core to the PSF‚Äôs values, as committed to in our mission statement:¬†The  
 mission of the Python Software Foundation is to promote, protect, and   
advance the Python programming language, and to support and facilitate   
the growth of a diverse and international community of Python programmers.Given  
 the value of the grant to the community and the PSF, we did our utmost   
to get clarity on the terms and to find a way to move forward in concert  
 with our values. We consulted our NSF contacts and reviewed decisions   
made by other organizations in similar circumstances, particularly The Carpentries.¬†¬†  
In  
 the end, however, the PSF simply can‚Äôt agree to a statement that we   
won‚Äôt operate any programs that ‚Äúadvance or promote‚Äù diversity, equity,   
and inclusion, as it would be a betrayal of our mission and our   
community.¬†  
We‚Äôre disappointed to   
have been put in the position where we had to make this decision,   
because we believe our proposed project would offer invaluable advances   
to the Python and greater open source community, protecting millions of   
PyPI users from attempted supply-chain attacks. The proposed project   
would create new tools for automated proactive review of all packages   
uploaded to PyPI, rather than the current process of reactive-only   
review. These novel tools would rely on capability analysis, designed   
based on a dataset of known malware. Beyond just protecting PyPI users,   
the outputs of this work could be transferable for all open source   
software package registries, such as NPM and [Crates.io](http://Crates.io), improving   
security across multiple open source ecosystems.  
In  
 addition to the security benefits, the grant funds would have made a   
big difference to the PSF‚Äôs budget. The PSF is a relatively small   
organization, operating with an annual budget of around $5 million per   
year, with a staff of just 14. $1.5 million over two years would have   
been quite a lot of money for us, and easily the largest grant we‚Äôd ever  
 received. Ultimately, however, the value of the work and the size of   
the grant were not more important than practicing our values and   
retaining the freedom to support every part of our community. The PSF   
Board voted unanimously to withdraw our application.¬†  
Giving  
 up the NSF grant opportunity‚Äîalong with inflation, lower sponsorship,   
economic pressure in the tech sector, and global/local uncertainty and   
conflict‚Äîmeans the PSF needs financial support now more than ever. We   
are incredibly grateful for any help you can offer. If you're already a   
PSF member or regular donor, you have our deep appreciation, and we urge  
 you to share your story about why you support the PSF. Your stories   
make all the difference in spreading awareness about the mission and   
work of the PSF.¬†  
  


[https://pyfound.blogspot.com/2025/10/NSF-funding-statement.html](https://pyfound.blogspot.com/2025/10/NSF-funding-statement.html)",1464,361,2025-10-27 16:17:33,DoubleUnlikely9789,https://www.reddit.com/r/Python/comments/1ohh6v2/the_psf_has_withdrawn_15_million_proposal_to_us/
1oicb3y,reddit,PyCharm: Hide library stack frames,"Hey,  
  
I made a PyCharm plugin called¬†**StackSnack**¬†that hides library stack frames.

Not everyone know that other IDEs have it as a built-in, so I've carefully crafted this one & really proud to share it with the community.

# What my project does

Helps you to filter out library stack frames(i.e. those that does not belong to your project, without imported files), so that you see frames of your own code. Extremely powerful & useful tool when you're debugging.

# Preview

[https://imgur.com/a/v7h3ZZu](https://imgur.com/a/v7h3ZZu)

# GitHub

[https://github.com/heisen273/stacksnack](https://github.com/heisen273/stacksnack)

# JetBrains marketplace

[https://plugins.jetbrains.com/plugin/28597-stacksnack--library-stack-frame-hider](https://plugins.jetbrains.com/plugin/28597-stacksnack--library-stack-frame-hider)",14,0,2025-10-28 16:23:15,anton273,https://www.reddit.com/r/Python/comments/1oicb3y/pycharm_hide_library_stack_frames/
1oi1dkm,reddit,Which linting rules do you always enable or disable?,"I'm working on a Python LSP with a type checker and want to add some basic linting rules. So far I've worked on the rules from Pyflakes but was curious if there were any rules or rulesets that you always turn on or off for your projects?

Edit: thank you guys for sharing!

[This](https://github.com/stormlightlabs/beacon) is the project if you wanna take a look!
 [These](https://stormlightlabs.github.io/beacon/lsp/lint_rules.html) are the rules I've committed to so far
",70,97,2025-10-28 06:36:14,thunder-desert,https://www.reddit.com/r/Python/comments/1oi1dkm/which_linting_rules_do_you_always_enable_or/
1oici7a,reddit,pyeasydeploy ‚Äì Simple Python deployment for VPS/local servers,"Hey everyone!

I built a small library called **pyeasydeploy** that I've been using for my own projects, and I thought I'd share it to see if it's useful for anyone else (and get some feedback).

## What My Project Does

**pyeasydeploy** automates deploying Python applications to remote servers (VPS, local servers, etc.). It handles:

- Python version detection and virtual environment setup
- Package installation (PyPI, GitHub, local packages)
- File uploads to remote servers
- Supervisor service configuration and management

Instead of manually SSHing and running commands, you write a Python script that does it for you.

**Quick example:**

```python
from pyeasydeploy import *

# Connect to your server
conn = connect_to_host(host=""192.168.1.100"", user=""deploy"", password=""..."")

# Setup Python environment
python = get_target_python_instance(conn, ""3.11"")
venv = create_venv(conn, python, ""/home/deploy/venv"")
install_packages(conn, venv, [""fastapi"", ""uvicorn[standard]""])

# Deploy your app
upload_directory(conn, ""./my_app"", ""/home/deploy/my_app"")

# Run it with supervisor
service = SupervisorService(
    name=""my_app"",
    command=f""{venv.venv_path}/bin/uvicorn main:app --host 0.0.0.0 --port 8000"",
    directory=""/home/deploy/my_app"",
    user=""deploy""
)

deploy_supervisor_service(conn, service)
supervisor_start(conn, ""my_app"")
```

That's it. Your app is running.

## Target Audience

This is aimed at developers who:

- Have small Python projects on VPS or local servers (DigitalOcean droplets, Linode, home servers, etc.)
- Find manual SSH deployment tedious but consider Docker/Kubernetes overkill
- Want something simpler than Ansible for basic Python deployments
- Are comfortable with Python but don't want to learn new tools/DSLs

**Current state:** Personal project / early testing phase. It works for my use cases, but I'm sharing to gauge interest and get feedback. Not production-ready yet ‚Äì APIs may change.

## Comparison

**vs. Manual SSH deployment:**
- Stop copy-pasting the same 20 bash commands
- Never forget if it's `supervisorctl reread` or `reload` again
- Your deployment is versioned Python code, not notes in a text file

**vs. Ansible:**
- **No DSL to learn**: It's just Python. Use your existing skills.
- **Type-safe**: NamedTuples catch errors before deployment, not after
- **Debuggable**: Put a `print()` or breakpoint. No `-vvv` incantations.
- **Abstracts the boring stuff**: Finding Python versions, activating venvs, supervisor config paths ‚Äì it knows where things go
- **Composable**: Functions, classes, normal Python patterns. Not YAML gymnastics.
- **Trade-off**: Less powerful for complex multi-language/multi-server infrastructure

**vs. Docker/Kubernetes:**
- Zero containerization overhead
- Much lighter on resources (perfect for small VPS)
- **Trade-off**: No container isolation or orchestration

**vs. Pure Fabric:**
- Higher-level abstractions for Python deployments
- Remembers state (venv paths, Python versions) so you don't have to
- Handles venv/packages/supervisor automatically
- Still lets you drop to raw Fabric when needed

**The sweet spot:** You know Python, you have small projects on VPS, and you're tired of both manual SSH and learning new tools. You want deployment to be as simple as writing a Python script.

## Why I Made It

I have several small projects running on cheap VPS and local servers, and I was tired of:

- SSHing manually every time I needed to deploy
- Copy-pasting the same bash commands over and over
- Forgetting which Python version I used or where I put the venv
- Remembering supervisor command sequences (reread? reload? update?)
- Setting up Docker/K8s felt like overkill for a $5/month VPS

So I made this to automate my own workflow. It's only around 250 lines of code that abstracts the repetitive parts while staying transparent.

## Current Limitations

Full transparency: This is very fresh and still in testing phase:

- Currently only tested with **password authentication** (SSH keys support is implemented but not tested yet)
- Supervisor-focused (no Docker/systemd support yet)
- Only tested on Ubuntu/Debian servers
- APIs might change as I learn what works best

## Why I'm Sharing

Mainly two reasons:

1. **Get feedback** ‚Äì Is this actually useful for anyone else? Or does everyone just use Ansible/Docker?
2. **Gauge interest** ‚Äì If people find it useful, I'll clean it up more, publish to PyPI, add better docs, and implement the features that make sense

I'm curious to hear:

- Do you have a similar use case?
- What would make this more useful for you?
- Am I reinventing the wheel? (probably, but maybe a simpler wheel?)

**Repo:** https://github.com/offerrall/pyeasydeploy

Thanks for reading! Any feedback is welcome, even if it's ""this is terrible, just use X instead"" ‚Äì I'm here to learn.

---

**TL;DR:** Made a ~250 LOC Python library to deploy apps to VPS/servers. No YAML, no DSL ‚Äì just Python functions. Built for my own use, sharing to see if it's useful for others.",5,1,2025-10-28 16:30:35,drboom9,https://www.reddit.com/r/Python/comments/1oici7a/pyeasydeploy_simple_python_deployment_for/
1oj0x41,reddit,"Why does this function not work, even though I tried fixing it multiple times throughout the book","Hello everybody,

So basically, I've been learning to program through a book by Eric Matthes. And I should write a list about text messages and move them to a function called show\_messages(), which displays the individual messages. The next step is to use the same program and write a new function called send\_messages(), which moves the messages to a new list, sent\_messages().  Here is my 6th attempt:  

    def send_messages(finished_messages, unfinished_message):
    ¬† ¬† """"""A function send_message that outputs the text messages and moves them to the new list sent_messages.""""""
    ¬† ¬† while unfinished_message:
    ¬† ¬† ¬† ¬† current_message = unfinished_message.pop()
    ¬† ¬† ¬† ¬† print(f""Printing current message {current_message}"")
    ¬† ¬† ¬† ¬† finished_messages.append(current_message)
    
    
    def show_completed_message(finished_messages):
    ¬† ¬† """"""Show all the finished messages.""""""
    ¬† ¬† print(""\nThe following message has been finished:"")
    ¬† ¬† for finished_message in finished_messages:
    ¬† ¬† ¬† ¬† print(finished_message)
    
    
    unfinished_message = ['Hello']
    finished_message = []
    
    
    send_messages(unfinished_message, finished_message)
    show_completed_message(finished_message)                                                             I would be happy, if someone could explain what mistakes I did here. And how it should be written. Thanks for any future help.",0,8,2025-10-29 11:30:41,Nutellatoast_2,https://www.reddit.com/r/Python/comments/1oj0x41/why_does_this_function_not_work_even_though_i/
1oi2yzp,reddit,ttkbootstrap-icons 2.1 released,"3 new installable icon providers added to **ttkbootstrap-icons 2.1**

* **Eva Icons**  `ttkbootstrap-icons-eva`
* **Dev Icons**  `ttkbootstrap-icons-devicon`
* **RPG Icons** *(this one is pretty cool)*  `ttkbootstrap-icons-rpga`

**Planned for next release (2.2.0)**

* Meteocons
* StateFace Icons
* Foundation Icons 3
* Coure UI Icons
* Line Awesome Icons
* Typicons

**Planned for 2.3.0**

* Stateful icon utilities

[https://github.com/israel-dryer/ttkbootstrap-icons](https://github.com/israel-dryer/ttkbootstrap-icons)",6,0,2025-10-28 08:23:03,ProfessionOld,https://www.reddit.com/r/Python/comments/1oi2yzp/ttkbootstrapicons_21_released/
1oi8ptl,reddit,mcputil: A lightweight library that converts MCP tools into Python tools.,"# What My Project Does

[mcputil](https://github.com/RussellLuo/mcputil) is a lightweight library that converts [MCP](https://modelcontextprotocol.io) tools into Python tools (function-like objects).

# Installation

    pip install mcputil

# Basic Usage

Given the following MCP server:

    from mcp.server.fastmcp import FastMCP
    
    mcp = FastMCP(name=""Basic"", log_level=""ERROR"")
    
    
    @mcp.tool()
    def add(a: int, b: int) -> int:
        """"""Add two numbers""""""
        return a + b
    
    
    if __name__ == ""__main__"":
        mcp.run(transport=""stdio"")

We can use `mcputil` to call the `add` tool easily:

    import inspect
    import mcputil
    
    
    async def main():
        async with mcputil.Client(
            mcputil.Stdio(
                command=""python"",
                args=[""/path/to/server.py"")],
            ),
        ) as client:
            tool: mcputil.Tool = (await client.get_tools())[0]
            print(f""tool signature: {tool.name}{inspect.signature(tool)}"")
    
            output = await tool(a=1, b=2)
            print(f""tool output: {output}"")
    
        # Output:
        # tool signature: add(a: int, b: int) -> int
        # tool output: 3

# Progress Tracking

Given the following MCP server:

    from mcp.server.fastmcp import Context, FastMCP
    from mcp.server.session import ServerSession
    
    mcp = FastMCP(name=""Progress"")
    
    
    @mcp.tool()
    async def long_running_task(
        task_name: str, ctx: Context[ServerSession, None], steps: int = 5
    ) -> str:
        """"""Execute a task with progress updates.""""""
        for i in range(steps):
            progress = (i + 1) / steps
            await ctx.report_progress(
                progress=progress,
                total=1.0,
                message=f""Step {i + 1}/{steps}"",
            )
    
        return f""Task '{task_name}' completed""
    
    
    if __name__ == ""__main__"":
        mcp.run(transport=""streamable-http"")

    python server.py

We can use `mcputil` to track the progress of the `long_running_task` tool:

    import inspect
    import mcputil
    
    
    async def main():
        async with mcputil.Client(
            mcputil.StreamableHTTP(url=""http://localhost:8000""),
        ) as client:
            tool: mcputil.Tool = (await client.get_tools())[0]
            print(f""tool signature: {tool.name}{inspect.signature(tool)}"")
    
            result: mcputil.Result = await tool.call(
                ""call_id_0"", task_name=""example-task"", steps=5
            )
            async for event in result.events():
                if isinstance(event, mcputil.ProgressEvent):
                    print(f""tool progress: {event}"")
                elif isinstance(event, mcputil.OutputEvent):
                    print(f""tool output: {event.output}"")
    
        # Output:
        # tool signature: long_running_task(task_name: str, steps: int = 5) -> str
        # tool progress: ProgressEvent(progress=0.2, total=1.0, message='Step 1/5')
        # tool progress: ProgressEvent(progress=0.4, total=1.0, message='Step 2/5')
        # tool progress: ProgressEvent(progress=0.6, total=1.0, message='Step 3/5')
        # tool progress: ProgressEvent(progress=0.8, total=1.0, message='Step 4/5')
        # tool progress: ProgressEvent(progress=1.0, total=1.0, message='Step 5/5')
        # tool output: Task 'example-task' completed",1,0,2025-10-28 14:00:23,RussellLuo,https://www.reddit.com/r/Python/comments/1oi8ptl/mcputil_a_lightweight_library_that_converts_mcp/
1oio83q,reddit,I made a YouTube to mp4 Converter!,Here is the link to my repo. [https://github.com/Coolythecoder/Youtube-to-mp4](https://github.com/Coolythecoder/Youtube-to-mp4),0,4,2025-10-28 23:55:54,Intrepid-Carpet-3005,https://www.reddit.com/r/Python/comments/1oio83q/i_made_a_youtube_to_mp4_converter/
1oiqata,reddit,Blank page paralysis,"Hey everyone, 
I hope you‚Äôre doing well, I don‚Äôt know if I‚Äôm the only one to endure this but every time I open a new script for a new project or just a simple script I feel a blank page paralysis not knowing where to start. Frequently I will check Claude just for the start then I continue on my own. So I wanna know if some of you experienced this and if so what have u done to make it better.
Thank you for your time !",0,17,2025-10-29 01:24:19,Firm-Employment-9253,https://www.reddit.com/r/Python/comments/1oiqata/blank_page_paralysis/
1ohuito,reddit,Python mobile app,"Hi, i just wanted to ask what to build my finance tracker app on, since I want others to use it too, so im looking for some good options.",10,26,2025-10-28 00:48:28,TailorLazy801,https://www.reddit.com/r/Python/comments/1ohuito/python_mobile_app/
1oi8qug,reddit,"I built Clockwork: Intelligent, Composable Primitives for Infrastructure in Python","# Clockwork: Composable Infrastructure with Adjustable AI

## What My Project Does

Clockwork is a Python library that provides composable infrastructure primitives with adjustable AI involvement. Instead of choosing between fully manual infrastructure-as-code or fully automated AI deployment, you get a spectrum - dial the AI up or down per resource based on what you care about.

The core workflow: Declare your infrastructure using Pydantic models, let AI optionally complete the details you don't specify, and deploy using Pulumi's automation API. Same resource type, different levels of control depending on your needs.

## Example Usage

The ""adjustable AI"" concept in action:

```python
# Specify everything yourself
nginx = DockerResource(
    image=""nginx:1.25-alpine"",
    ports=[""8080:80""],
    volumes=[""/configs:/etc/nginx""]
)

# Just set constraints, AI fills the rest
nginx = DockerResource(
    description=""web server with caching"",
    ports=[""8080:80""]
)

# Or just describe it
nginx = DockerResource(
    description=""web server for static files"",
    assertions=[HealthcheckAssert(url=""http://localhost:8080"")]
)
```

Same resource type, you pick the level of control. What I find tedious (picking nginx vs caddy vs httpd) you might care deeply about. So every resource lets you specify what matters to you and skip what doesn't.

### Composable Resources

Group related things together:

```python
BlankResource(name=""dev-stack"", description=""Local dev environment"").add(
    DockerResource(description=""postgres"", ports=[""5432:5432""]),
    DockerResource(description=""redis"", ports=[""6379:6379""]),
    DockerResource(description=""api server"", ports=[""8000:8000""])
)
```

The AI sees the whole group and configures things to work together. Or you can `.connect()` independent resources for dependency ordering and auto-generated connection strings (this is still WIP as is the whole project and I'm currently thinking of a mechanism of ""connecting"" things together appropriately).

## Target Audience

This is an **early-stage research project** (v0.3.0) exploring the concept of adjustable AI in infrastructure tooling. It's not production-ready.

**Best suited for**:

- Developers experimenting with AI-assisted infrastructure
- Local development environments and prototyping
- Those curious about composable IaC patterns
- People who want flexibility between manual control and automation

I'm actively figuring out what patterns work and what don't. Feedback from experimentation is more valuable than production usage at this stage.

## Comparison

**vs Terraform/Pulumi directly**: Traditional IaC is fully manual - you specify every detail. Clockwork lets you specify only what you care about and delegates the rest to AI. Think of it as a higher-level abstraction where you can drop down to manual control when needed.

**vs Pulumi + AI prompts**: You could prompt Claude/GPT to generate Pulumi code, but you lose composability and incremental control. Clockwork makes ""adjustable AI"" first-class with typed interfaces, assertions for validation, and compositional primitives.

**Key differentiator**: The adjustability. It's not ""AI does everything"" or ""you do everything"" - it's a spectrum you control per resource.

## Technical Details

- Built on Pulumi for deployment - with its Dynamic Providers and Automation API features
- Uses Pydantic for declarative specifications
- Works with local LLMs (LM Studio) and cloud providers (OpenRouter)
- Supports Docker containers, files, git repos, Apple containers
- Assertions provide validation without locking implementation

**Repo**: https://github.com/kessler-frost/clockwork

## Questions for the Community

1. The ""adjustable AI"" concept - is this useful or confusing?
2. Which resources/features would be most valuable next?

Would love to hear if this resonates with anyone or if I'm solving a problem nobody has.
",1,2,2025-10-28 14:01:30,kesslerfrost,https://www.reddit.com/r/Python/comments/1oi8qug/i_built_clockwork_intelligent_composable/
1oigffx,reddit,What is the best computer or programming language to learn the basics then the more advanced stuff?,I have been studying basic programming for years and kind of get the basics if else etc. Still a bit stuck on a lot of the more advanced stuff. As for usage I would like to learn basic app programming such as making GUI programs etc. Not thinking of programming games right away but long term goals say in years I might want to give that a try. I would really like to get the skills to make something like a low resource Linux desktop or components of such. I really want to learn C++ but heard Python is easier to learn. What would you recommend?,0,23,2025-10-28 18:55:09,Tom-CyberBio-1968,https://www.reddit.com/r/Python/comments/1oigffx/what_is_the_best_computer_or_programming_language/
1oig9i0,reddit,gvit - Automatic Python virtual environment setup for every Git repo,"Hey r/Python! üëã

An important part of working on Python projects is ensuring that each one runs in the appropriate environment, with the correct Python version and dependencies. We use virtual environments for this. Each Python project should have its own virtual environment.

When working on multiple projects, this can take time and cause some headaches, as it is easy to mix up environments. That is why I created **gvit**, a command-line tool that automatically creates and manages virtual environments when you work with Git repositories. However, **gvit** is not a technology for creating virtual environments, it is an additional layer that lets you create and manage them using your preferred backend, even a different one for each project.

>One repo, its own environment ‚Äî without thinking about it.

Another helpful feature is that it centralizes your environments, each one mapped to a different project, in a registry. This allows you to easily review and manage your projects, something that is hard to achieve when using `venv` or `virtualenv`.

**What it does?**

* ‚úÖ Automatically creates environments (and install dependencies) when cloning or initializing repositories.
* üêç Centralizes all your virtual environments, regardless of the backend (currently supports venv, virtualenv, and conda.).
* üóÇÔ∏è Tracks environments in a registry (\~/.config/gvit/envs/).
* üîÑ Auto-detects and reinstalls changed dependencies on gvit pull.
* üßπ Cleans up orphaned environments with gvit envs prune.

**Installation**

    pipx install gvit
    # or
    pip install gvit

**Links**

* GitHub: [https://github.com/jaimemartinagui/gvit](https://github.com/jaimemartinagui/gvit)
* PyPI: [https://pypi.org/project/gvit/](https://pypi.org/project/gvit/)

Open to feedback!",0,20,2025-10-28 18:49:02,Candid-Handle4074,https://www.reddit.com/r/Python/comments/1oig9i0/gvit_automatic_python_virtual_environment_setup/
1ohusug,reddit,Tuesday Daily Thread: Advanced questions,"# Weekly Wednesday Thread: Advanced Questions üêç

Dive deep into Python with our Advanced Questions thread! This space is reserved for questions about more advanced Python topics, frameworks, and best practices.

## How it Works:

1. **Ask Away**: Post your advanced Python questions here.
2. **Expert Insights**: Get answers from experienced developers.
3. **Resource Pool**: Share or discover tutorials, articles, and tips.

## Guidelines:

* This thread is for **advanced questions only**. Beginner questions are welcome in our [Daily Beginner Thread](#daily-beginner-thread-link) every Thursday.
* Questions that are not advanced may be removed and redirected to the appropriate thread.

## Recommended Resources:

* If you don't receive a response, consider exploring r/LearnPython or join the [Python Discord Server](https://discord.gg/python) for quicker assistance.

## Example Questions:

1. **How can you implement a custom memory allocator in Python?**
2. **What are the best practices for optimizing Cython code for heavy numerical computations?**
3. **How do you set up a multi-threaded architecture using Python's Global Interpreter Lock (GIL)?**
4. **Can you explain the intricacies of metaclasses and how they influence object-oriented design in Python?**
5. **How would you go about implementing a distributed task queue using Celery and RabbitMQ?**
6. **What are some advanced use-cases for Python's decorators?**
7. **How can you achieve real-time data streaming in Python with WebSockets?**
8. **What are the performance implications of using native Python data structures vs NumPy arrays for large-scale data?**
9. **Best practices for securing a Flask (or similar) REST API with OAuth 2.0?**
10. **What are the best practices for using Python in a microservices architecture? (..and more generally, should I even use microservices?)**

Let's deepen our Python knowledge together. Happy coding! üåü",3,1,2025-10-28 01:00:31,AutoModerator,https://www.reddit.com/r/Python/comments/1ohusug/tuesday_daily_thread_advanced_questions/
1ohczpq,reddit,Retry manager for arbitrary code block,"There are about two pages of retry decorators in Pypi. I know about it. But, I found one case which is not covered by all other retries libraries (correct me if I'm wrong).

I needed to retry an arbitrary block of code, and not to be limited to a lambda or a function.

So, I wrote a library **loopretry** which does this. It combines an iterator with a context manager to wrap any block into retry.

    from loopretry import retries
    import time
    
    for retry in retries(10):
        with retry():
            # any code you want to retry in case of exception
            print(time.time())
            assert int(time.time()) % 10 == 0, ""Not a round number!""

Is it a novel approach or not?

Library code (any critique is highly welcomed): at [Github](https://githubhttps).

If you want to try it: `pip install loopretry`.",16,11,2025-10-27 13:25:52,amarao_san,https://www.reddit.com/r/Python/comments/1ohczpq/retry_manager_for_arbitrary_code_block/
1oh7dcw,reddit,A Binary Serializer for Pydantic Models (7√ó Smaller Than JSON),"**What My Project Does**  
I built a compact binary serializer for Pydantic models that dramatically reduces RAM usage compared to JSON. The library is designed for high-load systems (e.g., Redis caching), where millions of models are stored in memory and every byte matters. It serializes Pydantic models into a minimal binary format and deserializes them back with zero extra metadata overhead.

**Target Audience**  
This project is intended for developers working with:

* high-load APIs
* in-memory caches (Redis, Memcached)
* message queues
* cost-sensitive environments where object size matters

It is production-oriented, not a toy project ‚Äî I built it because I hit real scalability and cost issues.

**Comparison**  
I benchmarked it against JSON, Protobuf, MessagePack, and BSON using 2,000,000 real Pydantic objects. These were the results:

|Type|Size (MB)|% from baseline|
|:-|:-|:-|
|JSON|34,794.2|100% (baseline)|
|**PyByntic**|**4,637.0**|**13.3%**|
|Protobuf|7,372.1|21.2%|
|MessagePack|15,164.5|43.6%|
|BSON|20,725.9|59.6%|

JSON wastes space on quotes, field names, ASCII encoding, ISO date strings, etc. PyByntic uses binary primitives (UInt, Bool, DateTime32, etc.), so, for example, a date takes **3**2 bits instead of 208 bits, and field names are not repeated.

If your bottleneck is RAM, JSON loses every time.

Repo (GPLv3): [https://github.com/sijokun/PyByntic](https://github.com/sijokun/PyByntic)

Feedback is welcome: I am interested in edge cases, feature requests, and whether this would be useful for your workloads.",49,6,2025-10-27 07:37:21,luck20yan,https://www.reddit.com/r/Python/comments/1oh7dcw/a_binary_serializer_for_pydantic_models_7_smaller/
1oguael,reddit,Meta: Limiting project posts to a single day of the week?,"Given that this subreddit is currently being overrun by ""here's my new project"" posts (with a varying level of LLMs involved), would it be a good idea to move all those posts to a single day? (similar to what other subreddits does with Show-off Saturdays, for example).

It'd greatly reduce the noise during the week, and maybe actual content and interesting posts could get any decent attention instead of drowning out in the constant stream of projects.

Currently the last eight posts under ""New"" on this subreddit is about projects, before the post about backwards compatibility in libraries - a post that actually created a good discussion and presented a different viewpoint.

A quick guess seems to be that currently at least 80-85% of all posts are of the type ""here's my new project"".",277,40,2025-10-26 20:58:02,fiskfisk,https://www.reddit.com/r/Python/comments/1oguael/meta_limiting_project_posts_to_a_single_day_of/
1ohe75v,reddit,Looking for a python course that‚Äôs worth it,Hi I am a BSBA major graduating this semester and have very basic experience with python. I am looking for a course that‚Äôs worth it and that would give me a solid foundation. Thanks ,11,13,2025-10-27 14:19:26,lilacglowstick,https://www.reddit.com/r/Python/comments/1ohe75v/looking_for_a_python_course_thats_worth_it/
1ohw03o,reddit,NLP Search Algorithm Optimization,"Hey everyone,

I‚Äôve been experimenting with different ways to improve the search experience on an FAQ page and wanted to share the approach I‚Äôm considering.

**The project:**  
Users often phrase their questions differently from how the articles are written, so basic keyword search doesn‚Äôt perform well. The goal is to surface the most relevant FAQ articles even when the query wording doesn‚Äôt match exactly.

**Current idea:**

* About 300 FAQ articles in total.
* Each article would be parsed into smaller chunks capturing the key information.
* When a query comes in, I‚Äôd use NLP or a retrieval-augmented generation (RAG) method to match and rank the most relevant chunks.

The challenge is finding the right balance, most RAG pipelines and embedding-based approaches feel like overkill for such a small dataset or end up being too resource-intensive.

Curious to hear thoughts from anyone who‚Äôs explored lightweight or efficient approaches for semantic search on smaller datasets.",1,2,2025-10-28 01:55:33,Dull-Summer3106,https://www.reddit.com/r/Python/comments/1ohw03o/nlp_search_algorithm_optimization/
1ohbuhl,reddit,Duron - Durable async runtime for Python,"Hi r/Python!

I built **Duron**, a lightweight **durable execution runtime** for Python async workflows. It provides replayable execution primitives that can work standalone or serve as building blocks for complex workflow engines.

**GitHub:** [https://github.com/brian14708/duron](https://github.com/brian14708/duron)

## What My Project Does

Duron helps you write Python async workflows that can pause, resume, and continue even after a crash or restart.

It captures and replays async function progress through deterministic logs and pluggable storage backends, allowing consistent recovery and integration with custom workflow systems.

## Target Audience

* Embed simple durable workflows into application
* Building custom durable execution engines
* Exploring ideas for interactive, durable agents

## Comparison

Compared to temporal.io or restate.dev:

- Focuses purely on Python async runtime, not distributed scheduling or other languages
- Keeps things lightweight and embeddable
- Experimental features: tracing, signals, and streams


---

Still early-stage and experimental ‚Äî any feedback, thoughts, or contributions are very welcome!",11,2,2025-10-27 12:27:37,brian14708,https://www.reddit.com/r/Python/comments/1ohbuhl/duron_durable_async_runtime_for_python/
1oh8yh4,reddit,Lightweight Python Implementation of Shamir's Secret Sharing with Verifiable Shares,"Hi¬†[r/Python](https://www.reddit.com/r/Python/)!

I built a lightweight Python library for Shamir's Secret Sharing (SSS), which splits secrets (like keys) into shares, needing only a threshold to reconstruct. It also supports Feldman's Verifiable Secret Sharing to check share validity securely.

**What my project does**

Basically you have a secret(a password, a key, an access token, an API token, password for your cryptowallet, a secret formula/recipe, codes for nuclear missiles). You can split your secret in n shares between your friends, coworkers, partner etc. and to reconstruct your secret you will need at least k shares. For example: total of 5 shares but you need at least 3 to recover the secret). An impostor having less than k shares learns nothing about the secret(for context if he has 2 out of 3 shares he can't recover the secret even with unlimited computing power - unless he exploits the discrete log problem but this is infeasible for current computers). If you want to you can not to use this Feldman's scheme(which verifies the share) so your secret is safe even with unlimited computing power, even with unlimited quantum computers - mathematically with fewer than k shares it is impossible to recover the secret

Features:

* Minimal deps (pycryptodome), pure Python.
* File or variable-based workflows with Base64 shares.
* Easy API for splitting, verifying, and recovering secrets.
* MIT-licensed, great for secure key management or learning crypto.

Comparison with other implementations:

* pycryptodome - it allows only 16 bytes to be split where mine allows unlimited(as long as you're willing to wait cause everything is computed on your local machine). Also this implementation does not have this feature where you can verify the validity of your share. Also this returns raw bytes array where mine returns base64 (which is easier to transport/send)
* [This](https://github.com/thedanhub/shamir-secret-sharing)¬†repo allows you to share your secret but it should already be in number format where mine automatically converts your secret into number. Also this repo requires you to put your share as raw coordinates which I think is too technical.
* Other notes: my project allows you to recover your secret with either vars or files. It implements Feldman's Scheme for verifying your share. It stores the share in a convenient format¬†*base64*¬†and a lot more, check it out for docs

**Target audience**

I would say it is production ready as it covers all security measures: primes for discrete logarithm problem of at least 1024 bits, perfect secrecy and so on. **Even so, I wouldn't recommend its use for high confidential data(like codes for nuclear missiles) unless some expert confirms its secure**

Check it out:

* PyPI:¬†[https://pypi.org/project/shamir-lbodlev/](https://pypi.org/project/shamir-lbodlev/)¬†(pip install shamir-lbodlev)
* GitHub:¬†[https://github.com/lbodlev888/shamir](https://github.com/lbodlev888/shamir)¬†(README with examples)

\-Feedback or feature ideas? Let me know¬†[here](https://github.com/lbodlev888/shamir/issues)!",12,7,2025-10-27 09:27:05,Excellent_Double_726,https://www.reddit.com/r/Python/comments/1oh8yh4/lightweight_python_implementation_of_shamirs/
1ohjw99,reddit,Best opensource quad remesher,"I need an opensource way to remesh STL 3D model with quads, ideally squares. This needs to happen programmatically, ideally without external software. I want use the remeshed model in hydrodynamic diffraction calculations. 

Does anyone have recommendations? Thanks!",3,4,2025-10-27 17:57:59,adoss,https://www.reddit.com/r/Python/comments/1ohjw99/best_opensource_quad_remesher/
1oh6xmz,reddit,Downloads Folder Organizer: My first full Python project to clean up your messy Downloads folder,"I first learned Python years ago but only reached the basics before moving on to C and C++ in university. Over time, working with C++ gave me a deeper understanding of programming and structure.

Now that I‚Äôm finishing school, I wanted to return to Python with that stronger foundation and build something practical. This project came from a simple problem I deal with often: a cluttered Downloads folder. It was a great way to apply what I know, get comfortable with Python again, and make something genuinely useful.

AI tools helped with small readability and formatting improvements, but all of the logic and implementation are my own.

**What My Project Does**

This Python script automatically organizes your Downloads folder, on Windows machines by sorting files into categorized subfolders (like *Documents*, *Pictures*, *Audio*, *Archives*, etc.) while leaving today‚Äôs downloads untouched.

It runs silently in the background right after installation and again anytime the user logs into their computer. All file movements are timestamped and logged in `logs/activity.log`.

I built this project to solve a small personal annoyance ‚Äî a cluttered Downloads folder ‚Äî and used it as a chance to strengthen my Python skills after spending most of my university work in C++.

**Target Audience**

This is a small desktop automation tool designed for:

* Windows users who regularly downloads files and forgets to clean them up
* Developers or students who want to see an example of practical Python automation
* Anyone learning how to use modules like `pathlib`, `os`, and `shutil` effectively

It‚Äôs built for learning, but it‚Äôs also genuinely useful for everyday organization.

**GitHub Repository**

[https://github.com/elireyhernandez/Downloads-Folder-Organizer](https://github.com/elireyhernandez/Downloads-Folder-Organizer)

This is a personal learning project that I‚Äôm continuing to refine. I‚Äôd love to hear thoughts on things like code clarity, structure, or possible future features to explore.

\[Edit}  
This program was build and tested for windows machines.",14,11,2025-10-27 07:08:20,misery4k,https://www.reddit.com/r/Python/comments/1oh6xmz/downloads_folder_organizer_my_first_full_python/
1ohufub,reddit,zipstream-ai : A Python package for streaming and querying zipped datasets using LLMs,"I‚Äôve released **zipstream-ai**, an open-source Python package designed to make working with compressed datasets easier.

Repository and documentation:

GitHub: [https://github.com/PranavMotarwar/zipstream-ai](https://github.com/PranavMotarwar/zipstream-ai)

PyPI: [https://pypi.org/project/zipstream-ai/](https://pypi.org/project/zipstream-ai/)

Many datasets are distributed as .zip or .tar.gz archives that need to be manually extracted before analysis. Existing tools like zipfile and tarfile provide only basic file access, which can slow down workflows and make integration with AI tools difficult.

**zipstream-ai** addresses this by enabling direct streaming, parsing, and querying of archived files ‚Äî without extraction. The package includes:

* ZipStreamReader for streaming files directly from compressed archives.
* FileParser for automatically detecting and parsing CSV, JSON, TXT, Markdown, and Parquet files.
* ask() for natural language querying of parsed data using Large Language Models (OpenAI GPT or Gemini).

The tool can be used from both a Python API and a command-line interface.

Example:

`pip install zipstream-ai`

`zipstream query` [`dataset.zip`](http://dataset.zip) `""Which columns have missing values?""`",0,1,2025-10-28 00:44:53,Puzzled-Pension6385,https://www.reddit.com/r/Python/comments/1ohufub/zipstreamai_a_python_package_for_streaming_and/
1oh86zh,reddit,human-errors: a nice way to show errors in config files,"source code: https://github.com/NSPC911/human-errors

what my project does:
- allows you to display any errors in your configuration files in a nice way

comparision:
- as far as i know, most targetted python's exceptions, like rich's traceback handler and friendly's handler

why:
- while creating [rovr](https://nspc911.github.io/rovr), i made a better handler for toml config errors. i showed it off to a couple discord servers, and they wanted it to be plug-and-playable, so i just extracted the core stuff

what now?
- i still have yaml support planned, along with json schema. im happy to take up any contributions!",4,0,2025-10-27 08:33:55,NotSoProGamerR,https://www.reddit.com/r/Python/comments/1oh86zh/humanerrors_a_nice_way_to_show_errors_in_config/
1oh3x1p,reddit,"ttkbootstrap-icons 2.0 supports 8 new icon sets! material, font-awesome, remix, fluent, etc...","I'm excited to announce that **ttkbootstrap-icons 2.0** has been release and now supports 8 new icon sets.

The icon sets are extensions and can be installed as needed for your project.  Bootstrap icons are included by default, but you can now install the following icon providers:

    pip install ttkbootstrap-icons-fa       # Font Awesome (Free)
    pip install ttkbootstrap-icons-fluent   # Fluent System Icons
    pip install ttkbootstrap-icons-gmi      # Google Material Icons 
    pip install ttkbootstrap-icons-ion      # Ionicons v2 (font)
    pip install ttkbootstrap-icons-lucide   # Lucide Icons
    pip install ttkbootstrap-icons-mat      # Material Design Icons (MDI)
    pip install ttkbootstrap-icons-remix    # Remix Icon
    pip install ttkbootstrap-icons-simple   # Simple Icons (community font)
    pip install ttkbootstrap-icons-weather  # Weather Icons

After installing, run \`ttkbootstrap-icons\` from your command line and you can preview and search for icons in any installed icon provider.

[israel-dryer/ttkbootstrap-icons: Font-based icons for Tkinter/ttkbootstrap with a built-in Bootstrap set and installable providers: Font Awesome, Material, Ionicons, Remix, Fluent, Simple, Weather, Lucide.](https://github.com/israel-dryer/ttkbootstrap-icons)  
",6,1,2025-10-27 04:12:56,ProfessionOld,https://www.reddit.com/r/Python/comments/1oh3x1p/ttkbootstrapicons_20_supports_8_new_icon_sets/
1ogjjrl,reddit,I built a Python tool to debug HTTP request performance step-by-step,"# What My Project Does

httptap is a CLI and Python library for detailed HTTP request performance tracing.

It breaks a request into real network stages - **DNS ‚Üí TCP ‚Üí TLS ‚Üí TTFB ‚Üí Transfer** ‚Äî and shows precise timing for each.

It helps answer not just *‚Äúwhy is it slow?‚Äù* but *‚Äúwhich part is slow?‚Äù*

You get a full **waterfall breakdown**, TLS info, redirect chain, and structured JSON output for automation or CI.

* üîó **Repo:** [github.com/ozeranskii/httptap](https://github.com/ozeranskii/httptap)
* üì¶ **PyPI:** [pypi.org/project/httptap](https://pypi.org/project/httptap)
* **üìï Documentation:** [https://httptap.dev/](https://httptap.dev/)
* üìπ **asciinema:** [https://asciinema.org/a/751564](https://asciinema.org/a/751564)

# Target Audience

* Developers debugging API latency or network bottlenecks
* DevOps / SRE teams investigating performance regressions
* Security engineers checking TLS setup
* Anyone who wants a native Python equivalent of curl -w + Wireshark + stopwatch

httptap works cross-platform (macOS, Linux, Windows), has minimal dependencies, and can be used both interactively and programmatically.

# Comparison

When exploring similar tools, I found two common options:

* [reorx/httpstat (Python)](https://github.com/reorx/httpstat) ‚Äî depends on curl, unmaintained, limited visibility
* [davecheney/httpstat (Go)](https://github.com/davecheney/httpstat) ‚Äî cleaner, but mostly a decorated curl -v, no TLS or JSON export

httptap takes a different route:

* **Pure Python implementation** using httpx and httpcore trace hooks (no curl)
* **Deep TLS inspection** (protocol, cipher, expiry days)
* **Rich output modes**: human-readable table, compact line, metrics-only, and full JSON
* **Extensible** \- you can replace DNS/TLS/visualization components or embed it into your pipeline

# Example Use Cases

* Performance troubleshooting - find where time is lost
* Regression analysis - compare baseline vs current
* TLS audit - check protocol and cert parameters
* Network diagnostics - DNS latency, IPv4 vs IPv6 path
* Redirect chain analysis - trace real request flow

If you find it useful, I‚Äôd really appreciate a ‚≠ê on GitHub - it helps others discover the project.

üëâ [https://github.com/ozeranskii/httptap](https://github.com/ozeranskii/httptap)",103,33,2025-10-26 13:36:51,ozeranskii,https://www.reddit.com/r/Python/comments/1ogjjrl/i_built_a_python_tool_to_debug_http_request/
1ogf2iw,reddit,My Python based open-source project PdfDing is receiving a grant,"Hi r/Python,

for quite some time I have been working on the open-source project PdfDing - a Django based selfhosted PDF manager, viewer and editor offering a seamless user experience on multiple devices. You can find the repository [here](https://github.com/mrmn2/PdfDing). As always I would be quite happy about a star and you trying out the application.

Last week PdfDing was selected to receive a grant from the [NGI Zero Commons Fund](https://nlnet.nl/news/2025/20251016-selection-NGI0CommonsFund.html). This fund is dedicated to helping deliver, mature and scale new internet commons across the whole technology spectrum and is amongst others funded by the European Commission. The exact sum of the grant still needs to be discussed, but obviously I am very stocked to have been selected and need to share it with the community.

**What My Project Does**

PdfDing's features include:

* Seamless browser based PDF viewing on multiple devices. Remembers current position - continue where you stopped reading
* Stay on top of your PDF collection with multi-level tagging, starring and archiving functionalities
* Edit PDFs by adding comments, highlighting and drawings
* Manage and export PDF highlights and comments in dedicated sections
* Clean, intuitive UI with dark mode, inverted color mode, custom theme colors and multiple layouts
* SSO support via OIDC
* Share PDFs with an external audience via a link or a QR Code with optional access control
* Markdown Notes
* Progress bars show the reading progress of each PDF at a quick glance

**Target Audience**

As PDF is an omnipresent file type PdfDing has quite a diverse target group, including:

* Avid readers (e.g. me) that want to seamlessly read PDFs on multiple devices
* Hobbyist, that want to make their content available to other users. For example one user wants to share his automotive literature (manuals, brochures etc) with fellow enthusiasts.
* Researchers and students trying to stay on top of there big PDF collection
* Small businesses that want to share PDFs with their customers or employees. Think of a small office where PDF based instructions to different appliances can be opened by scanning a QR on the appliance.

**Comparison**

Currently there is no other solution that can be used as a drop in replacement for PdfDing. I started developing PdfDing because there was no available solution that satisfied the following (already implemented) requirements:

* Complete control over my data.
* Easy to self-host via docker. PdfDing can be used with a SQLite database -> No other containers necessary
* Lightweight and minimal, should run on cheap hardware
* Continue reading where you left off on all devices
* Browser based
* Support single sign on via OIDC in order to leverage an existing identity provider
* PDFs should be shareable with an external audience with optional access control
* Open source
* Content should not be curated by an admin instead every user should be able to upload PDFs via the UI

Surprisingly, there was no solution available that could do this. In the following I‚Äôll list the available alternatives and how they compare to my requirements.",223,13,2025-10-26 09:09:44,Hopeful-Brick-7966,https://www.reddit.com/r/Python/comments/1ogf2iw/my_python_based_opensource_project_pdfding_is/
1ohe4xu,reddit,Python Handwritten Notes with Q&A PDF for Quick Prep,"Get **Python handwritten notes** along with 90+ frequently asked interview questions and answers in one PDF. Designed for students, beginners, and professionals, this resource covers Python basics to advanced concepts in an easy-to-understand handwritten style. The Q&A section helps you practice and prepare for coding interviews, exams, and real-world applications making it a perfect quick-revision companion

[Python Handwritten Notes + Qus/Ans PDF](https://topmate.io/techie_arbaaz/1714203)",0,2,2025-10-27 14:16:47,arbaazian,https://www.reddit.com/r/Python/comments/1ohe4xu/python_handwritten_notes_with_qa_pdf_for_quick/
1ohiwaw,reddit,Frist chess openings library,"Hi I'm 0xh7, and I just finish building Openix, a simple Python library for working with chess openings (ECO codes).

What my project does:
Openix lets you load chess openings from JSON files, validate their moves using python-chess, and analyze them step by step on a virtual board. You can search by name, ECO code, or move sequence.

Target audience:
It's mainly built for Python developers, and anyone interested in chess data analysis or building bots that understand opening theory.

 Comparison:
Unlike larger chess databases or engines, Openix is lightweight and purely educational 

 https://github.com/0xh7/Openix-Library
 I didn‚Äôt write the txt üòÖ but that true üëç

[Openix ](https://github.com/0xh7/Openix-Library)",0,1,2025-10-27 17:21:06,0xh7,https://www.reddit.com/r/Python/comments/1ohiwaw/frist_chess_openings_library/
1ogzye9,reddit,Monday Daily Thread: Project ideas!,"# Weekly Thread: Project Ideas üí°

Welcome to our weekly Project Ideas thread! Whether you're a newbie looking for a first project or an expert seeking a new challenge, this is the place for you.

## How it Works:

1. **Suggest a Project**: Comment your project idea‚Äîbe it beginner-friendly or advanced.
2. **Build & Share**: If you complete a project, reply to the original comment, share your experience, and attach your source code.
3. **Explore**: Looking for ideas? Check out Al Sweigart's [""The Big Book of Small Python Projects""](https://www.amazon.com/Big-Book-Small-Python-Programming/dp/1718501242) for inspiration.

## Guidelines:

* Clearly state the difficulty level.
* Provide a brief description and, if possible, outline the tech stack.
* Feel free to link to tutorials or resources that might help.

# Example Submissions:

## Project Idea: Chatbot

**Difficulty**: Intermediate

**Tech Stack**: Python, NLP, Flask/FastAPI/Litestar 

**Description**: Create a chatbot that can answer FAQs for a website.

**Resources**: [Building a Chatbot with Python](https://www.youtube.com/watch?v=a37BL0stIuM)

# Project Idea: Weather Dashboard

**Difficulty**: Beginner

**Tech Stack**: HTML, CSS, JavaScript, API

**Description**: Build a dashboard that displays real-time weather information using a weather API.

**Resources**: [Weather API Tutorial](https://www.youtube.com/watch?v=9P5MY_2i7K8)

## Project Idea: File Organizer

**Difficulty**: Beginner

**Tech Stack**: Python, File I/O

**Description**: Create a script that organizes files in a directory into sub-folders based on file type.

**Resources**: [Automate the Boring Stuff: Organizing Files](https://automatetheboringstuff.com/2e/chapter9/)

Let's help each other grow. Happy coding! üåü",6,0,2025-10-27 01:00:30,AutoModerator,https://www.reddit.com/r/Python/comments/1ogzye9/monday_daily_thread_project_ideas/
1ognagk,reddit,I‚Äôve built cstructimpl: turn C structs into real Python classes (and back) without pain,"If you've ever had to parse binary data coming from C code, embedded systems, or network protocols, you know the drill:

* write some¬†`struct.unpack`¬†calls,
* try to remember how alignment works,
* pray that you didn‚Äôt miscount byte offsets.

I‚Äôve been there way too many times, so I decided to write something a little more¬†**pain free**.

# What my project does

It‚Äôs a Python package that makes C‚Äëstyle structs feel completely natural to use.  
You just¬†**declare a dataclass-like class**, annotate your fields with their C types, and call¬†`c_decode()`¬†or¬†`c_encode(),`that‚Äôs it, you don't need to perform anymore strange rituals like with `ctypes` or `struct`.

    from cstructimpl import *
    
    class Info(CStruct):
        age: Annotated[int, CType.U8]
        height: Annotated[int, CType.U16]
    
    class Person(CStruct):
        info: Info
        name: Annotated[str, CStr(8)]
    
    raw = bytes([18, 0, 170, 0]) + b""Peppino\x00""
    assert Person.c_decode(raw) == Person(Info(18, 170), ""Peppino"")

All alignment, offset, and nested struct handling are automatic.  
Need to go the other way? Just call¬†`.c_encode()`¬†and it becomes proper raw bytes again.

If you want to checkout all the available features go check out my github repo: [https://github.com/Brendon-Mendicino/cstructimpl](https://github.com/Brendon-Mendicino/cstructimpl)

Install it via pip:

    pip install cstructimpl

# Target audience

Python developers who work with binary data, parse or build C structs, or want a cleaner alternative to¬†`struct.unpack`‚ÄØand‚ÄØ`ctypes.Structure`.

# Comparison:

**cstructimpl¬†vs¬†struct.unpack¬†vs¬†ctypes.Structure**

Simple C struct representation;

    struct Point {
        uint8_t  x;
        uint16_t y;
        char     name[8];
    };

**With¬†struct**

You have to remember the format string and tuple positions yourself:

    import struct
    raw = bytes([1, 0, 2, 0]) + b""Peppino\x00""
    
    x, y, name = struct.unpack(""<BxH8s"", raw)
    name = name.decode().rstrip(""\x00"")
    
    print(x, y, name)
    # 1 2 'Peppino'

Pros: native, fast, everywhere.  
Cons: one wrong character in the format string and everything shifts.

**With¬†ctypes.Structure**

You define a class, but it's verbose, type-unsafe and C‚Äëlike:

    from ctypes import *
    
    class Point(Structure):
        _fields_ = [(""x"", c_uint8), (""y"", c_uint16), (""name"", c_char * 8)]
    
    raw = bytes([1, 0, 2, 0]) + b""Peppino\x00""
    p = Point.from_buffer_copy(raw)
    
    print(p.x, p.y, bytes(p.name).split(b""\x00"")[0].decode())
    # 1 2 'Peppino'

Pros: matches C layouts exactly.  
Cons: low readability, no built‚Äëin encode/decode symmetry, system‚Äëdependent alignment quirks, type-unsafe.

**With¬†cstructimpl**

Readable, type‚Äësafe, and declarative, true Python code that mirrors the data:

    pythonfrom cstructimpl import *
    
    class Point(CStruct):
        x: Annotated[int, CInt.U8]
        y: Annotated[int, CInt.U16]
        name: Annotated[str, CStr(8)]
    
    raw = bytes([1, 0, 2, 0]) + b""Peppino\x00""
    point = Point.c_decode(raw)
    print(point)
    # Point(x=1, y=2, name='Peppino')

Pros:

* human‚Äëreadable field definitions
* automatic decode/encode symmetry
* nested structs, arrays, enums supported out of the box
* works identically on all platforms

Cons: tiny bit of overhead compared to bare¬†`struct`, but massively clearer.",25,10,2025-10-26 16:20:52,ZioAldo,https://www.reddit.com/r/Python/comments/1ognagk/ive_built_cstructimpl_turn_c_structs_into_real/
1ogug1w,reddit,[P] textnano - Build ML text datasets in 200 lines of Python (zero dependencies),"I got frustrated building text datasets for NLP projects for learning purposes, so I built textnano - a single-file (\~200 LOC) dataset builder inspired by lazynlp.

**The pitch:** URLs ‚Üí clean text, that's it. No complex setup, no dependencies.

**Example:**

    python 
    import textnano 
    textnano.download_and_clean('urls.txt', 'output/') # Done. 
    Check output/ for clean text files 

**Key features:**

* Single Python file (\~200 lines total)
* Zero external dependencies (pure stdlib)
* Auto-deduplication using fingerprints
* Clean HTML ‚Üí text - Separate error logs (failed.txt, timeout.txt, etc.)

**Why I built this**:

Every time I need a small text dataset for experiments, I end up either:

1. Writing a custom scraper (takes hours)
2. Using Scrapy (overkill for 100 pages)
3. Manual copy-paste (soul-crushing)

Wanted something I could understand completely and modify easily.

**GitHub:** [https://github.com/Rustem/textnano](https://github.com/Rustem/textnano) Inspired by [lazynlp](https://github.com/chiphuyen/lazynlp) but simplified to a single file. **Questions for the community:**

\- What features would you add while keeping it simple? - Should I add optional integrations (HuggingFace, PyTorch)? Happy to answer questions or take feedback!",11,6,2025-10-26 21:04:26,rkamun,https://www.reddit.com/r/Python/comments/1ogug1w/p_textnano_build_ml_text_datasets_in_200_lines_of/
1ohn0fy,reddit,Build datasets larger than GPT-1 & GPT-2 with ~200 lines of Python,"I built `textnano` - a minimal text dataset builder that lets you create preprocessed datasets comparable to (or larger than) what was used to train GPT-1 (5GB) and GPT-2 (40GB).
**Why I built this:**
- Existing tools like Scrapy are powerful but have a learning curve
- ML students need simple tools to understand the data pipeline
- Sometimes you just want clean text datasets *quickly*

**What makes it different to other offerrings:**

- ‚úÖ **Zero dependencies** - Pure Python stdlib
- ‚úÖ **Built-in extractors** - Wikipedia, Reddit, Gutenberg support (all <50 LOC each!)
- ‚úÖ **Auto deduplication** - No duplicate documents
- ‚úÖ **Smart filtering** - Excludes social media, images, videos by default
- ‚úÖ **Simple API** - One command to build a dataset

**Quick example:**

```bash
# Create URL list
cat > urls.txt << EOF
https://en.wikipedia.org/wiki/Machine_learning
https://en.wikipedia.org/wiki/Deep_learning
...
EOF
# Build dataset
textnano urls urls.txt dataset/
# Output:
# Processing 2 URLs...
# [1/20000] ‚úì Saved (3421 words)
# [2/20000] ‚úì Saved (2890 words)
...
```
**Target Audience**:
For those who are making their first steps with AI/ML, or experimenting with NLP or trying to build tiny LLMs from scratch.
If you find this useful, **please star the repo** ‚≠ê ‚Üí [github.com/Rustem/textnano](https://github.com/Rustem/textnano)
**Purpose**:
For educational purpose only.
Happy to answer questions or accept PRs!",0,2,2025-10-27 19:52:45,rkamun,https://www.reddit.com/r/Python/comments/1ohn0fy/build_datasets_larger_than_gpt1_gpt2_with_200/
1oh2saj,reddit,Seeking Recommendations for Online Python Courses Focused on Robotics for Mechatronics Students,"Hello,

I'm currently studying mechatronics and am eager to enhance my skills in robotics using Python. I'm looking for online courses that cater to beginners but delve into robotics applications. I'm open to both free and paid options.",0,4,2025-10-27 03:15:48,Afraid-Part-2137,https://www.reddit.com/r/Python/comments/1oh2saj/seeking_recommendations_for_online_python_courses/
1ogqjn6,reddit,RedDownloader v4.4.0 The Ultimate Reddit Media Downloader Back Under Maintenance After 1.5 Years!,"After almost two years of inactivity, I have finally revived my open-source project [RedDownloader](https://github.com/Jackhammer9/RedDownloader), a lightweight, PRAW-less Reddit media downloader written in Python.

# What My Project Does

RedDownloader allows users to download Reddit media such as images, videos, and gallery posts from individual posts or entire subreddits.  
It also supports bulk downloading by flair and sorting options including Hot, Top, and New.

Newer versions can additionally fetch metadata such as original poster information, titles, and timestamps, all without requiring Reddit API credentials.

Install using:

    pip install RedDownloader

Example: Downloading 10 Posts from the memes subreddit

    from RedDownloader import RedDownloader
    RedDownloader.DownloadBySubreddit (""memes"" , 10)

# Target Audience

RedDownloader is designed for:

* Developers who want to automate Reddit content downloading
* The best point is the easy single line downloading
* Anyone looking for a simple, scriptable Reddit downloader for long-term projects

# Comparison to Alternatives (for example, RedVid)

While tools like RedVid are great for quick single-post video downloads, RedDownloader focuses on flexibility and automation.  
It works entirely without API keys, supports bulk subreddit downloads filtered by flair or sorting, and can retrieve extra metadata.

# Maintenance Update

The v4.4.0 release resolves the major issues that made older versions unusable due to Reddit API changes.  
The response handling and error management have been reworked, and the project is now officially back under active maintenance., If you use it and find any issues please open an issue and i will have a look :)

GitHub: [https://github.com/Jackhammer9/RedDownloader](https://github.com/Jackhammer9/RedDownloader)

  
Edit: Corrected Memes Spelling",8,17,2025-10-26 18:31:05,PreppyToast,https://www.reddit.com/r/Python/comments/1ogqjn6/reddownloader_v440_the_ultimate_reddit_media/
1ogjt7h,reddit,Python package for getting bulk transcripts and metadata from any Youtube channel.,"**What It Does:**

This package allows you to fetch thousands of transcripts from any Youtube channel with additional metadata that perfectly structured for ML and NLP usages.

It basically uses async structure for getting transcripts in bulk.

Here's a quick CLI usage:

    pip install ytfetcher
    
    ytfetcher from_channel -c TheOffice -m 50 -f json

This will give you 50 videos of structured transcripts from `TheOffice` channel and exports it as `json`.

**Target Audience:**

This package could be used for machine learning, natural language processing and fine-tuning jobs.

So if you are working with data and AI, this could be save ton of time for you.

**How it differs:**

The difference between this package and others is, this package handles transcripts in bulk thanks to its async structure. It is fast and also well structured for direct uses. Lastly you can export data as json, csv and txt.

This package is not new, I have been working on this project almost for 3 months and added so much great features by now.

That's why your suggestions and improvements are so important for me. If you want to check it out or create an issue with feedback, here's github the link:

[https://github.com/kaya70875/ytfetcher](https://github.com/kaya70875/ytfetcher)

Lastly if this package saved you some time, please don't forget to star it. That means a lot to me.",10,1,2025-10-26 13:50:08,nagmee,https://www.reddit.com/r/Python/comments/1ogjt7h/python_package_for_getting_bulk_transcripts_and/
1ogmg78,reddit,pypi.guru: Search Python Packages - Fast!,"Hi there,

**EDIT: After consulting with PSF and for the sake of avoiding confusion in the community I moved the domain to** [**https://pypkg.guru**](https://pypkg.guru)

I just launched [~~https://pypi.guru~~](https://pypi.guru) [https://pypkg.guru](https://pypkg.guru) a search engine over [pypi.org](http://pypi.org) package index, but much faster and more interactive to improve discoverability of packages.

Why it‚Äôs useful:

* Faster search over known packages: [~~pypi.guru~~](http://pypi.guru) [https://pypkg.guru](https://pypkg.guru) renders results quickly
* Interactive: the search renders results as you type, making it more interactive to explore unknown packages
* Discover packages: For example the query ""fast dataframe"" does not render anything on other search engines, but with [~~pypi.guru~~](http://pypi.guru) [https://pypkg.guru](https://pypkg.guru) you would get you to the popular ""polars"" package.
* It's free!

Give it a try,  I am keen to hear your feedback!",5,12,2025-10-26 15:46:49,fbrdm,https://www.reddit.com/r/Python/comments/1ogmg78/pypiguru_search_python_packages_fast/
1og1yzs,reddit,Pip 25.3 - build constraints and PEP 517 builds only!,"This weekend I got to be the release manager for pip 25.3!

I'd say the the big highlights are:

* A new option `--build-constraint` that allows you to define build time dependency constraints without affecting install constraints. 
* Building from source is now PEP 517 only, no more directly calling `setup.py`. This will affect only a tiny % of projects, as PEP 517 automatically falls back to setuptools (but using the official build interface), but it finally removes legacy behavior that tools like uv never even supported.
* Similarly, editable installs are PEP 660 only, pip now no longer calls `setup.py` here either, this does mean if you use editable installs with setuptools you need to use v66+.

A small highlight, but one I'm very happy with, is if your remote index supports PEP 658 metadata (PyPI does), then `pip install --dry-run` and `pip lock` will avoid downloading the entire package.

The official announcement post is at: https://discuss.python.org/t/announcement-pip-25-3-release/104550

The full changelog is at: https://github.com/pypa/pip/blob/main/NEWS.rst#253-2025-10-24",131,28,2025-10-25 21:36:31,zurtex,https://www.reddit.com/r/Python/comments/1og1yzs/pip_253_build_constraints_and_pep_517_builds_only/
1ogigib,reddit,Proxy parser and formatter for Python - proxyutils,"Hey everyone!

One of my first struggles when building CLI tools for end-users in Python was that customers always had problems inputting proxies. They often struggled with the¬†`scheme://user:pass@ip:port`¬†format, so a few years ago I made a parser that could turn any user input into Python's proxy format with a one-liner.  
After a long time of thinking about turning it into a library, I finally had time to publish it. Hope you find it helpful ‚Äî feedback and stars are appreciated :)

# What My Project Does

proxyutils parses any format of proxy into Python's niche proxy format with one-liner . It can also generate proxy extension files / folders for libraries Selenium.

# Target Audience

People who does scraping and automating with Python and uses proxies. It also concerns people who does such projects for end-users.

# Comparison

Sadly, I didn't see any libraries that handles this task before. Generally proxy libraries in Python are focusing on collecting free proxies from various websites.

It worked excellently, and finally, I didn‚Äôt need to handle complaints about my clients‚Äô proxy providers and their odd proxy formats

[https://github.com/meliksahbozkurt/proxyutils](https://github.com/meliksahbozkurt/proxyutils)",4,0,2025-10-26 12:38:50,heyoneminute,https://www.reddit.com/r/Python/comments/1ogigib/proxy_parser_and_formatter_for_python_proxyutils/
1oglk47,reddit,# üéâ Release‚ÄØv1.0.0 of ttkbootstrap‚Äëicons -- easy icon sets for tkinter & ttkbootstrap!,"Hi everyone --- I'm excited to announce the **v1.0.0** release of [**ttkbootstrap‚Äëicons**](https://github.com/israel-dryer/ttkbootstrap-icons), a Python package for seamless icon usage in‚ÄØTkinter /‚ÄØttkbootstrap applications.

# üöÄ What is it

ttkbootstrap‚Äëicons brings together two popular icon sets --- Bootstrap Icons and Lucide Icons --- and makes them easy to use in Tkinter/ttkbootstrap apps:

* Create icons with a single class (e.g., `BootstrapIcon(""house"", size=32, color=""blue"")`)
* Icons are rendered as efficient fonts and produce `PhotoImage` instances to use directly in labels, buttons, etc.
* Supports cross‚Äëplatform (Windows / macOS / Linux) usage.

# ‚úÖ Key features

* Two nice icon sets included: Bootstrap Icons (2,000+ icons) *and* Lucide Icons (1,600+ icons) in one package.
* Size and color easily adjustable at runtime (via constructor params `size`, `color`).
* Built‚Äëin previewer/CLI to browse icon sets, search, adjust size & color interactively.
* Works with‚ÄØPyInstaller out of the box (hook included) so you can freeze your app easily without missing icon assets.

# üîß Installation & Quick‚ÄëStart

    pip install ttkbootstrap‚Äëicons
    
    import tkinter as tk
    from ttkbootstrap_icons import BootstrapIcon, LucideIcon
    
    root = tk.Tk()
    
    icon1 = BootstrapIcon(""house"", size=32, color=""blue"")
    label1 = tk.Label(root, image=icon1.image)
    label1.pack()
    
    icon2 = LucideIcon(""home"", size=24, color=""red"")
    button2 = tk.Button(root, image=icon2.image, text=""Home"", compound=""left"")
    button2.pack()
    
    root.mainloop()

# üß≠ Where you might find it useful

If you're building a GUI with ttkbootstrap, this library takes away the hassle of managing icon files or sprite-sheets. Instead you get a simple Python API to handle icons as widgets, with full flexibility for size & color. Perfect for: - Toolbars, side panels, action buttons

* Icon‚Äërich dashboards or graphical utilities
* Rapid prototyping of Tkinter/ttkbootstrap apps where icons matter

# üìù Changelog (v1.0.0)

* Initial stable release
* Major features implemented: icon sets + previewer + PyInstaller support
* Basic API documentation in README + examples folder included.

# üëÄ What's next?

* More icon sets? (Let me know your favorite ones!)

# üí¨ Feedback & contributions

I'd love to hear how you use it (or plan to use it). If you run into issues, have feature requests, or want to contribute example code / icon sets --- please drop a PR or open an issue on GitHub.

Hopefully this will make building icon‚Äëenhanced Tkinter/ttkbootstrap GUIs smoother and more fun.",0,0,2025-10-26 15:09:10,ProfessionOld,https://www.reddit.com/r/Python/comments/1oglk47/release_v100_of_ttkbootstrapicons_easy_icon_sets/
1ofrx8v,reddit,Wheels for free-threaded Python now available for psutil,"Blogpost:  
[https://gmpy.dev/blog/2025/wheels-for-free-threaded-python-now-available-in-psutil](https://gmpy.dev/blog/2025/wheels-for-free-threaded-python-now-available-in-psutil)",73,9,2025-10-25 14:45:05,grodola,https://www.reddit.com/r/Python/comments/1ofrx8v/wheels_for_freethreaded_python_now_available_for/
1ofsfoz,reddit,[Release] Quantium 0.1.0 ‚Äî Building toward a Physics-Aware Units Library for Python,"**What my project does**  
Quantium is a Python library for physics with **unit-safe, dimensionally consistent arithmetic**. You can write equations like `F = m * a` or `E = h * f` directly in Python, and Quantium ensures that units remain consistent ‚Äî for example, `kg * (m/s)^2` is automatically recognized as Joules (`J`).

This initial release focuses on **getting units right** ‚Äî building a solid, reliable foundation for future symbolic and numerical physics computations.

**Target audience**  
Quantium is aimed at **Scientists, engineers, and students** who work with physical quantities and want to avoid subtle unit mistakes.

**Comparison**  
Quantium 0.1.0 is an **early foundation release**, so it‚Äôs not yet as feature-rich as established libraries like `pint` or `astropy.units`.  
Right now, the focus is purely on correctness, clarity, and a clean design for future extensions, especially toward combining **symbolic math (SymPy)** with **unit-aware arithmetic**.

Think of it as the groundwork for a physics-aware Python environment where you can symbolically manipulate equations, run dimensional checks, and eventually integrate with numerical solvers.

**Example (currently supported)**

    from quantium import u
    
    mass = 2 * u.kg
    velocity = 3 * u.m / u.s  # or u('m/s')
    
    energy = 0.5 * mass * velocity**2
    print(energy)

**Output**

    9.0 J

Note: NumPy integration isn‚Äôt available yet ‚Äî it‚Äôs planned for a future update.

Repo: [https://github.com/parneetsingh022/quantium](https://github.com/parneetsingh022/quantium)

Docs: [https://quantium.readthedocs.io](https://quantium.readthedocs.io)",46,14,2025-10-25 15:07:20,parneetsingh022,https://www.reddit.com/r/Python/comments/1ofsfoz/release_quantium_010_building_toward_a/
1ofswpq,reddit,Flask-Admin 2.0.0 ‚Äî Admin Interfaces for Flask,"# What it is

[Flask-Admin](https://github.com/pallets-eco/flask-admin) is a popular extension for quickly building admin interfaces in Flask applications. With only a few lines of code, it allows complete CRUD panels that can be extensively customized with a clean OOP syntax.

The new **2.0.0 release** modernizes the codebase for **Flask 3**, **Python 3.10+**, and **SQLAlchemy 2.0**, adding type hints and simplifying configuration.

# What‚Äôs new

* **Python 3.10+** required ‚Äî support for Python <=3.9 dropped
* **Full compatibility** with Flask 3.x, SQLAlchemy 2.x, WTForms 3.x, and Pillow 10+
* **Async route support** ‚Äî you can now use Flask-Admin views in async apps
* **Modern storage backends:**
   * AWS S3 integration now uses `boto3` instead of the deprecated `boto`
   * Azure Blob integration updated from SDK v2 ‚Üí v12
* **Better pagination and usability tweaks** across model views
* **type-hints**
* various fixes and translation updates
* dev env using **uv** and docker

# Breaking changes

* Dropped **Flask-BabelEx** and **Flask-MongoEngine** (both unmaintained), replacing them with **Flask-Babel** and bare **MongoEngine**
* Removed **Bootstrap 2/3 themes**
* All settings are now namespaced under `FLASK_ADMIN_*`, for example:
   * `MAPBOX_MAP_ID` ‚Üí `FLASK_ADMIN_MAPBOX_MAP_ID`
* **Improved theming:** replaced `template_mode` with a cleaner `theme` parameter

If you‚Äôre upgrading from 1.x, plan for a small refactor pass through your `Admin()` setup and configuration file.

# Target audience

Flask-Admin 2.0.0 is for developers maintaining or starting **Flask apps** who want a **modern, clean, and actively maintained admin interface**.

# Example

    from flask import Flask
    from flask_admin import Admin
    from flask_admin.contrib.sqla import ModelView
    from models import db, User
    
    app = Flask(__name__)
    app.config[""SQLALCHEMY_DATABASE_URI""] = ""sqlite:///example.db""
    db.init_app(app)
    
    # New API
    admin = Admin(app, name=""MyApp"", theme=""bootstrap4"")
    admin.add_view(ModelView(User, db.session))
    
    if __name__ == ""__main__"":
        app.run()

**Output:**  
A working admin interface supporting CRUD operations at `/admin` like this one: [image](https://private-user-images.githubusercontent.com/45307609/505743860-177c1ffd-1f55-4c0d-88a8-abce0d3371f6.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjE1NjgwMjgsIm5iZiI6MTc2MTU2NzcyOCwicGF0aCI6Ii80NTMwNzYwOS81MDU3NDM4NjAtMTc3YzFmZmQtMWY1NS00YzBkLTg4YTgtYWJjZTBkMzM3MWY2LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTEwMjclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUxMDI3VDEyMjIwOFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTA5ZjJkMzA1ZjIyYzg3Mjg5Yjk0NGYyZTYzZGE0NTdiYWE1ZjE5MWVjMGM2NjliNmQzYjBiNDQ5NTVhYTgwNTAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.W5cO_EBOWOq6waIpzuNe7lzP_BlFSAzyo3uUE4ELoIY)



**Github:** [github.com/pallets-eco/flask-admin](https://github.com/pallets-eco/flask-admin)  
**Release notes:** [https://github.com/pallets-eco/flask-admin/releases/tag/v2.0.0](https://github.com/pallets-eco/flask-admin/releases/tag/v2.0.0)",39,20,2025-10-25 15:27:43,ArabicLawrence,https://www.reddit.com/r/Python/comments/1ofswpq/flaskadmin_200_admin_interfaces_for_flask/
1oftnnx,reddit,Python script I wrote for generating an ASCII folder tree with flags and README.md integration,"**What it does:**

Works like Windows's tree command, but better! Generates ASCII tree structures with optional flags for hiding subdirectories and automatic README integration. You add two comment markers to your README, run the script, and your tree stays up to date.

**Target audience:**

I originally wrote this for one of my projects' README, because it bugged me that my docs were always outdated. If you have teaching repos, project templates, or just like having clean documentation, this might save you some time.

**How it differs:**

Windows `tree` just dumps output to terminal and you'd have to manually copy-paste into docs every time. This automates the documentation workflow and lets you hide specific folders by name (like ALL `cmake-build-debug` directories throughout your project), not just everything or nothing. Python has `rich` and `pathlib` for trees too, but same issue - no README automation or smart filtering.

I hope this will be as useful for others as it is for me!

[https://github.com/ipowi01/folder-tree-generator/tree/main](https://github.com/ipowi01/folder-tree-generator/tree/main)",26,16,2025-10-25 15:59:06,Ipowi01,https://www.reddit.com/r/Python/comments/1oftnnx/python_script_i_wrote_for_generating_an_ascii/
1ogn0io,reddit,AlertaTemprana v4.0 ‚Äî Bot Meteorol√≥gico Inteligente con Python y Telegram,"üå¶Ô∏è **What My Project Does:**  
AlertaTemprana es un **bot meteorol√≥gico interactivo** desarrollado en **Python** que combina datos de **Open-Meteo** y del **Servicio Meteorol√≥gico Nacional (SMN)**.  
Genera **alertas autom√°ticas**, muestra **im√°genes satelitales**, y realiza **an√°lisis clim√°ticos en tiempo real** directamente desde **Telegram**.

Permite:

* Configurar la ubicaci√≥n geogr√°fica del usuario.
* Consultar el clima actual desde el chat.
* Recibir alertas solo cuando se superan umbrales definidos (lluvia, tormenta, granizo, etc.).
* Registrar los datos localmente (CSV) para an√°lisis posteriores.



üéØ **Target Audience:**  
Est√° pensado para desarrolladores, investigadores, estudiantes o cualquier persona interesada en **automatizaci√≥n meteorol√≥gica, bots de Telegram o proyectos educativos con Python**.

Tambi√©n es √∫til para peque√±as instituciones o comunidades que necesiten **alertas locales** sin depender de plataformas externas.



‚öñÔ∏è **Comparison:**  
A diferencia de otros bots de clima, **AlertaTemprana** no depende solo de una API externa, sino que **fusiona datos de distintas fuentes** (Open-Meteo + SMN) y permite **personalizar la frecuencia de alertas** y la **ubicaci√≥n geogr√°fica** del usuario.  
Adem√°s, **guarda el historial localmente**, facilitando el an√°lisis con herramientas de data science o IA.



üîó **Repositorio GitHub:** [github.com/Hanzzel-corp/AlertaTemprana](https://github.com/Hanzzel-corp/AlertaTemprana)  
üåê **M√°s proyectos:** [hanzzel-corp.github.io/hanzzel-store/#libros](https://hanzzel-corp.github.io/hanzzel-store/#libros)

üí° Proyecto **educativo, libre y de c√≥digo abierto (MIT License)**.  
Cualquier sugerencia, mejora o fork es bienvenida üöÄ",0,1,2025-10-26 16:09:47,BackInternational743,https://www.reddit.com/r/Python/comments/1ogn0io/alertatemprana_v40_bot_meteorol√≥gico_inteligente/
1ofqmg6,reddit,A very simple native dataclass JSON serialization library,"# What My Project Does

I love using¬†[dataclasses](https://docs.python.org/3/library/dataclasses.html)¬†for internal structures so I wrote a very simple native library with no dependencies to handle serialization and deserialization using this type.

The first version only implements a JSON Codec as Proof-of-Concept but more can be added. It handles the default behavior, similar to `dataclasses.asdict` but can be customized easily.

The package exposes a very simple API:

    from dataclasses import dataclass
    from dataclasses_codec import json_codec, JSONOptional, JSON_MISSING
    from dataclasses_codec.codecs.json import json_field
    import datetime as dt
    
    # Still a dataclass, so we can use its features like slots, frozen, etc.
    @dataclass(slots=True)
    class MyMetadataDataclass:
        created_at: dt.datetime
        updated_at: dt.datetime
        enabled: bool | JSONOptional = JSON_MISSING # Explicitly mark a field as optional
        description: str | None = None # None is intentionally serialized as null
    
    
    @dataclass
    class MyDataclass:
        first_name: str
        last_name: str
        age: int
        metadata: MyMetadataDataclass = json_field(
            json_name=""meta""
        )
    
    obj = MyDataclass(""John"", ""Doe"", 30, MyMetadataDataclass(dt.datetime.now(), dt.datetime.now()))
    
    raw_json = json_codec.to_json(obj)
    print(raw_json)
    # Output: '{""first_name"": ""John"", ""last_name"": ""Doe"", ""age"": 30, ""meta"": {""created_at"": ""2025-10-25T11:53:35.918899"", ""updated_at"": ""2025-10-25T11:53:35.918902"", ""description"": null}}'

# Target Audience

Mostly me, as a learning project. However may be interesting from some python devs that need native Python support for their JSON serde needs.

# Comparison

Many similar alternatives exist. Most famous [Pydantic](https://docs.pydantic.dev/latest/). There is a similar package name [https://pypi.org/project/dataclass-codec/](https://pypi.org/project/dataclass-codec/) but I believe mine supports a higher level of customization.

# Source

You can find it at:¬†[https://github.com/stupid-simple/dataclasses-codec](https://github.com/stupid-simple/dataclasses-codec)

Package is published at PyPI:¬†[https://pypi.org/project/dataclasses-codec/](https://pypi.org/project/dataclasses-codec/)¬†.

Let me know what you think!

  
Edit: some error in the code example.",27,10,2025-10-25 13:45:17,lazyb_,https://www.reddit.com/r/Python/comments/1ofqmg6/a_very_simple_native_dataclass_json_serialization/
1ogkw8r,reddit,I built AgentHelm: Production-grade orchestration for AI agents [Open Source],"## What My Project Does

AgentHelm is a lightweight Python framework that provides production-grade orchestration for AI agents. It adds observability, safety, and reliability to agent workflows through automatic execution tracing, human-in-the-loop approvals, automatic retries, and transactional rollbacks.

## Target Audience

**This is meant for production use**, specifically for teams deploying AI agents in environments where:
- Failures have real consequences (financial transactions, data operations)
- Audit trails are required for compliance
- Multi-step workflows need transactional guarantees
- Sensitive actions require approval workflows

If you're just prototyping or building demos, existing frameworks (LangChain, LlamaIndex) are better suited.

## Comparison

**vs. LangChain/LlamaIndex:**
- They're excellent for building and prototyping agents
- AgentHelm focuses on production reliability: structured logging, rollback mechanisms, and approval workflows
- Think of it as the orchestration layer that sits around your agent logic

**vs. LangSmith (LangChain's observability tool):**
- LangSmith provides observability for LangChain specifically
- AgentHelm is LLM-agnostic and adds transactional semantics (compensating actions) that LangSmith doesn't provide

**vs. Building it yourself:**
- Most teams reimplement logging, retries, and approval flows for each project
- AgentHelm provides these as reusable infrastructure

---

## Background

AgentHelm is a lightweight, open-source Python framework that provides production-grade orchestration for AI agents.

**The Problem**

Existing agent frameworks (LangChain, LlamaIndex, AutoGPT) are excellent for prototyping. But they're not designed for production reliability. They operate as black boxes when failures occur.

Try deploying an agent where:
- Failed workflows cost real money
- You need audit trails for compliance
- Certain actions require human approval
- Multi-step workflows need transactional guarantees

**You immediately hit limitations.** No structured logging. No rollback mechanisms. No approval workflows. No way to debug what the agent was ""thinking"" when it failed.

## The Solution: Four Key Features

### 1. Automatic Execution Tracing

Every tool call is automatically logged with structured data:

```python
from agenthelm import tool

@tool
def charge_customer(amount: float, customer_id: str) -> dict:
    """"""Charge via Stripe.""""""
    return {""transaction_id"": ""txn_123"", ""status"": ""success""}
```

AgentHelm automatically creates audit logs with inputs, outputs, execution time, and the agent's reasoning. No manual logging code needed.

### 2. Human-in-the-Loop Safety

For high-stakes operations, require manual confirmation:

```python
@tool(requires_approval=True)
def delete_user_data(user_id: str) -> dict:
    """"""Permanently delete user data.""""""
    pass
```

The agent pauses and prompts for approval before executing. No surprise deletions or charges.

### 3. Automatic Retries

Handle flaky APIs gracefully:

```python
@tool(retries=3, retry_delay=2.0)
def fetch_external_data(user_id: str) -> dict:
    """"""Fetch from external API.""""""
    pass
```

Transient failures no longer kill your workflows.

### 4. Transactional Rollbacks

The most critical feature‚Äîcompensating transactions:

```python
@tool
def charge_customer(amount: float) -> dict:
    return {""transaction_id"": ""txn_123""}

@tool
def refund_customer(transaction_id: str) -> dict:
    return {""status"": ""refunded""}

charge_customer.set_compensator(refund_customer)
```

If a multi-step workflow fails at step 3, AgentHelm automatically calls the compensators to undo steps 1 and 2. Your system stays consistent.

Database-style transactional semantics for AI agents.

## Getting Started

```bash
pip install agenthelm
```

Define your tools and run from the CLI:

```bash
export MISTRAL_API_KEY='your_key_here'
agenthelm run my_tools.py ""Execute task X""
```

AgentHelm handles parsing, tool selection, execution, approval workflows, and logging.

## Why I Built This

I'm an optimization engineer in electronics automation. In my field, systems must be observable, debuggable, and reliable. When I started working with AI agents, I was struck by how fragile they are compared to traditional distributed systems.

AgentHelm applies lessons from decades of distributed systems engineering to agents:
- Structured logging (OpenTelemetry)
- Transactional semantics (databases)
- Circuit breakers and retries (service meshes)
- Policy enforcement (API gateways)

These aren't new concepts. We just haven't applied them to agents yet.

## What's Next

This is v0.1.0‚Äîthe foundation. The roadmap includes:
- Web-based observability dashboard for visualizing agent traces
- Policy engine for defining complex constraints
- Multi-agent coordination with conflict resolution

But I'm shipping now because teams are deploying agents today and hitting these problems immediately.

## Links

- **PyPI:** `pip install agenthelm`
- **GitHub:** https://github.com/hadywalied/agenthelm
- **Docs:** https://hadywalied.github.io/agenthelm/

I'd love your feedback, especially if you're deploying agents in production. What's your biggest blocker: observability, safety, or reliability?

Thanks for reading!",0,2,2025-10-26 14:40:44,hadywalied,https://www.reddit.com/r/Python/comments/1ogkw8r/i_built_agenthelm_productiongrade_orchestration/
1og6hlr,reddit,Sunday Daily Thread: What's everyone working on this week?,"# Weekly Thread: What's Everyone Working On This Week? üõ†Ô∏è

Hello /r/Python! It's time to share what you've been working on! Whether it's a work-in-progress, a completed masterpiece, or just a rough idea, let us know what you're up to!

## How it Works:

1. **Show & Tell**: Share your current projects, completed works, or future ideas.
2. **Discuss**: Get feedback, find collaborators, or just chat about your project.
3. **Inspire**: Your project might inspire someone else, just as you might get inspired here.

## Guidelines:

* Feel free to include as many details as you'd like. Code snippets, screenshots, and links are all welcome.
* Whether it's your job, your hobby, or your passion project, all Python-related work is welcome here.

## Example Shares:

1. **Machine Learning Model**: Working on a ML model to predict stock prices. Just cracked a 90% accuracy rate!
2. **Web Scraping**: Built a script to scrape and analyze news articles. It's helped me understand media bias better.
3. **Automation**: Automated my home lighting with Python and Raspberry Pi. My life has never been easier!

Let's build and grow together! Share your journey and learn from others. Happy coding! üåü",3,4,2025-10-26 01:00:31,AutoModerator,https://www.reddit.com/r/Python/comments/1og6hlr/sunday_daily_thread_whats_everyone_working_on/
1ofv37e,reddit,Caddy Snake Plugin,"# üêç What My Project Does

Caddy Snake lets you run Python web apps directly in the Caddy process.  
It loads your application module, executes requests through the Python C API, and responds natively through Caddy‚Äôs internal handler chain.  
This approach eliminates an extra network hop and simplifies deployment.

Link: [https://github.com/mliezun/caddy-snake](https://github.com/mliezun/caddy-snake)

# üéØ Target Audience

Developers who:

* Want **simpler deployments** without managing multiple servers (no Gunicorn + Nginx stack).
* Are curious about **embedding Python** in Go.
* Enjoy experimenting with **low-level performance** or **systems integration** between languages.

It‚Äôs functional and can run production apps, but it‚Äôs currently **experimental** ideal for research, learning, or early adopters.

# ‚öñÔ∏è Comparison

* **vs Gunicorn + Nginx**: Caddy Snake runs the Python app *in-process*, removing the need for inter-process HTTP communication.
* **vs Uvicorn / Daphne**: Those run a standalone Python web server; this plugin integrates Python execution directly into a Caddy module.
* **vs mod\_wsgi**: Similar conceptually, but built for Caddy‚Äôs modern, event-driven architecture and with ASGI support.",4,8,2025-10-25 16:57:09,Plus_Technology_7569,https://www.reddit.com/r/Python/comments/1ofv37e/caddy_snake_plugin/
1oggfn8,reddit,Does this need to be a breaking change? A plea to library maintainers.,"I have been part of many dev teams making ""task force"" style efforts to upgrade third-party dependencies or tools. But far too often it is work that add zero business (or project) value for us.

I think this a problem in our industry in general, and wrote a short blog post about it.

EDIT: I am also a library and tools maintainer. All my Open Source work is without funding and 100% on my spare time. Just want to make that clear.

The post ""Please don't break things"": https://davidvujic.blogspot.com/2025/10/please-dont-break-things.html",0,52,2025-10-26 10:37:52,david-vujic,https://www.reddit.com/r/Python/comments/1oggfn8/does_this_need_to_be_a_breaking_change_a_plea_to/
1ogf6ft,reddit,URL Shortener with FastAPI,"**What My Project Does**¬†  
Working with Django in real life for years, I wanted to try something new.  
This project became my hands-on introduction to FastAPI and helped me get started with it.

Miniurl a simple and efficient URL shortener.

**Target Audience**¬†  
This project is designed for anyone who frequently shares links online‚Äîsocial media users

**Comparison**¬†  
Unlike larger URL shortener services, miniurl is open-source, lightweight, and free of complex tracking or advertising.

[](https://preview.redd.it/url-shortener-with-fastapi-v0-ou0e2ms4yexf1.png?width=640&format=png&auto=webp&s=efb24bbd2d4ab0dda413d41456f9a242a7fd9441)

**URL**¬†  
Documentation and Github repo:¬†[https://github.com/tsaklidis/miniurl.gr](https://github.com/tsaklidis/miniurl.gr)

*Any stars are appreciated*",0,6,2025-10-26 09:16:56,steftsak,https://www.reddit.com/r/Python/comments/1ogf6ft/url_shortener_with_fastapi/
1ofk1vx,reddit,Thermal Monitoring for S25+,"Just for ease, the repo is also posted up here.

https://github.com/DaSettingsPNGN/S25_THERMAL-

What my project does: Monitors core temperatures using sys reads and Termux API. It models thermal activity using Newton's Law of Cooling to predict thermal events before they happen and prevent Samsung's aggressive performance throttling at 42¬∞ C. 

Target audience: Developers who want to run an intensive server on an S25+ without rooting or melting their phone. 

Comparison: I haven't seen other predictive thermal modeling used on a phone before. The hardware is concrete and physics can be very good at modeling phone behavior in relation to workload patterns. Samsung itself uses a reactive and throttling system rather than predicting thermal events. Heat is continuous and temperature isn't an isolated event. 

I didn't want to pay for a server, and I was also interested in the idea of mobile computing. As my workload increased, I noticed my phone would have temperature problems and performance would degrade quickly. I studied physics and realized that the cores in my phone and the hardware components were perfect candidates for modeling with physics. By using a ""thermal bank"" where you know how much heat is going to be generated by various workloads through machine learning, you can predict thermal events before they happen and defer operations so that the 42¬∞ C thermal throttle limit is never reached. At this limit, Samsung aggressively throttles performance by about 50%, which can cause performance problems, which can generate more heat, and the spiral can get out of hand quickly. 

My solution is simple: never reach 42¬∞ C

https://github.com/DaSettingsPNGN/S25_THERMAL-

Please take a look and give me feedback.

Thank you!",13,6,2025-10-25 07:01:54,DaSettingsPNGN,https://www.reddit.com/r/Python/comments/1ofk1vx/thermal_monitoring_for_s25/
1ofevmc,reddit,Skylos: Dead code + Vibe code security flaws detector,"Hi everyone

I have created Skylos to detect dead code quite a while back. Just here to give a short update. We have updated and expanded Skylos' capabilities to include common security flaws generated by AI. These things include the basic stuff like SQL injection, path traversal etc. So how this works, your py files are parsed through the AST.. After that the security scanners will take over and run over that same tree. Once that is complete, a generic ""dangerous"" table is applied node by node to catch any security flaws.  As for how the dead code side works, i'm gonna keep it short. basically it parses the py files to build a graph of functions, classes, variables etc etc. it will then record where each symbol is referenced. thats it. 

# Target audience

Anyone working with python code. 

# Why use Skylos? 

I know people will ask why use this when there's vulture, bandit etc etc. Well I mean those are really established and great libraries too. We're kind of more niche. For starters, Skylos provides real taint tracking by propagating the taint in the AST. If i'm not wrong although i may be, bandit uses pattern matching. Just a different approach. We also tuned skylos specifically for handling poor ai coding practises since now I know a fair bit of people who are placing more reliance on ai. So we found out that these are the common problems that AI generate. That is why we have tuned skylos specifically for this purpose. We will definitely expand its abilities in the future. Lastly, why Skylos? One tool, one AST, thats it. 

  
We have provided a VSC extension in the marketplace. You can search for skylos via the marketplace if you're using VSC. The tool will highlight and search for dead code etc. We will work on this further. We also do have a CI/CD pipeline in the README so yall can use it to scan your repos before merging etc. 

  
If you all have found this library useful, please give us a star on github, share it and give us feedback. We're happy to hear from yall and if you will like to collab, contribute do drop me a message here. I also will like to apologise if i have been inactive for a bit, been doing a peer review for my research paper so have been really swarmed. 

  
Thanks once again! 

  
Links: [https://github.com/duriantaco/skylos](https://github.com/duriantaco/skylos)",28,4,2025-10-25 02:17:13,papersashimi,https://www.reddit.com/r/Python/comments/1ofevmc/skylos_dead_code_vibe_code_security_flaws_detector/
1ofu5t2,reddit,Python 3.14t free-threading (GIL disabled) in Termux on Android,"Hi there! Maybe you would be interested ;)

**Python 3.14t free-threading (GIL disabled) on Termux Android**

This project brings Python 3.14t with free-threading capabilities to Termux on Android, enabling **true multi-core parallel execution** on mobile devices. 

My benchmarks show that free-threaded Python 3.14t delivers about 6-7x (6.8x to be precise) in multi-threaded workloads compared to the standard Python 3.12 (Standard GIL) available in Termux.

**What My Project Does:**

Provides a straightforward installation method for Python 3.14t with GIL disabled on Termux, allowing Android users to harness true concurrent threading on their phones.

**Target Audience:**

Hobbyists and developers who want to experiment with cutting-edge Python features on Android, run CPU-intensive multi-threaded applications, or explore the benefits of free-threading on mobile hardware.

**Why Free-Threading Matters:**

With the GIL disabled, multiple threads can execute Python bytecode concurrently, utilizing all available CPU cores simultaneously.

Enjoy!

https://github.com/Fibogacci/python314t-for-termux

***

**Syntax Highlighting in the REPL**

Python 3.14 adds real-time syntax highlighting while writing code in the REPL. Different syntax elements receive their own colors:

- Keywords, Strings and comments
- Numbers and operators
- Built-in function names

The highlighting also works in the Python debugger (PDB), making code much easier to read during debugging sessions.

***

**F1, F2, F3 Keyboard Functions**

The REPL in Python 3.14 introduces those keyboard shortcuts:

**F1** - opens the built-in help browser in a pager, where you can browse Python documentation, modules, and objects

**F2** - opens the persistent history browser in a pager, allowing you to copy and reuse code from previous sessions

**F3** - activates paste mode, although direct pasting usually works without problems

I'm using Hacker's Keyboard on Android.",2,6,2025-10-25 16:19:07,Fibogacci,https://www.reddit.com/r/Python/comments/1ofu5t2/python_314t_freethreading_gil_disabled_in_termux/
1ofdbzk,reddit,Saturday Daily Thread: Resource Request and Sharing! Daily Thread,"# Weekly Thread: Resource Request and Sharing üìö

Stumbled upon a useful Python resource? Or are you looking for a guide on a specific topic? Welcome to the Resource Request and Sharing thread!

## How it Works:

1. **Request**: Can't find a resource on a particular topic? Ask here!
2. **Share**: Found something useful? Share it with the community.
3. **Review**: Give or get opinions on Python resources you've used.

## Guidelines:

* Please include the type of resource (e.g., book, video, article) and the topic.
* Always be respectful when reviewing someone else's shared resource.

## Example Shares:

1. **Book**: [""Fluent Python""](https://www.amazon.com/Fluent-Python-Concise-Effective-Programming/dp/1491946008) \- Great for understanding Pythonic idioms.
2. **Video**: [Python Data Structures](https://www.youtube.com/watch?v=pkYVOmU3MgA) \- Excellent overview of Python's built-in data structures.
3. **Article**: [Understanding Python Decorators](https://realpython.com/primer-on-python-decorators/) \- A deep dive into decorators.

## Example Requests:

1. **Looking for**: Video tutorials on web scraping with Python.
2. **Need**: Book recommendations for Python machine learning.

Share the knowledge, enrich the community. Happy learning! üåü",7,0,2025-10-25 01:00:32,AutoModerator,https://www.reddit.com/r/Python/comments/1ofdbzk/saturday_daily_thread_resource_request_and/
1ofuh7m,reddit,Created a music for coders soundtrack for my latest course,"Enjoy the soundtrack if you need some chill background music.

[https://mkennedy.codes/posts/this-course-has-its-own-soundtrack/](https://mkennedy.codes/posts/this-course-has-its-own-soundtrack/) ",0,25,2025-10-25 16:32:15,mikeckennedy,https://www.reddit.com/r/Python/comments/1ofuh7m/created_a_music_for_coders_soundtrack_for_my/
1oet078,reddit,Faster Jupyter Notebooks with the Zuban Language Server,"The [Zuban Language Server](https://github.com/zubanls/zuban/) now supports Jupyter notebooks in addition to standard Python files.

You can use this, for example, if you have the [Zuban extension](https://marketplace.visualstudio.com/items?itemName=zuban.zubanls) installed in VSCode and work with Jupyter notebooks there. This update marks one of the final steps towards a feature-complete Python Language Server; remaining work includes auto-imports and a few smaller features.",63,19,2025-10-24 10:17:54,zubanls,https://www.reddit.com/r/Python/comments/1oet078/faster_jupyter_notebooks_with_the_zuban_language/
1oei7fa,reddit,Wove 1.0.0 Release Announcement - Beautiful Python Async,"I've been testing Wove for a couple months now in two production systems that have served millions of requests without issue, so I think it is high time to release a version 1. I found Wove's flexibility, ability to access local variables, and inline nature made refactoring existing non-async Django views and Celery tasks painless. Thinking about concurrency with Wove's design pattern is so easy that I find myself using Wove all over the place now. Version 1.0.0 comes with some great new features:

* Official support for free threaded python versions. This means wove is an excellent way to smoothly implement backwards-compatible true multithreaded processing in your existing projects. Just use the non-async `def` for weave tasks -- these internally are run with a `threading` pool.
* Background processing in both embedded and forked modes. This means you can detach a wove block and have it run after your containing function ends. Embedded mode uses threading internally and forked mode makes a whole new python process so the main process can end and be returned to a server's pool for instance.
* 93% test coverage
* Tested on Windows, Linux, and Mac on Python versions 3.8 to 3.14t

Here's a snippet from the [readme](https://github.com/curvedinf/wove):

Wove is for running high latency async tasks like web requests and database queries concurrently in the same way as asyncio, but with a drastically improved user experience. Improvements compared to asyncio include:

* **Reads Top-to-Bottom:** The code in a `weave` block is declared in the order it is executed inline in your code instead of in disjointed functions.
* **Implicit Parallelism:** Parallelism and execution order are implicit based on function and parameter naming.
* **Sync or Async:** Mix `async def` and `def` freely. A weave block can be inside or outside an async context. Sync functions are run in a background thread pool to avoid blocking the event loop.
* **Normal Python Data:** Wove's task data looks like normal Python variables because it is. This is because of inherent multithreaded data safety produced in the same way as map-reduce.
* **Automatic Scheduling:** Wove builds a dependency graph from your task signatures and runs independent tasks concurrently as soon as possible.
* **Automatic Detachment:** Wove can run your inline code in a forked detached process so you can return your current process back to your server's pool.
* **Extensibility:** Define parallelized workflow templates that can be overridden inline.
* **High Visibility:** Wove includes debugging tools that allow you to identify where exceptions and deadlocks occur across parallel tasks, and inspect inputs and outputs at each stage of execution.
* **Minimal Boilerplate:** Get started with just the `with weave() as w:` context manager and the [`w.do`](http://w.do) decorator.
* **Fast:** Wove has low overhead and internally uses `asyncio`, so performance is comparable to using `threading` or `asyncio` directly.
* **Free Threading Compatible:** Running a modern GIL-less Python? Build true multithreading easily with a `weave`.
* **Zero Dependencies:** Wove is pure Python, using only the standard library. It can be easily integrated into any Python project whether the project uses `asyncio` or not.

Example Django view:

    # views.py
    import time
    from django.shortcuts import render
    from wove import weave
    from .models import Author, Book
    
    def author_details(request, author_id):
        with weave() as w:
            # `author` and `books` run concurrently
            @w.do
            def author():
                return Author.objects.get(id=author_id)
            @w.do
            def books():
                return list(Book.objects.filter(author_id=author_id))
    
            # Map the books to a task that updates each of their prices concurrently
            @w.do(""books"", retries=3)
            def books_with_prices(book):
                book.get_price_from_api()
                return book
    
            # When everything is done, create the template context
            @w.do
            def context(author, books_with_prices):
                return {
                    ""author"": author,
                    ""books"": books_with_prices,
                }
        return render(request, ""author_details.html"", w.result.final)

Check out all the other features on github: [https://github.com/curvedinf/wove](https://github.com/curvedinf/wove)",107,33,2025-10-24 00:13:57,1ncehost,https://www.reddit.com/r/Python/comments/1oei7fa/wove_100_release_announcement_beautiful_python/
1oeg83l,reddit,Nyno (open-source n8n alternative using YAML) now supports Python for high performing Workflows,"Github link: [https://github.com/empowerd-cms/nyno](https://github.com/empowerd-cms/nyno)

For the latest updates/links see also [r/Nyno](https://www.reddit.com/r/Nyno/)",44,27,2025-10-23 22:47:34,EveYogaTech,https://www.reddit.com/r/Python/comments/1oeg83l/nyno_opensource_n8n_alternative_using_yaml_now/
1oe6mu7,reddit,Maintained fork of filterpy (Bayesian/Kalman filters),"# What My Project Does

I forked filterpy and got it working with modern Python tooling. It's a library for Kalman filters and other Bayesian filtering algorithms - basically state estimation stuff for robotics, tracking, navigation etc.

The fork ([bayesian\_filters](https://github.com/GeorgePearse/bayesian_filters)) has all the original filterpy functionality but with proper packaging, tests, and docs.

# Target Audience

Anyone who needs Bayesian filtering in Python - whether that's production systems, research, or learning. It's not a toy project - filterpy is/was used all over the place in robotics and computer vision.

# Comparison

The original filterpy hasn't been updated since 2018 and broke with newer setuptools versions. This caused us (and apparently many others) real problems in production.

Since the original seems abandoned, I cleaned it up:

* Fixed the setuptools incompatibility
* Added proper tests
* Updated to modern Python packaging
* Actually maintaining it

You can install it with:

    uv pip install bayesian-filters

GitHub: [https://github.com/GeorgePearse/bayesian\_filters](https://github.com/GeorgePearse/bayesian_filters)

This should help anyone else who's been stuck with the broken original package. It's one of those libraries that's simultaneously everywhere and completely unmaintained.

Literally just aiming to be a steward, I work in object detection so I might setup some benchmarks to test how well they improve object tracking (which has been my main use-case so far)",74,9,2025-10-23 16:40:24,Georgehwp,https://www.reddit.com/r/Python/comments/1oe6mu7/maintained_fork_of_filterpy_bayesiankalman_filters/
1oeauls,reddit,undersort: a util for sorting class methods,"# What My Project Does

[undersort](https://github.com/kivicode/undersort) is a little util I created out of frustration.

It's usually very confusing to read through a class with a mix of instance/class/static and public/protected/private methods in random order. Yet oftentimes that's exactly what we have to work with (especially now in the era of vibecoding).

This util will sort the methods for you. Fully configurable in terms of your preferred order of methods, and is fully compatible with \`pre-commit\`.

>underscore + sorting = \`undersort\`

# Target Audience

For all developers who want to keep the methods organized.

# Comparison

I'm not aware of a tool that deals with this problem.

\---

GitHub: [https://github.com/kivicode/undersort](https://github.com/kivicode/undersort)

PyPI: [https://pypi.org/project/undersort/](https://pypi.org/project/undersort/)",38,9,2025-10-23 19:18:57,kivicode,https://www.reddit.com/r/Python/comments/1oeauls/undersort_a_util_for_sorting_class_methods/
1oem2vj,reddit,sdax 0.5.0 ‚Äî Run complex async tasks with automatic cleanup,"Managing async workflows with dependencies, retries, and guaranteed cleanup is hard.  
[sdax](https://pypi.org/project/sdax) ‚Äî Structured Declarative Async eXecution ‚Äî does the heavy lifting.

You define async functions, wire them together as a **graph** (or just use ‚Äúlevels‚Äù), and let [sdax](https://pypi.org/project/sdax) handle ordering, parallelism, and teardown.

**Why graphs are faster:**  
The new graph-based scheduler doesn‚Äôt wait for entire ‚Äúlevels‚Äù to finish before starting the next ones.  
It launches any task as soon as its dependencies are done ‚Äî removing artificial barriers and keeping the event loop busier.  
The result is tighter concurrency and lower overhead, especially in mixed or irregular dependency trees.  
However, it does mean you need to ensure your dependency graph actually reflects the real ordering ‚Äî for example, open a connection before you write to it.

**What's new in 0.5.0:**

* Unified graph-based scheduler with full dependency support
* Level adapter now builds an equivalent DAG under the hood
* Functions can optionally receive a `TaskGroup` to manage their own subtasks
* You can specify which exceptions are retried

**What it has:**

* Guaranteed cleanup: every task that starts `pre_execute` gets its `post_execute`, even on failure
* Immutable, reusable processors for concurrent executions (build once, reuse many times). No need to build the AsyncTaskProcessor every time.
* Built on `asyncio.TaskGroup` and `ExceptionGroup` (Python 3.11+) (I have a backport of these if someone really does want to use it pre 3.11 but I'm not going to support it.)

Docs + examples:  
PyPI: [https://pypi.org/project/sdax](https://pypi.org/project/sdax)  
GitHub: [https://github.com/owebeeone/sdax](https://github.com/owebeeone/sdax)",7,4,2025-10-24 03:22:25,GianniMariani,https://www.reddit.com/r/Python/comments/1oem2vj/sdax_050_run_complex_async_tasks_with_automatic/
1of6v3c,reddit,SimplePrompts - Simple way to create prompts from within python (no jinja2 or prompt stitching),"Writing complex prompts that might require some level of control flow (removing or adding certain bits based on specific conditions, looping etc.) is easy using python (stitching strings) but it makes the prompt hard to read holistically, alternatively you can use templating languages that embed the control flow within the string itself (e.g jinja2), but this requires dealing with those templating languages syntax.

SimplePrompts is an attempt to provide a way to construct prompts from within python, that are easily configurable programmatically, yet readable.  
  
**What My Project Does**  
Simplifies creating LLM prompts from within python, while being fairly readable

**Target Audience**  
Devs who build LLM based apps, the library is still in ""alpha"" as the api could change heavily

**Comparison**  
Instead of stitching strings within familiar python but losing the holistic view of the prompt, or using a templating language like jinja2 that might take you out of comfy python land, SimplePrompts tries to provide the best of both worlds

Github link: [Infrared1029/simpleprompts: A simple library for constructing LLM prompts](https://github.com/Infrared1029/simpleprompts)",0,3,2025-10-24 20:22:03,Infrared12,https://www.reddit.com/r/Python/comments/1of6v3c/simpleprompts_simple_way_to_create_prompts_from/
1oejm1a,reddit,KickNoSub: A CLI Tool for Extracting Stream URLs from Kick VODs (for Educational Use),"[GitHub](https://github.com/Enmn/KickNoSub)

Hi folks

**What My Project Does**

It‚Äôs designed purely for **educational and research purposes**, showing how Kick video metadata and HLS stream formats can be parsed and retrieved programmatically.

**With KickNoSub, you can:**

* Input a Kick video URL
* Choose from multiple stream quality options (1080p60, 720p60, 480p30, etc.)
* Instantly get the **raw** `.m3u8` **stream URL**
* Use that URL with media tools like **VLC**, **FFmpeg**, or any HLS-compatible player

**KickNoSub is intended for:**

* **Developers, researchers, and learners** interested in understanding how Kick‚Äôs video delivery works
* **Python enthusiasts** exploring how to parse and interact with streaming metadata
* Ideal for those learning about HLS stream extraction and command-line automation.

**Work in Progress**

* Expanding support for more stream formats
* Improving the command-line experience
* Adding optional logging and debugging modes
* Providing better error handling and output formatting

**Feedback**

If you have ideas, suggestions, or improvements, feel free to open an issue or pull request on GitHub!  
Contributions are always welcome ü§ç

**Legal Disclaimer**

KickNoSub is provided **strictly for educational, research, and personal learning** purposes only.

**It is not intended to:**

* Circumvent subscriber-only content or paywalls
* Facilitate piracy or unauthorized redistribution
* Violate Kick‚Äôs Terms of Service or any applicable laws

By using KickNoSub, you agree that you are solely responsible for your actions and compliance with all platform rules and legal requirements.

If you enjoy content on Kick, please support the creators by subscribing and engaging through the official platform.",5,5,2025-10-24 01:19:37,Few-Independent8041,https://www.reddit.com/r/Python/comments/1oejm1a/kicknosub_a_cli_tool_for_extracting_stream_urls/
1oefhu1,reddit,neatnet: an open-source Python toolkit for street network geometry simplification,"_not my project, but a very interesting one_

## What My Project Does

`neatnet` simplifies street network geometry from transportation-focused to morphological representations. With a single function call (`neatnet.neatify()`), it:

- **Automatically detects** dual carriageways, roundabouts, slipways, and complex intersections that represent transportation infrastructure rather than urban space
- **Collapses** dual carriageways into single centerlines
- **Simplifies** roundabouts to single nodes and complex intersections to cleaner geometries
- **Preserves** network continuity throughout the simplification process

The result transforms messy OpenStreetMap-style transportation networks into clean morphological networks that better represent actual street space - all mostly parameter-free, with adaptive detection derived from the network itself.

## Target Audience

**Production-ready for research and analysis.** This is a peer-reviewed, scientifically-backed tool aimed at:

- Urban morphology researchers studying street networks and spatial structure
- Anyone working with OSM or similar data who needs morphological rather than transportation representations
- GIS professionals conducting spatial analysis where street space matters more than routing details
- Researchers who‚Äôve been manually simplifying networks

The API is considered stable, though the project is young and evolving. It‚Äôs designed to handle entire urban areas but works equally well on smaller networks.

## Comparison

**Unlike existing tools, `neatnet` focuses on continuity-preserving geometric simplification for morphological analysis:**

- **OSMnx** (Geoff Boeing): Great for collapsing intersections, but doesn‚Äôt go all the way and can have issues with fixed consolidation bandwidth
- **cityseer** (Gareth Simons): Handles many simplification tasks but can be cumbersome for custom data inputs
- **parenx** (Robin Lovelace et al.): Uses buffering/skeletonization/Voronoi but struggles to scale and can produce wobbly lines
- **Other approaches**: Often depend on OSM tags or manual work (trust me, you don‚Äôt want to simplify networks by hand)

`neatnet` was built specifically because none of these satisfied the need for automated, adaptive simplification that preserves network continuity while converting transportation networks to morphological ones. It outperforms current methods when compared to manually simplified data (see the paper for benchmarks).

The approach is based on detecting artifacts (long/narrow or too-small polygons formed by the network) and simplifying them using rules that minimally affect network properties - particularly continuity.

**Links:**

- **Repo**: <https://github.com/uscuni/neatnet>
- **Docs**: <https://uscuni.org/neatnet/>
- **Tutorial**: <https://uscuni.org/neatnet/intro.html>
- **Blog post**: <https://martinfleischmann.net/simplification-of-street-networks/>
- **Paper** (preprint): <https://arxiv.org/abs/2504.16198>",9,2,2025-10-23 22:17:28,Balance-,https://www.reddit.com/r/Python/comments/1oefhu1/neatnet_an_opensource_python_toolkit_for_street/
1odk7pl,reddit,How common is Pydantic now?,"Ive had several companies asking about it over the last few months but, I personally havent used it much. 

Im strongly considering looking into it since it seems to be rather popular?

What is your personal experience with Pydantic?",335,194,2025-10-22 21:53:10,GongtingLover,https://www.reddit.com/r/Python/comments/1odk7pl/how_common_is_pydantic_now/
1oe4n7h,reddit,pyochain: method chaining on iterators and dictionnaries,"Hello everyone,

I'd like to share a project I've been working on, `pyochain`. It's a Python library that brings a fluent, declarative, and 100% type-safe API for data manipulation, inspired by Rust Iterators and the style of libraries like Polars.

**Installation**

`uv add pyochain`

**Links**

* **Source Code (GitHub):** [https://github.com/OutSquareCapital/pyochain](https://github.com/OutSquareCapital/pyochain)
* **Documentation:** [https://outsquarecapital.github.io/pyochain/](https://outsquarecapital.github.io/pyochain/)
* **Pypi**: [https://pypi.org/project/pyochain/](https://pypi.org/project/pyochain/)

**What my project does**

It provides chainable, functional-style methods for standard Python data structures, with a rich collections of methods operating on lazy iterators for memory efficiency, an exhaustive documentation, and a complete, modern type coverage with generics and overloads to cover all uses cases.

Here‚Äôs a quick example to show the difference in styles with 3 different ways of doing it in python, and pyochain:

    import pyochain as pc
    
    result_comp = [x**2 for x in range(10) if x % 2 == 0]
    
    result_func = list(map(lambda x: x**2, filter(lambda x: x % 2 == 0, range(10))))
    
    result_loop: list[int] = []
    for x in range(10):
    ¬† ¬† if x % 2 == 0:
    ¬† ¬† ¬† ¬† result_loop.append(x**2)
    
    result_pyochain = (
    ¬† ¬† pc.Iter.from_(range(10)) # pyochain.Iter.__init__ only accept Iterator/Generators
    ¬† ¬† .filter(lambda x: x % 2 == 0) # call python filter builtin 
    ¬† ¬† .map(lambda x: x**2) # call python map builtin
    ¬† ¬† .collect() # convert into a Collection, by default list, and return a pyochain.Seq
    ¬† ¬† .unwrap() # return the underlying data
    )
    assert (
    ¬† ¬† result_comp == result_func == result_loop == result_pyochain == [0, 4, 16, 36, 64]
    )

Obviously here the intention with the list comprehension is quite clear, and performance wise is the best you could do in pure python.

However once it become more complex, it quickly becomes incomprehensible since you have to read it in a non-inuitive way:

\- the input is in the middle  
\- the output on the left  
\- the condition on the right  
(??)

The functional way suffer of the other problem python has : nested functions calls .

The order of reading it is.. well you can see it for yourself.

All in all, data pipelines becomes quickly unreadable unless you are great at finding names or you write comments. Not funny.

For my part, whem I started programming with python, I was mostly using pandas and numpy, so I was just obligated to cope with their bad API's.

Then I discovered polars, it's fluent interface and my perspective shifted.  
Afterwards, when I tried some Rust for fun in another project, I was shocked to see how much easier it was to work with lazy Iterator with the plethora of methods available. See for yourself:

[https://doc.rust-lang.org/std/iter/trait.Iterator.html](https://doc.rust-lang.org/std/iter/trait.Iterator.html)

Now with pyochain, I only have to read my code from top to bottom, from left to right.

If my lambda become too big, I can just isolate it in a function.  
I can then chain functions with pipe, apply, into on the same pipeline effortlessly, and I rarely have to implement data oriented classes besides NamedTuples, basic dataclasses, etc... since I can express high level manipulations already with pyochain.

pyochain also implement a lot of functionnality for dicts (or convertible objects compliants to the Mapping Protocol).  
There are methods to work on all keys, values, etc... in a fast way thanks to cytoolz usage under the hood (a library implemented in Cython) with the same chaining style.  
But also methods to conveniently flatten the structure of a dict, extract it's ""schema"" (recursively find the datatypes inside), modify and select keys in nested structure thanks to an API inspired by polars with pyochain.key function who can create ""expressions"".

For example,  pyochain.key(""a"").key(""b"").apply(lambda x: x + 1), when passed in a select or with fields context (pyochain.Dict.select, pyochain.Dict.with\_fields), will extract the value, just like foo\[""a""\]\[""b""\].

**Target Audience**

This library is aimed at Python developers who enjoy method chaining/functionnal style, Rust Iterators API, python lazy Generators/Iterators, or, like me, data scientist who are enthusiast Polars users.

It's intended for anyone who wants to make their data transformation code more readable and composable by using method chaining on any python object who adhere to the protocols defined in [collections.abc](http://collections.abc) who are Iterable, Iterator/Generator, Mapping, and Collection (meaning a LOT of use cases).

**Comparison**

* **vs.** `itertools/cytoolz`: Basically uses most of their functions under the hood. pyochain provides de facto type hints and documentation on all the methods used, by using stubs made by me that you can find here: [https://github.com/py-stubs/cytoolz-stubs](https://github.com/py-stubs/cytoolz-stubs)
* **vs.** `more-itertools`: Like `itertools`, `more-itertools` offers a great collection of utility functions, and pyochain uses some of them when needed or when cytoolz doesn't implement them (the latter is prefered due to performance).
* vs `pyfunctional`:  this is a library that I didn't knew of when I first started writing pyochain. pyfunctional provides the same paradigm (method chaining), parallel execution, and IO operations, however it provides no typing at all (vs 100% coverage of pyochain), and it has a redundant API (multiples ways of doing the exact same thing, filer and where methods for example).
* **vs.** `polars`: `pyochain` is **not** a DataFrame library. It's for working with *standard Python iterables and dictionaries*. It borrows the *style* of polars APIs but applies it to everyday data structures. It allows to work with non tabular data for pre-processing it before passing it in a dataframe(e.g deeply nested JSON data), OR to conveniently works with expressions, for example by calling methods on all the expressions of a context, or generating expressions in a more flexible way than polars.selectors, all whilst keeping the same style as polars (no more ugly for loops inside a beautiful polars pipeline). Both of those are things that I use a lot in my own projects.

**Performance consideration**

There's no miracle, pyochain will be slower than native for loops. This is is simply due to the fact that pyochain need to generate wrapper objects, call methods, etc....  
However the bulk of the work won't be really impacted (the loop in itself), and tbh if function call /object instanciation overhead is a bottleneck for you, well you shouldn't be using python in the first place IMO.

**Future evolution**

To me this library is still far from finished, there's a lot of potential for improvements, namely performance wise.  
Namely reimplementing all functions of itertools and pyochain closures in Rust (if I can figure out how to create Generators in Pyo3) or in Cython.

Also, in the past I implemented a JIT Inliner, consisting of an AST parser that was reading my list of function calls (each pyochain object method was adding a function to a list, instead of calling it on the underlying data immediatly, so double lazy in a way) and was creating on the fly python code that was ""optimized"", meaning that that the code generated was inlined (no more func(func(func())) nested calls) and hence avoided all the function overhead calls.

Then, I went further ahead and improved that by generating on the fly cython code from this optimized python code who was then compiled. To avoid costly recompilation at each run I managed a physical cache, etc...

Inlining, JIT Cython compilation, + the fact that my main classes were living in cython code (hence instanciation and calls cost were far cheaper), allowed my code to match or even beat optimized python loops on arbitrary objects.

But the code was becoming messy and added a lot of complexity so I abandonned the idea, it can still be found here however, and could be reimplemented I'm sure:

[https://github.com/OutSquareCapital/pyochain/commit/a7c2d80cf189f0b6d29643ccabba255477047088](https://github.com/OutSquareCapital/pyochain/commit/a7c2d80cf189f0b6d29643ccabba255477047088)

I also need to take a decision regarding the pychain.key function. Should I ditch it completely? should I keep it as simple as possible? Should I go back how I designed it originally and implement it in a manner as complete as possible? idk yet.

**Conclusion**

I learned a lot and had a lot of fun (well except when dealing with Sphinx, then Pydocs, then Mkdocs, etc... when I was trying to generate the documentation from docstrings) when writing this library.

This is my first package published on Pypi!

All questions and feedback are welcome.

I'm particularly interested in discussing software design, would love to have others perspectives on my implementation (mixins by modules to avoid monolithic files whilst still maintaining a flat API for end user)",14,10,2025-10-23 15:24:16,Beginning-Fruit-1397,https://www.reddit.com/r/Python/comments/1oe4n7h/pyochain_method_chaining_on_iterators_and/
1oenkf8,reddit,"Best logging module for integration to observability providers (Datadog, signoz)?",Currently torn between using stdlib logging (with a bunch of config/setup) vs structlog or loguru. Looking for advice and/or tales from production on what works best.,1,2,2025-10-24 04:38:15,rm-rf-rm,https://www.reddit.com/r/Python/comments/1oenkf8/best_logging_module_for_integration_to/
1odnnrv,reddit,What's the best package manager for python in your opinion?,"Mine is personally uv because it's so fast and I like the way it formats everything as a package. But to be fair, I haven't really tried out any other package managers.",111,220,2025-10-23 00:16:30,Ok_Sympathy_8561,https://www.reddit.com/r/Python/comments/1odnnrv/whats_the_best_package_manager_for_python_in_your/
1oej7tv,reddit,Friday Daily Thread: r/Python Meta and Free-Talk Fridays,"# Weekly Thread: Meta Discussions and Free Talk Friday üéôÔ∏è

Welcome to Free Talk Friday on /r/Python! This is the place to discuss the r/Python community (meta discussions), Python news, projects, or anything else Python-related!

## How it Works:

1. **Open Mic**: Share your thoughts, questions, or anything you'd like related to Python or the community.
2. **Community Pulse**: Discuss what you feel is working well or what could be improved in the /r/python community.
3. **News & Updates**: Keep up-to-date with the latest in Python and share any news you find interesting.

## Guidelines:

* All topics should be related to Python or the /r/python community.
* Be respectful and follow Reddit's [Code of Conduct](https://www.redditinc.com/policies/content-policy).

## Example Topics:

1. **New Python Release**: What do you think about the new features in Python 3.11?
2. **Community Events**: Any Python meetups or webinars coming up?
3. **Learning Resources**: Found a great Python tutorial? Share it here!
4. **Job Market**: How has Python impacted your career?
5. **Hot Takes**: Got a controversial Python opinion? Let's hear it!
6. **Community Ideas**: Something you'd like to see us do? tell us.

Let's keep the conversation going. Happy discussing! üåü",1,0,2025-10-24 01:00:43,AutoModerator,https://www.reddit.com/r/Python/comments/1oej7tv/friday_daily_thread_rpython_meta_and_freetalk/
1oe5qmx,reddit,STP to XML parser/conversion - Python,"As the title suggests, is there an existing python library that allows for helping to translate and restruct the EXPRESS language for CAD files exported as STEP (AP242 to be specific) to XML?

My situation is that I am trying to achieve a QIF standardized process flow which requires the transfer of information of MBD (Model-Based Definitions) in XML format. However, when I for example start in the design process of the CAD model, I can only export its geometry and annotations in the STEP AP242 format and my program does not allow an export to the QIF and even in any XML formats.

Since the exported STEP AP242 Part 21 file is in the EXPRESS language, I was wondering is there is any existing and working python libraries that allow for a sort of ""conversion"" or ""translation"" of the STP to XML.

Thank you in advanced for your suggestions!",3,0,2025-10-23 16:05:53,static_beqa,https://www.reddit.com/r/Python/comments/1oe5qmx/stp_to_xml_parserconversion_python/
1oe64ef,reddit,Built a way for marimo Python notebooks to talk to AI systems,"**What this feature does:** 

Since some AI tools and agents still struggle to collaborate effectively with Python notebooks, I recently designed and built a new --mcp flag for marimo, an AI-native Python notebook (16K+‚≠ê). This flag turns any marimo notebook into a Model Context Protocol (MCP) server so AI systems can safely inspect, diagnose, and reason about live notebooks without wrappers or extra infrastructure.

**Target audience:**

1. Python developers building AI tools, agents, or integrations.
2. Data scientists and notebook users interested in smarter, AI-assisted workflows.

**What I learned while building it:** 

I did a full write-up on how I designed and built the feature, the challenges I ran into and lessons learned here: [https://opensourcedev.substack.com/p/beyond-chatbots-how-i-turned-python](https://opensourcedev.substack.com/p/beyond-chatbots-how-i-turned-python)

**Source code:** 

[https://github.com/marimo-team/marimo](https://github.com/marimo-team/marimo)

Hope you find the write-up useful. Open to feedback or thoughts on how you‚Äôd approach similar integrations.",0,5,2025-10-23 16:20:44,Muted_Estate890,https://www.reddit.com/r/Python/comments/1oe64ef/built_a_way_for_marimo_python_notebooks_to_talk/
1oe01g5,reddit,Anyone having difficulty to learn embedded programming because of python background?,"I have seen arduino c++ which people start with for learning embedded but as a python programmer it will be quite difficult for me to learn both the hardware micro controller unit as well as its programming in c++.

How should i proceed?

Is there an easy way to start with?

And how many of you are facing the same issue?",0,27,2025-10-23 11:48:49,hellosobik,https://www.reddit.com/r/Python/comments/1oe01g5/anyone_having_difficulty_to_learn_embedded/
1oe1k8s,reddit,Building an browser automation framework in python,"\# What My Project Does

This is \`[py-browser-automation](https://pypi.org/project/py-browser-automation/)\`, its a python library that you can use to basically automate a chromium browser and make it do things based on simple instructions. The reason I came up with this is two-folds:

1. It was part of my bigger project of automating the process of OSINT. Without a way to navigate the web, it is hard to gain any credible intelligence.
2. There is a surge of automated browsers which do everything for you in the market today, none of them open sourced so I thought why not.

\# Target Audience

This is meant for hobbyists, OSINT fellows, anyone who wants to replicate what OpenAI is doing with Atlas (mine's not that good, but eventually it will be!)

  
\# Comparison

Its an extension of the automation tools that exist today. Right now for web scraping for example, you'll have to write the entire code for the website by hand. There is no interactive way to update the elements if the DOM changes. This handles all of that and it can visit any website, interact with any element and do all this without you having to write multiple lines of code. 

\## What's it under the hood?

Its essentially a framework over playwright, as playwright is easy enough, it does the job. In the most basic sense I am having one LLM take in the current context and decide which move to perform next. I couldn't think of an easier approach than this!

This makes me able to visit any website, interact with any field and stay within token limits of the LLM. It also has triggers for running login scripts, so lets say during the automation cycle it needs to visit instagram, its going to trigger the login script (if you set the trigger to be on) and log you in with your credentials (This is a TOS violation so you must be careful about whether you want to do this or not).

\## How can you test it out?

If you happen to have an OpenAI key or a VertexAI project (its easy, and you'll get around 300$ worth of free credits) you can just install this library and start running.

\## The problems I am aware of:

1. Right now things are very sequential. I am expecting you to enter things exactly as you want it. So, something like ""go over to amazon and order a phantom orion for me"" works but ""order a beyblade"" doesn't (its too vague).

My solution for this was to come up with a clarification based framework. So, during execution, the library will ask you questions to clarify if what its doing is correct or if you want to change a value or something. This makes it more interactive but not 'fully' automated.

2. Its slow because of API calls and its going one step at a time.

One optimisation I am working on is to have the LLM gimme not just the immediate next step but the next 3-4 steps in the same output. I will attach a priority based on how we normally expect things to go (like, first goto a page, then enter a value, then click on search etc.) and execute those steps in that order.  
This requires a lot more work but its a neat optimisation in my opinion.

3. No logs

Right now, its not logging anything. Its just going to do things and basically, its only for fun. I am working on attaching a database to this, but I just don't know what to log for and when exactly.

\## At the moment, what is this?

Right now, its a fun tool, you can watch browsers run by themselves and you can add this in your code if you need such a thing.

\## Installing

Checkout the website linked at the top, it has the necessary details for installing and running this. Also, this is the GitHub page if you want to check the code: [https://github.com/fauvidoTechnologies/PyBrowserAutomation/](https://github.com/fauvidoTechnologies/PyBrowserAutomation/)

\# Closing remarks

Thank you for reading this far! Would love if you run this, give me any feedback, good or bad, and I will work on it!

\# Thank you",0,8,2025-10-23 13:10:09,Ok-Sky6805,https://www.reddit.com/r/Python/comments/1oe1k8s/building_an_browser_automation_framework_in_python/
1oean84,reddit,pyupdate: a small CLI tool to update your Python dependencies to their latest version,"I was hoping that at some point¬†`uv`¬†will add it, but that is still¬†[pending](https://github.com/astral-sh/uv/issues/6692).

Here's a small CLI tool,¬†[pyupdate](https://github.com/ashishb/pyupdate/),¬†that updates all your dependencies to their latest available versions, updating both¬†`pyproject.toml`¬†and¬†`uv.lock`¬†file.

Currently, it only supports¬†`uv`¬†But I am planning to add support for¬†`poetry`¬†as well.",0,33,2025-10-23 19:11:02,ashishb_net,https://www.reddit.com/r/Python/comments/1oean84/pyupdate_a_small_cli_tool_to_update_your_python/
1odzpr5,reddit,Log Real-Time BLE Air Quality Data from to Google Sheets using python,"this tutorial shows how to capture real-time  air quality data such as CO2, temperature, and humidity readings over¬†**Bluetooth Low Energy (BLE)**, then automatically log them into¬†**Google Sheets**¬†for easy tracking and visualization.  
details of the project and source code availabe at [https://www.bleuio.com/blog/log-real-time-ble-air-quality-data-from-hibouair-to-google-sheets-using-bleuio/](https://www.bleuio.com/blog/log-real-time-ble-air-quality-data-from-hibouair-to-google-sheets-using-bleuio/)",0,0,2025-10-23 11:29:16,bleuio,https://www.reddit.com/r/Python/comments/1odzpr5/log_realtime_ble_air_quality_data_from_to_google/
1od4jpv,reddit,I built a Go-like channel package for Python asyncio,"[Repositoy here ](https://github.com/Gwali-1/PY_CHANNELS_ASYNC)

Docs here  => https://gwali-1.github.io/PY_CHANNELS_ASYNC/

Roughly a month ago, I was looking into concurrency as a topic, specifically async-await implementation internals in C# trying to understand the various components Involved, like the event loop, scheduling etc.

After sometime I understood enough to want to implement a channel data structure in Python so I built one. 

**What My Project Does.**

Pychanasync provides a channel-based message passing abstraction for asyncio coroutines. With it, you can 

Create buffered and unbuffered channels 
Send and receive values between coroutines synchronously and asynchronously 
Use channels as async iterators 
Use a select-like utility to wait on multiple channel operations.

It enables seamless and synchronized coroutune communication using structured message passing instead of relying shared state and locks. 


**Target Audience**

 Pychanasync is for developers working with asyncio.

If you're doing asynchronous programming in Python or exploring asycio and want a provide some
structure and synchronization to your program I highly recommend. 

**Comparison**

Pychanasync is heavily inspired by Go‚Äôs native channel primitive. It follows its the behaviour semantics and design. 
",32,14,2025-10-22 11:27:16,Turbulent-Pause-9212,https://www.reddit.com/r/Python/comments/1od4jpv/i_built_a_golike_channel_package_for_python/
1oe36b0,reddit,Python Mutability,"An exercise to build the right mental model for Python data. The ‚ÄúSolution‚Äù link uses memory_graph to visualize execution and reveals what‚Äôs actually happening.

What is the output of this Python program?

    def fun(a, b, c, d):
        a += [1, 2]
        b += (1, 2)
        c |= {1, 2}
        d |= {1, 2}

    a = [1]
    b = (1,)
    c = {1}
    d = frozenset({1})
    fun(a, b, c, d)

    print(a, b, c, d)
    # --- possible answers ---
    # A) [1, 1, 2] (1,) {1, 2} frozenset({1})
    # B) [1, 1, 2] (1,) {1, 1, 2} frozenset({1})
    # C) [1, 1, 2] (1, 1, 2) {1, 2} frozenset({1, 2})
    # D) [1, 1, 2] (1, 1, 2) {1, 1, 2} frozenset({1, 1, 2})

- [Solution](https://memory-graph.com/#codeurl=https://raw.githubusercontent.com/bterwijn/memory_graph_videos/refs/heads/main/exercises/exercise14.py&breakpoints=9&continues=1&play)
- [Explanation](https://github.com/bterwijn/memory_graph?tab=readme-ov-file#python-data-model)
- [More exercises](https://www.reddit.com/r/Python_memory_graph/)",0,0,2025-10-23 14:24:09,Sea-Ad7805,https://www.reddit.com/r/Python/comments/1oe36b0/python_mutability/
1odomzr,reddit,"Thursday Daily Thread: Python Careers, Courses, and Furthering Education!","# Weekly Thread: Professional Use, Jobs, and Education üè¢

Welcome to this week's discussion on Python in the professional world! This is your spot to talk about job hunting, career growth, and educational resources in Python. Please note, this thread is **not for recruitment**.

---

## How it Works:

1. **Career Talk**: Discuss using Python in your job, or the job market for Python roles.
2. **Education Q&A**: Ask or answer questions about Python courses, certifications, and educational resources.
3. **Workplace Chat**: Share your experiences, challenges, or success stories about using Python professionally.

---

## Guidelines:

- This thread is **not for recruitment**. For job postings, please see r/PythonJobs or the recruitment thread in the sidebar.
- Keep discussions relevant to Python in the professional and educational context.
  
---

## Example Topics:

1. **Career Paths**: What kinds of roles are out there for Python developers?
2. **Certifications**: Are Python certifications worth it?
3. **Course Recommendations**: Any good advanced Python courses to recommend?
4. **Workplace Tools**: What Python libraries are indispensable in your professional work?
5. **Interview Tips**: What types of Python questions are commonly asked in interviews?

---

Let's help each other grow in our careers and education. Happy discussing! üåü",2,2,2025-10-23 01:00:38,AutoModerator,https://www.reddit.com/r/Python/comments/1odomzr/thursday_daily_thread_python_careers_courses_and/
1odyrzh,reddit,Jaspr CLI Generator ‚Äì Use Gemini AI to Build Jaspr Web Apps Instantly,"just open sourced a Python CLI tool that leverages Gemini AI to generate fully-structured Jaspr (Dart) web projects. You interactively type a prompt, and it handles code, structure, and dependencies for you.

* API-driven assistant for web project bootstrapping
* Rich CLI interface with file preview
* Python handles AI, file generation, and shell Would appreciate any feedback, bug reports, or ideas for more Python integrations. 

[Github](https://github.com/3lvin-Kc/jaspr-ai)",0,0,2025-10-23 10:31:43,Fine_Factor_456,https://www.reddit.com/r/Python/comments/1odyrzh/jaspr_cli_generator_use_gemini_ai_to_build_jaspr/
1od9sxp,reddit,Heap/Priority Queue that supports removing arbitrary items and frequency tracking,"I created a Python heap implementation that supports:
- Removing any item (not just the root via pop)
- Tracking the frequency of items so that duplicates are handled efficiently

**Source**: [https://github.com/Ite-O/python-indexed-heap](https://github.com/Ite-O/python-indexed-heap)  
**PyPI**: [https://pypi.org/project/indexedheap/](https://pypi.org/project/indexedheap/)

## What My Project Does
`indexedheap` is a Python package that provides standard heap operations, insert (push), pop, and peek, along with additional features:

- Remove any arbitrary item efficiently.
- Track frequencies of items to handle duplicates.
- Insert or remove multiple occurrences in a single operation.
- Iterate over heap contents in sorted order without modifying the heap.

It is designed for scenarios requiring dynamic priority queues, where an item‚Äôs priority may change over time Common in task schedulers, caching systems or pathfinding algorithms.

## Target Audience
- Developers needing dynamic priority queues where priorities can increase or decrease.
- Users who want duplicate-aware heaps for frequency tracking.
- Engineers implementing task schedulers, caches, simulations or pathfinding algorithms in Python.

## Comparison
### Python‚Äôs built-in `heapq` vs `indexedheap`

| Operation | Description | `heapq` | `indexedheap` |
|------------|--------------|---------|----------------|
| `heappush(heap, item)` / `insert(value)` | Add an item/value to the heap | ‚úÖ `O(log N)` | ‚úÖ `O(log N)` / *(`O(1)` if item already exists and count is incremented)* |
| `heappop(heap)` / `pop()`| Remove and return the root item/value | ‚úÖ `O(log N)` | ‚úÖ `O(log N)` |
| `heap[0]` / `peek()` | Return root item/value without removing it | ‚úÖ Manual (`heap[0]`) | ‚úÖ `O(1)` |
| `remove(value)` | Remove any arbitrary value | ‚ùå Not supported | ‚úÖ `O(log(N))` for last occurence in heap, `O(1)` if only decrementing frequency |
| `heappushpop(heap, item)` | Push then pop in a single operation | ‚úÖ `O(log N)` | ‚ùå Not directly supported *(use `insert()` + `pop()`)* |
| `heapreplace(heap, item)` | Pop then push in a single operation | ‚úÖ `O(log N)` | ‚ùå Not directly supported *(use `pop()` + `insert()`)* |
| `count(value)` | Get frequency of a specific value | ‚ùå Not supported | ‚úÖ `O(1)` |
| `item in heap` / `value in heap` | Membership check | ‚ö†Ô∏è `O(N)` (linear scan) |‚úÖ `O(1)` |
| `len(heap)` | Number of elements | ‚úÖ `O(1)` | ‚úÖ `O(1)` |
| `to_sorted_list()` | Return sorted elements without modifying heap | ‚úÖ Requires creating a sorted copy of the heap `O(N log N)` | ‚úÖ `O(N log N)` |
| `iter(heap)` | Iterate in sorted order | ‚úÖ Requires creating a sorted copy of the heap and iterating over the copy `O(N log N)`) | ‚úÖ `O(N log N)` |
| `heapify(list)` / `MinHeap(list), MaxHeap(list)` | Convert list to valid heap | ‚úÖ `O(N)` | ‚úÖ `O(N)` |
| `heap1 == heap2` | Structural equality check | ‚úÖ `O(N)` |  ‚úÖ `O(N)` |
| `Frequency tracking` | Track frequency of items rather than store duplicates | ‚ùå Not supported | ‚úÖ Yes |
| `Multi-inserts/removals` | Insert/ remove multiples of an item in a single operation |‚ùå Not supported | ‚úÖ Yes (see insert/ remove rows for time complexity) |

---

 ## Installation

```bash
pip install indexedheap
```

## Feedback
If there is demand, I am considering adding support for `heappushpop` and `heapreplace` operations, similar to those in Python's `heapq` module.

Open to any feedback!


## Updates
 - Updated terminology in the comparison table to show both ""value"" and ""item"" in some rows. Since the terminology used in my package for the inserted object is ""value"", whereas the terminology used in heapq is ""item"".",3,6,2025-10-22 15:28:17,oetio,https://www.reddit.com/r/Python/comments/1od9sxp/heappriority_queue_that_supports_removing/
1occonw,reddit,T-Strings: Python's Fifth String Formatting Technique?,"Every time I've talked about Python 3.14's new t-strings online, many folks have been confused about how t-strings are different from f-strings, why t-strings are useful, and whether t-strings are a replacement for f-strings.

  
I published [a short article (and video) on Python 3.14's new t-strings](https://pym.dev/t-strings-in-python/) that's meant to explain this.

The TL;DR:

* Python has had 4 string formatting approaches before t-strings
* T-strings are different because they *don't actually return strings*
* T-strings are useful for library authors who need the disassembled parts of a string interpolation for the purpose of pre-processing interpolations
* T-strings definitely do not replace f-strings: keep using f-strings until specific libraries tell you to use a t-string with one or more of their utilities

Watch the video or read the article for a short demo and a library that uses them as well.

If you've been confusing about t-strings, I hope this explanation helps.",226,80,2025-10-21 14:16:36,treyhunner,https://www.reddit.com/r/Python/comments/1occonw/tstrings_pythons_fifth_string_formatting_technique/
1odwlx3,reddit,Besoin d'aide : r√©duire le temps d'ouverture d'un fichier Excel macro,"**r√©duire le temps d'ouverture √† l'aide d'un script python** : J'ai un script python qui doit ouvrir mon fichier Excel qui est remplit de macro et de feuille. le probl√®me est que mon script mets 13 min (temps chronom√©tr√©) pour seulement ouvrir le document pour ensuite modifier seulement 2 pages (= ajout automatique de donn√©e brut, prends maximum 1 min). J'aimerai r√©duire ce temps, mais je n'y arrive pas. pouvez-vous m'aider svp ?",0,5,2025-10-23 08:08:36,Pale-Celebration-562,https://www.reddit.com/r/Python/comments/1odwlx3/besoin_daide_r√©duire_le_temps_douverture_dun/
1odtzbc,reddit,Need urgent support with frappe python framework,"I‚Äôm currently working on integrating HDFC SmartPay into my ERPNext (Frappe) application and looking for someone familiar with payment gateway integrations in this framework. The task involves migrating from Razorpay/DeltaPay to HDFC SmartPay, handling API calls, payment link generation, webhook verification, and updating Payment Entry records in ERPNext. If you‚Äôve previously worked with Frappe‚Äôs Payment Gateway interface, Python REST integrations, or SmartPay APIs, your guidance or collaboration would be highly appreciated. Please reach out or DM me if you can help with best practices, authentication flow, or sandbox testing. Let‚Äôs connect and get this integration live smoothly and securely.
",0,6,2025-10-23 05:27:57,kirankikar3117,https://www.reddit.com/r/Python/comments/1odtzbc/need_urgent_support_with_frappe_python_framework/
1ocnrz9,reddit,FastAPI Preset - A beginner-friendly starter template for personal projects,"**Hey everyone!üëã** Wanted to share a FastAPI preset I created for my personal side projects.



Taking a break from my main project and decided to clean up and share a FastAPI preset I've been using for my personal side projects.

Just to be clear - I'm not a professional developer (but I try to find job now lol) and this isn't claiming to be the ""perfect"" architecture, but I've tried to make it as clear and simple as possible.

  
**What My Project Does**

This FastAPI Preset is a ready-to-use template that provides essential backend functionality out of the box. It includes:

* **JWT Authentication**¬†\- Complete user registration/login system with secure password hashing
* **Database Management**¬†\- Supports both SQLite (development) and PostgreSQL (production) with Alembic migrations
* **CRUD Operations**¬†\- User and item management with ownership-based permissions
* **Auto Documentation**¬†\- Automatic Swagger UI generation at¬†`/docs`
* **Structured Architecture**¬†\- Clean separation of concerns with DAO pattern and repository layer

The project is heavily documented with clear comments in every file, making it easy to understand and modify.  


**Target Audience**

This template is primarily designed for:

* **Beginners learning FastAPI**¬†\- The detailed comments and straightforward structure make it perfect for understanding how FastAPI works
* **Personal projects & prototypes**¬†\- Skip the boilerplate and start building features immediately
* **Students & hobbyists**¬†\- Great for educational purposes and side projects
* **Junior developers**¬†\- Provides a solid foundation without overwhelming complexity

**Note:**¬†This is a personal project template, not an enterprise-grade solution. It's perfect for learning and small-to-medium personal projects.  


**Quick Overview**

**Authentication:**

* JWT-based login/registration
* Secure password hashing with bcrypt
* Protected routes with user context

**Database:**

* SQLite (development) & PostgreSQL (production)
* Alembic migrations
* Async SQLAlchemy 2.0

**Setup is simple:**

1. Configure¬†`.env`¬†file
2. Set up database in¬†`database.py`
3. Configure Alembic in¬†`alembic.ini`

**Check it out:**¬†[https://github.com/Iwlj4s/FastAPIPreset](https://github.com/Iwlj4s/FastAPIPreset)

I built this for my personal projects and decided to share it while taking a break from my main work. Not claiming perfect architecture - just something that works and is easy to understand!

Would love feedback and suggestions!",22,9,2025-10-21 21:17:13,Oh_Dude_You_Clown,https://www.reddit.com/r/Python/comments/1ocnrz9/fastapi_preset_a_beginnerfriendly_starter/
1ocgcqh,reddit,New UV Gitlab Component,"I tried today to recreate a GitHub action which provides a python \`uv setup as a GitLab CI component.

# What this Component achieves

While the documentation of UV already explains how to implement `uv` inside of GitLab CI, it still fills the `.gitlab-ci.yml` quite a bit.

My Component tries to minimize that, by also providing a lot of customizations.

# Examples

The following example demonstrates how to implement the component on gitlab.com:

    include:
      - component: $CI_SERVER_FQDN/gitlab-uv-templates/python-uv-component/python-uv@1.0.0
    
    single-test:
      extends: .python-uv-setup
      stage: test
      script:
        - uv run python -c ""print('Hello UV!')""

The next examples demonstrate how to achieve parallel matrix execution:

    include:
      - component: $CI_SERVER_FQDN/gitlab-uv-templates/python-uv-component/python-uv@1.0.0
        inputs:
          python_version: $PYTHON_V
          uv_version: 0.9.4
          base_layer: bookworm-slim
    
    matrix-test:
      extends: .python-uv-setup
      stage: test
      parallel:
        matrix:
          - PYTHON_V: [""3.12"", ""3.11"", ""3.10""]
      script:
        - uv run python --version""
      variables:
        PYTHON_V: $PYTHON_V

# Comparison

I am not aware of any public component which achieves similar as demonstrated above.

I am quite happy about the current result, which I published via the GitLab CI/CD catalogue:

[https://gitlab.com/explore/catalog/gitlab-uv-templates/python-uv-component](https://gitlab.com/explore/catalog/gitlab-uv-templates/python-uv-component)",10,0,2025-10-21 16:41:07,MaKaNuReddit,https://www.reddit.com/r/Python/comments/1ocgcqh/new_uv_gitlab_component/
1od8vne,reddit,Converter PNG e JPG para WEBP com Python (Script Completo) 2025,"Converter imagens tradicionais como PNG e JPG para o formato WEBP de forma simples e pr√°tica usando Python!  
Neste tutorial, voc√™ vai ver o passo a passo utilizando as bibliotecas Pillow e Watchdog, automatizando o processo de convers√£o e deixando tudo mais produtivo.  
[https://youtu.be/9XeEWi39bFY](https://youtu.be/9XeEWi39bFY)",0,0,2025-10-22 14:52:18,Additional_Peak_3096,https://www.reddit.com/r/Python/comments/1od8vne/converter_png_e_jpg_para_webp_com_python_script/
1ocg3p5,reddit,Python Pest - A port of Rust's pest,"I recently released Python Pest, a port of the Rust pest parsing library.

# What My Project Does

Python‚ÄØPest is a declarative PEG parser generator for Python, ported from Rust's Pest. You write grammars instead of hand-coding parsing logic, and it builds parse trees automatically.

Define a grammar using Pest version 2 syntax, like this:

    jsonpath        = _{ SOI ~ jsonpath_query ~ EOI }
    jsonpath_query  = _{ root_identifier ~ segments }
    segments        = _{ (S ~ segment)* }
    root_identifier = _{ ""$"" }
    
    segment = _{
      | child_segment
      | descendant_segment
    }
    
    // snip

And traverse parse trees using [structural pattern matching](https://peps.python.org/pep-0636/), like this:

    def parse_segment(self, segment: Pair) -> Segment:
        match segment:
            case Pair(Rule.CHILD_SEGMENT, [inner]):
                return ChildSegment(segment, self.parse_segment_inner(inner))
            case Pair(Rule.DESCENDANT_SEGMENT, [inner]):
                return RecursiveDescentSegment(segment, self.parse_segment_inner(inner))
            case Pair(Rule.NAME_SEGMENT, [inner]) | Pair(Rule.INDEX_SEGMENT, [inner]):
                return ChildSegment(segment, [self.parse_selector(inner)])
            case _:
                raise JSONPathSyntaxError(""expected a segment"", segment)

See [docs](https://jg-rp.github.io/python-pest/), [GitHub](https://github.com/jg-rp/python-pest) and [PyPi](https://pypi.org/project/python-pest/) for a complete example.

# Target Audience

* Python developers who need to parse custom languages, data formats, or DSLs.
* Anyone interested in grammar-first design over hand-coded parsers.
* Developers curious about leveraging Python's match/case for tree-walking.

# Comparison

Parsimonious is another general purpose, pure Python parser package that reads parsing expression grammars. Python Pest differs in grammar syntax and subsequent tree traversal technique, preferring external iteration of parse trees instead of defining a visitor.

# Feedback

I'd appreciate any feedback, especially your thoughts on the trade-off between declarative grammars and performance in Python. Does the clarity and maintainability make up for slower execution compared to hand-tuned parsers?

GitHub: [https://github.com/jg-rp/python-pest](https://github.com/jg-rp/python-pest)",10,0,2025-10-21 16:31:24,Hefty-Pianist-1958,https://www.reddit.com/r/Python/comments/1ocg3p5/python_pest_a_port_of_rusts_pest/
1odf3fk,reddit,You need some advanced decorator patterns,"Most developers know the basics of decorators ‚Äî like `staticmethod` or `lru_cache`.  
But once you go beyond these, decorators can become *powerful building blocks* for clean, reusable, and elegant code.

In my latest [blog](https://medium.com/techtofreedom/10-advanced-python-decorator-patterns-for-clean-and-efficient-code-6d4ac670b26e?sk=23d2e31c38c382808b37753460e1371b), I explored **10 advanced decorator patterns** that go beyond the usual tutorials.

Here‚Äôs a quick summary of what‚Äôs inside:

# 1Ô∏è‚É£ TTL-Based Caching

Forget `lru_cache` that keeps results forever.  
A **time-to-live cache** decorator lets your cache entries expire after a set duration ‚Äî perfect for APIs and temporary data.

# 2Ô∏è‚É£ Retry on Failure

Wrap any unstable I/O call (like a flaky API) and let the decorator handle retries with delay logic automatically.

# 3Ô∏è‚É£ Execution Time Tracker

Measure function performance in milliseconds without modifying your core logic.

# 4Ô∏è‚É£ Role-Based Access Control

Add lightweight user permission checks (`@require_role(""admin"")`) without touching your business code.

# 5Ô∏è‚É£ Simple Logging Decorator

A minimal yet powerful pattern to track every call and return value ‚Äî no need for heavy logging frameworks.

# 6Ô∏è‚É£ Dependency Injection Decorator

Inject services (like `logger` or `validator`) into your functions globally ‚Äî no need for long argument lists.

# 7Ô∏è‚É£ Class-Wide Decorator

Decorate *all* methods of a class in one shot. Useful for timing, logging, or enforcing constraints project-wide.

# 8Ô∏è‚É£ Singleton Factory

Implement the singleton pattern with a one-liner decorator ‚Äî ideal for configurations or resource-heavy classes.

# 9Ô∏è‚É£ Rate Limiter

Throttle function calls to avoid API abuse or user spamming ‚Äî essential for stable production systems.

# üîü Context Management Decorator

Propagate request IDs, user contexts, or session data automatically across threads and async tasks.

üí¨ **Would love to know:**  
What‚Äôs your favorite use case for decorators in production code?",0,7,2025-10-22 18:42:12,wyhjsbyb,https://www.reddit.com/r/Python/comments/1odf3fk/you_need_some_advanced_decorator_patterns/
1ocdw2j,reddit,"GUI Toolkit Slint 1.14 released with universal transforms, asyncio and a unified text engine","We‚Äôre proud to release [\#Slint](https://chat.slint.dev/public/channels/docs-internal#) 1.14 üíô with universal transforms üåÄ, [\#Python](https://chat.slint.dev/public/channels/docs-internal#) asyncio üêç, and a unified text engine with fontique and parley üñãÔ∏è  
Read more about it in the blog here üëâ [https://slint.dev/blog/slint-1.14-released](https://slint.dev/blog/slint-1.14-released)    
  
",14,4,2025-10-21 15:05:25,slint-ui,https://www.reddit.com/r/Python/comments/1ocdw2j/gui_toolkit_slint_114_released_with_universal/
1ocib9b,reddit,I created a Riot API library for python,"Hello all,

I've been working on a super simple api wrapper for league of legends and would love some feedback.

[https://github.com/diodemusic/pyke](https://github.com/diodemusic/pyke)

Thanks :)",5,11,2025-10-21 17:55:00,Electrical-Lab-5952,https://www.reddit.com/r/Python/comments/1ocib9b/i_created_a_riot_api_library_for_python/
1ochltx,reddit,IDS Project in Python,"Hello everyone,



I recently uploaded a repository to GitHub where I created an IDS in Python. I would appreciate any feedback and suggestions for improvement.

[https://github.com/javisys/IDS-Python](https://github.com/javisys/IDS-Python)

Thank you very much, best regards.",2,1,2025-10-21 17:28:08,Javi_16018,https://www.reddit.com/r/Python/comments/1ochltx/ids_project_in_python/
1oborib,reddit,I built a Persistent KV Store in Pure Python,"Hi everyone!

 I'm a final year CS student and I've been reading about data storage and storage engines. This is a passion project that I've been working on for the past few months. It is a lightweight, persistent key-value storage engine in Python, built from scratch to understand and implement the Log-Structured Merge-tree (LSM-tree) architecture. The project, which is fully open-source, is explicitly optimized for write-heavy workloads. 



# Core Architecture:

The engine implements the three fundamental LSM components: the **Write Ahead Log (WAL)** for durability, an in-memory **Memtable** (using `SortedDict` for sorted writes), and immutable persistent **SSTables (Sorted String Tables)**.

Some features that I'm proud of:

* **Async Compaction**: Merging and compaction are handled by a **separate background worker thread**. The process itself takes a hybrid approach.
* **Client/Server Model**: The entire storage engine runs behind a **FastAPI server**. This allows multiple clients to connect via REST APIs or the included CLI tool.
* **Efficient Range Queries**: Added full support for range queries from `start_key` to `end_key`. This is achieved via a memory-efficient **k-way merge iterator** that combines results from the Memtable and all SSTables. The FastAPI server delivers the results using a `StreamingResponse` to prevent memory exhaustion for large result sets.
* **Bloom Filter**: Implemented a **Bloom Filter** for each SSTable to drastically reduce disk I/O by confirming that a key definitely does not exist before attempting a disk seek.
* **Binary Storage**: SSTables now use **Msgpack binary format** instead of JSON for smaller file sizes and reduced CPU load during serialization/deserialization.

My favourite part of the project is that I actually got to see a practical implementation of [Merge Sorted Arrays - GeeksforGeeks](https://www.geeksforgeeks.org/dsa/merge-k-sorted-arrays/). This is a pretty popular interview question and to see DSA being actually implemented is a crazy moment.

# Get Started

    pip install lsm_storage_engine_key_value_store

**Usage via CLI/Server:**

1. **Terminal 1 (Server):** `lsm-server`
2. **Terminal 2 (Client):** `lsm-cli` (Follow the CLI help for commands).

# Looking for Feedback

I'd love to hear your thoughts about this implementation and how I can make it better and what features I can add in later versions. Ideas and constructive criticism are always welcome. I'm also looking for contributors, if anyone is interested, please feel free to PM and we can discuss.

Repo link: [Shashank1985/storage-engine](https://github.com/Shashank1985/storage-engine)  
Thanks!!",103,14,2025-10-20 18:51:07,vollhard-natta,https://www.reddit.com/r/Python/comments/1oborib/i_built_a_persistent_kv_store_in_pure_python/
1ocd9i4,reddit,Advice for a Javascript/Typescript dev getting into the python ecosystem,"I'm a typescript dev that worked with frontend frameworks and nodejs for the last 10 years.

I just joined a startup and I'm required to build a serverless rest api with a python based stack.

The problem is that I have around a few days to figure out what's considered industry standard currently for the python ecosystem, and I can't afford to take any wrong turns here.

Of course the particularities of the project might affect your answer to some degree and I'm aware of that, but for the sake of trying to point me to the right direction let's try to make the best out of this.

I would make some typescript analogies in order for you to better understand what I'm aiming at with the stack.

1.ORM - drizzle (will use postgres)
2.Deployment - vercel/fallback to aws lambda
3.Package manager - pnpm
4.Types - typescript

The most uncertainities I have are about the platform where I have to deploy this(I really want something that is serverless and has good DX), vercel is such a no brainer rn for typescript projects, and I wonder if I have similar no brainers in python as well.

I have read about modal for deploying FastAPI, but again I'm not sure.

Really appreciate anyone taking time to answer this.
",2,11,2025-10-21 14:40:36,Lupexlol,https://www.reddit.com/r/Python/comments/1ocd9i4/advice_for_a_javascripttypescript_dev_getting/
1oc4122,reddit,"NGXSMK GameNet Optimizer: A Python-Powered, Privacy-First System and Network Optimization","I'm excited to share **NGXSMK GameNet Optimizer**, a comprehensive, open-source tool written primarily in **Python** designed to enhance system and network performance for gamers.

While the primary use case is gaming, the core is a set of Python modules for process management, network analysis, and system configuration, making it a great example of Python for low-level system interaction on Windows/Linux.

# What My Project Does

NGXSMK GameNet Optimizer is a utility suite that addresses common performance bottlenecks by providing:

* **Network Optimization:** Uses a Python module to analyze and test latency to various global servers (especially for games like League of Legends) and includes a traffic shaper to prioritize gaming packets (QoS).
* **System Performance:** Manages system resources by setting high process priority for games, cleaning up unnecessary background applications, and optimizing RAM usage in real-time.
* **System-Agnostic Core:** The majority of the logic is contained in cross-platform Python scripts (`main.py`, `modules/`), with platform-specific commands handled by batch/shell scripts (`run.bat`, `run.sh`).

Target Audience

This tool is primarily for **PC Gamers** who are performance-conscious and want a free, transparent alternative to commercial ""game booster"" software.

From a development perspective, the **Target Audience** also includes **Python developers** interested in:

* Python for **system programming** (e.g., process and memory management on Windows/Linux).
* Building **cross-platform utility applications** with a Python backend.

This is meant to be a **production-ready utility** that is robust and reliable for daily use.

# Comparison

NGXSMK GameNet Optimizer differentiates itself from existing optimization software in two key areas:

|| || |**Feature**|**NGXSMK GameNet Optimizer**|**Commercial Alternatives (e.g., Razer Cortex)| |Source Code**|**100% Open Source (MIT Licensed)|Closed Source| |Data/Telemetry**|**Privacy-First (No Telemetry, All Local)|Often collect usage data| |Customization**|Python-based modules are easily auditable and modifiable.|Configuration limited to the provided UI.| |**Core Function**|Focuses on Network Quality, FPS, and RAM.|Varies, often focuses heavily on simple process termination.|

You can find the full source code and installation steps on GitHub:

[**GitHub Repository: toozuuu/ngxsmk-gamenet-optimizer**](https://github.com/toozuuu/ngxsmk-gamenet-optimizer)

**Public Release:** [**https://github.com/toozuuu/ngxsmk-gamenet-optimizer/releases**](https://github.com/toozuuu/ngxsmk-gamenet-optimizer/releases)

Feel free to check out the code and provide any feedback, particularly on the Python modules for system-level operations!",8,3,2025-10-21 05:56:16,Forsaken_Lie_9989,https://www.reddit.com/r/Python/comments/1oc4122/ngxsmk_gamenet_optimizer_a_pythonpowered/
1obmzbm,reddit,func-to-web is now much better ‚Äì Thanks for the feedback!,"15 days ago I shared func-to-web here and got amazing feedback (150+ upvotes, thank you!). Since then, I've been working hard on the suggestions and added some major features.

**What it does (quick reminder):**
Turn any Python function into a web UI with zero boilerplate:

```python
from func_to_web import run

def divide(a: int, b: int):
    return a / b

run(divide)  # Web form at localhost:8000
```

**Major updates since v0.1:**

**Dynamic Lists** ‚Äì Add/remove items with advanced validation:
```python
def process_data(
    # Dynamic lists with add/remove buttons
    images: list[ImageFile],                      # Multiple file uploads
    
    # Dual validation: list size AND individual items
    scores: Annotated[
        list[Annotated[int, Field(ge=0, le=100)]], 
        Field(min_length=3, max_length=10)
    ],  # 3-10 items required, each 0-100
    
    # Optional fields with toggle switches
    notes: str | None = None,                     # Optional text
    tags: list[str] | None = None                 # Optional list
):
    return FileResponse(generate_pdf(), ""report.pdf"")  # Auto-download
```

**High-Performance File Handling** ‚Äì Optimized streaming for large files:
- **Upload**: Real-time progress bars, 8MB chunks, handles GB+ files
- **Download**: Return `FileResponse(data, filename)` for auto-downloads
- **Performance**: ~237 MB/s localhost, ~115 MB/s over Gigabit Ethernet
- **Memory efficient**: Constant usage regardless of file size
- **Any format**: PDF, Excel, ZIP, images, binary data

**Optional Fields** ‚Äì `Type | None` creates toggle switches:
- Fields with defaults start enabled, without defaults start disabled
- Explicit control: `Type | OptionalEnabled/OptionalDisabled`
- Works with all types, constraints, and lists

**Dynamic Dropdowns** ‚Äì Runtime-generated options:
```python
def get_themes(): return fetch_from_database()

def configure(theme: Literal[get_themes]): pass  # Fresh options each request
```

**Rich Output Support**:
- **PIL Images**: Auto-displayed in browser
- **Matplotlib plots**: Rendered as PNG
- **File downloads**: Single or multiple files with streaming
- **JSON/text**: Formatted with copy-to-clipboard

**UX Improvements**:
- Dark mode with theme persistence
- Keyboard shortcuts (Ctrl+Enter to submit)
- Auto-focus first field
- Toast notifications
- Upload progress with speed indicators

**Current stats:**
- 180+ GitHub stars (The chinese community is sharing it too!)
- 454 unit tests
- Published on PyPI: `pip install func-to-web`
- 20+ runnable examples
- Used daily for internal tools at multiple companies

**Other improvements:**
- **Modular architecture**: Code separated by responsibilities (analysis, validation, form building...)
- **Comprehensive documentation**: Every function and class documented
- **Detailed changelog**: Track all improvements and breaking changes

I've tried to make this as professional and production-ready as possible while keeping the simple API.

Still focused on internal tools and rapid prototyping, not replacing proper web frameworks.

GitHub: https://github.com/offerrall/FuncToWeb

The community feedback really shaped these improvements. Thank you again! Keep the suggestions coming.",22,0,2025-10-20 17:27:41,drboom9,https://www.reddit.com/r/Python/comments/1obmzbm/functoweb_is_now_much_better_thanks_for_the/
1ocucv4,reddit,Is my code horrible,"    import random
    
    
    wordle_list = [
    ¬† ¬† ""APPLE"", ""BRAVE"", ""CRANE"", ""DREAM"", ""FLUTE"", ""GRACE"", ""HOUSE"", ""JUMPS"",
    ¬† ¬† ""KNIFE"", ""LIGHT"", ""MOUSE"", ""NIGHT"", ""OCEAN"", ""PLANT"", ""QUICK"", ""ROBIN"",
    ¬† ¬† ""SHINE"", ""TIGER"", ""UNITY"", ""VIVID"", ""WORST"", ""YOUTH"", ""ZEBRA"", ""ALARM"",
    ¬† ¬† ""BREAD"", ""CLOUD"", ""DRIVE"", ""FROST"", ""GLASS"", ""HEART"", ""INDEX"", ""JUICE"",
    ¬† ¬† ""KNOCK"", ""LEMON"", ""MAGIC"", ""NOBLE"", ""OPERA"", ""PEACH"", ""QUEST"", ""RIVER"",
    ¬† ¬† ""SHEET"", ""TREND"", ""UNDER"", ""VIRUS"", ""WAGON"", ""YEAST"", ""ZONAL"", ""ANGEL"",
    ¬† ¬† ""BASIC"", ""CHAIR"", ""DELTA"", ""FANCY"", ""GIANT"", ""HONEY"", ""IMAGE"", ""JOLLY"",
    ¬† ¬† ""KINGS"", ""LEAFY"", ""MIRTH"", ""NOVEL"", ""ORBIT"", ""PRIZE"", ""QUILT"", ""RANGE"",
    ¬† ¬† ""SUGAR"", ""TRAIL"", ""URBAN"", ""VOTER"", ""WORRY"", ""YACHT"", ""ZESTY"", ""ADULT"",
    ¬† ¬† ""BLEND"", ""CROWN"", ""DEPTH"", ""FAITH"", ""GRAND"", ""HUMAN"", ""INPUT"", ""JOKER"",
    ¬† ¬† ""KNEEL"", ""LUNCH"", ""MOTOR"", ""NURSE"", ""OFFER"", ""PILOT"", ""QUIET"", ""REACH"",
    ¬† ¬† ""SHARE"", ""THINK"", ""UPPER"", ""VOICE"", ""WASTE"", ""YIELD"", ""ZONED"", ""ABOVE"",
    ¬† ¬† ""BIRTH"", ""CABLE"", ""DEMON"", ""FLOOD""
    ]
    total_words = len(wordle_list) - 1
    score = 0
    number = random.randint(0, total_words)
    choice = wordle_list[number]
    
    
    for i in range(10):
    ¬† ¬† number = random.randint(0, total_words)
    ¬† ¬† choice = wordle_list[number]
    ¬† ¬† for i in range(10):
    ¬† ¬† ¬†# Automatically puta the input in uppercase
    ¬† ¬† ¬† ¬† raw_guess = input(""guess the word: "")
    ¬† ¬† ¬† ¬† guess = raw_guess.upper()
    ¬† ¬† ¬† ¬† print(""Your guess is"", guess)
    
    
    # Checks if the guess is five letters
    ¬† ¬† ¬† ¬† if len(guess) == 5:
    ¬† ¬† ¬† ¬† ¬† ¬† if str(choice) == str(guess):
    ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† print(guess[0], ""is correct"")
    ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† print(guess[1], ""is correct"")
    ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† print(guess[2], ""is correct"")
    ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† print(guess[3], ""is correct"")
    ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† print(guess[4], ""is correct"")
    ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† score += 1
    ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† print(""Current Score is "", score)
    ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† break
    
    
    # Wanted to make it analyse each letter and give feedback
    # I am convinced that I can shorten this part
    # Also wanted to make it so that it tells you if the letter is elsewhere
    ¬† ¬† ¬† ¬† ¬† ¬† else:
    ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† if str(choice[0]) == str(guess[0]):
    ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† print(guess[0], ""is correct"")
    ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† else:
    ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† print(guess[0], ""is incorrect"")
    
    
    ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† if str(choice[1]) == str(guess[1]):
    ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† print(guess[1], ""is correct"")
    ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† else:
    ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† print(guess[1], ""is incorrect"")
    
    
    ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† if str(choice[2]) == str(guess[2]):
    ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† print(guess[2], ""is correct"")
    ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† else:
    ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† print(guess[2], ""is incorrect"")
    
    
    ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† if str(choice[3]) == str(guess[3]):
    ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† print(guess[3], ""is correct"")
    ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† else:
    ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† print(guess[3], ""is incorrect"")
    
    
    ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† if str(choice[4]) == str(guess[4]):
    ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† print(guess[4], ""is correct"")
    ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† else:
    ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† print(guess[4], ""is incorrect"")
    ¬† ¬† ¬† ¬† else:
    ¬† ¬† ¬† ¬† ¬† ¬† print(""Word needs to be 5 letters"")
    print(""Final Score is"", score, ""Over 10"")",0,22,2025-10-22 01:51:59,TheDrayn0001,https://www.reddit.com/r/Python/comments/1ocucv4/is_my_code_horrible/
1ob3na1,reddit,I built a tool that tells you how hard a website is to scrape,"# UPDATE:

Website is now live!

Try it now: [https://www.caniscrape.org](https://www.caniscrape.org/)

\- No installation required

\- Instant analysis

\- Same comprehensive checks as the CLI

NOTE:  
I haven't added the flag capabilities yet so its just the default scan. Its also still one link at a time, so all the great ideas I've received for the website will come soon (I'm gonna keep working on it). It'll take about 1-3 days but ill make it a lot better for the V1.0.0 release.

CLI still available on GitHub for those who prefer it.



Hi everyone,  
I made a Python package called **caniscrape** that analyzes any website's anti-bot protections before you start scraping.

It tells you what you're up against (Cloudflare, rate limits, JavaScript rendering, CAPTCHAs, TLS fingerprinting, honeypots) and gives you a difficulty score + specific recommendations.

# What My Project Does

caniscrape checks a website for common anti-bot mechanisms and reports:

* A difficulty score (0‚Äì10)
* Which protections are active (e.g., Cloudflare, Akamai, hCaptcha, etc.)
* What tools you‚Äôll likely need (headless browsers, proxies, CAPTCHA solvers, etc.)
* Whether using a scraping API might be better

This helps you decide the right scraping approach before you waste time building a bot that keeps getting blocked.

# Target Audience

* Web scrapers, data engineers, and researchers who deal with protected or dynamic websites
* Developers who want to test bot-detection systems or analyze site defenses
* Hobbyists learning about anti-bot tech and detection methods

It‚Äôs not a bypassing or cracking tool ‚Äî it‚Äôs for diagnostics and awareness.

# Comparison

Unlike tools like WAFW00F or WhatWaf, which only detect web application firewalls,  
caniscrape runs multi-layered tests:

* Simulates browser and bot requests (via Playwright)
* Detects rate limits, JavaScript challenges, and honeypot traps
* Scores site difficulty based on detection layers
* Suggests scraping strategies or alternative services

So it‚Äôs more of a pre-scrape analysis toolkit, not just a WAF detector.

# Installation

    pip install caniscrape

Quick setup (required):

    playwright install chromium  # Download browser
    pipx install wafw00f         # WAF detection

# Example Usage

    caniscrape https://example.com

Output includes:

* Difficulty score (0‚Äì10)
* Active protections
* Recommended tools/approach

# ADVICE:

Results can vary between runs because bot protections adapt dynamically.  
Some heavy-protection sites (like Amazon) may produce these varied results. Of course, this will improve over time, but running the command multiple times can mitigate this.

# GitHub

[https://github.com/ZA1815/caniscrape](https://github.com/ZA1815/caniscrape)",528,51,2025-10-19 23:50:55,CrroakTTV,https://www.reddit.com/r/Python/comments/1ob3na1/i_built_a_tool_that_tells_you_how_hard_a_website/
1obrz11,reddit,Assembly-to-Minecraft-Command-Block-Compiler (Python) ‚Äî updated ‚Äî testers & contributors wanted,"¬†I updated a small Python compiler that converts an assembly-like language into Minecraft command-block command sequences. Looking for testers, feedback, and contributors. Repo:¬†[https://github.com/Bowser04/Assembly-to-Minecraft-Command-Block-Compiler](https://github.com/Bowser04/Assembly-to-Minecraft-Command-Block-Compiler)

What My Project Does:

* Parses a tiny assembly-style language (labels, arithmetic, branches, simple I/O) and emits Minecraft command sequences tailored for command blocks.
* Produces low-level, inspectable output so you can see how program logic maps to in-game command-block logic.
* Implemented in Python for readability and easy contribution.

Target Audience:

* Minecraft command-block creators who want to run low-level programs without mods.
* Hobbyist compiler writers and learners looking for a compact Python codegen example.
* Contributors interested in parsing, code generation, testing strategies, or command optimization.
* This is an educational/hobby tool for small demos and experiments ‚Äî not a production compiler for large-scale programs.

Comparison (how it differs from alternatives):

* Assembly-focused: unlike high-level language‚ÜíMinecraft tools, it targets an assembly-like input so outputs are low-level and easy to debug in command blocks.
* Python-first and lightweight: prioritizes clarity and contributor-friendliness over performance.
* Command-block oriented: designed to work with vanilla in-game command blocks (does not target datapacks or mods).

How to help:

* Test: run examples, try outputs in a world, and note Minecraft version and exact steps when something fails.
* Report: open issues with minimal reproduction files and steps.
* Contribute: PRs welcome for bug fixes, examples, optimizations, docs, or tests ‚Äî look for good-first-issue.",9,2,2025-10-20 20:57:47,bowser04410,https://www.reddit.com/r/Python/comments/1obrz11/assemblytominecraftcommandblockcompiler_python/
1obi9f6,reddit,Access computed Excel values made easy using calc-workbook library,"`calc-workbook` is an easy-to-use Python library that lets you access *computed Excel values* directly from Python. It loads Excel files, evaluates all formulas using the `formulas` engine, and provides a clean, minimal API to read the computed results from each sheet ‚Äî no Excel installation required.

# What My Project Does

This project solves a common frustration when working with Excel files in Python: most libraries can read or write workbooks, but they can‚Äôt compute formulas. `calc-workbook` bridges that gap. You load an Excel file, it computes all the formulas using the `formulas` package, and you can instantly access the computed cell values ‚Äî just like Excel would show them. Everything runs natively in Python, making it platform-independent and ideal for Linux users who want full Excel compatibility without Excel itself.

# Target Audience

For Python developers, data analysts, or automation engineers who work with Excel files and want to access real formula results (not just static values) without relying on Excel or heavy dependencies.

# Comparison

* **openpyxl** and **pandas** can read and write Excel files but do not calculate formulas.
* **xlwings** requires Excel to compute formulas and is Windows/macOS only.
* **calc-workbook** computes formulas natively in Python using the `formulas` engine and gives you the results in one simple call.

# Installation

    pip install calc-workbook

# Example

    from calc_workbook import CalcWorkbook
    
    wb = CalcWorkbook.load(""example.xlsx"")
    print(wb.get_sheet_names())           # ['sheet1']
    
    sheet = wb.get_sheet(""sheet1"")        # or get_sheet() to get the first sheet
    print(""A1:"", sheet.cell(""A1""))        # 10
    print(""A2:"", sheet.cell(""A2""))        # 20
    print(""A3:"", sheet.cell(""A3""))        # 200

# Example Excel file:

|**A**|**B**|
|:-|:-|
|**1**|10|
|**2**|20|
|**3**|`=A1+A2`|

# GitHub

[https://github.com/a-bentofreire/calc-workbook](https://github.com/a-bentofreire/calc-workbook)",26,10,2025-10-20 13:55:00,abentofreire,https://www.reddit.com/r/Python/comments/1obi9f6/access_computed_excel_values_made_easy_using/
1obqtmz,reddit,Has any library emerged as the replacement for Poliastro?,"I'm trying to develop some code that works with orbital dynamics, and it looks like the go-to is somehow still Poliastro, and at this point it's a no-go. Even if you restrict yourself to 3.11 you *also* have to go back to pip <24.1 because of how some package requirements are written. I've looked around and can't find any other orbital dynamics libraries that are more than personal projects. Is the field just dead in python?",9,5,2025-10-20 20:15:23,KerPop42,https://www.reddit.com/r/Python/comments/1obqtmz/has_any_library_emerged_as_the_replacement_for/
1objndl,reddit,temporals - periods support for the core datetime library,"Hi all!


Nearly a year ago (apparently, just a day shy of a whole year!), I shared the first iteration of my Python library with you all; now, a year later, I'm hoping to bring you an improved version of it. :)


# What Does It Do


**temporals** aims to provide a minimalistic utility layer on top of the Python standard library's `datetime` package in regards to working with `time`, `date` and `datetime` periods.


The library offers four different flavours of periods:

* `TimePeriod`
* `DatePeriod`
* `WallClockPeriod`
* `AbsolutePeriod`


The separation between a wall clock and an absolute period replaces the original DatetimePeriod with more concrete types as well as support for DST time changes and/or leap years. 


This iteration also comes with more interfaces which should allow you to further extend the library to match your own needs, in case the current implementations aren't satisfactory.


# Examples, Documentation, Links


My original post contains a bit more information on available methods as well as comparison to other libraries, I wanted to save you from being blasted with a wall of text, but if you're curious, feel free to have a look here - https://old.reddit.com/r/Python/comments/1g8nu9s/temporals_a_time_date_and_datetime_periods_support/


In-depth documentation and examples is available on the Wiki page in Github - https://github.com/dimitarOnGithub/temporals/wiki


PyPi page - https://pypi.org/project/temporals/


Source Code - https://github.com/dimitarOnGithub/temporals



# Notes


* Any feedback and criticism is always more than welcome and will be greatly appreciated! Thank you for taking the time and have a fantastic day!",12,4,2025-10-20 14:56:56,winterchillz,https://www.reddit.com/r/Python/comments/1objndl/temporals_periods_support_for_the_core_datetime/
1obprx2,reddit,Building an open-source observability tool for multi-agent systems - looking for feedback,"I've been building multi-agent workflows with LangChain and got tired of debugging them with scattered console.log statements, so I built an open-source observability tool.   
  
**What it does**:  
\- Tracks information flow between agents   
\- Shows which tools are being called with what parameters   
\- Monitors how prompt changes affect agent behavior   
\- Works in both development and production   
  
**The gap I'm trying to fill**: Existing tools (LangSmith, LangFuse, AgentOps) are great at LLM observability (tokens, costs, latency), but I feel like they don't help much with multi-agent coordination. They show you **what** happened but not **why** agents failed to coordinate.   
  
  
**Looking for feedback**:  
1. Have you built multi-agent systems? What do you use for debugging?   
2. Does this solve a real problem or am I overengineering?   
3. What features would actually make this useful for you? Still early days, but happy to share the repo if folks are interested.",4,9,2025-10-20 19:35:45,Standard_Career_8603,https://www.reddit.com/r/Python/comments/1obprx2/building_an_opensource_observability_tool_for/
1obxzya,reddit,Tuesday Daily Thread: Advanced questions,"# Weekly Wednesday Thread: Advanced Questions üêç

Dive deep into Python with our Advanced Questions thread! This space is reserved for questions about more advanced Python topics, frameworks, and best practices.

## How it Works:

1. **Ask Away**: Post your advanced Python questions here.
2. **Expert Insights**: Get answers from experienced developers.
3. **Resource Pool**: Share or discover tutorials, articles, and tips.

## Guidelines:

* This thread is for **advanced questions only**. Beginner questions are welcome in our [Daily Beginner Thread](#daily-beginner-thread-link) every Thursday.
* Questions that are not advanced may be removed and redirected to the appropriate thread.

## Recommended Resources:

* If you don't receive a response, consider exploring r/LearnPython or join the [Python Discord Server](https://discord.gg/python) for quicker assistance.

## Example Questions:

1. **How can you implement a custom memory allocator in Python?**
2. **What are the best practices for optimizing Cython code for heavy numerical computations?**
3. **How do you set up a multi-threaded architecture using Python's Global Interpreter Lock (GIL)?**
4. **Can you explain the intricacies of metaclasses and how they influence object-oriented design in Python?**
5. **How would you go about implementing a distributed task queue using Celery and RabbitMQ?**
6. **What are some advanced use-cases for Python's decorators?**
7. **How can you achieve real-time data streaming in Python with WebSockets?**
8. **What are the performance implications of using native Python data structures vs NumPy arrays for large-scale data?**
9. **Best practices for securing a Flask (or similar) REST API with OAuth 2.0?**
10. **What are the best practices for using Python in a microservices architecture? (..and more generally, should I even use microservices?)**

Let's deepen our Python knowledge together. Happy coding! üåü",1,1,2025-10-21 01:00:30,AutoModerator,https://www.reddit.com/r/Python/comments/1obxzya/tuesday_daily_thread_advanced_questions/
1occzel,reddit,NamedTuples are a PITA,"I've also created a thread for this on Python forum - [see here](https://discuss.python.org/t/allow-to-pass-defaults-when-defining-namedtuple-dynamically/104484).

TL;DR - When defining NamedTuples dynamically, there should be a single interface that'd allow to pass all 3 - field names, annotations, and defaults.

I needed to convert to convert normal Python classes into NamedTuples. (see final implementation [here](https://github.com/django-components/django-components/pull/1466#discussion_r2447261223))

‚ùå For normal classes, you could simply make a new class that subclasses from both.

    class X(MyClass, NamedTuple):
        pass

But NamedTuples don't support that.

‚ùå And you can't further subclass the subclass of `NamedTuples`:

    class Another(NamedTuple):
        x: int = 1
    
    class X(Another):
        y: str

‚ùå When using `typing.NamedTuple` as a function, you can't pass in defaults:

    my_class = typing.NamedTuple(""MyClass"", [(""x"", int), (""y"", str)])

I tried setting the defaults ([`_field_defaults`](https://docs.python.org/3/library/collections.html#collections.somenamedtuple._field_defaults)) manually, but Python wasn't picking that up.

‚ùå One option was to define the NamedTuple with a class syntax as a string, and then evaluate that string. But that had 2 problems - 1) security risk, and 2) we'd need to import all the types used in annotations:

    my_cls_str = """"""
    from typing import NamedTuple
    
    from path.to.custom import CustomClass
    
    class MyClass(NamedTuple):
        x: int
        y: str
        z: CustomClass
    """"""
    my_cls = eval(my_cls_str, {}, {})

‚úÖ Lastly I managed to get it working using `collections.namedtuple`. This function doesn't define the field annotations, but it is able to handle defaults. Just one annoying thing was how it sets defaults the same way as Python functions do - it assigns the defaults from the back of the function signature.

So if I have NamedTuple with 3 fields - `x`, `y`, and `z`, and I set defaults to `[""hello"", 123]`:

    my_cls = namedtuple(""MyClass"", [""x"", ""y"", ""z""], defaults=[""hello"", 123])

then this is the same as writing:

    class MyClass(NamedTuple):
        x: int
        y: str = ""hello""
        z: int = 123

One caveat is that `collections.namedtuple()` doesn't set the annotations, so I had also set `__annotations__` at the end.

One thing I didn't know - when defining `NamedTuple`, the fields it recognizes are only those that are annotated. If a field is NOT annotated, it's treated as a CLASS VARIABLE:

    class MyClass(NamedTuple):
        x: int            # Required field
        y: str = ""hello""  # Optional field (with default)
        z = 123           # Class var!

So at the end I also assigned the class variables to the new namedtuple class.

Surprisingly LLMs were really bad at solving this, so I'm hoping this comment gets into the next training set.",0,19,2025-10-21 14:28:58,JuroOravec,https://www.reddit.com/r/Python/comments/1occzel/namedtuples_are_a_pita/
1oc9sm4,reddit,Sprechstimme python library,Hey guys! I just made a library called sprechstimme which everyone should definitely download. **no pressure**. You can make synthesisers and music so you could just try‚Ä¶ ,0,1,2025-10-21 11:56:03,Alive-Call-3453,https://www.reddit.com/r/Python/comments/1oc9sm4/sprechstimme_python_library/
1obktic,reddit,Anything funny and engaging for python devs,"Hi everyone. 

So every day I have to travel around 4 hours (2-2) to reach my job. 

In that spare time I get really bored. I waste so much crucial time on YouTube music and other non sensical social media stuff.

I have tried watching YouTube tutorial, but the only problem is that they are long and thus get boring. One advice that my boss had once given me when I was recording video tutorial for our staff ( our staff is not that tech friendly so we have to actually teach them about excel, google workspace and other kind of very common stuff) is that it shouldn't be longer then 2 minutes, else it start to become boring. 

As I travel through underground metro rail, and internet is not stable there. 

I had heard about devdocs and it is good. 

So, is there any such android app for developers which is engaging and fun. 

Engaging podcast
Interesting facts
Small tutorials 
Quizzes
Docs to read ( with big fonts ) 

I love solving those leetcode problems but the thing is they don't have any mobile app. 

It should have the facility to save offline content. 

Till now this is what I have tried:
1. YouTube ( long tutorials become boring ) 
2. Reddit ( doesn't work without internet, less content) 
3. Discord ( doesn't work without internet) 
4. PDFs ( small fonts not that mobile friendly, I have to scroll both horizontal and vertical) 

If I am Posting it in wrong forum then kindly let me know I will delete it. 

I and open to any sort of suggestions/ feedback / criticism. 

Sorry if I have asked too much. 

Right now I work as a django dev",6,5,2025-10-20 15:46:45,virtualshivam,https://www.reddit.com/r/Python/comments/1obktic/anything_funny_and_engaging_for_python_devs/
1oc59ki,reddit,We are automating the mobile apps via our agent,"# What My Project Does

My project is called Droidrun, it is first native mobile AI agent. It can:

* Automates Android apps through real user interactions (click, swipe, type, scroll)
* Connects to real Android devices or emulators via ADB
* Accepts natural language or JSON instructions
* Runs via CLI or Python API

You can automate workflows like:

* Open WhatsApp ‚Üí tap Login ‚Üí enter number ‚Üí check for code
* Scroll through a feed and capture screenshots
* Simulate checkout flows in test builds

# Target Audience

This will help developers, QA engineers to test apps automatically. 

# Comparison

We live our digital lives through mobile apps, yet for AI and automation, this vibrant ecosystem often remains a locked garden. Unlike the relatively open structure of the web, comprehensive APIs for mobile apps are rare, leaving countless essential workflows and valuable data trapped behind native user interfaces designed solely for human taps and swipes.

# Open Source & Free Credits

Droidrun is open source and we are continously improving its speed and functionality. Make sure to can try it, test it, and modify it.   
Here is more about Droidrun: [https://www.droidrun.ai/](https://www.droidrun.ai/)  
Github: [https://github.com/droidrun/droidrun](https://github.com/droidrun/droidrun)  
Discord: [https://discord.com/invite/ZZbKEZZkwK](https://discord.com/invite/ZZbKEZZkwK)

DM me if you have any questions, I would be happy to answer.",0,0,2025-10-21 07:09:02,ya_Priya,https://www.reddit.com/r/Python/comments/1oc59ki/we_are_automating_the_mobile_apps_via_our_agent/
1ob2vp3,reddit,friendly PyTorch book ‚Äî here‚Äôs what I learned about explaining machine learning simply üëá,"Hey everyone,

I recently published Tabular Machine Learning with PyTorch: Made Easy for Beginners, and while writing it, I realized something interesting ‚Äî most people don‚Äôt struggle with code, they struggle with understanding what the model is doing underneath.

So in the book, I focused on:
	‚Ä¢	Making tabular ML (the kind that powers loan approvals, churn prediction, etc.) actually intuitive.
	‚Ä¢	Showing how neural networks think step-by-step ‚Äî from raw data to predictions.
	‚Ä¢	Explaining why we normalize, what layers really do, and how to debug small models before touching big ones.

It‚Äôs not a dense textbook ‚Äî more like a hands-on guide for people who want to ‚Äúget it‚Äù before moving to CNNs or Transformers.

I‚Äôd love your feedback or suggestions:
üëâ What part of ML do you wish was explained more clearly?

If anyone‚Äôs curious, here‚Äôs the Amazon link: https://www.amazon.com/dp/B0FV76J3BZ

Thanks for reading ‚Äî I‚Äôm here to learn and discuss with anyone building their ML foundation too.

#MachineLearning #PyTorch #DeepLearning
",38,8,2025-10-19 23:17:08,disciplemarc,https://www.reddit.com/r/Python/comments/1ob2vp3/friendly_pytorch_book_heres_what_i_learned_about/
1obo3rg,reddit,Kryypto an open source python text editor.,"Kryypto A lightweight, fully keyboard-supported python text editor with deep customization and GitHub integration.

* Lightweight ‚Äì minimal overhead
* Full Keyboard Support ‚Äì no need for the mouse, every feature is accessible via hotkeys
* Discord presence
* Live MarkDown Preview
* Session Restore
* Custom Styling
   * `config\configuration.cfg` for editor settings
   * CSS for theme and style customization
* Editing Tools
   * Find text in file
   * Jump to line
   * Adjustable cursor (color & width)
   * Configurable animations (types & duration)
* Git & GitHub Integration
   * View total commits
   * See last commit message & date
   * Track file changes directly inside the editor
* Productivity Features
   * Autocompleter
   * Builtin Terminal
   * Docstring panel (hover to see function/class docstring)
   * Tab-based file switching
   * Bookmarking lines
   * Custom title bar
* Syntax Highlighting for
   * Python
   * CSS
   * JSON
   * Config files
   * Markdown

Target Audience

* Developers who prefer keyboard-driven workflows (no mouse required)
* Users looking for a lightweight alternative to heavier IDEs
* People who want to customize their editor with CSS and configuration settings
* Anyone experimenting with Python-based editors or open-source text editing tools

# Comparison:

* Lightweight ‚Äì minimal overhead, focused on speed
* Highly customizable ‚Äì styling via CSS and config files
* Keyboard-centric ‚Äì designed to be fully usable without a mouse

  
github repo: [https://github.com/NaturalCapsule/Kryypto](https://github.com/NaturalCapsule/Kryypto)

  
website: [https://naturalcapsule.github.io/Kryypto/](https://naturalcapsule.github.io/Kryypto/)",2,7,2025-10-20 18:21:30,SxxVe,https://www.reddit.com/r/Python/comments/1obo3rg/kryypto_an_open_source_python_text_editor/
1ob3xmq,reddit,Production-ready FastAPI template with CI/CD and Docker releases,"**What My Project Does**

This is a starter template for FastAPI applications that comes with production-friendly defaults:

Continuous Integration on every push (tests, linting, CodeQL security scan)

Automated releases on tag push: builds a Docker image, runs a health check, pushes to GHCR, and creates a GitHub Release

Dependabot integration for dependency upkeep

Optional features (Postgres integration tests and Sentry release) that activate when you add secrets, but the template works fine with no secrets out of the box

**Target Audience**

This is meant for developers who want to start a new FastAPI service with deployment and release hygiene already set up. It works both for learners (since it runs green with no configuration) and for teams who want a reproducible release pipeline from day one.

**Comparison**

There are cookiecutter templates and boilerplates for FastAPI, but most focus on project structure or async patterns. This one focuses on shipping: tag-driven releases, GHCR publishing, CI/CD pipelines, and optional integrations. It‚Äôs not trying to reinvent frameworks, just remove the boilerplate around DevOps setup.

Repo: [https://github.com/ArmanShirzad/fastapi-production-template](https://github.com/ArmanShirzad/fastapi-production-template)",24,3,2025-10-20 00:03:43,Armanshirzad,https://www.reddit.com/r/Python/comments/1ob3xmq/productionready_fastapi_template_with_cicd_and/
1ob0jk7,reddit,üß™ Promethium ‚Äî The Offline Chemistry Toolkit for Python,"# What My Project Does

**Promethium** is your go-to **periodic table and chemistry toolkit for Python,** designed for scientists, students, and developers who want powerful chemistry features without external dependencies.

It works **100% offline**, with all elements and reaction data bundled inside the library, making it fast, reliable, and perfect for classrooms, research, or automation scripts where internet access isn‚Äôt guaranteed.

# Target Audience

Promethium is ideal for:

* Chemistry students and educators
* Scientific software developers
* Automation and data science enthusiasts who need chemistry computation in Python

# Comparison¬†

While **Mendeleev** is a great reference library for elemental data, **Promethium** takes it further by offering **offline data access** *and* a **built-in chemical reaction balancer**, all wrapped in a more lightweight, performance-oriented design. Mendeleev still works just fine for elemental purposes.

# GitHub

[https://github.com/rohankishore/Promethium](https://github.com/rohankishore/Promethium)",30,3,2025-10-19 21:42:02,Specialist-Arachnid6,https://www.reddit.com/r/Python/comments/1ob0jk7/promethium_the_offline_chemistry_toolkit_for/
1ob573h,reddit,Monday Daily Thread: Project ideas!,"# Weekly Thread: Project Ideas üí°

Welcome to our weekly Project Ideas thread! Whether you're a newbie looking for a first project or an expert seeking a new challenge, this is the place for you.

## How it Works:

1. **Suggest a Project**: Comment your project idea‚Äîbe it beginner-friendly or advanced.
2. **Build & Share**: If you complete a project, reply to the original comment, share your experience, and attach your source code.
3. **Explore**: Looking for ideas? Check out Al Sweigart's [""The Big Book of Small Python Projects""](https://www.amazon.com/Big-Book-Small-Python-Programming/dp/1718501242) for inspiration.

## Guidelines:

* Clearly state the difficulty level.
* Provide a brief description and, if possible, outline the tech stack.
* Feel free to link to tutorials or resources that might help.

# Example Submissions:

## Project Idea: Chatbot

**Difficulty**: Intermediate

**Tech Stack**: Python, NLP, Flask/FastAPI/Litestar 

**Description**: Create a chatbot that can answer FAQs for a website.

**Resources**: [Building a Chatbot with Python](https://www.youtube.com/watch?v=a37BL0stIuM)

# Project Idea: Weather Dashboard

**Difficulty**: Beginner

**Tech Stack**: HTML, CSS, JavaScript, API

**Description**: Build a dashboard that displays real-time weather information using a weather API.

**Resources**: [Weather API Tutorial](https://www.youtube.com/watch?v=9P5MY_2i7K8)

## Project Idea: File Organizer

**Difficulty**: Beginner

**Tech Stack**: Python, File I/O

**Description**: Create a script that organizes files in a directory into sub-folders based on file type.

**Resources**: [Automate the Boring Stuff: Organizing Files](https://automatetheboringstuff.com/2e/chapter9/)

Let's help each other grow. Happy coding! üåü",12,1,2025-10-20 01:00:32,AutoModerator,https://www.reddit.com/r/Python/comments/1ob573h/monday_daily_thread_project_ideas/
1obzlam,reddit,About Me (and the order i code in),"hi, i recently started python, and i am really happy, i enjoy it very much and it has become a hobby,

the order i code in: 1: imports 2 variables: 3: normal code (print, lists etc) 4: if/else statements. (i put notes at the tops of each section.)",0,8,2025-10-21 02:13:32,Consistent_Hall631,https://www.reddit.com/r/Python/comments/1obzlam/about_me_and_the_order_i_code_in/
1obgm3n,reddit,Up-to-date syntax highlighting for Vim?,"All the Python syntax plugins I can find were abandoned 4+ years ago.

Last commit age for a handful of plugins I've found:

* [https://github.com/vim-python/python-syntax:](https://github.com/vim-python/python-syntax:) 5 years
* [https://github.com/numirias/semshi:](https://github.com/numirias/semshi:) 4 years
* [https://github.com/kh3phr3n/python-syntax:](https://github.com/kh3phr3n/python-syntax:) 4 years

There's a bunch of new syntax that's popped up since then, and I'm surprised that there's no actively maintained plugin for Python syntax highlighting in Vim. Am I missing something?",2,4,2025-10-20 12:33:27,tapered_elephant,https://www.reddit.com/r/Python/comments/1obgm3n/uptodate_syntax_highlighting_for_vim/
1oavf1l,reddit,"[Fun project] UV scripts, but for functions.","**What My Project Does**

I recently created [**uv-func**](https://github.com/Roulbac/uv-func), a small tool that brings the dependency-isolation concept of tools like *uv scripts* down to the level of individual Python functions. Instead of managing dependencies per module or script, uv-func lets you run discrete functions in a contained environment so they can run, communicate with each other, and manage their dependencies cleanly and separately.

**Target Audience**

* Python developers working with scripts or functions that need to be isolated or decoupled in terms of dependencies.
* Hobbyists or maintainers who appreciate minimal tooling (uv-func has only three dependencies: cloudpickle, portalocker and rich).

Note: This isn‚Äôt a full framework for large applications ‚Äî it‚Äôs intended to be lightweight and easy to embed or integrate as needed.

**Comparison**

There are other tools that handle dependency isolation or function-level execution (for example, using containers, virtual environments per script, or Function-as-a-Service frameworks like Ray, etc...). 

What sets uv-func apart in my opinion:

1. Minimal footprint: only three external dependencies.
2. Focused on the function-level rather than full modules or services.
3. Lightweight and easy to drop into existing Python codebases without heavy platform or infrastructure requirements.

I see many AWS lambdas using requirements.txt then needing to run \`pip install\` somewhere in their app or infra code, and one example that comes immediately to mind is to use \`uv-func\` instead of \`requirements.txt\` for something like that (or even just uv scripts if function-level granularity isn't needed).

I‚Äôd love to hear your thoughts, thanks!

",22,5,2025-10-19 18:23:20,DifficultDifficulty,https://www.reddit.com/r/Python/comments/1oavf1l/fun_project_uv_scripts_but_for_functions/
1ob1kxr,reddit,gs-batch-pdf v0.6.0: Parallel PDF processing with Ghostscript,"As a structural engineer I have to deal with lots of pdfs and Public Administration strict, sometimes ridiculous, size requirements. I don't like to use online tools, but instead I prefer a nifty cli like Ghostscript (`gs`). The only problem is that `gs` syntax could be quite criptic sometimes, and I always need to search online for it because I would forget it. So I built a wrapper for it.

# What My Project Does

gs-batch-pdf is a CLI tool that batch-processes multiple PDF files simultaneously using Ghostscript. It handles compression (5 quality levels), PDF/A conversion (PDF/A-1/2/3), and custom Ghostscript operations with multi-threaded execution. Features include automatic file size comparison (keeps smaller file by default), recursive directory processing, flexible output naming with prefixes/suffixes, and configurable error handling modes (prompt/skip/abort).

Installation: `pipx install gs-batch-pdf`

Quick example:

    # Compress all PDFs in docs/ recursively, attach prefix to output
    gsb ./docs/ -r --compress --prefix compressed_
    
    # Compress + convert to PDF/A inplace
    gsb *.pdf --compress --pdfa --force

# Target Audience

For users who regularly process multiple PDFs (archiving, compliance, file size reduction). Requires Ghostscript installed as a system dependency. Tested on Windows, Linux with Python 3.12+ (macOS user, tell me). Particularly useful for:

* Batch compress multiple files
* Batch conversion to PDF/A standard (2 recommended)
* Automated document processing pipelines

# Comparison

Unlike running Ghostscript directly (which processes one file at a time), **gs-batch-pdf adds parallel execution**, progress tracking, and smart file management. Compared to Python PDF libraries (pypdf, PyPDF2), this leverages Ghostscript's robust compression/conversion capabilities rather than pure-Python implementations. Unlike pdftk (focused on splitting/merging), this specializes in compression and standards compliance.

**Unlike online tools, all processing happens locally with no privacy concerns.**

GitHub: [https://github.com/kompre/gs-batch](https://github.com/kompre/gs-batch)

PyPI: [https://pypi.org/project/gs-batch-pdf/](https://pypi.org/project/gs-batch-pdf/)",10,0,2025-10-19 22:23:16,komprexior,https://www.reddit.com/r/Python/comments/1ob1kxr/gsbatchpdf_v060_parallel_pdf_processing_with/
1oborpj,reddit,I made a Python bot that turns your text & images into diagrams right in Telegram.,"https://i.imgur.com/O1R7s3X.gif

**(sample)**

---

Hey everyone!

Like many of you, I often need to quickly visualize an idea ‚Äì sketch out a project structure, a mind map, or just explain a concept. Every time, I had to open heavy editors like Miro or Figma, which felt like overkill.

So, I decided to build a tool that lives right inside the app I use for communication all day: Telegram.

I'm excited to share my side project: **Diagrammer Bot**. It's a simple yet powerful bot in Python that lets you create diagrams on the fly.

**Here are the key features:**
*   **Text & Image Nodes:** You can create blocks not just from text, but from any image you send.
*   **Full Editing:** Create, connect, edit, and delete both nodes and edges.
*   **Project System:** Save your diagrams with custom names, load them later, or start new ones.
*   **Themes & Export:** Switch between a sleek dark mode and a clean light mode. Export your final diagram as a high-quality PNG.
*   **Open-Source:** The entire project is available on GitHub!

**Tech Stack:** Python, `python-telegram-bot`, `Graphviz` for rendering, and `Pillow` for watermarking.

I would be incredibly grateful for any feedback, feature ideas, or bug reports. And of course, a star ‚≠ê on GitHub would make my day!

*   **Try the bot here:** [https://t.me/diagrammer_robot](https://t.me/diagrammer_robot)
*   **Check out the code on GitHub:** [https://github.com/Lixher/Diagrammer-bot](https://github.com/Lixher/Diagrammer-Bot)",0,6,2025-10-20 18:51:22,No_Mongoose_8139,https://www.reddit.com/r/Python/comments/1oborpj/i_made_a_python_bot_that_turns_your_text_images/
1obo0ze,reddit,Forgetting Python,"I started python when i was 9th grade through udemy lectures, i watched a lot of them but didnt solve problems after that i took 2-3 gap for preping for college exams , now when i come back to python it feels i have lost my level and my touch i feel like fkn loser , all those hrs spent in 8th grade for nothing , i forgot a lot , is it common or just me???",0,5,2025-10-20 18:17:52,Ashamed-Society-2875,https://www.reddit.com/r/Python/comments/1obo0ze/forgetting_python/
1obl20g,reddit,Refurbished De-Googled Smartphones (LineageOS),"Salut,

On a de la chance d'avoir une tonne de distributions Linux pour nos PC ador√©s (respectueux de la vie priv√©e et s√©curis√©s -> merci l'open source).

Par contre, c√¥t√© t√©l√©phone, on est toujours pist√©s par nos GAFAM pr√©f√©r√©s, Apple et Google.

Chez Apple, avec iOS, c'est ""LES ROIS DU VERROUILLAGE"", impossible de faire quoi que ce soit.

Par contre, c√¥t√© Android, on a la possibilit√© de ""d√©-googliser"" certains smartphones.

Notre objectif :

On pr√©voit d'acheter des smartphones reconditionn√©s (genre Google Pixel, d'autres ?) et d'installer LineageOS dessus, puis de les revendre pr√™ts √† l'emploi.

Vous pensez que c'est une bonne id√©e ? √áa vous int√©resserait ? √áa int√©resserait vos potes ?

Merci les amis.",0,2,2025-10-20 15:57:40,talithaka,https://www.reddit.com/r/Python/comments/1obl20g/refurbished_degoogled_smartphones_lineageos/
1oalj6u,reddit,For those who miss terminal animations...,"Just for ease, the repo is also posted up here. 

https://github.com/DaSettingsPNGN/PNGN-Terminal-Animator

What my project does: animates text in Discord to look like a terminal output!

Target audience: other nostalgic gamers who enjoy Fallout and Pok√©mon, and who are interested in animation in Discord using Python.

Comparison: to my knowledge, there's not another Discord bot that generates on-demand custom responses, animated in a terminal style, and uploaded to Discord as a 60 frame, 5 second 12 FPS GIF. I do this to respect Discord rate limits. It only counts as one message. I also use neon as the human eye has a neon reaction biologically similar to a phosphor glow. The colors persist longer with higher saturation on the human retina, and we interpolate to smooth the motion. 

I'm new to Python, but I absolutely love it. I designed an animated Discord bot that has Pok√©mon/Fallout style creatures. I was thinking of adding battling, but for now it is more an interactive guide. 

I used accurate visual width calculations to get the text art wrapping correct. Rendered and then scaled so it fits any device. And then vectorized the rendering. Visual width is expensive, but it lines up in nice columns allowing vectorized rendering. 

I wanted to see what you all thought, so here is the repo! It has everything you should need to get your own terminal animations going. It includes my visual width file, my scaling file, and also an example animation of my logo that demonstrates how to use the width calculations. That is the trickiest part. Once you have that down you're solid. 

https://github.com/DaSettingsPNGN/PNGN-Terminal-Animator

Note: I included the custom emojis for the renderer. They work fairly well but not perfectly quite yet. The double cell size is hard to handle with visual width calculations. I will be working on it!

Please take a look and give me feedback! I will attach animated GIFs to the repo that are outputted from my bot! There is an example logo renderer too to get you started. 

Thank you!",22,14,2025-10-19 10:42:14,DaSettingsPNGN,https://www.reddit.com/r/Python/comments/1oalj6u/for_those_who_miss_terminal_animations/
1oar9y1,reddit,CTkSidebar: a customizable sidebar navigation control for CustomTkinter,"Hi everyone.

I'm sharing a new package I've been working on: **ctk-sidebar**. It's a customizable control for CustomTkinter that adds sidebar navigation to your Python GUI app.

Project link and screenshots: [https://github.com/anthony-bernaert/ctk-sidebar](https://github.com/anthony-bernaert/ctk-sidebar)

# What My Project Does

* Adds a sidebar to your CustomTkinter app
* Handles navigation: each menu item gets a separate view where you can add your controls
* Easy to use
* Customizable styling
* Supports hierarchical navigation (tree structure) with collapsible submenus
* Optional, automatic colorization of menu icons

# Target Audience

Everyone who wants to include multiple UI panes inside the same window, and wants an easy, modern-looking solution.

# Comparison

CustomTkinter already features a tab view control to switch between multiple views, but a sidebar is better suited for more complex types of navigation, or to navigate between more unrelated sections. Except for some code snippets, I didn't find any existing package that implemented this in CustomTkinter yet.

",5,1,2025-10-19 15:38:38,abernaert,https://www.reddit.com/r/Python/comments/1oar9y1/ctksidebar_a_customizable_sidebar_navigation/
1oah08y,reddit,Trio - Should I move to a more popular async framework?,"I'm new-ish to python but come from a systems and embedded programming background and want to use python and pytest to automate testing with IoT devices through BLE, serial or other transports in the future. I started prototyping with Trio as that was the library I saw being used in a reference pytest plugin, I checked out Trio and was very pleased on the emphasis of the concept of structured concurrency  (Swift has this concept with the same name in-grained so I knew what it meant and love it) and started writing a prototype to get something working. 

It was quick for me to notice the lack of  IO library that support Trio natively and this was bummer at first but no big deal as I could manage to find a small wrapper library for serial communication with Trio and wrote my own. However now that I'm having to prototype the BLE side of things I've found zero library, examples or material that uses Trio. Bleak which is the prime library I see pop-up when I look for BLE and python is written with the asyncio backend. I haven't done a lot of research into asyncio or anyio but now I'm thinking if I should switch to one of these (preferably anyio as it's the middle ground) and have to refactor while it is still early.

So wanted to ask if I would be losing  much by not going with Trio instead of one of the other libraries? I would hate to lose Tasks and TaskGroups (Nurseries in Trio) as well as Channels and Events but I think Anyio has them too although the implementation might be different. I also like Trio's support for sockets, subprocess and other low level APIs out of the box. Would appreciate any feedback on your experience using Trio or the other async libraries for similar use cases as mine. ",27,26,2025-10-19 05:56:38,IncreaseMelodic9809,https://www.reddit.com/r/Python/comments/1oah08y/trio_should_i_move_to_a_more_popular_async/
1oa4r54,reddit,Saving Memory with Polars (over Pandas),"You can save some memory by moving to Polars from Pandas but watch out for a subtle difference in the quantile's different default interpolation methods.  
  
Read more here:  
[https://wedgworth.dev/polars-vs-pandas-quantile-method/](https://wedgworth.dev/polars-vs-pandas-quantile-method/)

Are there any other major differences between Polars and Pandas that could sneak up on you like this?",105,31,2025-10-18 20:23:02,paltman94,https://www.reddit.com/r/Python/comments/1oa4r54/saving_memory_with_polars_over_pandas/
1oa9e3c,reddit,Showcase: I wrote a GitHub Action to Summarize uv.lock Changes,"**What My Project Does**

I have been loving everything about uv but reviewing changes as git diffs is always a chore.  
I wrote this action to summarize the changes and provide a simple report via PR comment.

**Target Audience**

This is intended for anyone building or maintaining Python projects with uv in Github.

**Comparison**  
I could not find any other similar actions out there.

URL: [https://github.com/mw-root/uv-lock-report](https://github.com/mw-root/uv-lock-report)

Example PR Comments:
[https://github.com/mw-root/uv-lock-report/raw/main/images/uv-lock-report-simple-comment.png](https://github.com/mw-root/uv-lock-report/raw/main/images/uv-lock-report-simple-comment.png)

[https://github.com/mw-root/uv-lock-report/raw/main/images/uv-lock-report-table-comment.png](https://github.com/mw-root/uv-lock-report/raw/main/images/uv-lock-report-table-comment.png)",56,16,2025-10-18 23:29:43,burlyginger,https://www.reddit.com/r/Python/comments/1oa9e3c/showcase_i_wrote_a_github_action_to_summarize/
1o9zow6,reddit,"I've written an article series about SQLAlchemy, hopefully it can benefit some of you","You can read it here [https://fullstack.rocks/article/sqlalchemy/brewing\_with\_sqlalchemy](https://fullstack.rocks/article/sqlalchemy/brewing_with_sqlalchemy)  
I'm really attempting to go deep into the framework with this one. Obviously, the first few articles are not going to provide too many new insights to experienced SQLAlchemy users, but I'm also going into some advanced topics, such as:

* Custom data types
* Polymorphic tables
* Hybrid declarative approach (next week)
* JSON and JSONb (week after that)

In the coming weeks, I'll be continuing to add articles to this series, so if you see anything that is missing that might benefit other developers (or yourself), let me know.",143,25,2025-10-18 17:04:31,Moon_Walking_Ape,https://www.reddit.com/r/Python/comments/1o9zow6/ive_written_an_article_series_about_sqlalchemy/
1oaaddg,reddit,Google Tasks TUI,"What My Project Does:

This project is a TUI(terminal user interface) that hooks up with the Google Tasks Api, allowing you to edit and view your tasks straight from your terminal.

Target Audience:

This is just a toy project and for everyone. It is also open source so feel free to make any contributions.

Comparison:

I'm sure there are other TUIs out there similar to this that allows you to keep track of your tasks/notes. I guess this application is nice because it hooks up with your Google Tasks which allows for cross platform use. 

Source:

[https://github.com/huiiy/GTask](https://github.com/huiiy/GTask)",34,9,2025-10-19 00:13:30,Cow-Primary,https://www.reddit.com/r/Python/comments/1oaaddg/google_tasks_tui/
1oa8cwj,reddit,New package: gnosis-dispatch,"I created the [gnosis-dispatch](https://pypi.org/project/gnosis-dispatch/) package in large part to ""scratch an itch"" that followed Brett Slatkin's excellent PyCon US 2025 presentation, [The Zen of Polymorphism](https://us.pycon.org/2025/schedule/presentation/99) (a number of months ago).

I think that [Multiple and Predicative Dispatch](https://gnosis-dispatch.readthedocs.io/en/latest/) is often a more elegant and more straightforwardly extensible way of structuring programs than is Protocol inheritance, OOP in general, the Registration Pattern, or other existing approaches to extensibility of related capabilities.

I gave a talk on this package, but also on the concepts that underlay it at [PyCon Africa 2025](https://za.pycon.org/talks/303-multiple-and-predicative-dispatch/) that was extraordinarily well received, with questions running long over the scheduled time.

Following my trip to Johannesburg, I finalized a few API details, added tests, and created the RtD pages for this module. All of which makes me comfortable calling it 1.0 now.

I'd love for folks to try it out, give me feedback, report bugs, build large projects using the framework, etc.

A quick `uv add gnosis-dispatch` or `uv pip install gnosis-dispatch` will get you started (or whatever people who don't use `uv` do to install software :-)).",21,3,2025-10-18 22:45:32,DavidMertz,https://www.reddit.com/r/Python/comments/1oa8cwj/new_package_gnosisdispatch/
1o9tvtc,reddit,Which language is similar to Python?,"I‚Äôve been using Python for almost 5 years now. 
For work and for personal projects.

Recently I thought about expanding programming skills and trying new language.

Which language would you recommend (for backend, APIs, simple UI)? Did you have experience switching from Python to another language and how it turned out?",126,244,2025-10-18 13:00:19,iglebov,https://www.reddit.com/r/Python/comments/1o9tvtc/which_language_is_similar_to_python/
1oad5wv,reddit,Skylos- Expanded capabilities,"Hello Everyone. Skylos is a static analyzer that finds dead code (unused functions, imports, classes,  vars). It runs locally and has a CI/CD hook . Under the hood, Skylos uses AST with framework/test awareness, confidence scoring, and LibCST edits to flush out any dead code. We have expanded its capabilities to also detect the most common security flaws that is output by an AI model, aka to catch vibe coding vulnerabilities. 

  
The system is not perfect and we are constantly refining it. We have also included a VSC extension that you can use by searching for \`Skylos\` in the extension marketplace. Or you can download it via 

    pip install skylos==2.4.0

To use skylos with the security enhancement, run 

    skylos /path/to/your/folder --danger

# Target audience:

Anyone and everyone who uses python. Currently it's only for python. 

  
We are looking for feedback and contributors. If you have any feedback or will like to contribute, feel free to reach out to me over here. Please leave a star if you find it useful and share it. 

  
I apologise if I disappear for a wk or two and have 0 updates to the repo, because I'm in the midst of writing my research paper. Once it's done i'll focus more on building this to its full potential. 

  
This is the link to the repo. [https://github.com/duriantaco/skylos](https://github.com/duriantaco/skylos)",6,6,2025-10-19 02:28:51,papersashimi,https://www.reddit.com/r/Python/comments/1oad5wv/skylos_expanded_capabilities/
1oaski5,reddit,What should be the design and functionality of an agent framework like Langchain?,"I would like to study and deepen my knowledge on how to build a framework, how it should be designed and so on.
I tried searching on Google but couldn't find anything satisfactory.
Is there any discussion, paper or book where it is possible to delve into this topic professionally?",0,0,2025-10-19 16:31:11,Warm_Interaction_375,https://www.reddit.com/r/Python/comments/1oaski5/what_should_be_the_design_and_functionality_of_an/
1o9wltp,reddit,"üöÄ Shipped My First PyPI Package ‚Äî httpmorph, a C-backed ‚Äúbrowser-like‚Äù HTTP client for Python","Hey¬†r/Python¬†üëã


Just published my first package to PyPI and wanted to share what I learned along the way.It‚Äôs called¬†httpmorph¬†‚Äî a¬†requests-compatible HTTP client built with a native C extension for more realistic network behavior.

üß© What My Project Does


httpmorph¬†is a Python HTTP library written in¬†C¬†with¬†Python bindings.It reimplements parts of the HTTP and TLS layers using¬†BoringSSL¬†to more closely resemble modern browser-style connections (e.g., ALPN, cipher order, TLS 1.3 support).
You can use it just like¬†requests:

import httpmorph

r = httpmorph.get(""<the_url>"")

print(r.status_code)

It‚Äôs designed to help developers explore and understand how small transport-layer differences affect responses from servers and APIs.

üéØ Target Audience


This project is meant for:
* Developers curious about¬†C extensions and networking internals
* Students or hobbyists learning how¬†HTTP/TLS clients¬†are built
* Researchers exploring¬†protocol-level differences¬†across clients
It‚Äôs a learning-oriented tool ‚Äî not production-ready yet, but functional enough for experiments and debugging.

‚öñÔ∏è Comparison


Compared to existing libraries like¬†requests,¬†httpx, or¬†aiohttp:
* Those depend on¬†OpenSSL, while¬†httpmorph¬†uses¬†BoringSSL, offering slightly different protocol negotiation flows.
* It‚Äôs fully synchronous for now (like¬†requests), but the goal is transparency and low-level visibility into the connection process.
* No dependencies ‚Äî it builds natively with a single¬†pip install.

üß† Why I Built It


I wanted to stop overthinking and finally learn how C extensions work.After a few long nights and 2000+ GitHub Actions minutes testing on Linux, Windows, and macOS (Python 3.8‚Äì3.14), it finally compiled cleanly across all platforms.

üîó Links

* PyPI ‚Üí https://pypi.org/project/httpmorph

* GitHub ‚Üí¬†https://github.com/arman-bd/httpmorph


üí¨ Feedback Welcome


Would love your feedback on:
* Code structure or API design improvements
* Packaging/build tips for cross-platform C extensions
* Anything confusing about the usage or docs

I‚Äôm mainly here to learn ‚Äî any insights are super appreciated üôè
",27,8,2025-10-18 15:00:56,armanfixing,https://www.reddit.com/r/Python/comments/1o9wltp/shipped_my_first_pypi_package_httpmorph_a_cbacked/
1oabdtm,reddit,Sunday Daily Thread: What's everyone working on this week?,"# Weekly Thread: What's Everyone Working On This Week? üõ†Ô∏è

Hello /r/Python! It's time to share what you've been working on! Whether it's a work-in-progress, a completed masterpiece, or just a rough idea, let us know what you're up to!

## How it Works:

1. **Show & Tell**: Share your current projects, completed works, or future ideas.
2. **Discuss**: Get feedback, find collaborators, or just chat about your project.
3. **Inspire**: Your project might inspire someone else, just as you might get inspired here.

## Guidelines:

* Feel free to include as many details as you'd like. Code snippets, screenshots, and links are all welcome.
* Whether it's your job, your hobby, or your passion project, all Python-related work is welcome here.

## Example Shares:

1. **Machine Learning Model**: Working on a ML model to predict stock prices. Just cracked a 90% accuracy rate!
2. **Web Scraping**: Built a script to scrape and analyze news articles. It's helped me understand media bias better.
3. **Automation**: Automated my home lighting with Python and Raspberry Pi. My life has never been easier!

Let's build and grow together! Share your journey and learn from others. Happy coding! üåü",3,2,2025-10-19 01:00:32,AutoModerator,https://www.reddit.com/r/Python/comments/1oabdtm/sunday_daily_thread_whats_everyone_working_on/
1o9gyxa,reddit,Rant: Python imports are convoluted and easy to get wrong,"Inspired by the famous ""module 'matplotlib' has no attribute 'pyplot'"" error, but let's consider another example: numpy.

This works:

    from numpy import ma, ndindex, typing
    ma.getmask
    ndindex.ndincr
    typing.NDArray

But this doesn't:

    import numpy
    numpy.ma.getmask
    numpy.ndindex.ndincr
    numpy.typing.NDArray  # AttributeError

And this doesn't:

    import numpy.ma, numpy.typing
    numpy.ma.getmask
    numpy.typing.NDArray
    import numpy.ndindex  # ModuleNotFoundError

And this doesn't either:

    from numpy.ma import getmask
    from numpy.typing import NDArray
    from numpy.ndindex import ndincr  # ModuleNotFoundError

There are explanations behind this (`numpy.ndindex` is not a module, `numpy.typing` has never been imported so the attribute doesn't exist yet, `numpy.ma` is a module and has been imported by numpy's `__init__.py` so everything works), but they don't convince me. I see no reason why `import A.B` should only work when B is a module. And I see no reason why using a not-yet-imported submodule shouldn't just import it implicitly, clearly you were going to import it anyway. All those subtle inconsistencies where you can't be sure whether something works until you try are annoying. Rant over.

**Edit**: as some users have noted, the AttributeError is gone in modern numpy (2.x and later). To achieve that, the numpy devs [implemented](https://github.com/numpy/numpy/blob/0066c73f573daafa01cbb975fde7f21d2b045ccb/numpy/__init__.py#L626) lazy loading of modules themselves. Keep that in mind if you want to try it for yourselves.",155,69,2025-10-18 00:48:43,zabolekar,https://www.reddit.com/r/Python/comments/1o9gyxa/rant_python_imports_are_convoluted_and_easy_to/
1oav08x,reddit,"–ò—â—É —á–µ–ª–æ–≤–µ–∫–∞ —Å –∫–æ—Ç–æ—Ä—ã–º –º–æ–∂–Ω–æ –æ–∫—É–Ω—É—Ç—å—Å—è –≤ IT, –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ Python.","–ú–Ω–µ 16 –ª–µ—Ç, —Ö–æ—á—É –∑–∞–Ω–∏–º–∞—Ç—å—Å—è –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ–º –Ω–∞ Python. –ò—â—É —á–µ–ª–æ–≤–µ–∫–∞ –∫—Ç–æ –∑–∞–∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞–Ω –≤ —ç—Ç–æ–º –∏ —Ö–æ—á–µ—Ç –Ω–∞—á–∞—Ç—å –≤–º–µ—Å—Ç–µ. –ó–∞—Ä–∞–Ω–µ–µ –≤—Å–µ–º —Å–ø–∞—Å–∏–±–æ!",0,1,2025-10-19 18:07:07,fresco_03,https://www.reddit.com/r/Python/comments/1oav08x/–∏—â—É_—á–µ–ª–æ–≤–µ–∫–∞_—Å_–∫–æ—Ç–æ—Ä—ã–º_–º–æ–∂–Ω–æ_–æ–∫—É–Ω—É—Ç—å—Å—è_–≤_it/
1oarf25,reddit,EEG WIP. Can you do better than Claude?,"Working on an EEG device that reads brainwaves- and does stuff with them after initial tests.

Claude made this initial code. I would have tested it myself if I had everything for my device. See if you can't make something better!

The final AI I am working on- Idas- will be under GPL 3, using Python 3.12.

import torch
import pyeeg
import queue

signal_queue = queue.Queue()

while True:
eeg_data = read.EEG()
tensor = torch.tensor(eeg_data)
signal_queue.put(tensor)
# Other processes consume from queue

GPL 3 link and Ko-Fi page:
https://ko-fi.com/nerdzmasterz",0,0,2025-10-19 15:44:29,Member9999,https://www.reddit.com/r/Python/comments/1oarf25/eeg_wip_can_you_do_better_than_claude/
1o9s17w,reddit,Passive SDR Radar with KrakenSDR: DVB-T2 for Drone/Target Detection,"Hello everyone,

I'm starting a new open-source project aimed at developing a fully functional **Passive SDR Radar (PCL)** system using the **KrakenSDR** platform. The primary goal is to effectively detect and track **dynamic aerial targets** (like drones and aircraft) by processing existing broadcast signals, specifically **DVB-T2**, in the 514 MHz range .

We are currently in the architecture and initial development phase, and I welcome any feedback, expertise, and collaboration from the KrakenSDR community, especially regarding signal processing and phase calibration.



# Project Overview & Goals



This system operates entirely passively, making it robust against electronic countermeasures (ECM).

* **Hardware:** KrakenSDR (5 channels), 5 x Yagi-Uda Antennas (1 Reference + 4 Surveillance for a phased array setup), Raspberry Pi 5.
* **Illuminator:** DVB-T2 broadcast signals (around **514 MHz**).
* **Target:** Drones, aircraft, and missiles.



# Core Processing Pipeline



The project focuses heavily on signal processing to separate moving targets from static ground reflections (clutter). Our pipeline involves these key steps:

1. **IQ Data Acquisition:** Capture raw data from the 5 KrakenSDR channels.
2. **Calibration:** Synchronization and phase calibration (a critical challenge with non-coherent sources).
3. **CAF Calculation:** Generate the **Cross Ambiguity Function (CAF)**, which creates a `delay √ó doppler` map (our radar frame).
4. **Clutter Suppression:** Apply **MTI (Moving Target Indication)** or FIR High-Pass filters along the time axis to suppress stationary echoes (zero-Doppler).
5. **Detection:** Use 2D **CFAR (Constant False Alarm Rate)** to extract targets from the filtered CAF maps.
6. **Tracking:** Implement a **Kalman Filter** combined with the **Hungarian Algorithm** for robust data association and continuous tracking of targets (creating unique IDs and time series data).



# Current Focus & Challenges



We are seeking advice and discussion on the following technical points:

1. **Phase Synchronization:** Best practices for achieving precise phase synchronization between the four surveillance channels on the KrakenSDR using an external clock or through software compensation, especially for non-coherent DVB-T2 signals.
2. **CAF Optimization:** Techniques to optimize the computation time of the CAF on resource-limited devices like the Raspberry Pi 5.
3. **MTI/Clutter Filtering:** Experience with adaptive clutter suppression algorithms (beyond simple MTI) for PCL systems utilizing OFDM signals like DVB-T2.



# Repository and Collaboration



The project structure is available on GitHub. We are organizing the code into logical folders (`src/`, `config/`, `systemd/`) and are documenting the technical specifications in the `docs/` folder.

**GitHub Repository:** [`https://github.com/Stanislav-sipiko/passive-sdr-radar`](https://github.com/Stanislav-sipiko/passive-sdr-radar)

Feel free to check out the repo, submit issues, or share your knowledge here!

Thanks in advance for your input!",7,0,2025-10-18 11:12:58,After-Ad-8431,https://www.reddit.com/r/Python/comments/1o9s17w/passive_sdr_radar_with_krakensdr_dvbt2_for/
1o9ar5b,reddit,De-emojifying scripts - setting yourself apart from LLMs,"I am wondering if anyone else has had to actively try to set themselves apart from LLMs. That is, to convince others that you made something with blood, sweat and tears rather than clanker oil.

For context, I'm the maintainer of [Spectre](https://github.com/jcfitzpatrick12/spectre) ([https://github.com/jcfitzpatrick12/spectre](https://github.com/jcfitzpatrick12/spectre)), a Python program for recording radio spectrograms from software-defined radios. A long while ago, I wrote a setup script - it's the first thing a user runs to install the progam. That script printed text to the terminal indicating progress, and that text included emoji's ‚úîÔ∏è

Certainly! Here‚Äôs a way to finish your post with a closing sentiment that emphasizes your personal touch and experience:

Markdown

    I guess what I'm getting at is, sometimes the little details‚Äîlike a hand-picked emoji or a carefully-worded progress message‚Äîcan be a subtle but honest sign that there's a real person behind the code. In a world where so much content is generated, maybe those small human touches are more important than ever.
    
    Has anyone else felt the need to leave these kinds of fingerprints in their work?
    ",90,33,2025-10-17 20:28:48,jcfitzpatrick12,https://www.reddit.com/r/Python/comments/1o9ar5b/deemojifying_scripts_setting_yourself_apart_from/
1o9756d,reddit,"I was tired of writing CREATE TABLE statements for my Pydantic models, so I built PydSQL to automate","Hey,

I'd like to share a project I built to streamline a common task in my workflow. I've structured this post to follow the showcase rules.

**What My Project Does:**

**PydSQL** is a lightweight,  no dependencies besides Pydantic utility that converts Pydantic models directly into SQL `CREATE TABLE` statements.

The goal is to eliminate the manual, error-prone process of keeping SQL schemas synchronized with your Python data models.

For example, you write this Pydantic model:

Python

    from pydantic import BaseModel
    from datetime import date
    
    class Product(BaseModel):
        product_id: int
        name: str
        price: float
        launch_date: date
        is_available: bool

And PydSQL instantly generates the corresponding SQL:

SQL

    CREATE TABLE product (
        product_id INTEGER,
        name TEXT,
        price REAL,
        launch_date DATE,
        is_available BOOLEAN
    );

It does one thing and aims to do it well, without adding the complexity of a full database toolkit.

**Target Audience:**

The target audience is **Python developers who prefer writing raw SQL or use lightweight database libraries** (like `sqlite3`, `psycopg2`, etc.) instead of a full ORM.

It's intended for small to medium-sized projects where a tool like SQLAlchemy or Django's ORM might feel like overkill, but you still want the benefit of automated schema generation from a single source of truth (your Pydantic model). It is meant for practical development workflows, not just as a toy project.

**Comparison**

* **vs. Manual SQL:** PydSQL is a direct replacement for manually writing and updating `.sql` files. It reduces boilerplate, prevents typos, and ensures your database schema never drifts from your application's data models.
* **vs. ORMs (SQLAlchemy, Django ORM):** PydSQL is **not an ORM**. It doesn't handle database connections, sessions, or query building. This makes it far more lightweight and simpler. It's for developers who want to write their own SQL queries but just want to automate the table creation part.
* **vs. SQLModel:** While SQLModel also uses Pydantic, it is a full ORM built on top of SQLAlchemy. PydSQL is different because it has no opinion on how you interact with your database it only generates the `CREATE` statement.

**Links**

* **Source Code (GitHub):**[https://github.com/pranavkp71/PydSQL](https://github.com/pranavkp71/PydSQL)
* **PyPI:** `pip install pydsql`

The project is very new, and I'm actively looking for feedback, feature requests, and contributors. Thanks for checking it out!",62,43,2025-10-17 18:11:04,MainWild1290,https://www.reddit.com/r/Python/comments/1o9756d/i_was_tired_of_writing_create_table_statements/
1oael9w,reddit,I am not able to start with GUI in Python.,"Hi, i recently completed my CS50's Introduction to programming with Python Course, and was planning to start on GUIs to build better desktop apps for me or my friends... But Can't really Figure out where to start with GUI, There are dozens of different ways to learn it and create decent apps but I which one should i start with? Would love to know your experiences and opinions as well.",0,8,2025-10-19 03:42:38,ComplaintGlass2005,https://www.reddit.com/r/Python/comments/1oael9w/i_am_not_able_to_start_with_gui_in_python/
1o98n90,reddit,"If starting from scratch, what would you change in Python. And bringing back an old discussion."," I know that it's a old discussion on the community, the trade of between simplicity and ""magic"" was a great topic about 10 years ago. Recently I was making a Flask project, using some extensions, and I stop to think about the usage pattern of this library. Like you can create your app in some function scope, and use current\_app to retrieve it when inside a app context, like a route. But extensions like socketio you most likely will create a ""global"" instance, pass the app as parameter, so you can import and use it's decorators etc. I get why in practice you will most likely follow.

  
 What got me thinking was the decisions behind the design to making it this way. Like, flask app you handle in one way, extensions in other, you can create and register multiples apps in the same instance of the extension, one can be retrieved with the proxy like current\_app, other don't (again I understand that one will be used only in app context and the other at function definition time). Maybe something like you accessing the instances of the extensions directly from app object, and making something like route declaration, o things that depends on the instance of the extension being declared at runtime, inside some app context. Maybe this will actually make things more complex? Maybe.

 I'm not saying that is wrong, or that my solution is better, or even that I have a good/working solution, I'm just have a strange fell about it. Mainly after I started programming in low level lang like C++ and Go, that has more strict rules, that makes things more complex to implement, but more coherent. But I know too that a lot of things in programming goes as it was implemented initially and for the sake of just make things works you keep then as it is and go along, or you just follow the conventions to make things easier (e.g. banks system still being in Cobol).

  
 Don't get me wrong, I love this language and it's still my most used one, but in this specific case it bothers me a little, about the abstraction level (I know, I know, it's a Python programmer talking about abstraction, only a Js could me more hypocritical). And as I said before, I know it's a old question that was exhausted years ago. So my question for you guys is, to what point is worth trading convenience with abstraction? And if we would start everything from scratch, what would you change in Python or in some specific library?",40,239,2025-10-17 19:08:02,FenomoJs,https://www.reddit.com/r/Python/comments/1o98n90/if_starting_from_scratch_what_would_you_change_in/
1o9axeo,reddit,Pygls v2.0.0 released: a library for building custom LSP servers,"We've just released [v2.0.0 of pygls](https://pypi.org/project/pygls/2.0.0/), the library to help you build your own LSP servers: https://github.com/openlawlibrary/pygls

It's the first major rewrite since its inception 7 years ago. The pre-release has been available for over a year, so this is already well used and tested code.

If you write Python in VSCode it's likely you're already using [a _pygls_-based LSP server implementation](https://github.com/openlawlibrary/pygls/blob/main/Implementations.md) as we work with Microsoft to support their [lsprotocol](https://github.com/microsoft/lsprotocol) typing library.",18,5,2025-10-17 20:35:36,tombh,https://www.reddit.com/r/Python/comments/1o9axeo/pygls_v200_released_a_library_for_building_custom/
1o9dey5,reddit,"I just released PyPIPlus.com 2.0 offline-ready package bundles, reverse deps, license data, and more","Hey everyone,

I‚Äôve pushed a major update to PyPIPlus.com my tool for exploring Python package dependencies in a faster, cleaner way.

Since the first release, I‚Äôve added a ton of improvements based on feedback:   
‚Ä¢	Offline Bundler: Generate a complete, ready-to-install package bundle with all wheels, licenses, and an installer script   
‚Ä¢	Automatic Compatibility Resolver: Checks Python version, OS, and ABI for all dependencies   
‚Ä¢	Expanded Dependency Data: Licensing, size, compatibility, and version details for every sub-dependency ‚Ä¢	Dependents View: See which packages rely on a given project   
‚Ä¢	Health Metrics & Score: Quick overview of package quality and metadata completeness   
‚Ä¢	Direct Links: Access project homepages, documentation, and repositories instantly ‚Ä¢  
	Improved UI: Expanded view, better mobile layout, faster load times   
‚Ä¢	Dedicated Support Email: For feedback, suggestions, or bug reports

It‚Äôs now a much more complete tool for developers working with isolated or enterprise environments or anyone who just wants deeper visibility into what they‚Äôre installing.

Would love your thoughts, ideas, or feedback on what to improve next.

üëâ [https://pypiplus.com](https://pypiplus.com)

If you missed it, here‚Äôs the original post: [https://www.reddit.com/r/Python/s/BvvxXrTV8t](https://www.reddit.com/r/Python/s/BvvxXrTV8t)",12,11,2025-10-17 22:13:00,RoyalW1zard,https://www.reddit.com/r/Python/comments/1o9dey5/i_just_released_pypipluscom_20_offlineready/
1o90fan,reddit,Free-threaded Python on GitHub Actions,[https://hugovk.dev/blog/2025/free-threaded-python-on-github-actions/](https://hugovk.dev/blog/2025/free-threaded-python-on-github-actions/),47,4,2025-10-17 13:50:14,pauloxnet,https://www.reddit.com/r/Python/comments/1o90fan/freethreaded_python_on_github_actions/
1o9frjw,reddit,Platform differences Windows <-> MacOS,"Context: scans of documents, python environment, running configuration-file-based OCR against said scans. Configuration options include certain things for x- and y-thresholds on joining data in lines, etc. Using Regular Expressions to pull structured data from different parts of the document. Documents are PDFs and PNGs of structured, form-based documents.

I built a config for a new client yesterday that worked picture perfect, basically first time and for a number of documents I ran as a test suite. Very little tweaking and special configs. It was straight forward and was probably the first time this system didn't feel overtaxed. (don't get me started on the overall design of it)

Coworker ran the same setup, and it failed. Built on the same version of Python, all from the same requirements list, etc. Literally the only difference is I'm running on MacOS and he's running Windows 11. Same code base, pulled from same repository. Same config file. Same same all around. 

He had to adjust one setting to get it to work at all, and I'm still not sure the whole thing worked as expected. Mine did, repeatedly, on multiple documents. 

  
As this will eventually be running on a container in some silly google environment which is probably running some version of \*nix OS, I'd say my Mac is closer to the ""real deal"" than his windows machine; gun to my head, I'm saying if it works on mine and not on his, his is the bigger problem. 

Anyone aware of such differences on disparate platforms?",5,2,2025-10-17 23:53:39,Any_Peace_4161,https://www.reddit.com/r/Python/comments/1o9frjw/platform_differences_windows_macos/
1o9h81g,reddit,Saturday Daily Thread: Resource Request and Sharing! Daily Thread,"# Weekly Thread: Resource Request and Sharing üìö

Stumbled upon a useful Python resource? Or are you looking for a guide on a specific topic? Welcome to the Resource Request and Sharing thread!

## How it Works:

1. **Request**: Can't find a resource on a particular topic? Ask here!
2. **Share**: Found something useful? Share it with the community.
3. **Review**: Give or get opinions on Python resources you've used.

## Guidelines:

* Please include the type of resource (e.g., book, video, article) and the topic.
* Always be respectful when reviewing someone else's shared resource.

## Example Shares:

1. **Book**: [""Fluent Python""](https://www.amazon.com/Fluent-Python-Concise-Effective-Programming/dp/1491946008) \- Great for understanding Pythonic idioms.
2. **Video**: [Python Data Structures](https://www.youtube.com/watch?v=pkYVOmU3MgA) \- Excellent overview of Python's built-in data structures.
3. **Article**: [Understanding Python Decorators](https://realpython.com/primer-on-python-decorators/) \- A deep dive into decorators.

## Example Requests:

1. **Looking for**: Video tutorials on web scraping with Python.
2. **Need**: Book recommendations for Python machine learning.

Share the knowledge, enrich the community. Happy learning! üåü",3,0,2025-10-18 01:00:30,AutoModerator,https://www.reddit.com/r/Python/comments/1o9h81g/saturday_daily_thread_resource_request_and/
1o8ors4,reddit,"TOML is great, and after diving deep into designing a config format, here's why I think that's true","Developers have strong opinions about configuration formats. YAML advocates appreciate the clean look and minimal syntax. JSON supporters like the explicit structure and universal tooling. INI users value simplicity. Each choice involves tradeoffs, and those tradeoffs matter when you're configuring something that needs to be both human-readable and machine-reliable. This is why I settled on TOML. 

[https://agent-ci.com/blog/2025/10/15/object-oriented-configuration-why-toml-is-the-only-choice](https://agent-ci.com/blog/2025/10/15/object-oriented-configuration-why-toml-is-the-only-choice)",171,79,2025-10-17 02:52:41,tcdent,https://www.reddit.com/r/Python/comments/1o8ors4/toml_is_great_and_after_diving_deep_into/
1o9bqks,reddit,Resources from Intermediate - Advanced for decently experienced dev to upskill?,"Hey guys A bit of a background - I have a bachelors in CS (just finished) and quite a bit of ""experience"" - since I started working basically full time after my sophomore year of uni at an AI startup based in SF. Since then I have graduated, switched jobs to a different startup in SF that values me more. I also do some part time research in AI, have a research paper - and a couple more on the way - beside my day job. However the problem is - I dont think in the past 1-2 years or so - I haven't really made my skills more robust. So here I am looking for resources on how to learn some of the more intermediate concepts in Python specifically - as that is the language that I use the most often. A bit of background of my familiarity with programming - have done a decent bit of C - in undergrad - dealt with some networking and OS-level code in C (sockets, raw sockets, implementing file transfer protocols from RFCs etc). For Python - obviously know the basic stuff, but a lot of the nice-to-haves that I dont understand. Like yeah I'm very familiar with the raw types and basic concepts like dicts, lists, mutability etc, have extensively used Flask, and also built ""production apps"". But I find that I lack for example proper understanding of when/where would I need to use stuff like dataclasses, or other niceties of python. Due to my day job - which usually involves ""shipping quickly"" - I find that I dont really follow the best practices/probably dont really write ""clean"" code. Part of it is also just some practice that comes from the jupyter notebook type of prototyping because I do quite a bit of ML research and the code that you write there isnt really ever ""clean"" or prod grade What are some intermediate level books to learn from/learn design patterns and OOP applications from? For example - when would I need to build abstractions when building CRUD apps/ when to just let it be? I'm looking for stuff like the interpreter book in Go but for my usecase.

Gave that example because I really want a resource to ""do"" stuff instead of just read/have small exercises at the end to solve - I dont really feel I learn much from that.

Maybe also stuff like ""practical version"" of the Designing Data intensive applications or similar books.

  
TLDR:

Decently experienced in terms of just programming - looking for stuff that is like ""The Interpreter book using Go"" but for Python + Design pattern related stuff. Any suggestions?",5,0,2025-10-17 21:07:39,DarthLoki79,https://www.reddit.com/r/Python/comments/1o9bqks/resources_from_intermediate_advanced_for_decently/
1o9ldg2,reddit,Private Package Hosting + Vetted Packatges / Security Auditing,"[I've previously asked about package hosting before](https://www.reddit.com/r/Python/comments/17tg1lk/third_party_private_package_hosting/), but with the fairly constant stream of supply chain attacks ocurring it's clear to me that having a ""vetted"" PyPI mirror is needed on top of any private package hosting.

This isn't a particularly poignant realisation, but good solutions that are suitable for for small organisations / security teams seem few and far between.

From my point of view ^(feel free to argue with me on this) an ideal solution would meet the following:

* Hosted (i.e. SaaS)
* Must be able to have both private packages and mirrored packages in the same index.
* Packages mirrored from PyPI should be vetted in a no-touch / low-touch way. As a solo security person I don't have the time or skills to vett every package and version and built artifact.
* Pricing should be usage based - preferably with fine-grained pay-as-you-go metering. Many that do price on usage tend to be course grained on pre-selected amounts rather than metered. Pricing should absolutely not be priced on number of users.

So far I've not found anything that suits - so please provide your recommendations / reviews if you have any.

Here's things I've looked at so far:

* [**Inedo ProGet**](https://inedo.com/proget/features) \- mostly self-hosted, very coarse grained pricing.
* [**ActiveState**](https://www.activestate.com/platform/supported-languages/python/) \- appears to mostly be container based, doesn't look like standard private respository hosting.
* [**Cloudsmith**](https://cloudsmith.com/product/formats/python-repository) \- looks like the cloest thing, their minimum pricing is still a lot for tiny teams / organisations.
* [**JFrog**](https://jfrog.com/pricing/) \- Epensive coarse grained pricing
* [**Sonatype (Nexus / Firewall)**](https://www.sonatype.com/products/pricing) \- expensive per user based pricing. Self hosted Nexus is a lot of manual work.

Finally, I'm aware that there are CI/CD based solutions for this, but really want to push it at the repository level because generally speaking they also give access to things like centralised reporting and SBOMs.",1,2,2025-10-18 04:28:57,nicholashairs,https://www.reddit.com/r/Python/comments/1o9ldg2/private_package_hosting_vetted_packatges_security/
1oa0gx2,reddit,"Built a PyTorch system that trains ML models 11√ó faster with 90% energy savings [850 lines, open sou","    Hey r/Python! Wanted to share a PyTorch project I just open-sourced.
    
    
    **What it does:**
    Trains deep learning models by automatically selecting only the most important 10% of training samples each epoch. Results in 11√ó speedup and 90% energy savings.
    
    
    **Tech Stack:**
    - Python 3.8+
    - PyTorch 2.0+
    - NumPy, Matplotlib
    - Control theory (PI controller)
    
    
    **Results:**
    - CIFAR-10: 61% accuracy in 10.5 minutes (vs 120 min baseline)
    - Energy savings: 89.6%
    - Production-ready (850 lines, fully documented)
    
    
    **Python Highlights:**
    - Clean OOP design (SundewAlgorithm, AdaptiveSparseTrainer classes)
    - Type hints throughout
    - Comprehensive docstrings
    - Dataclasses for config
    - Context managers for resource management
    
    
    **Interesting Python Patterns Used:**
    ```python
    @dataclass
    class SundewConfig:
    ¬† ¬† activation_threshold: float = 0.7
    ¬† ¬† target_activation_rate: float = 0.06
    ¬† ¬† # ... (clean config pattern)
    
    
    class SundewAlgorithm:
    ¬† ¬† def __init__(self, config: SundewConfig):
    ¬† ¬† ¬† ¬† self.threshold = config.activation_threshold
    ¬† ¬† ¬† ¬† self.activation_rate_ema = config.target_activation_rate
    ¬† ¬† ¬† ¬† # ... (EMA smoothing for control)
    
    
    ¬† ¬† def process_batch(self, significance: np.ndarray) -> np.ndarray:
    ¬† ¬† ¬† ¬† # Vectorized gating (50,000√ó faster than loops)
    ¬† ¬† ¬† ¬† return significance > self.threshold
    ```
    
    
    **GitHub:**
    https://github.com/oluwafemidiakhoa/adaptive-sparse-training
    
    
    **Good for Python devs interested in:**
    - ML engineering practices
    - Control systems in Python
    - GPU optimization
    - Production ML code
    
    
    Let me know if you have questions about the implementation!",0,5,2025-10-18 17:36:20,Klutzy-Aardvark4361,https://www.reddit.com/r/Python/comments/1oa0gx2/built_a_pytorch_system_that_trains_ml_models_11/
1o9v5sq,reddit,"Realistically speaking, what can you do with Python besides web backends and ML/DS ?","Hello there!  
I am working in web development for three years and I've got a strong glimpse at most of the programming languages out there. I know CSharp, Python and JavaScript and I've toyed with many others too. My main question is what can you actually build with Python more than app backends or software for machine learning and data science?

There's like lots of libraries designed for making desktop applications or games in Python or physics simulations and much more. But I am pretty sure I've never seen and used an app that is entirely written in Python. At best, I've seen some internal dashboards or tools made at my workplace to monitor our project's parameters and stuff.

There seems to be lots of potential for Python with all these frameworks and libaries supported by so many people. Yet, I can't find an application that is successful and destined for the normal user like a drawing program, a game or an communication app. I know that Python is pretty slow, sometimes dozens of times slower than CSharp/Java. But there are JIT compilers available, an official one is right now in development.

Personally, I enjoy writing Python much more because of it's more functional approach. Sending an input string through sockets in Java is as complicated as instantiating a Socket, a DataInputStream, a DataOutputStream, a Scanner and some more objects I don't remember the name of. In Python it's as easy as passing a string through functions. Java likes to hide primitives behind class walls while Python embraces their use.

So, realistically speaking, what makes Python so unpopular for real, native app development compared to other languages? Given the fact that now the performance gap is closing and hardware is faster?

Thanks!",0,31,2025-10-18 14:00:23,yughiro_destroyer,https://www.reddit.com/r/Python/comments/1o9v5sq/realistically_speaking_what_can_you_do_with/
1o9bk6z,reddit,React Native with Python Backend Developer,"My company has a react native app close to being finished but we need to make a decision on the backend. We have a cms that manages the feed for our content that‚Äôs built in Python and we were thinking of using Python for the backend. We need to hire a developer to do the back end of the app and connect our subscription management software. The app is fitness related and in the future will have device data and gamification. We also may do some algorithms for displaying content etc so possible machine learning or AI. 

Is it better to find someone that can do react native and python or two specialists? Does choosing this stack make it harder to find developers in the future? ",4,4,2025-10-17 21:00:39,Ok-Mechanic940,https://www.reddit.com/r/Python/comments/1o9bk6z/react_native_with_python_backend_developer/
1oa3n4x,reddit,Hot take: list comprehensions are almost always a bad idea,"simply annoyed by the amount of long list comprehensions i find in codebases, what the hell happened to readability, sure, its convenient, but come back to it a month later and you'll hate yourself as well as every other dev that had to read your code.   
  
STOP using list comprehensions if you have more than 1 for loop in it and more than 1 conditional üôè",0,17,2025-10-18 19:40:49,Quirky_Decision_2827,https://www.reddit.com/r/Python/comments/1oa3n4x/hot_take_list_comprehensions_are_almost_always_a/
1o9m98i,reddit,Am I allowed to ask whether anyone has PandasGUI working with 3.14 here?,"LearnPython seems an odd subreddit to ask that question - I'm hoping a power user might see this post and let me know the dependencies external to Python (VS interpreters etc).  Depending upon where you look, the responses vary wildly.",0,0,2025-10-18 05:16:47,myposttracker2,https://www.reddit.com/r/Python/comments/1o9m98i/am_i_allowed_to_ask_whether_anyone_has_pandasgui/
1o8un9r,reddit,"Sanguine ‚Äî Local Semantic Code Search, No Cloud, No APIs","What My Project Does:
Sanguine is a CLI tool that indexes your code across multiple repos and languages using Tree-sitter. It allows you to search for code by meaning, not just keywords. For example:

> sanguine search ""parse http headers""
will find the actual functions that perform that task. It integrates with Git (optional post-commit hook) to keep the index up to date. Everything runs locally ‚Äî no servers, no APIs, no telemetry.


Link:
https://github.com/n1teshy/sanguine

Would love your feedback.",12,2,2025-10-17 08:13:40,Specialist_Ruin_9333,https://www.reddit.com/r/Python/comments/1o8un9r/sanguine_local_semantic_code_search_no_cloud_no/
1o9o3f5,reddit,Guido knew better than his boss,"Looking into the history it appears Guido built Python as a project to just help him in his real job.

It turned out that Python was a more important product than what he was paid to actually do.

I see that as almost a comfort to me that perhaps the work I am assigned is not the work I should be.

Anyone else relate?",0,5,2025-10-18 07:04:05,Jealous_Lock_393,https://www.reddit.com/r/Python/comments/1o9o3f5/guido_knew_better_than_his_boss/
1o9oqao,reddit,Need a function to get the average of two colours,"Hi I am building a program that scans along a line and checks the change in colour.

Is there an easy way to get the average of two colours? E.g. with 0,0,0 and 255,255,255 the average is 128,128,128",0,13,2025-10-18 07:42:52,Jealous_Lock_393,https://www.reddit.com/r/Python/comments/1o9oqao/need_a_function_to_get_the_average_of_two_colours/
1o907tp,reddit,"Talk Python Podcast Ep 523 ‚Äì Pyrefly: Fast, IDE-Friendly Typing for Python","https://talkpython.fm/episodes/show/523/pyrefly-fast-ide-friendly-typing-for-python

Topics covered in this episode:
- Pyrefly = fast type checker plus full IDE language server, built in Rust
- Why speed matters: IDE feel and developer flow
- Designed as a language server from the ground up
- Installation is a single click in editors and simple on the CLI
- Inference first, even for lightly typed code
- Inlay hints in the editor and a one shot CLI to add annotations
- Pragmatic adoption with migration and suppression scripts
- Open source from day one with weekly releases and community input
- Real world anchor: Instagram scale and deep dependency graphs
- Ecosystem alignment rather than ‚Äúthe one true checker‚Äù
- Comparing to ty (Astral)
- Typing helps AI workflows and code mods
- Use today for IDE; adopt type checking as it stabilizes

(Disclaimer: I'm a maintainer for Pyrefly, happy to answer further questions in the comments)
",2,0,2025-10-17 13:41:00,BeamMeUpBiscotti,https://www.reddit.com/r/Python/comments/1o907tp/talk_python_podcast_ep_523_pyrefly_fast/
1o8fz6j,reddit,I built a VS Code extension for uv integration and PEP 723 scripts,"Hey folks! I've been working on a VS Code extension that brings [uv](https://docs.astral.sh/uv/) integration and [PEP 723](https://peps.python.org/pep-0723/) support directly into your editor ‚Äî making Python script development way more powerful.

The extension lets you manage packages, run scripts, and handle dependencies without ever leaving VS Code or switching to the terminal. Plus, with PEP 723 support, your scripts become truly portable and shareable.

Here's what a PEP 723 script looks like:

```python
# /// script
# requires-python = "">=3.9""
# dependencies = [
#     ""cowsay""
# ]
# ///
import cowsay

cowsay.cow(""Hello World!"")
```

You can copy this script anywhere, share it with anyone, and it'll just work ‚Äî no setup instructions needed.

## What My Project Does

My extension provides:
* `uv` integration built directly into VS Code
* Add, remove, and update packages without touching the terminal
* Automatic PEP 723 script metadata detection and management
* Complete LSP support (autocomplete, type checking, go-to-definition) for scripts
* One-click run and debug for scripts
* Smart virtual environment handling behind the scenes

Basically, you get the speed and power of `uv` with the convenience of never leaving your editor, plus a better way to write and share self-contained Python scripts.

## Target Audience

This is mainly aimed at:
* Python developers who want faster package management in their workflow
* People who love quick scripts and prototypes without the setup overhead
* Developers who want to share scripts that ""just work"" for anyone

I've been using it daily for my own work and would love to hear your feedback! If you find it useful, a GitHub star would mean a lot ‚≠ê And if you have ideas for improvements or want to contribute, PRs are super welcome! üôå

‚≠ê GitHub: https://github.com/karpetrosyan/uv-vscode

üì¶ Marketplace: https://marketplace.visualstudio.com/items?itemName=KarPetrosyan.uv-vscode",63,10,2025-10-16 20:37:29,karosis88,https://www.reddit.com/r/Python/comments/1o8fz6j/i_built_a_vs_code_extension_for_uv_integration/
1o9o13e,reddit,Python question about dictionaries,"In Python if you have a dictionary k={} and you do del k['s'] it raises an exception.

Why is it designed like this?

I feel like there should be some kind of ""ignore if already deleted"" option.",0,41,2025-10-18 07:00:21,Jealous_Lock_393,https://www.reddit.com/r/Python/comments/1o9o13e/python_question_about_dictionaries/
1o9ctmg,reddit,[Project] git2mind ‚Äî Summarize your repo for AI models in seconds,"Hi folks! Ever tried feeding a large codebase to an LLM, only to hit the context window limit? Zipping it or copying files is a pain, and Repomix just bundled the whole project instead of giving a clean summary.

### What my project does?
**git2mind** solves this: it‚Äôs a CLI tool that generates a clean Markdown or JSON summary of your repo. Think of it as a ‚ÄúTL;DR‚Äù for your codebase. 

It generates a general summary by extracting the names of classes and functions, without including the actual code. As long as the variable, class, and function names are meaningful, the AI can easily understand their purpose.
### Target audience
Python developers who want brief summary of their project for onboarding and documentation generation.
### Comparison
The tool is similiar to Repomix but doesn't include the source code in the output. I tried to feed Repomix output to local models on Ollama and models couldn't read majority of the file because the file was too large.

### Installation
**Source code:** [https://github.com/yegekucuk/git2mind](https://github.com/yegekucuk/git2mind)
The project is on PyPi so you can install with pip. The README file is fairly detailed and easy to read, you can find the flags, usage tips and examples there. You can install and try the tool as easy as this:
```sh
# Install
pip install git2mind
# Run (Generate summary of current directory)
g2m .
```

For now, the project really summarizes only Python projects. Currently, git2mind parses Python, Markdown, and Dockerfile files. But I plan to add parsers for many other programming languages. ",0,0,2025-10-17 21:49:46,ResearchSwimming6553,https://www.reddit.com/r/Python/comments/1o9ctmg/project_git2mind_summarize_your_repo_for_ai/
1o9i7p0,reddit,"Uber Eats Account Generator Showcase, and ethical concerns?","Hey yall, I wanted to discuss the ethical concerns about this new project I did. This area in python on web scraping & automation has pretty divided opinions based on what im seeing so far, so im looking to get your guys insight on things. 

  
So I got into automation not too long ago, there was this guy in a small community im in asking for help on this project he was doing related to uber, so I tried helping but didn't really have the answers to his questions. His solution required mobile requests, so I started to do more research on it. I hit a hard block for around a week, as there are BARLEY any resources on youtube or online in general. Most the guides are very simple and just scratch the surface. I had to do a lot of trial and error and finally got a medium understanding on this area of automation. After spending a long time purely on research and starting to build the project, I finished the prototype if you would call it that in around a month or so working almost every day. In the middle of this, I asked others for help in different web scraping communities, and I had quite a few chats on the ethics of this project. So, as any normal person would do, I tried looking for anything related to any developer or technical support team I could report this issue to. There was no reliable places I could email or submit a form, and reliable in the sense that they actually listen and attempt to do anything about this problem. I talked with their normal support team, and they kept telling me things like 'I will escalate your case sir' which pissed me off, because I know damn well they ghosted me each time. So my opinion on this topic is that it should be allowed to do research and have practice and open sourced material for learning, and companies should have a dedicated(and actually helpful) support team for developers and people who actually know their stuff. These projects help out the companies security a lot as well. However, the other opinion I heard was that the user experience would go down when companies add more security, such as captcha and stuff. But cmon, is the user experience really that important to where we sacrifice security?? So honestly would want your thoughts on this, and see other perspectives on this, especially in an era where bots are becoming really advanced.

  
Now heres the brief description overview/showcase of my project:

* Automatically generates uber eats accounts all using their mobile api
* To make this, I used a jailbroken iphone(to bypass ssl pinning) and mitmproxy to capture the network requests of their api
* Built it out using python curl\_cffi library to make requests, useful for spoofing the tls handshake to make the requests look more authentic
* Options to use catch-all domains with googles imap, or a list of hotmail accounts, to generate mass amounts in batch.
* Auto gets the OTP code on signup from either hotmail or google imap
*  And a couple other stuff like proxy support, multi imap domain support, and spoofed device data and signature to avoid spam looking account generations.

  
If anyone would like to check it out, its open-sourced on github here: [https://github.com/yubunus/Uber-Eats-Account-Generator](https://github.com/yubunus/Uber-Eats-Account-Generator)

  
Honestly the learning curve on this was brutal, im thinking of maybe making my own youtube video to guide beginners, with something thats actually a bit more advanced and not some basic api requests like most youtube videos I watched during my research. Let me know if thats something yall would be interested in. But do you guys think there should be more educational resources covering this?",0,11,2025-10-18 01:48:46,TheCompMann,https://www.reddit.com/r/Python/comments/1o9i7p0/uber_eats_account_generator_showcase_and_ethical/
1o8pn4t,reddit,Made A Video Media Player that Plays Multi-Track Audio with Python,"# Crusty Media Player

I made a media player that was built to be able to take Multi-Track Video Files (ex: If you clip Recordings with separate Audio Tracks like System Audio and Microphone Audio) and give you the ability to play them back with both tracks synced without the use of an external editing software like Premiere Pro! And it's Open Source!

# What This Project Does.

It utilizes¬†[ffmpeg](https://ffmpeg.org/)¬†bundled in to rip apart audio tracks from multi-tracked video media and¬†[PyQt6](https://www.pythonguis.com/tutorials/pyqt6-widgets)¬†to build the application and display video media.

[GitHub](https://github.com/CrustyMonk/Crusty-Media-Player)¬†**<---- Repo Here**

[Crusty Media Player v0.1.1](https://github.com/CrustyMonk/Crusty-Media-Player/releases/tag/MediaPlayer)¬†**<---- First Downloadable Release Here**

# Why Did I Make This?

It's simple really lol. I like clipping funny and cool parts of when my friends and I play video games and such. I also like sometimes editing the videos as a hobby! To make the video editing simpler I have my recording settings set to record two tracks of audio, my system audio, and my microphone audio separate. The problem lies in that, if I ever want to just pull up a clip to show a friend or something, with any other media player I've used I am only able to select one track or the other! I have to open Premiere pro with my game running (Making my machine use a lot of resources!) and drag the clip into Premiere. This solves that problem by being able to just open the file with the low resource app and watch the clip with all the audio goods!

# Target Audience?

If you really have that niche issue that I have, then Crusty Media Player might be perfect for you! I just have the .exe pinned to my task bar so I can run it whenever I get the urge to show off or even just view a clip!

# Quick Start

0. Download the packaged zip folder containing the .exe and bundled packages from the¬†[Downloadable Release](https://github.com/CrustyMonk/Crusty-Media-Player/releases/tag/MediaPlayer)

1. Extract zip folder contents to desired location
2. Run the¬†**Crusty\_Media\_Player.exe**
3. If prompted with ""Windows protected your PC"" Pop-up, just click ""More Info"" and then ""Run Anyway""
4. Open Video Files that contain up to two tracks of audio (i.e. System and Microphone Audio)
5. Watch the media all in sync! (Without the use of an editing software!)

I would really appreciate any constructive criticism and any suggestions on things that I could add it for ease of use in future releases as well!

# Comparison

Media Players like VLC and such also play video files from your computer. When using these tools though, you are always unable to play both audio tracks for multi-tracked videos simultaneously! Crusty Media Player fixes this problem, making you able to view multi-track audio media with both tracks simultaneously without the use of any resource heavy editing software like Premiere Pro or Filmora.

# TLDR

**Crusty Media Player**¬†is a media player that was built to be able to take Multi-Track Video Files (ex: If you clip Recordings with separate Audio Tracks like System Audio and Microphone Audio) and give you the ability to play them back with both tracks synced without the use of an external editing software like Premiere Pro!",9,1,2025-10-17 03:33:48,Crusty_Monk,https://www.reddit.com/r/Python/comments/1o8pn4t/made_a_video_media_player_that_plays_multitrack/
1o8sxlx,reddit,How to profile django backend + celery worker app?,"I'm working on a decently-sized codebase at my company that runs off a Django backend with Celery workers for computing our workflows. It's getting to the point where we seriously need to start profiling and adding optimizations, and I'm not sure of what tooling exists for this kind of stack. I'm used to compiled languages where it is much more straight-forward. We do not have proper tracing spans or anything of the sort. What's a good solution to profiling this sort of application? The compute-heavy stuff runs on Celery so I was considering just writing a script that launches Django + Celery in subprocesses then attaches pyspy to them and dumps flamegraph/speedscope data after executing calculation commands in a third process. All help is appreciated.",4,9,2025-10-17 06:27:27,auric_gremlin,https://www.reddit.com/r/Python/comments/1o8sxlx/how_to_profile_django_backend_celery_worker_app/
1o8gd22,reddit,Python as a Configuration Language Using Starlark,I wrote an [article](https://openrun.dev/blog/starlark/) about how Pythonic syntax (using Starlark) helps avoids many of the configuration related challenges seen with YAML and other such languages. Let me know any feedback.,17,2,2025-10-16 20:52:05,avkijay,https://www.reddit.com/r/Python/comments/1o8gd22/python_as_a_configuration_language_using_starlark/
1o9a3f0,reddit,invert PDF colors,"`import subprocess`

`import sys`

`import os`



`try:`

`import fitz`

`except ImportError:`

`subprocess.check_call([sys.executable, ""-m"", ""pip"", ""install"", ""PyMuPDF""])`

`import fitz`



`try:`

`import tkinter`

`except ImportError:`

`subprocess.check_call([sys.executable, ""-m"", ""pip"", ""install"", ""tk""])`

`import tkinter`

`from tkinter.filedialog import askopenfilename`



`from PIL import Image, ImageOps`

`try:`

`from PIL import Image`

`except ImportError:`

`subprocess.check_call([sys.executable, ""-m"", ""pip"", ""install"", ""pillow""])`

`from PIL import Image, ImageOps`



`root = tkinter.Tk()`

`root.withdraw()`

`input_path = askopenfilename(title=""Select PDF"", filetypes=[(""PDF files"", ""*.pdf"")])`

`if not input_path:`

`print(""No file selected"")`

`exit()`



`dir_name, base_name = os.path.split(input_path)`

`name, _ = os.path.splitext(base_name)`

`output_path = os.path.join(dir_name, f""{name}_inverted.pdf"")`



`zoom = 4.0  # 4x resolution`

`mat = fitz.Matrix(zoom, zoom)`



`doc = fitz.open(input_path)`

`images = []`



`for page in doc:`

`pix = page.get_pixmap(matrix=mat, alpha=False)`

`img = Image.frombytes(""RGB"", [pix.width, pix.height], pix.samples)`

`img = ImageOps.invert(img)`

`images.append(img.convert(""RGB""))`



`if images:`

`images[0].save(output_path, save_all=True, append_images=images[1:])`

`print(f""inverted PDF saved to: {output_path}"")`

`else:`

`print(""No pages found in PDF"")`

",0,2,2025-10-17 20:03:35,DerrickBagels,https://www.reddit.com/r/Python/comments/1o9a3f0/invert_pdf_colors/
1o8meso,reddit,Friday Daily Thread: r/Python Meta and Free-Talk Fridays,"# Weekly Thread: Meta Discussions and Free Talk Friday üéôÔ∏è

Welcome to Free Talk Friday on /r/Python! This is the place to discuss the r/Python community (meta discussions), Python news, projects, or anything else Python-related!

## How it Works:

1. **Open Mic**: Share your thoughts, questions, or anything you'd like related to Python or the community.
2. **Community Pulse**: Discuss what you feel is working well or what could be improved in the /r/python community.
3. **News & Updates**: Keep up-to-date with the latest in Python and share any news you find interesting.

## Guidelines:

* All topics should be related to Python or the /r/python community.
* Be respectful and follow Reddit's [Code of Conduct](https://www.redditinc.com/policies/content-policy).

## Example Topics:

1. **New Python Release**: What do you think about the new features in Python 3.11?
2. **Community Events**: Any Python meetups or webinars coming up?
3. **Learning Resources**: Found a great Python tutorial? Share it here!
4. **Job Market**: How has Python impacted your career?
5. **Hot Takes**: Got a controversial Python opinion? Let's hear it!
6. **Community Ideas**: Something you'd like to see us do? tell us.

Let's keep the conversation going. Happy discussing! üåü",6,0,2025-10-17 01:00:42,AutoModerator,https://www.reddit.com/r/Python/comments/1o8meso/friday_daily_thread_rpython_meta_and_freetalk/
1o80g8o,reddit,[Project] doespythonhaveit: a semantic search engine for Python libraries,"Hey folks! I've been working on an open-source project called **doespythonhaveit**, a **semantic search engine for Python libraries** powered by `FastAPI` and `sentence-transformers`.

Basically, you can type something like:

>""machine learning time series""

and it'll (hopefully) suggest things like scikit-learn or darts.

The goal is to make discovering Python libraries faster, smarter, and a little less about keyword guessing.

It's not live *yet* (hosting the model costs a bit), but you can **try it locally**, setup instructions are in the repos:

* API: [github.com/hasboi/doespythonhaveit-api](https://github.com/hasboi/doespythonhaveit-api)
* Web: [github.com/hasboi/doespythonhaveit-web](https://github.com/hasboi/doespythonhaveit-web)

---

# What My Project Does

**doespythonhaveit** lets you search Python libraries *by meaning*, not by exact keywords. Instead of googling *""python library for handling CSVs elegantly""* and clicking through five Stack Overflow posts, you can just search that sentence directly ‚Äî and it'll understand what you mean using embeddings.

I am also planning a **terminal version**, so you can type something like:

    dphi <query> <flags>

and it will suggest relevant libraries **without leaving your code editor or terminal**, basically a semantic library search right where you write code.

---

# Target Audience

Mainly aimed at:

* **Developers** who are tired of remembering exact library names
* **Beginners** who want to discover tools without knowing where to start
* **Open-source enthusiasts** who love browsing cool Python projects

Right now it's mostly a **toy project / prototype**, but I‚Äôm hoping to make it stable enough for production someday.

---

# Comparison

It's kinda like if pypi.org and Google had a baby, but that baby actually understands what you're looking for. Unlike traditional search (which relies on exact matches), this one uses semantic similarity. So searching ""plotting dataframes nicely"" might bring up seaborn or plotly, even if you never mention the words ""plot"" or ""graph.""

If you'd like to support deployment and hosting, you can sponsor me via [GitHub Sponsors](https://github.com/sponsors/hasboi) or [Ko-fi](https://ko-fi.com/hasboi).

Also, contributions are super welcome! üôå I am looking for:

* More Python libraries to add to the dataset
* Help cleaning and improving the dataset, so results are more accurate and relevant
* Ideas for improving the search algorithm

Everything else (tech details, install guide, roadmap, etc.) is in the repos. Would love your feedback, PRs, or just general thoughts! üí¨",55,7,2025-10-16 09:13:15,OpportunityAway4972,https://www.reddit.com/r/Python/comments/1o80g8o/project_doespythonhaveit_a_semantic_search_engine/
1o8yhuk,reddit,Turn on Wi-Fi via browser in 7 lines?,"**What My Project Does**

The [mininterface](https://github.com/CZ-NIC/mininterface) project creates dialogs that work everywhere, ex. in the browser.

Here is the app that checks the Wi-Fi status and then turns it on/off. By default, it raises a desktop window with the confirmation dialog. See it here: [https://imgur.com/a/20476ZN](https://imgur.com/a/20476ZN)

    #!/usr/bin/env python3
    from subprocess import check_output, Popen
    from mininterface import run
    
    cmd = ""nmcli"", ""radio"", ""wifi""
    state = check_output(cmd, text=True).strip() # -> 'enabled' / 'disabled'
    
    m = run() # shows the dialog
    if m.confirm(f""The wifi is {state}. Turn it on?""):
        Popen(cmd + (""on"",))
    else:
        Popen(cmd + (""off"",))#!/usr/bin/env python3

However when you put the `interface=""web""` parameter in the `run` function or when use launch the file with the `MININTERFACE_INTERFACE=web`environment variable set like this:

`$ MININTERFACE_INTERFACE=web ./wifi.py`

it starts listening on the HTTP port 64646. That way, you can turn on/off the Wi-Fi status (or do anything else, it's up to you to imagine all the possibilities) remotely.

**Target Audience**

Even though opening a port needs a security measures that I won't enlist here, and thus the functionality I recommend for geeks, the library is ready for the production to handle all the system utility dialogs.

**Comparison**

There is none alternative to [https://github.com/CZ-NIC/mininterface](https://github.com/CZ-NIC/mininterface) that creates dialogs as a desktop application, as a terminal application, or as a web application at once.

However, you may do similar behaviour with these utilies:

\* Zenity ‚Äì just bash dialogs  
\* notify-send ‚Äì small utility to print out a notification in the desktop  
\* [Gooey](https://github.com/chriskiehl/Gooey) ‚Äì turn python script into a GUI application ‚Äì needs to work with ArgumentParser",0,1,2025-10-17 12:15:01,the-e2rd,https://www.reddit.com/r/Python/comments/1o8yhuk/turn_on_wifi_via_browser_in_7_lines/
1o97fxh,reddit,"I built a tool to run Python in a full Linux environment, instantly, in your browser.","I've been building a tool called Stacknow. It's a full Linux environment that boots instantly in a browser tab using WebAssembly. This isn't a remote VM‚Äîall the code runs locally on your machine, completely sandboxed from your file system.

Here's what it's for:

Instantly test libraries:¬†pip install¬†anything without touching your local setup.

Zero-setup scripting:¬†Just open a tab and start writing Python.

Safe execution:¬†The browser's sandbox means it's totally isolated from your machine.

Shareable environments:¬†Send a single link to a working, reproducible setup.

I'd love for you to try it out and let me know what you think. It's still early, so any feedback is super valuable.

You can find it here:¬†[https://console.stacknow.io/](https://console.stacknow.io/)",0,15,2025-10-17 18:22:22,Substantial-Stage459,https://www.reddit.com/r/Python/comments/1o97fxh/i_built_a_tool_to_run_python_in_a_full_linux/
1o86n2t,reddit,InfoLens - A python based GUI dashboard,"Hello everyone!

I‚Äôve been working on a Python project called **InfoLens,** a **CustomTkinter**\-based **GUI dashboard** that fetches and displays personalized information across multiple genres ‚Äî **news, finance,** and **weather** ‚Äî all in one place.

# What My Project Does:

It pulls live data from credible sources like:

üß™**ScienceDaily** ‚Äì for science and innovation headlines

üí∞**Economic Times & Yahoo Finance API** ‚Äì for real-time stock data and trends

üå§Ô∏è[**wttr.in**](http://wttr.in) **API** ‚Äì for location-based weather updates

# Purpose:

We live in a world where **information surrounds us everywhere.** In fact, the average person in 2025 processes about **75-80 GB of information per day** up from 34 GB in 2008 and 63 GB in 2012. That includes all the **ads**, **unnecessary clutter** that one doesn't even need. However, studies have shown **color-coded dashboards** improved **visual search performance** and **recall**, enhancing both comprehension and memory; exactly **what InfoLens does!**

# üîßBuilt with:

Python

CustomTkinter for the GUI

Web scraping (BeautifulSoup, requests)

APIs (yfinance, [wttr.in](http://wttr.in), etc.)

# Target Audience:

Currently this is a side project, but meant for all python enthusiasts who are eager to provide their invaluable experience in this app.

# Comparison:

As a GUI dashboard, InfoLens focuses highly on **data readability.** While other tools like Perplexity exist, InfoLens is **unique in the problem solving sense**, using web scraping to **remove  clutter** such as ads and provides you only what you need. Its still in its **budding phase** as it started out as just a science exhibition project, and **further refinements** in quality and user access and make it highly efficient.

# I‚Äôd love your feedback on:

UI/UX ‚Äì is the layout intuitive or could it be cleaner?

Performance or usability improvements

Feature ideas (e.g., more data sources, customization, alerts, etc.)

**GitHub Repo:** [https://github.com/WaveInCode/InfoLens.git](https://github.com/WaveInCode/InfoLens.git)

If you try it out, please let me know what you think! All feedback ‚Äî big or small ‚Äî will help shape future versions of InfoLens. Thanks in advance for checking it out! üöÄ",7,7,2025-10-16 14:48:27,Cool-Worry-8045,https://www.reddit.com/r/Python/comments/1o86n2t/infolens_a_python_based_gui_dashboard/
1o86j5t,reddit,Automating your heating with Octopus Energy AGILE tariff,"Hi all, I've just made a Python tutorial for how you can automate your electric heaters during the Agile Energy Plunge Pricing, in the UK.

Effectively, we're automatically switching on our smart plugs (electric radiators), when the price of electricity is negative. This results in consistent credit back every time there's an Octopus Energy Plunge Pricing, plus a nice warm home.

You just need Tapo smart plugs and a Raspberry pi.

[https://youtu.be/ch-9DpZL6Vg](https://youtu.be/ch-9DpZL6Vg)

code:

[https://github.com/yojoebosolo/AutoHeating/](https://github.com/yojoebosolo/AutoHeating/)

Hope it's helpful to some of you.",3,0,2025-10-16 14:44:02,None,https://www.reddit.com/r/Python/comments/1o86j5t/automating_your_heating_with_octopus_energy_agile/
1o8wuhr,reddit,What is the easiest neural network project to someone who is just starting with AI/ML and python,Is it easier to work with datasheets? like predicting the probability of someone having diabetes using pima Indians Diabetes Database? Or is images or something else easier ,0,8,2025-10-17 10:36:47,tomuchto1,https://www.reddit.com/r/Python/comments/1o8wuhr/what_is_the_easiest_neural_network_project_to/
1o8yfb5,reddit,Made an encryption tool in Python (and use of some C),"

# PyLI

Made a standalone GUI app that encrypts files locally, no middle-man interaction.

Uses **AES-256-GCM** or **ChaCha20-Poly1305** for encryption and **Argon2ID** (or **PBKDF2** as fallback) for key derivation. Works offline, open source (MIT);

\~40MB standalone.

# Source code

[**GitHub**](https://github.com/Commonwealthrocks/PyLI) **<-- here!**

More can be seen on my repo's README file, I recommend reading it before trying the app.

# What my project does?

Encrypts files using **AES-256-GCM (AEAD)** or **ChaCha20-Poly1305** locally on your PC / machine; uses **Argon2ID** as said earlier of **PBDKF2** for KDF.

  
All cryptowork is tweakable in the settings of the app.

# QUICK START

0. Install the .exe (or source) from the dist folder / releases tab for the full source code.

1. Run the app

2. Select file(s) or a folder; folders only work with drag n' drop

3. Choose a password, any kind for a simple test really

4. Hit encrypt / decrypt

It is recommended to also check out the apps settings tab, especially for archive mode and the crypto tweaks.

# FEATURES (as said earlier)

\- **AES-256-GCM or ChaCha20-Poly1305** encryption

\- Archive mode (encrypt multiple files into one; basically knockoff .zip files)

\- Optional compression

\- Optional error correction (Reedsolo)

\- Works completely offline

# COMPARISON

Tools like **WinRAR** or **7-zip** MIGHT do similar but they are compression focused; **PyLI** is dedicated to security / encryption. More dedicated tools for this stuff like **VeraCrypt** is for whole disks, overkill for regular files or **AxCrypt** which is also based on security. But they use **AES-128** for the free tier and their docs about the core crypto itself is vague.

# Target audience

**PyLI** is MOSTLY meant for power users, or users who want control over their settings without going through the pain that is trying to use **GPG** or **PGP**.

# TL--DR

**PyLI** as a whole can be seen as ""joke"" software, but from what it offers; you can decide that.

The code is not professionally audited or reviewed, but is open source for the community. Feel free to leave any feedback!",0,4,2025-10-17 12:11:04,CommonWealthHimself,https://www.reddit.com/r/Python/comments/1o8yfb5/made_an_encryption_tool_in_python_and_use_of_some/
1o8uh8d,reddit,gitfluff: Commit Message Linter (Conventional Commits + AI signature cleanup),"Hey Peeps,

I'm pleased to show case a new small and very fast commit message linter and autofixer tool [gitfluff](https://github.com/Goldziher/gitfluff).

## What My Project Does

Claude Code kept injecting ""ü§ñ Co-Authored-By"" trailers into commits. You can disable it now in local settings, but I needed team-wide enforcement across multiple repos and multiple languages. Plus I wanted strict Conventional Commits validation without cobbling together multiple tools.

## What it does

- **Enforces Conventional Commits 1.0.0** (type, scope, breaking changes, footers) with full spec compliance.
- **Strips AI signatures** automatically (configurable patterns)
- **Validates or rewrites** messages in place with `--write`
- **Zero config** to start, optional `.gitfluff.toml` for custom rules which allow you to do whatever you want basically. 

## Install & Use

The tool is written and rust and is compiled to multiple platforms. You can install it directly via cargo:

```bash
cargo install gitfluff
```

Or using homebrew:

```bash
brew install goldziher/tap/gitfluff
```

Or via NPM:

```bash
npm install -g gitfluff
```

Or via PIP:

```bash
pip install gitfluff
```

You can then install it as a commit message hook:

```bash
gitfluff hook install commit-msg --write
```

Alternatively you can install it as a hook for `pre-commit` (or `prek`) by adding the following to you `.pre-commit-config`:

```yaml
repos:
  - repo: https://github.com/Goldziher/gitfluff
    rev: v0.2.0
    hooks:
      - id: gitfluff-lint
        name: gitfluff (lint)
        entry: gitfluff lint --from-file
        language: system
        stages: [commit-msg]
        args: [""{commit_msg_file}""]

      # or using the autofix hook:

      # - id: gitfluff-write
      #  name: gitfluff (lint + write)
      #  entry: gitfluff lint --from-file
      #  language: system
      #  stages: [commit-msg]
      #  args: [""{commit_msg_file}"", ""--write""]
```

And then run `pre-commit install --hook-type commit-msg`, which will install the hook correctly. 

You can also integrate it into `lefthook` or `husky` using `npx` or `uvx` commands!

Main workflow: add to pre-commit config, forget about it. Devs commit normally, hook validates/cleans messages before they hit history.

## Target Audience

Teams enforcing commit conventions across polyglot projects. Devs using AI coding assistants who want clean commit history. Anyone who needs Conventional Commits validation without JavaScript dependencies.

## Comparison

- **commitlint** (Node ecosystem, requires separate config for cleanups)
- **cocogitto** (Rust, focused on semver release workflows)
- **gitlint** (Python, extensible but requires custom plugins for AI signatures)

And many other tools of course, I cant claim this is original. The main difference is that `gitfluff` combines validation + pattern cleanup in one binary with prebuilt distributions for all major platforms.

As usual, if you like the tool, star [github.com/Goldziher/gitfluff](https://github.com/Goldziher/gitfluff).",0,7,2025-10-17 08:02:43,Goldziher,https://www.reddit.com/r/Python/comments/1o8uh8d/gitfluff_commit_message_linter_conventional/
1o7bat4,reddit,Zuban - A Python Language Server / Typechecker - Beta Release,"I have just created a Beta Release for Zuban.

Zuban now supports all key features of a Python Language Server ‚Äî including completions, rename, and type checking ‚Äî with auto-imports coming soon.

Zuban is a high-performance Python Language Server and type checker implemented in Rust, by the author of Jedi. Zuban is **20‚Äì200√ó faster than Mypy**, while using roughly half the memory and CPU compared to Ty and Pyrefly. It offers both a PyRight-like mode and a Mypy-compatible mode, which behaves just like Mypy;  
supporting the same config files, command-line flags, and error messages.

You can find the source code [here](https://github.com/zubanls/zuban/).  
Different Python type checkers are compared [here](https://htmlpreview.github.io/?https://github.com/python/typing/blob/main/conformance/results/results.html).

The Zuban type checker is now in a very stable state, with many issues resolved and only a few remaining. The next planned features include dedicated support for Django and Pytest.

### Support

If you have a large Mypy codebase that needs significant bug fixing, I‚Äôd be happy to help.",133,39,2025-10-15 14:40:24,zubanls,https://www.reddit.com/r/Python/comments/1o7bat4/zuban_a_python_language_server_typechecker_beta/
1o77mip,reddit,Recommending `prek` - the necessary Rust rewrite of `pre-commit`,"Hi peeps,

I wanna recommend to all of you the tool [prek](https://github.com/j178/prek) to you. This is a Rust rewrite of the established Python tool [pre-commit](https://pre-commit.com), which is widely used. Pre-commit is a great tool but it suffers from several limitations:

1. Its pretty slow (although its surprisingly fast for being written in Python)
2. The maintainer ([asottile](https://github.com/asottile)) made it very clear that he is not willing to introduce monorepo support or any other advanced features (e.g. parallelization) asked over the years

I was following this project from its inception (whats now called Prek) and it evolved both very fast and very well. I am now using it across multiple project, e.g. in [Kreuzberg](https://github.com/Goldziher/kreuzberg), both locally and in CI and it does bring in an at least x10 speed improvement (linting and autoupdate commands!)

So, I warmly recommend this tool, and do show your support for Prek by giving it a star!",214,108,2025-10-15 11:46:11,Goldziher,https://www.reddit.com/r/Python/comments/1o77mip/recommending_prek_the_necessary_rust_rewrite_of/
1o8niqf,reddit,New to Coding in Python,"I don't have a question related to Python. I just wanted to say that I'm new to python and I'm just now finding out there is a function called ""cumsum."" As far as I'm concerned, python is now a 10/10 coding language.",0,1,2025-10-17 01:52:58,YaBoi843,https://www.reddit.com/r/Python/comments/1o8niqf/new_to_coding_in_python/
1o8apus,reddit,[Project] mini language based on Python: Montyp,"I thought it would be fun to base a mini language on python.

The result is less than stellar after a lot of work, there is basically not much, but anyway...I just wanted to do something funny.

If anyone wants to look around and contribute, or give advice, I would honored...

I wanted to call it Monthy or Monty to continue the reference on Monty Python but it is apparently already taken...

Anyway... I wanted to sort of make it even more human readable than python, and also (I know that this is crazy and impossible, but indentation made me a bit crazy at first I was always having indentation errors) indentation free, case insensitive keywords and various other things.

I know all of this may be stupid.

But anyway....here we are, this is the github¬†[repo](https://github.com/SimonGPrs/montyp_language).

  
I also tried to compile Montyp in Montyp but this has so far failed and failed and failed and failed forever. The file is nonetheless on Github.

  
If anyone has any advice, great...



\--------------------------------------------------------------------------------------------------------------------  
**What Montyp Does**

As said, the idea of Montyp was to have mega simple programming language that compiles to Python but removes the pain points that frustrate beginners related to strict indentation and other points. The idea would be to approach even more plain English.

Instead of writing:

    if score >= 10:
        print(f""Score: {score}"")

You write:

    if score is at least 10 ¬†¬†¬† say: Score {score} end

**Target Audience**

Curious people,

Advanced developers that would be crazy enough to play around this ""toy"" language

**Comparison**

I am not aware of other languages based on Python",0,13,2025-10-16 17:24:08,Whole-Ad7298,https://www.reddit.com/r/Python/comments/1o8apus/project_mini_language_based_on_python_montyp/
1o8e955,reddit,searching for job by preparing my own,"hi,am 35 years old with no prior experience in IT,now am preparing myself as python developer or related jobs.I learnt Python,Numpy,Pandas,Mattplotlib,[SQL.Am](http://SQL.Am) still in a process of learning. To get a job now may i know the path to proceed forward other than applying online? Any other guys who passed through the same path? Any other inputs plz.",0,3,2025-10-16 19:32:54,Zestyclose_Block5381,https://www.reddit.com/r/Python/comments/1o8e955/searching_for_job_by_preparing_my_own/
1o8a2bi,reddit,Quickest way to build a custom AI chatbot to query your python project,"Hi Community,

I‚Äôve been working on a side project to make it easier for Python developers to understand, explore, and interact with their own codebases ‚Äî using AI.

# What My Project Does

The tool indexes your code and creates a chatbot that acts like a personal coding assistant for your project.  
You can ask it things like:

* Generate code base on these functional requirements and my current code context
* Explain a specific API call
* Create a flowchart of this API call

It‚Äôs designed to help you navigate large projects faster and automate documentation and comprehension tasks.

# Quickstart

We‚Äôve got a hosted version you can try:

üëâ [https://firstmate.io/](https://firstmate.io/)  
üëâ [https://console.firstmate.io/](https://console.firstmate.io/)

Just connect your repo (GitHub or local) ‚Äî the chatbot will automatically build itself.

# Target Audience

* Python developers

# Comparison

* We are faster than index your code & build your own chatbot
* Unlike GitHub's Semantic, we generate a system of tools for you
* From my test, we work better than Github's copilot search. I might be biased. Let me know if you think otherwise üôè

# Features

* Supports Python projects
* Understands code structure, dependencies, and flow
* Lets you query or modify code directly
* Works on both private and open-source repos

Our Github: [https://github.com/firstmatecloud](https://github.com/firstmatecloud)

If it‚Äôs useful, a ‚≠ê on the repo and comments here really help prioritize the roadmap. üôè",0,4,2025-10-16 16:59:55,Ill_Ad4125,https://www.reddit.com/r/Python/comments/1o8a2bi/quickest_way_to_build_a_custom_ai_chatbot_to/
1o71ejn,reddit,GIL free and thread safety,"For Python 3.14 free GIL version to be usable, shouldn't also Python libraries be re-written to become thread safe? (or the underlying C infrastructure)",99,24,2025-10-15 05:20:34,Active-Fuel-49,https://www.reddit.com/r/Python/comments/1o71ejn/gil_free_and_thread_safety/
1o7r7dw,reddit,"blank-line-after-blocks, a formatter to improve readability and prevent errors","I recently developed [blank-line-after-blocks](https://github.com/jsh9/blank-line-after-blocks), a Python auto-formatter to improve code readability and prevent human errors.

# What My Project Does

It adds a blank line after if/for/while/with/try blocks. See the example below (the lines with `+` sign are added by this formatter.

      if condition:
          do_something()
    +
      next_statement()  if condition:
          do_something()
    +
      next_statement()

**Why is it s a good idea to add a blank line after blocks?**

This can improve readability:

* A blank line sends a visual cue that a block ends here
* A blank line makes it easier to distinguish `if` and `if/else` blocks. Look at this example

Hard to distinguish:

    if a > 2:
        print(a)
    if b < 3:
        print(b)
    else:
        print('1')

Easier to distinguish

    if a > 2:
        print(a)
    
    if b < 3:
        print(b)
    else:
        print('1')

Having a blank line after blocks can also reduce the chance of human errors. Sometimes we accidentally hit ""Tab"" or ""Backspace"" on our keyboards. This could introduce costly errors in Python, because Python relies on indentation as syntax cues.

Here is an example:

    raw_result = 0
    for i in range(10):
        raw_result += i
    final_result = my_func(raw_result)

If we accidentally hit ""Tab"" on the last line, the code becomes:

    raw_result = 0
    for i in range(10):
        raw_result += i
        final_result = my_func(raw_result)

which will yield a completely different result. **This error is very difficult to find, thus a costly error.**

But if we add a blank line after the block,

    raw_result = 0
    for i in range(10):
        raw_result += i
    
        final_result = my_func(raw_result)

It would be ***slightly*** easier to find out the error.

# Target Audience

Anyone who writes Python code. But this is especially helpful for production-level code, because reducing diffs and reducing human errors can be valuable.

# Comparison with Alternatives

As far as I know, there are no alternatives. No existing Python formatter does this.  
  
",1,4,2025-10-16 00:50:41,Linter-Method-589,https://www.reddit.com/r/Python/comments/1o7r7dw/blanklineafterblocks_a_formatter_to_improve/
1o7u9q1,reddit,Interactive HMTL,"Hi guys

I‚Äôm creating an interactive HTML page to study graphs. The idea is to create an interface where the user can click on each node and see information about it. Another feature is to display the graph legend in a pop-up window.
I‚Äôm using NetworkX to create the graph and Bokeh to generate the HTML. Do you know if it‚Äôs possible to create a professional interface using Bokeh or another Python library? 
I create a page but seems so simple :(",0,5,2025-10-16 03:13:34,gps100,https://www.reddit.com/r/Python/comments/1o7u9q1/interactive_hmtl/
1o6u9cg,reddit,Gave up on C++ and just went with Python,"I was super hesitant on going with python, since it felt like I wasn't gonna learn alot if I just go with python... which everyone in ProgrammingHumor was dissing on... then I started automating stuff... and Python just makes everything so smooth.... then I learned about the wonders of Cython... now I'm high on Cython..

How do you all speed up your python project?",131,74,2025-10-14 23:44:45,Gazuroth,https://www.reddit.com/r/Python/comments/1o6u9cg/gave_up_on_c_and_just_went_with_python/
1o7k3y6,reddit,Completely rewrote Buridan UI,"Hey everyone, so today I decided to rewrite my ui lib from scratch and implemented a new site architecture. It's not perfect nor is it the last iteration, but I really liked the results and so I deccided to share it here!

**What My Project Does**

Buridan UI is a component library for Reflex that you copy and paste directly into your project instead of installing as a package. It provides:

* Wrapped React components (CountUp, Icons, Spinner, Typed effects, etc.)
* Pre-built UI patterns and layouts
* Chart components and data visualizations
* JavaScript integrations ready to use
* Multiple theming options (Hematite, Feyrouz, Yaqout, Zumurrud, Kahraman, Amethyst)

New features in this rewrite:

* **Markdown files static serve** \- you can view the content as markdown
* **AI assistant integration** \- Click to open ChatGPT or Claude with pre-filled prompts about the component or page that can be easily scrapped in markdown
* **SPA architecture** \- Completely rebuilt for smoother navigation and better performance
* **Cleaner codebase** \- Rewrote everything from scratch with lessons learned from v1

**Target Audience**

This is built for any Reflex developer, the copy-paste approach means you can use it in serious projects without worrying about the library being abandoned or breaking changes in updates.

**Comparison**

It's heavily inspired theme from shadcn but its also heavily tailored for the reflex ecosystem, specifically where we wrap react and include JS integration documentation



You can check it out here: [Buridan UI](https://buridan-ui.reflex.run/docs/getting-started/introduction)  
The repo (it's open soruce!): [https://github.com/buridan-ui/ui](https://github.com/buridan-ui/ui)  


Feedback is always welcome! 

",4,2,2025-10-15 20:08:00,None,https://www.reddit.com/r/Python/comments/1o7k3y6/completely_rewrote_buridan_ui/
1o77t5h,reddit,Built a Tool to Sync GitHub Issues to Linear ‚Äì Feedback Welcome!,"Hey everyone,

**Target Audience**: Useful for technical support engineers, dev leads, or anyone managing projects via GitHub and Linear.

**What my project does**  
I‚Äôve built a tool that automatically syncs GitHub issues into Linear tickets. The idea is to reduce the manual overhead of copy-pasting or re-creating issues across platforms, especially when you're using GitHub for external collaboration (e.g., open source, customer bug reports) and Linear for internal planning and prioritization.

You can find it here:  
üîó [https://github.com/olaaustine/github-issues-linear](https://github.com/olaaustine/github-issues-linear)

The README is fairly detailed and should help you get it running quickly ‚Äî it's currently packaged as a customizable Docker container, so setup should be straightforward if you‚Äôre familiar with containers.

üß™ **Status:**  
The project is still in early development, so it‚Äôs very much a WIP. But it works, and I‚Äôm actively iterating on it. The goal is to make it reliable enough for daily use and eventually extend support to other issue trackers beyond Linear.

I‚Äôd really appreciate any thoughts or ideas ‚Äì even if it‚Äôs just a quick reaction. Thanks!",10,6,2025-10-15 11:56:37,Virtual_Initiative67,https://www.reddit.com/r/Python/comments/1o77t5h/built_a_tool_to_sync_github_issues_to_linear/
1o7rffb,reddit,"Thursday Daily Thread: Python Careers, Courses, and Furthering Education!","# Weekly Thread: Professional Use, Jobs, and Education üè¢

Welcome to this week's discussion on Python in the professional world! This is your spot to talk about job hunting, career growth, and educational resources in Python. Please note, this thread is **not for recruitment**.

---

## How it Works:

1. **Career Talk**: Discuss using Python in your job, or the job market for Python roles.
2. **Education Q&A**: Ask or answer questions about Python courses, certifications, and educational resources.
3. **Workplace Chat**: Share your experiences, challenges, or success stories about using Python professionally.

---

## Guidelines:

- This thread is **not for recruitment**. For job postings, please see r/PythonJobs or the recruitment thread in the sidebar.
- Keep discussions relevant to Python in the professional and educational context.
  
---

## Example Topics:

1. **Career Paths**: What kinds of roles are out there for Python developers?
2. **Certifications**: Are Python certifications worth it?
3. **Course Recommendations**: Any good advanced Python courses to recommend?
4. **Workplace Tools**: What Python libraries are indispensable in your professional work?
5. **Interview Tips**: What types of Python questions are commonly asked in interviews?

---

Let's help each other grow in our careers and education. Happy discussing! üåü",1,0,2025-10-16 01:00:29,AutoModerator,https://www.reddit.com/r/Python/comments/1o7rffb/thursday_daily_thread_python_careers_courses_and/
1o7fcvo,reddit,"I built a classic ""Crack the Code"" console game in Python: Digit Detective üïµÔ∏è‚Äç‚ôÄÔ∏è","Hello everyone! I'm sharing my completed project: Digit Detective, a pure Python console game.

My goal was to create a clean, working implementation of a code-breaking puzzle game, focusing on clean structure and good input validation.



# üîç What My Project Does (The Game and Code)



Digit Detective is a command-line utility where you try to crack a secret 4-digit numeric code in 8 attempts.

* Gameplay: The game gives you instant, clear textual feedback after each guess, indicating how many digits are:
   1. Correct and in the Right Position.
   2. Correct but in the Wrong Position.
* Code Focus: The project demonstrates basic Object-Oriented Programming (OOP), robust input validation to prevent non-numeric guesses, and clear separation of game logic. It's a single, runnable Python file.



# üéØ Target Audience



While anyone can play, the project is structured to benefit specific audiences:

* Python Beginners/Learners: The code is straightforward. It's an excellent, simple project to read, clone, and understand basic game loop structure and logic implementation.
* Fans of Mastermind: If you enjoy classic code-breaking puzzles, this offers a fast, clean, terminal-based version.



# üÜö Comparison:



This project is inspired by the logic of Mastermind, but adapted for the modern terminal environment. Unlike the classic board game:

* It deals exclusively with a 4-digit numeric code (0-9) instead of colored pegs, simplifying input.
* It provides instant, unambiguous textual hints instead of relying on manually tracking black and white pegs.
* The entire experience is self-contained in a single, accessible Python script, emphasizing a focus on logic and code execution over complex UI.

Feel free to check out the [digit-detective.py](http://digit-detective.py) file. I‚Äôd appreciate any feedback on the Python logic, structure, or best practices!

GitHub Link:[https://github.com/itsleenzy/digit-detective](https://github.com/itsleenzy/digit-detective)",3,3,2025-10-15 17:13:01,leenzy-leen,https://www.reddit.com/r/Python/comments/1o7fcvo/i_built_a_classic_crack_the_code_console_game_in/
1o7nwyp,reddit,"OpenJlang BetaV0.1 ""Verna"" is here!","The open source programming language oJl releases its first public version, find out more about the project on the website: https://ojlang.github.io/ojl/index.html See the oJl page on GitHub: https://github.com/ojlang",0,1,2025-10-15 22:33:01,Jaozerakkj,https://www.reddit.com/r/Python/comments/1o7nwyp/openjlang_betav01_verna_is_here/
1o6jivj,reddit,Python 3.15 Alpha Released,"[https://docs.python.org/3.15/whatsnew/3.15.html](https://docs.python.org/3.15/whatsnew/3.15.html)

  
Summary ‚Äì Release highlights

* [**PEP 799**](https://peps.python.org/pep-0799/):¬†[A dedicated profiling package for organizing Python profiling tools](https://docs.python.org/3.15/whatsnew/3.15.html#whatsnew315-sampling-profiler)
* [**PEP 686**](https://peps.python.org/pep-0686/):¬†[Python now uses UTF-8 as the default encoding](https://docs.python.org/3.15/whatsnew/3.15.html#whatsnew315-utf8-default)
* [**PEP 782**](https://peps.python.org/pep-0782/):¬†[A new PyBytesWriter C API to create a Python bytes object](https://docs.python.org/3.15/whatsnew/3.15.html#whatsnew315-pep782)
* [Improved error messages](https://docs.python.org/3.15/whatsnew/3.15.html#whatsnew315-improved-error-messages)

",189,35,2025-10-14 17:01:22,miabajic,https://www.reddit.com/r/Python/comments/1o6jivj/python_315_alpha_released/
1o6v4fb,reddit,I wrote a short tutorial on how to kill the GIL in Python 3.14,"Hey friends, for those who have heard about the new free-threading build but haven't had a chance to try it out, I wrote this tutorial that comes with a benchmark: [https://www.neelsomaniblog.com/p/killing-the-gil-how-to-use-python](https://www.neelsomaniblog.com/p/killing-the-gil-how-to-use-python)

Feel free to ask me any questions and appreciate any feedback!",47,12,2025-10-15 00:21:13,nsomani,https://www.reddit.com/r/Python/comments/1o6v4fb/i_wrote_a_short_tutorial_on_how_to_kill_the_gil/
1o7paue,reddit,Getting back into Python,I‚Äôm a perpetual Python beginner since I don‚Äôt have a chance to use it very often. Can anyone recommend any resources/ tutorials/ short courses for me to get up to speed fast? Thanks!,0,10,2025-10-15 23:30:44,dedenorio,https://www.reddit.com/r/Python/comments/1o7paue/getting_back_into_python/
1o74arl,reddit,I built a modern async Python SDK for Expo Push Notifications (with full type hints!),"I've been working with Expo push notifications in Python and got frustrated with the limitations of existing SDKs - no async support, limited type safety, and missing modern features. So I built \*\*async-expo-push-notifications\*\*.



\## What My Project Does



A Python SDK for sending push notifications through Expo's push notification service. It provides both async and sync interfaces for sending notifications to mobile apps built with Expo/React Native. The library handles message validation, batching, error handling, and provides full type safety with Pydantic models.



\## Target Audience



\*\*Production-ready\*\* for developers building:

\- FastAPI/Django/ETC backends that need async push notifications

\- Python servers communicating with Expo/React Native mobile apps

\- Applications requiring type-safe, testable notification systems

\- High-performance apps sending concurrent notifications



Requires Python 3.8+ and works with any modern Python web framework.



\## Comparison



Compared to the existing \[expo-server-sdk-python\](https://github.com/expo-community/expo-server-sdk-python):



| Feature | async-expo-push-notifications | expo-server-sdk-python |

|---------|------------------------------|------------------------|

| Async/await support | ‚úÖ Full async | ‚ùå Sync only |

| Type hints | ‚úÖ Complete | ‚ö†Ô∏è Partial |

| Pydantic models | ‚úÖ Type-safe validation | ‚ùå Named tuples |

| Dependency injection | ‚úÖ Testable | ‚ùå No |

| Rich content (images) | ‚úÖ Supported | ‚ùå No |

| Backward compatible | ‚úÖ Drop-in replacement | - |



The official SDK is great for synchronous use cases, but lacks modern Python features. This SDK provides the same API while adding async support, full type safety, and better testability - perfect for modern async Python applications.



\## Quick Example



\`\`\`python

import asyncio

from exponent\_server\_sdk import AsyncPushClient, PushMessage



async def send\_notification():

async with AsyncPushClient() as client:

message = PushMessage(

to=""ExponentPushToken\[xxxxxxxxxxxxxxxxxxxxxx\]"",

title=""Hello"",

body=""World!"",

data={""extra"": ""data""}

)

ticket = await client.publish(message)

ticket.validate\_response()



asyncio.run(send\_notification())

\`\`\`



\*\*Installation:\*\*

\`\`\`bash

pip install async-expo-push-notifications

\`\`\`



The synchronous API still works exactly the same, so you can migrate gradually. All your existing code continues to work without changes.



\*\*Why I built this:\*\*

The official community SDK is great but hasn't been updated with modern Python features. I wanted something that works seamlessly with async frameworks like FastAPI and provides the type safety that modern Python developers expect.



\*\*Important note:\*\* This is an independent project and not officially maintained by Expo. It's a modern reimplementation with async support.



GitHub: [https://github.com/tmdgusya/async-expo-notification-sdk](https://github.com/tmdgusya/async-expo-notification-sdk)

PyPI: [https://pypi.org/project/async-expo-push-notifications/](https://pypi.org/project/async-expo-push-notifications/)



Would love to hear your feedback and contributions are welcome! Let me know if you have any questions.

",5,0,2025-10-15 08:12:33,kr_roach,https://www.reddit.com/r/Python/comments/1o74arl/i_built_a_modern_async_python_sdk_for_expo_push/
1o6muzv,reddit,"ButtonPad, a simple GUI framework built on tkinter","## What My Project Does



Install: pip install buttonpad

To view the included demo programs: python -m buttonpad

PyPI page: https://pypi.org/project/buttonpad/

Git repo: https://github.com/asweigart/buttonpad

Blog post: https://inventwithpython.com/blog/buttonpad-introduction.html


## Target Audience

* Beginners who want to learn GUI programming without wrestling with verbose frameworks.

* Experienced developers who want to crank out prototypes, internal tools, game ideas, or teaching demos fast.


## Comparison

I modeled them after the design of programmable stream deck or drum machine hardware. Lots of times when I'm making small programs, I'd like to create a desktop app that is just a resizable window of a bunch of buttons and text boxes, but I don't want to think too hard about how to put it together.",18,0,2025-10-14 19:02:09,AlSweigart,https://www.reddit.com/r/Python/comments/1o6muzv/buttonpad_a_simple_gui_framework_built_on_tkinter/
1o69cvi,reddit,I built JSONxplode a complex json flattener,"I built this tool in python and I hope it will help the community. 

This code flattens deep, messy and complex json data into a simple tabular form without the need of providing a schema.

so all you need to do is: from jsonxplode import flatten flattened_json = flatten(messy_json_data)

once this code is finished with the json file none of the object or arrays will be left un packed.

you can access it by doing: pip install jsonxplode

code and proper documentation can be found at:

https://github.com/ThanatosDrive/jsonxplode

https://pypi.org/project/jsonxplode/



in the post i shared at the data engineering sub reddit these were some questions and the answers i provided to them:

why i built this code? because none of the current json flatteners handle properly deep, messy and complex json files without the need of having to read into the json file and define its schema.

how does it deal with some edge case scenarios of eg out of scope duplicate keys? there is a column key counter that increments the column name if it notices that in a row there is 2 of the same columns.

how does it deal with empty values does it do a none or a blank string? data is returned as a list of dictionaries (an array of objects) and if a key appears in one dictionary but not the other one then it will be present in the first one but not the second one.

if this is a real pain point why is there no bigger conversations about the issue this code fixes? people are talking about it but mostly everyone accepted the issue as something that comes with the job.

https://www.reddit.com/r/dataengineering/s/FzZa7pfDYG


I hope that this tool will be useful and I look forward to hearing how you're using it in your projects!",48,20,2025-10-14 08:53:41,Thanatos-Drive,https://www.reddit.com/r/Python/comments/1o69cvi/i_built_jsonxplode_a_complex_json_flattener/
1o6agbj,reddit,How to Design a Searchable PDF Database Archived on Verbatim 128‚ÄØGB Discs?,"Good morning everyone, 
I hope you‚Äôre doing well. 

How would you design and index a searchable database of 200,000 PDF books stored on Verbatim 128 GB optical discs?

Which software tools or programs should be integrated to manage and query the database prior to disc burning?
What data structure and search architecture would you recommend for efficient offline retrieval?

The objective is to ensure that, within 20 years, the entire archive can be accessed and searched locally using a standard PC with disc reader, without any internet connectivity.
",37,15,2025-10-14 10:05:26,Atronem,https://www.reddit.com/r/Python/comments/1o6agbj/how_to_design_a_searchable_pdf_database_archived/
1o6mv11,reddit,[Project] Plugboard - A framework for complex process modelling,"Hi everyone

I've been helping to build [plugboard](https://github.com/plugboard-dev/plugboard) - a framework for modelling complex processes.

## What is it for?

We originally started out helping data scientists to build models of industrial processes where there are lots of stateful, interconnected components. Think of a digital twin for a mining process, or a simulation of multiple steps in a factory production line.

Plugboard lets you define each component of the model as a Python class and then takes care of the flow of data between the components as you run your model. It really shines when you have many components and lots of connections between them (including loops and branches). 

We've since enhanced it with:

* Support for event-based models;
* Built-in optimisation, so you can fine-tune your model to achieve/optimise a specific output;
* Integration with [Ray](https://github.com/ray-project/ray) for running computationally intensive models in a distributed environment.

## Target audience

Anyone who is interested in modelling complex systems, processes, and digital twins. Particularly if you've faced the challenges of running data-intensive models in Python, and wished for a framework to make it easier. Would love to hear from anyone with experience in these areas.

## Links

* Repo: https://github.com/plugboard-dev/plugboard
* Documentation: https://docs.plugboard.dev/latest/
* Tutorials: https://docs.plugboard.dev/latest/examples/tutorials/hello-world/
* Usage examples: https://docs.plugboard.dev/latest/examples/demos/fundamentals/001_simple_model/simple-model/

## Key Features

- **Reusable classes** containing the core framework, which you can extend to define your own model logic;
- Support for different simulation paradigms: **discrete time** and **event based**.
- **YAML model specification** format for saving model definitions, allowing you to run the same model locally or in cloud infrastructure;
- A **command line interface** for executing models;
- Built to handle the **data intensive simulation** requirements of industrial process applications;
- Modern implementation with **Python 3.12 and above** based around **asyncio** with complete type annotation coverage;
- Built-in integrations for **loading/saving data** from cloud storage and SQL databases;
- **Detailed logging** of component inputs, outputs and state for monitoring and process mining or surrogate modelling use-cases.
",5,0,2025-10-14 19:02:11,top-dogs,https://www.reddit.com/r/Python/comments/1o6mv11/project_plugboard_a_framework_for_complex_process/
1o6rtc1,reddit,An open source access logs analytics script to block Bot attacks,"We built a small Python project for web server access logs analyzing to classify and dynamically block bad bots, such as L7 (application-level) DDoS bots, web scrappers and so on.

We'll be happy to gather initial feedback on usability and features, especially from people having good or bad experience wit bots.

The project is available at [Github](https://github.com/tempesta-tech/webshield/) and has a [wiki page](https://tempesta-tech.com/knowledge-base/Bot-Protection/)


**Requirements**

The analyzer relies on 3 Tempesta FW specific features which you still can get with other HTTP servers or accelerators:

1.  [JA5 client fingerprinting](https://tempesta-tech.com/knowledge-base/Traffic-Filtering-by-Fingerprints/). This is a HTTP and TLS layers fingerprinting, similar to [JA4](https://blog.foxio.io/ja4%2B-network-fingerprinting) and JA3 fingerprints. The last is also available in [Envoy](https://www.envoyproxy.io/docs/envoy/latest/api-v3/extensions/filters/listener/tls\_inspector/v3/tls\_inspector.proto.html) or [Nginx module](https://github.com/fooinha/nginx-ssl-ja3), so check the documentation for your web server
2. Access logs are directly written to Clickhouse analytics database, which can cunsume large data batches and quickly run analytic queries. For other web proxies beside Tempesta FW, you typically need to build a custom pipeline to load access logs into Clickhouse. Such pipelines aren't so rare though.
3. Abbility to block web clients by IP or JA5 hashes. IP blocking is probably available in any HTTP proxy.



**How does it work**

This is a daemon, which

1. Learns normal traffic profiles: means and standard deviations for client requests per second, error responses, bytes per second and so on. Also it remembers client IPs and fingerprints.
2. If it sees a spike in [z-score](https://en.wikipedia.org/wiki/Standard\_score) for traffic characteristics or can be triggered manually. Next, it goes in data model search mode
3. For example, the first model could be top 100 JA5 HTTP hashes, which produce the most error responses per second (typical for password crackers). Or it could be top 1000 IP addresses generating the most requests per second (L7 DDoS). Next, this model is going to be verified
4. The daemon repeats the query, but for some time, long enough history, in the past to see if in the past we saw a hige fraction of clients in both the query results. If yes, then the model is bad and we got to previous step to try another one. If not, then we (likely) has found the representative query.
5. Transfer the IP addresses or JA5 hashes from the query results into the web proxy blocking configuration and reload the proxy configuration (on-the-fly).
",3,0,2025-10-14 22:06:49,krizhanovsky,https://www.reddit.com/r/Python/comments/1o6rtc1/an_open_source_access_logs_analytics_script_to/
1o66tho,reddit,Pyrefly eats CPU like nobodies business.,"So I recently tried out the pyrefly and the ty typecheckers/LSPs in my project for ML. While ty wasn't as useful with it's errors and imports, pyrefly was great in that department. Only problem with the latter was that it sent CPU use to near 100% the whole time it ran.   
  
This was worse than even rust-analyzer, notorious for being a heavy-weight tool, which only uses a ton of CPU on startup but works on low CPU throughout but using a ton of RAM.

Is there some configuration for pyrefly I was missing or is this a bug and if it's the latter should I report it?   
  
Or even worse, is this intended behavior? If so, pyrefly will remain unusable to anyone without a really beefy computer making it completely useless for me. Hopefully not thought, cause I can't have an LSP using over 90% CPU while it runs in background running on my laptop.",39,25,2025-10-14 06:13:55,Different-Ad-8707,https://www.reddit.com/r/Python/comments/1o66tho/pyrefly_eats_cpu_like_nobodies_business/
1o66c21,reddit,[Beta] Django + PostgreSQL Anonymizer - DB-level masking for realistic dev/test datasets,">**TL;DR**  
`django-postgres-anonymizer` lets you mask PII at the **database layer** and create **sanitized dumps** for dev/CI‚Äîno app-code rewrites.

>GitHub: [https://github.com/CuriousLearner/django-postgres-anonymizer](https://github.com/CuriousLearner/django-postgres-anonymizer)

>Docs: [https://django-postgres-anonymizer.readthedocs.io/](https://django-postgres-anonymizer.readthedocs.io/)

>Example: `/example_project` (2-min try)

# What My Project Does

A thin Django integration over the **PostgreSQL anon** extension that lets you declare **DB-level masking policies** and then (a) run queries under a masked role or (b) produce anonymized dumps. Because policies live in Postgres, they apply to *any* client (ORM, psql, ETL).

**Key bits (beta):** management commands like `anon_init`/`anon_dump`, `AnonRoleMiddleware` for automatic role switching, `anonymized_data` context manager, `use_anonymized_data` decorator, admin helpers, and presets for common PII. Requires Postgres with the anonymizer extension enabled.

**Quickstart**

    pip install django-postgres-anonymizer==0.1.0b1
    # add app + settings, then:
    python manage.py anon_init

(You‚Äôll need a Postgres where you can install/enable the anonymizer extension before using the Django layer.)

# Target Audience

* **Django teams on Postgres** who need **production-like datasets** for local dev, CI, or ephemeral review apps - without shipping live PII.
* Orgs that prefer **DB-enforced masking** (central policy, fewer ‚Äúmissed spots‚Äù in app code).
* Current status: **beta (**`v0.1.0b1`**) -** great for dev/test pipelines; evaluate carefully before critical prod paths.

Typical workflows: share realistic fixtures within the team/CI, seed preview environments with masked data, and reproduce bugs that only surface with prod-like distributions.

# Comparison (how it differs)

* **vs Faker/synthetic fixtures:** Faker creates *plausible but synthetic* data; distributions often drift. DB-level masking preserves **real distributions and relationships** while removing PII.
* **vs app-layer masking (serializers/views):** easy to miss code paths. DB policies apply across **ORM, psql, ETL**, etc., reducing leakage risk.
* **vs using the extension directly:** this package adds **Django-friendly commands/middleware/decorators/presets** so teams don‚Äôt hand-roll plumbing each time.

**Status & Asks**  
This is **beta**‚ÄîI‚Äôd love feedback on:

* Missing PII recipes
* Managed-provider quirks (does your provider expose the extension?)
* DX rough edges in admin/tests/CI

If it‚Äôs useful, a ‚≠ê on the repo and comments here really help prioritize the roadmap. üôè",15,4,2025-10-14 05:46:13,curiousyellowjacket,https://www.reddit.com/r/Python/comments/1o66c21/beta_django_postgresql_anonymizer_dblevel_masking/
1o6bxx5,reddit,"[Project] Antback - A Tiny, Transparent Backtesting Library","Hey everyone,

I‚Äôve built a lightweight backtesting library called `Antback`

**What my project does**

Antback is a small, practical tool for backtesting trading ideas. It was primarily designed for rotational strategies, calendar effects, or other situations where a vectorized approach is difficult or impossible. It‚Äôs built to be clear, explicit, and easy to use with any kind of data. The README has some documentation, but the [examples](https://github.com/ts-kontakt/antback/tree/main/examples) are the best place to start: 

**Target audience**

Antback is for anyone who wants to experiment with different investment strategies, inspect each transaction in detail, or compare results with other libraries.

**Comparison**

Unlike many backtesting frameworks that rely on an inheritance-based approach like `class SmaCross(Strategy)` or hide logic behind layers of abstraction, Antback takes a more explicit, function-driven design. It uses efficient stateful helper functions and data containers instead of complex class hierarchies. This makes it easier to understand what‚Äôs happening at each step. Antback also produces interactive HTML or XLSX reports, so you can clearly filter and inspect every trade.

Repo: [https://github.com/ts-kontakt/antback](https://github.com/ts-kontakt/antback)



",5,1,2025-10-14 11:35:49,No_Pineapple449,https://www.reddit.com/r/Python/comments/1o6bxx5/project_antback_a_tiny_transparent_backtesting/
1o6arym,reddit,extend operation of list is threading safe in no-gil version??,"I found a code piece about web spider using 3.14 free threading,but `all_stories` is no lock between mutli thread operate, is the extend implement threading safe?

raw link is [https://py-free-threading.github.io/examples/asyncio/](https://py-free-threading.github.io/examples/asyncio/)

    async def worker(queue: Queue, all_stories: list) -> None:
        async with aiohttp.ClientSession() as session:
            while True:
                async with asyncio.TaskGroup() as tg:
                    try:
                        page = queue.get(block=False)
                    except Empty:
                        break
                    html = await fetch(session, page)
                    stories = parse_stories(html)
                    if not stories:
                        break
                    # for story in stories:
                    #     tg.create_task(fetch_story_with_comments(session, story))
                all_stories.extend(stories)",4,15,2025-10-14 10:26:18,LoVeF23,https://www.reddit.com/r/Python/comments/1o6arym/extend_operation_of_list_is_threading_safe_in/
1o6agzo,reddit,Exercise to Build the Right Mental Model for Python Data,"An exercise to build the right mental model for Python data. The ‚ÄúSolution‚Äù link below uses memory_graph to visualize execution and reveals what‚Äôs actually happening.

What is the output of this Python program?

     import copy
     
     def fun(c1, c2, c3, c4):
         c1[0].append(1)
         c2[0].append(2)
         c3[0].append(3)
         c4[0].append(4)
     
     mylist = [[]]
     c1 = mylist
     c2 = mylist.copy()
     c3 = copy.copy(mylist)
     c4 = copy.deepcopy(mylist)
     fun(c1, c2, c3, c4)
     
     print(mylist)
     # --- possible answers ---
     # A) [[1]]
     # B) [[1, 2]]
     # C) [[1, 2, 3]]
     # D) [[1, 2, 3, 4]]

- [Solution](https://memory-graph.com/#codeurl=https://raw.githubusercontent.com/bterwijn/memory_graph_videos/refs/heads/main/exercises/exercise8.py&breakpoints=11&continues=1&play)
- [Explanation](https://github.com/bterwijn/memory_graph?tab=readme-ov-file#python-data-model)
- [More Exercises](https://www.reddit.com/r/Python_memory_graph/)",3,4,2025-10-14 10:06:38,Sea-Ad7805,https://www.reddit.com/r/Python/comments/1o6agzo/exercise_to_build_the_right_mental_model_for/
1o6q53q,reddit,Improved projects,"A Spotify premiere handler has already been made available soon on my website. A new version of Influent Package Maker will be created now with bundle support and an OS emulator type test installer, everything looks like Android + WSA Apps with information and software protection to provide security to the code. We will be working in C# for the animations since Python does not support it, now it will have a new look",0,0,2025-10-14 21:04:32,Murky_Conference_894,https://www.reddit.com/r/Python/comments/1o6q53q/improved_projects/
1o5ro8i,reddit,ChanX: Type-Safe WebSocket Framework for Django and FastAPI,"# What My Project Does

ChanX is a batteries-included WebSocket framework that works with both Django Channels and FastAPI. It eliminates the boilerplate and repetitive patterns in WebSocket development by providing:

* Automatic message routing using Pydantic discriminated unions - no more if-else chains
* Type safety with full mypy/pyright support and runtime Pydantic validation
* Auto-generated AsyncAPI 3.0 documentation - like OpenAPI/Swagger but for WebSockets
* Channel layer integration for broadcasting messages across servers with Redis
* Event system to trigger WebSocket messages from anywhere in your application (HTTP views, Celery tasks, management commands)
* Built-in authentication with Django REST framework permissions support
* Comprehensive testing utilities for both frameworks
* Structured logging with automatic request/response tracing

The same decorator-based API works for both Django Channels and FastAPI:

    from typing import Literal
    from chanx.messages.base import BaseMessage
    from chanx.core.decorators import ws_handler, channel
    from chanx.channels.websocket import AsyncJsonWebsocketConsumer  # Django
    # from chanx.fast_channels.websocket import AsyncJsonWebsocketConsumer  # FastAPI
    
    class ChatMessage(BaseMessage):
        action: Literal[""chat""] = ""chat""
        payload: str
    
    (name=""chat"")
    class ChatConsumer(AsyncJsonWebsocketConsumer):
        groups = [""chat_room""]
    
        
        async def handle_chat(self, msg: ChatMessage) -> None:
            await self.broadcast_message(
                ChatNotification(payload=NotificationPayload(
                    message=msg.payload,
                    timestamp=datetime.now()
                ))
            )

# Target Audience

ChanX is designed for production use and is ideal for:

* Teams building real-time features who want consistent patterns and reduced code review overhead
* Django projects wanting to eliminate WebSocket boilerplate while maintaining REST API-like consistency
* FastAPI projects needing robust WebSocket capabilities (ChanX brings Django Channels' channel layers, broadcasting, and group management to FastAPI)
* Type-safety advocates who want comprehensive static type checking for WebSocket development
* API-first teams who need automatic documentation generation

Built from years of real-world WebSocket development experience, ChanX provides battle-tested patterns used in production environments. It has:

* Comprehensive test coverage with pytest
* Full type checking with mypy and pyright
* Complete documentation with high interrogate coverage
* Active maintenance and support

# Comparison

vs. Raw Django Channels:

* ChanX adds automatic routing via decorators (vs. manual if-else chains)
* Type-safe message validation with Pydantic (vs. manual dict checking)
* Auto-generated AsyncAPI docs (vs. manual documentation)
* Enforced patterns for team consistency

vs. Raw FastAPI WebSockets:

* ChanX adds channel layers for broadcasting (FastAPI has none natively)
* Group management for multi-user features
* Event system to trigger messages from anywhere
* Same decorator patterns as Django Channels

vs. Broadcaster:

* ChanX provides full WebSocket consumer abstraction, not just pub/sub
* Type-safe message handling with automatic routing
* AsyncAPI documentation generation
* Testing utilities included

vs. Socket.IO:

* Native Python/ASGI implementation (no Node.js required)
* Integrates directly with Django/FastAPI ecosystems
* Type safety with Python type hints
* Leverages existing Django Channels or FastAPI infrastructure

Detailed comparison: [https://chanx.readthedocs.io/en/latest/comparison.html](https://chanx.readthedocs.io/en/latest/comparison.html)

# Tutorials

I've created comprehensive hands-on tutorials for both frameworks:

Django Tutorial: [https://chanx.readthedocs.io/en/latest/tutorial-django/prerequisites.html](https://chanx.readthedocs.io/en/latest/tutorial-django/prerequisites.html)

* Real-time chat with broadcasting
* AI assistant with streaming responses
* Notification system
* Background tasks with WebSocket notifications
* Complete integration tests

FastAPI Tutorial: [https://chanx.readthedocs.io/en/latest/tutorial-fastapi/prerequisites.html](https://chanx.readthedocs.io/en/latest/tutorial-fastapi/prerequisites.html)

* Echo WebSocket with system messages
* Real-time chat rooms with channel layers
* ARQ background jobs with WebSocket updates
* Multi-layer architecture
* Comprehensive testing

Both use Git repositories with checkpoints so you can start anywhere or compare implementations.

# Installation

    # For Django
    pip install ""chanx[channels]""
    
    # For FastAPI
    pip install ""chanx[fast_channels]""

# Links

* GitHub: [https://github.com/huynguyengl99/chanx](https://github.com/huynguyengl99/chanx)
* Documentation: [https://chanx.readthedocs.io/](https://chanx.readthedocs.io/)
* PyPI: [https://pypi.org/project/chanx/](https://pypi.org/project/chanx/)

I'd love to hear feedback or answer questions about WebSocket development in Python.",14,9,2025-10-13 19:19:45,huygl99,https://www.reddit.com/r/Python/comments/1o5ro8i/chanx_typesafe_websocket_framework_for_django_and/
1o5ymks,reddit,Let's Build a Quant Trading Strategy: Part 1 - ML Model in PyTorch,"I created a series where we build a quant trading strategy in Python using PyTorch and polars.

https://youtu.be/iWSDY8_5N3U?si=NkFjg9B1sjPXNwKc",9,6,2025-10-13 23:39:55,memlabs,https://www.reddit.com/r/Python/comments/1o5ymks/lets_build_a_quant_trading_strategy_part_1_ml/
1o5vt9d,reddit,Jinx: a toy interpreter for the J programming language,"[https://github.com/ajcr/jinx](https://github.com/ajcr/jinx)

# What My Project Does

I wrote this toy interpreter for a chunk of the¬†[J programming language](https://www.jsoftware.com/#/README)¬†(an array programming language) using NumPy as the array engine.

My goal was to understand J a bit better. J was an influence on NumPy, but is markedly different in how the user is able to build and control the application of functions over a multidimensional arrays (you control the¬†*rank*¬†of the method you're applying, you don't specify axes or think about broadcasting).

J has a¬†[large set of primitives](https://code.jsoftware.com/wiki/NuVoc)¬†that operate on arrays, or else produce new objects that operate on arrays. It can look confusing at first. For example:

    +/ % #

are three distinct verbs (think: function) that, when arranged in this way, create a new verb that find the arithmetic mean of an array. Similarly:

    1&|.&.#:

creates a verb that solves the¬†[Josephus problem](https://code.jsoftware.com/wiki/Essays/Josephus_Problem).

Despite looking unusual, parsing J code and executing it it is actually relatively straightforward. There is no complicated grammar or precedence rules. In my project:

* Tokenization (breaking the code into words) is done in¬†[word\_formation.py](https://github.com/ajcr/jinx/blob/main/src/jinx/word_formation.py)¬†(using a transition table and single scan from left-to-right)
* Spelling (recognising these words as parts of J) is done in¬†[word\_spelling.py](https://github.com/ajcr/jinx/blob/main/src/jinx/word_spelling.py)¬†(just a few methods to detect what the words are, and parsing of numbers)
* Evaluation (executing the code) is done in¬†[word\_evaluation.py](https://github.com/ajcr/jinx/blob/main/src/jinx/word_evaluation.py)¬†(repeated use of`case`/¬†`match`¬†to check for 8 different patterns in a fragment of the code)

Most of the complexity I found was in defining the different language primitives in terms of NumPy and Python and working out how to apply these primitives to multidimensional arrays of different shapes (see for example¬†[application.py](https://github.com/ajcr/jinx/blob/main/src/jinx/execution/numpy/application.py)¬†and¬†[verbs.py](https://github.com/ajcr/jinx/blob/main/src/jinx/execution/numpy/verbs.py)).

The main reference books I used were:

1. [An Implementation of J](https://www.jsoftware.com/books/pdf/aioj.pdf)
2. [J for C Programmers](https://www.jsoftware.com/help/jforc/contents.htm)

# Target Audience

Anyone interested in programming with arrays or tensors, or understanding how J and similar array languages can be implemented.

Maybe you've used NumPy or PyTorch before and are interested in seeing a different approach to working with multidimensional arrays.

# Comparison

I'm not aware of any other full or partial implementations of J written in Python. A few other toy implementations exist in other languages, but they do not seem to implement as much of J as my project does.

The [official J source code](https://github.com/jsoftware/jsource) is here.",4,0,2025-10-13 21:49:46,aajjccrr,https://www.reddit.com/r/Python/comments/1o5vt9d/jinx_a_toy_interpreter_for_the_j_programming/
1o5kwve,reddit,"gRPC: Client side vs Server side load balancing, which one to choose?","Hello everyone,  
My setup:¬†Two FastAPI apps¬†calling gRPC ML¬†services (layout¬†analysis + table detection). Need to scale both the services.

Question:¬†For¬†GPU-based ML inference¬†over gRPC, does NGINX load balancing significantly hurt¬†performance vs client-side load balancing?

Main¬†concerns:

* Losing¬†HTTP/2 multiplexing benefits
* Extra¬†latency (though probably¬†negligible vs 2-5s processing time)
* Need priority handling for time-critical clients

Current¬†thinking:¬†NGINX seems¬†simpler operationally, but want to make sure I'm not shooting myself in the foot¬†performance-wise.

Experience¬†with gRPC + NGINX? Client-side LB worth the complexity¬†for this use case?",17,6,2025-10-13 15:16:19,Constant_Fun_5643,https://www.reddit.com/r/Python/comments/1o5kwve/grpc_client_side_vs_server_side_load_balancing/
1o5ofkq,reddit,Proxy parser / formatter for Python - proxyutils,"Hey everyone!

One of my first struggles when building CLI tools for end-users in Python was that customers always had problems inputting proxies. They often struggled with the `scheme://user:pass@ip:port` format, so a few years ago I made a parser that could turn any user input into Python's proxy format with a one-liner.   
After a long time of thinking about turning it into a library, I finally had time to publish it. Hope you find it helpful ‚Äî feedback and stars are appreciated :)

# What My Project Does

proxyutils parses any format of proxy into Python's niche proxy format with one-liner . It can also generate proxy extension files / folders for libraries Selenium.

# Target Audience

People who does scraping and automating with Python and uses proxies. It also concerns people who does such projects for end-users.

# Comparison

Sadly, I didn't see any libraries that handles this task before. Generally proxy libraries in Python are focusing on collecting free proxies from various websites.

It worked excellently, and finally, I didn‚Äôt need to handle complaints about my clients‚Äô proxy providers and their odd proxy formats



[https://github.com/meliksahbozkurt/proxyutils](https://github.com/meliksahbozkurt/proxyutils)",10,3,2025-10-13 17:25:16,heyoneminute,https://www.reddit.com/r/Python/comments/1o5ofkq/proxy_parser_formatter_for_python_proxyutils/
1o6bpjq,reddit,White pop up in Terminal,"I'm getting this really weird white box overlay in my console terminal. It contains all the text i enter into the terminal and also adds a weird text overlay to anything written in the terminal. Would really like help, shame i cannot upload a photo of this issue.

I'm trying my best to describe it put cannot find anything online with people having a similar issue.

edit: I have attached a photo of the image.

[https://imgur.com/a/q1bfASa](https://imgur.com/a/q1bfASa)",0,4,2025-10-14 11:22:46,Background-Shape9756,https://www.reddit.com/r/Python/comments/1o6bpjq/white_pop_up_in_terminal/
1o60ghk,reddit,Tuesday Daily Thread: Advanced questions,"# Weekly Wednesday Thread: Advanced Questions üêç

Dive deep into Python with our Advanced Questions thread! This space is reserved for questions about more advanced Python topics, frameworks, and best practices.

## How it Works:

1. **Ask Away**: Post your advanced Python questions here.
2. **Expert Insights**: Get answers from experienced developers.
3. **Resource Pool**: Share or discover tutorials, articles, and tips.

## Guidelines:

* This thread is for **advanced questions only**. Beginner questions are welcome in our [Daily Beginner Thread](#daily-beginner-thread-link) every Thursday.
* Questions that are not advanced may be removed and redirected to the appropriate thread.

## Recommended Resources:

* If you don't receive a response, consider exploring r/LearnPython or join the [Python Discord Server](https://discord.gg/python) for quicker assistance.

## Example Questions:

1. **How can you implement a custom memory allocator in Python?**
2. **What are the best practices for optimizing Cython code for heavy numerical computations?**
3. **How do you set up a multi-threaded architecture using Python's Global Interpreter Lock (GIL)?**
4. **Can you explain the intricacies of metaclasses and how they influence object-oriented design in Python?**
5. **How would you go about implementing a distributed task queue using Celery and RabbitMQ?**
6. **What are some advanced use-cases for Python's decorators?**
7. **How can you achieve real-time data streaming in Python with WebSockets?**
8. **What are the performance implications of using native Python data structures vs NumPy arrays for large-scale data?**
9. **Best practices for securing a Flask (or similar) REST API with OAuth 2.0?**
10. **What are the best practices for using Python in a microservices architecture? (..and more generally, should I even use microservices?)**

Let's deepen our Python knowledge together. Happy coding! üåü",1,0,2025-10-14 01:00:30,AutoModerator,https://www.reddit.com/r/Python/comments/1o60ghk/tuesday_daily_thread_advanced_questions/
1o5jkb9,reddit,Parsegument! - Argument Parsing and function routing,"Project Source code: [https://github.com/RyanStudioo/Parsegument](https://github.com/RyanStudioo/Parsegument)

Project Docs: [https://www.ryanstudio.dev/docs/parsegument/](https://www.ryanstudio.dev/docs/parsegument/)

# What My Project Does
Parsegument allows you to easily define Command structures with Commands and CommandGroups.
Parsegument also automatically parses arguments, converts them to your desired type, then executes functions automatically, all with just one method call and a string.

# Target Audience
Parsegument is targetted for people who would like to simplify making CLIs. I started this project as I was annoyed at having to use lines and lines of switch case statements for another project I was working on

# Comparison
Compared to python's built in argparse, Parsegument has a more intuitive syntax, and makes it more convenient to route and execute functions. 

This project is still super early in development, I aim to add other features like aliases, annotations, and more suggestions from you guys!",7,6,2025-10-13 14:21:51,RyanStudioDev,https://www.reddit.com/r/Python/comments/1o5jkb9/parsegument_argument_parsing_and_function_routing/
1o4uyrv,reddit,"Advice on logging libraries: Logfire, Loguru, or just Python's built-in logging?","Hey everyone,

I‚Äôm exploring different logging options for my projects (fastapi backend with langgraph) and I‚Äôd love some input.

So far I‚Äôve looked at:

* **Python‚Äôs built-in** `logging` module
* **Loguru**
* **Logfire**

I‚Äôm mostly interested in:

* Clean and beautiful output (readability really matters)
* Ease of use / developer experience
* Flexibility for future scaling (e.g., larger apps, integrations)

Has anyone here done a serious comparison or has strong opinions on which one strikes the best balance?  
Is there some hidden gem I should check out instead?

Thanks in advance!",200,76,2025-10-12 18:22:27,Ranteck,https://www.reddit.com/r/Python/comments/1o4uyrv/advice_on_logging_libraries_logfire_loguru_or/
1o5gurz,reddit,Need advice on simulating real time bus movement and eta predictions,"Hello Everyone,

I'm currently studying in college and for semester project i have selected project which can simulate real time bus movement and can predict at what bus will arrive that the certain destination.

What I have:

1. Bus departure time from station
2. Distance between each bus stop
3. Bus stop map coordinates

What I'm trying to achive:

1. Simulating bus moving on real map
2. Variable speeds, dwell times, traffic variation.
3. Estimate arrival time per stop using distance and speed.
4. Live dashboard predicting at what time will reach certain stop based upon traffic flow,speed

Help I need:

1. How to simulate it on real map (showing bus is actually moving along the route)
2. What are the best tools for this project
3. How to model traffic flow

Thanks

",5,12,2025-10-13 12:14:16,Weird_Celebration651,https://www.reddit.com/r/Python/comments/1o5gurz/need_advice_on_simulating_real_time_bus_movement/
1o654sz,reddit,Bluetooth beacon and raspberry Pi,"I have a python coding project, but dont know how to code. We already have the code but cant solve an fsm issue for the bluetooth scanner we are working with is there any freelancer who can work on this and solve the issue. URGENT NEED!!!",0,2,2025-10-14 04:42:27,LividStep1672,https://www.reddit.com/r/Python/comments/1o654sz/bluetooth_beacon_and_raspberry_pi/
1o5w6re,reddit,Web package documentation,"Is it me or is web package documentation just terrible? Authlib, itsdangerous, oauthlib2client, google-auth-oauthlib, etc. They're all full of holes on what I'd consider pretty basic functionality. The authlib authors spent so much time formatting their little website to make it look pretty that they forgot to document how to create timed web tokens.",0,5,2025-10-13 22:03:28,Over_Palpitation_658,https://www.reddit.com/r/Python/comments/1o5w6re/web_package_documentation/
1o5jej5,reddit,Erdos: data science open-source AI IDE,"We're launching¬†**Erdos**, an¬†AI IDE for data science! ([https://www.lotas.ai/erdos](https://www.lotas.ai/erdos),¬†[https://github.com/lotas-ai/erdos](https://github.com/lotas-ai/erdos))

# What My Project Does

Erdos is built for data science - it has:

* An AI that searches, reads, and writes all common data science file formats including Jupyter notebooks, Python, R, and Quarto
* Built-in Python and R consoles accessible to the user and AI
* Single-click sign in to a secure, zero data retention backend; or users can bring their own keys
* Plots pane with plots history organized by file and time
* Help pane for Python and R documentation
* Database pane for connecting to SQL and FTP databases and manipulating data
* Environment pane for managing python environments and Python and R packages
* AGPLv3 license

# Target Audience

Data scientists at any level

# Comparison

Other AI IDEs are primarily built for software development and don't have the things data scientists need like efficient Jupyter notebook editing, plots, environment management, and database connections. We bring all these together and add an AI that understands them too.

Would love feedback and questions!  
",2,0,2025-10-13 14:15:12,SigSeq,https://www.reddit.com/r/Python/comments/1o5jej5/erdos_data_science_opensource_ai_ide/
1o4jul0,reddit,Cronboard - A terminal-based dashboard for managing cron jobs,"## What My Project Does

**Cronboard** is a terminal-based application built with **Python** that lets you manage and schedule cron jobs both locally and on remote servers. It provides an interactive way to view, create, edit, and delete cron jobs, all from your terminal, without having to manually edit crontab files.

Python powers the entire project: it runs the CLI interface, parses and validates cron expressions, manages SSH connections via `paramiko`, and formats job schedules in a human-readable way.

## Target Audience

Cronboard is mainly aimed at **developers, sysadmins, and DevOps engineers** who work with cron jobs regularly and want a cleaner, more visual way to manage them.
## Comparison

Unlike tools such as `crontab -e` or GUI-based schedulers, Cronboard focuses on **terminal usability** and **clarity**. It gives immediate feedback when creating or editing jobs, translates cron expressions into plain English, and will soon support remote SSH-based management out of the box using ssh keys (for now, it supports remote ssh using hostname, username and password).

## Features
- Check existing cron jobs
- Create cron jobs with validation and human-readable feedback
- Pause and resume cron jobs
- Edit existing cron jobs
- Delete cron jobs
- View formatted last and next run times
- Connect to servers using SSH

The project is still in early development, so I‚Äôd really appreciate any feedback or suggestions!

**GitHub Repository:** [github.com/antoniorodr/Cronboard](https://github.com/antoniorodr/Cronboard)",157,31,2025-10-12 09:34:40,NorskJesus,https://www.reddit.com/r/Python/comments/1o4jul0/cronboard_a_terminalbased_dashboard_for_managing/
1o5p1hi,reddit,Cool project idea (master's degree final project),"Hi, guys.

I wanted to ask for some project ideas in adition to my list.

Currently I was thinking about an app that makes text summarization and data analysis based on documents uploaded by the users (with the help of AI agents).

My second idea was to make an app that lets the users track their eating and workout routine and also suggest changes in their routine, calorie and protein intake recomandations and so on.

What do you think? I would like to experiment with cool libraries such as TensorFlow or PyTorch because I've never used them and consider this a good opportunity.",0,6,2025-10-13 17:47:00,ThisUsernam31sTaken,https://www.reddit.com/r/Python/comments/1o5p1hi/cool_project_idea_masters_degree_final_project/
1o54sdj,reddit,Monday Daily Thread: Project ideas!,"# Weekly Thread: Project Ideas üí°

Welcome to our weekly Project Ideas thread! Whether you're a newbie looking for a first project or an expert seeking a new challenge, this is the place for you.

## How it Works:

1. **Suggest a Project**: Comment your project idea‚Äîbe it beginner-friendly or advanced.
2. **Build & Share**: If you complete a project, reply to the original comment, share your experience, and attach your source code.
3. **Explore**: Looking for ideas? Check out Al Sweigart's [""The Big Book of Small Python Projects""](https://www.amazon.com/Big-Book-Small-Python-Programming/dp/1718501242) for inspiration.

## Guidelines:

* Clearly state the difficulty level.
* Provide a brief description and, if possible, outline the tech stack.
* Feel free to link to tutorials or resources that might help.

# Example Submissions:

## Project Idea: Chatbot

**Difficulty**: Intermediate

**Tech Stack**: Python, NLP, Flask/FastAPI/Litestar 

**Description**: Create a chatbot that can answer FAQs for a website.

**Resources**: [Building a Chatbot with Python](https://www.youtube.com/watch?v=a37BL0stIuM)

# Project Idea: Weather Dashboard

**Difficulty**: Beginner

**Tech Stack**: HTML, CSS, JavaScript, API

**Description**: Build a dashboard that displays real-time weather information using a weather API.

**Resources**: [Weather API Tutorial](https://www.youtube.com/watch?v=9P5MY_2i7K8)

## Project Idea: File Organizer

**Difficulty**: Beginner

**Tech Stack**: Python, File I/O

**Description**: Create a script that organizes files in a directory into sub-folders based on file type.

**Resources**: [Automate the Boring Stuff: Organizing Files](https://automatetheboringstuff.com/2e/chapter9/)

Let's help each other grow. Happy coding! üåü",4,0,2025-10-13 01:00:32,AutoModerator,https://www.reddit.com/r/Python/comments/1o54sdj/monday_daily_thread_project_ideas/
1o5i5rg,reddit,What is the best Python learning course?,"

I have been searching for days for the best course that can qualify me to learn back-end and machine learning.I need recommendations based on experience.
Edit :
For your information, I do not have a large background, so I am distracted by the large amount of content on YouTube. ",0,8,2025-10-13 13:20:46,Soft-Razzmatazz-9385,https://www.reddit.com/r/Python/comments/1o5i5rg/what_is_the_best_python_learning_course/
1o4sswc,reddit,üöÄ Blinter The Linter - A Cross Platform Batch Script Linter,"**Yes, it's 2025. Yes, people still write batch scripts. No, they shouldn't crash.**

## What It Does
‚úÖ **158 rules** across Error/Warning/Style/Security/Performance  
‚úÖ **Catches the nasty stuff**: Command injection, path traversal, unsafe temp files  
‚úÖ **Handles the weird stuff**: Variable expansion, FOR loops, multilevel escaping  
‚úÖ **10MB+ files?** No problem. **Unicode?** Got it. **Thread-safe?** Always.

## Get It Now
```bash
pip install Blinter
```
Or grab the standalone `.exe` from [GitHub Releases](https://github.com/tboy1337/Blinter/releases/latest)

## One Command
```bash
python -m blinter script.bat
```

That's it. No config needed. No ceremony. Just point it at your `.bat` or `.cmd` files.

---

**The first professional-grade linter for Windows batch files.**  
Because your automation scripts shouldn't be held together with duct tape.

[üì¶ PyPI](https://pypi.org/project/Blinter/) ‚Ä¢ [‚öôÔ∏è GitHub](https://github.com/tboy1337/Blinter)

What My Project Does
A cross platform linter for batch scripts.

Target Audience
Developers, primarily Windows based.

Comparison
There is no comparison, it's the only batch linter so theres nothing to compare it to.",8,3,2025-10-12 16:59:50,Ok_Bottle8789,https://www.reddit.com/r/Python/comments/1o4sswc/blinter_the_linter_a_cross_platform_batch_script/
1o5oeo6,reddit,Guess The Output,"matrix = \[\[1, 2, 3\], \[4, 5, 6\], \[7, 8, 9\]\]

print(matrix\[1\]\[2\])

  
What is the answer to this nested list? how do you guys learn faster?",0,4,2025-10-13 17:24:22,CryBright2629,https://www.reddit.com/r/Python/comments/1o5oeo6/guess_the_output/
1o4q4vt,reddit,rovr v0.4.0: an update to the modern terminal file explorer,"source code: [https://github.com/nspc911/rovr](https://github.com/nspc911/rovr)

what my project does:

* it's a file manager in the terminal, made with the textual framework

comparison:

* as a python project, it cannot compete in performance with yazi at all, nor can it compete with an ncurses-focused ranger. superfile is also catching up, with its async-based preview that was just released.
* the main point of rovr was to make it a nice experience in the terminal, and also to have touch support, something that lacked, or just felt weird, when using other file explorers.

hey everyone, this follow-up on [https://www.reddit.com/r/Python/comments/1mx7zzj/rovr\_a\_modern\_customizable\_and\_aesthetically/](https://www.reddit.com/r/Python/comments/1mx7zzj/rovr_a_modern_customizable_and_aesthetically/) that I released about a month ago, and during the month, there have been quite a lot of changes! A shortcut list was added in #71 that can be spawned with `?`, so if you are confused about any commands, just press the question mark! You can also search for any keybinds if necessary. rovr also integrates with [fd](https://github.com/sharkdp/fd), so you can simply enable the `finder` plugin and press `f` to start searching! yazi/spf style `--chooser-file` flag has also been added. An extra flag `--cwd-file` Also exists to allow you to grab the file if necessary (I'm planning to remove cd on quit to favour this instead) cases where opening a file results in a ui overwrite have also been resolved, and a lot more bugfixes!

I would like to hear your opinion on how this can be improved. So far, the things that need to be done are a PDF preview, a config specifying flag, non-case-sensitivity of the rename operation and a bunch more. For those interested, the next milestone is also up for [v0.5.0](https://github.com/NSPC911/rovr/milestone/5) !",11,0,2025-10-12 15:13:42,NotSoProGamerR,https://www.reddit.com/r/Python/comments/1o4q4vt/rovr_v040_an_update_to_the_modern_terminal_file/
1o4oozb,reddit,My first medium blog on GIL,"Hi everyone, today I tried my first attempt at writing a tech blog on GIL basics like what is it, why it is needed as recent 3.14 gil removal created a lot of buzz around it. Please give it a read. Only a 5 min read. Please suggest if anything wrong or any improvements needed.

[**GIL in Python: The Lock That Makes and Breaks It**](https://medium.com/@randomedev/gil-in-python-the-lock-that-makes-and-breaks-it-cbc87c30cb17)

PS: I wrote it by myself based on my understanding. Only used llm as proof readers so it may appear unpolished here and there.",15,5,2025-10-12 14:11:10,suntzuhere,https://www.reddit.com/r/Python/comments/1o4oozb/my_first_medium_blog_on_gil/
1o4p7rj,reddit,Comet 3I/Atlas - Some calculations,"Hey everyone,

  
have you heard about Comet Atlas? The interstellar visitor? If yes: well maybe you have also heard about weird claims of the comet being an interstellar artificial visitor. Because of its movement and its shape.

Hmm... weird claims indeed.

So I am a astrophysicsts who works on asteroids, comet, cosmic dust. You name it; the small universe stuff.

And I just created 2 small Python scripts regarding its hyperbolic movement, and regarding the ""cylindric shape"" (that is indeed an artifact of how certain cameras in space are tracking stars and not comets).

If you like, take a look at the code here:

[https://github.com/ThomasAlbin/Astroniz-YT-Tutorials/blob/main/CompressedCosmos/CompressedCosmos\_Interstellar\_Comets.ipynb](https://github.com/ThomasAlbin/Astroniz-YT-Tutorials/blob/main/CompressedCosmos/CompressedCosmos_Interstellar_Comets.ipynb)

[https://github.com/ThomasAlbin/Astroniz-YT-Tutorials/blob/main/CompressedCosmos/CompressedCosmos\_CometMovement.ipynb](https://github.com/ThomasAlbin/Astroniz-YT-Tutorials/blob/main/CompressedCosmos/CompressedCosmos_CometMovement.ipynb)

And the corresponding short videos:

[https://youtu.be/zaOoZ7WL9B0](https://youtu.be/zaOoZ7WL9B0)

[https://youtu.be/Z\_-J8jZQIHE](https://youtu.be/Z_-J8jZQIHE)

If you have heard of further weird claims, please let me know. It is kinda fun to catch these claims and use Python to ""debunk"" it. Well... people who ""believe"" in certain things won't belive me anyway, but I do it for fun.",7,0,2025-10-12 14:33:56,MrAstroThomas,https://www.reddit.com/r/Python/comments/1o4p7rj/comet_3iatlas_some_calculations/
1o5lsbv,reddit,"The Key Python 3.14 Updates To Make Your Coding Easier, Faster, and Better","Finally, the Python 3.14 was released. 

It catched so much attention,given that Python is the de facto ruling language now.

I tried it for a few days and summarised the top 7 most useful updates [here](https://medium.com/techtofreedom/7-key-python-3-14-updates-to-make-your-coding-easier-faster-and-better-17ace5791d09?sk=956f8f3ce66db7feca6f448f141d2cbc).

What do you think?",0,1,2025-10-13 15:49:38,wyhjsbyb,https://www.reddit.com/r/Python/comments/1o5lsbv/the_key_python_314_updates_to_make_your_coding/
1o3voso,reddit,"I made a game that is teaching you Python! :) After more than three years, I finally released it!","It's called The Farmer Was Replaced

Program and optimize a drone to automate a farm and watch it do the work for you. Collect resources to unlock better technology and become the most efficient farmer in the world. Improve your problem solving and coding skills.

Unlike most programming games the game isn't divided into distinct levels that you have to complete but features a continuous progression.

Farming earns you resources which can be spent to unlock new technology.

Programming is done in a simple language similar to Python. The beginning of the game is designed to teach you all the basic programming concepts you will need by introducing them one at a time.

While it introduces everything that is relevant, it won't hold your hand when it comes to solving the various tasks in the game. You will have to figure those out for yourself, and that can be very challenging if you have never programmed before.

If you are an experienced programmer, you should be able to get through the early game very quickly and move on to the more complex tasks of the later game, which should still provide interesting challenges.

Although the programming language isn't exactly Python, it's similar enough that Python IntelliSense works well with it. All code is stored in .py files and can optionally be edited using external code editors like VS Code. When the ""File Watcher"" setting is enabled, the game automatically detects external changes.

You can find it here:¬†[https://store.steampowered.com/app/2060160/The\_Farmer\_Was\_Replaced/](https://store.steampowered.com/app/2060160?utm_source=RD)",477,75,2025-10-11 14:29:46,AdSad9018,https://www.reddit.com/r/Python/comments/1o3voso/i_made_a_game_that_is_teaching_you_python_after/
1o4gvj5,reddit,I built dataspot to find fraud patterns automatically [Open Source],"
After years detecting fraud, I noticed every fraud has a data concentration somewhere.

Built a tool to find them:

```python
pip install dataspot

from dataspot import Dataspot

ds = Dataspot()
hotspots = ds.find(your_data)
```

**What My Project Does**
Automatically finds data concentrations that indicate fraud, bot networks, or coordinated attacks. No manual thresholds needed.

**Target Audience**
Fraud analysts, data scientists, security teams working with transactional or behavioral data.

**Comparison**
Unlike scikit-learn's anomaly detection (needs feature engineering) or PyOD (requires ML expertise), dataspot works directly on raw data structures and finds patterns automatically.

Full story: 
https://3l1070r.dev/en/2025/01/24/building-dataspot.html

Used it in production to detect attacks and anomalies.

- GitHub: https://github.com/frauddi/dataspot
- PyPI: https://pypi.org/project/dataspot/
- Docs: https://frauddi.github.io/dataspot/

Questions welcome.
",14,4,2025-10-12 06:27:49,Competitive_Side4457,https://www.reddit.com/r/Python/comments/1o4gvj5/i_built_dataspot_to_find_fraud_patterns/
1o4hjl6,reddit,"Those who have managed to get into IT in the last couple of years, please share your experiences!","I'm finishing my fourth year of university as a software engineer. Looking at companies' requirements, I realize it's easier to get into IT with your product than to go through a three- or even five-stage interview process for a meager salary.",8,6,2025-10-12 07:08:21,South_Machine_5075,https://www.reddit.com/r/Python/comments/1o4hjl6/those_who_have_managed_to_get_into_it_in_the_last/
1o3p4bf,reddit,Best practices for using Python & uv inside Docker,"Getting¬†`uv`¬†right inside¬†Docker¬†is a bit tricky and even their¬†[official recommendations](https://docs.astral.sh/uv/guides/integration/docker/)¬†are not optimal.

It is better to use a [two-step build process](https://ashishb.net/programming/using-python-uv-inside-docker/) to eliminate¬†`uv`¬†from the final image size.

A two-step build process not only saves disk space but also reduces attack surface against [security vulerabilities](https://astral.sh/blog/uv-security-advisory-cve-2025-54368)",189,111,2025-10-11 08:12:35,ashishb_net,https://www.reddit.com/r/Python/comments/1o3p4bf/best_practices_for_using_python_uv_inside_docker/
1o4ap8i,reddit,Sunday Daily Thread: What's everyone working on this week?,"# Weekly Thread: What's Everyone Working On This Week? üõ†Ô∏è

Hello /r/Python! It's time to share what you've been working on! Whether it's a work-in-progress, a completed masterpiece, or just a rough idea, let us know what you're up to!

## How it Works:

1. **Show & Tell**: Share your current projects, completed works, or future ideas.
2. **Discuss**: Get feedback, find collaborators, or just chat about your project.
3. **Inspire**: Your project might inspire someone else, just as you might get inspired here.

## Guidelines:

* Feel free to include as many details as you'd like. Code snippets, screenshots, and links are all welcome.
* Whether it's your job, your hobby, or your passion project, all Python-related work is welcome here.

## Example Shares:

1. **Machine Learning Model**: Working on a ML model to predict stock prices. Just cracked a 90% accuracy rate!
2. **Web Scraping**: Built a script to scrape and analyze news articles. It's helped me understand media bias better.
3. **Automation**: Automated my home lighting with Python and Raspberry Pi. My life has never been easier!

Let's build and grow together! Share your journey and learn from others. Happy coding! üåü",7,7,2025-10-12 01:00:31,AutoModerator,https://www.reddit.com/r/Python/comments/1o4ap8i/sunday_daily_thread_whats_everyone_working_on/
1o4lh7w,reddit,I wrote some optimizers for TensorFlow,"**What My Project Does**

The optimizers is a lightweight library that implements a collection of advanced optimization algorithms specifically for TensorFlow and Keras. These optimizers are designed to drop right into your existing training pipelines‚Äîjust like the built-in Keras optimizers. The goal is to give you more tools to experiment with for faster convergence, better handling of complex loss landscapes, and improved performance on deep learning models.

**Target Audience**

\* TensorFlow / Keras researchers and engineers looking to experiment with different optimizers.

\* Deep learning / reinforcement-learning practitioners who want quick, API-compatible optimizer swaps.

\* Students and small teams who prefer lightweight, source-first libraries.

**Comparison**

\* vs. built-in Keras optimizers: offers additional/experimental variants for quick comparisons.

\* vs. larger 3rd-party ecosystems (e.g. tensorflow-addons or JAX/Optax): this repo is a lightweight, code-first collection focused on TensorFlow/Keras.

[https://github.com/NoteDance/optimizers](https://github.com/NoteDance/optimizers)",0,0,2025-10-12 11:19:00,NoteDancing,https://www.reddit.com/r/Python/comments/1o4lh7w/i_wrote_some_optimizers_for_tensorflow/
1o53ave,reddit,I built an ultra-strict typing setup in Python (FastAPI + LangGraph + Pydantic + Pyright + Ruff) üöÄ,"Hey everyone,

I recently worked on a project using FastAPI + LangGraph, and I kept running into typing headaches. So I went down the rabbit hole and decided to build the strictest setup I could, making sure no Any could sneak in.

Here‚Äôs the stack I ended up with:

* Pydantic / Pydantic-AI ‚Üí strong data validation.
* types-requests ‚Üí type stubs for requests.
* Pyright ‚Üí static checker in ""strict"": true mode.
* Ruff ‚Üí linter + enforces typing/style rules.

What I gained:

* Catching typing issues before running anything.
* Much less uncertainty when passing data between FastAPI and LangGraph.
* VSCode now feels almost like I‚Äôm writing TypeScript‚Ä¶ but in Python üòÖ.

Here‚Äôs my pyproject.toml if anyone wants to copy, tweak, or criticize it:


```toml
# ============================================================
# ULTRA-STRICT PYTHON PROJECT TEMPLATE
# Maximum strictness - TypeScript strict mode equivalent
# Tools: uv + ruff + pyright/pylance + pydantic v2
# Python 3.12+
# ============================================================

[build-system]
requires = [""setuptools>=61.0""]
build-backend = ""setuptools.build_meta""

[project]
name = ""your-project-name""
version = ""0.1.0""
description = ""Your project description""
authors = [{ name = ""Your Name"", email = ""your.email@example.com"" }]
license = { text = ""MIT"" }
readme = ""README.md""
requires-python = "">=3.12""
dependencies = [
    ""pydantic"",
    ""pydantic-ai-slim[openai]"",
    ""types-requests"",
    ""python-dotenv"",
]

[project.optional-dependencies]
dev = [
    ""pyright"",
    ""ruff"",
    ""gitingest"",
		""poethepoet""
]

[tool.setuptools.packages.find]
where = ["".""]
include = [""*""]
exclude = [""tests*"", ""scripts*"", ""docs*"", ""examples*""]

# ============================================================
# POE THE POET - Task Runner
# ============================================================
[tool.poe.tasks]
# Run with: poe format or uv run poe format
# Formats code, fixes issues, and type checks
format = [
    {cmd = ""ruff format .""},
    {cmd = ""ruff check . --fix""},
    {cmd = ""pyright""}
]

# Run with: poe check
# Lint and type check without fixing
check = [
    {cmd = ""ruff check .""},
    {cmd = ""pyright""}
]

# Run with: poe lint or uv run poe lint
# Only linting, no type checking
lint = {cmd = ""ruff check . --fix""}

# Run with: poe lint-unsafe or uv run poe lint-unsafe
# Lint with unsafe fixes enabled (more aggressive)
lint-unsafe = {cmd = ""ruff check . --fix --unsafe-fixes""}

# ============================================================
# RUFF CONFIGURATION - MAXIMUM STRICTNESS
# ============================================================
[tool.ruff]
target-version = ""py312""
line-length = 88
indent-width = 4
fix = true
show-fixes = true

[tool.ruff.lint]
# Comprehensive rule set for strict checking
select = [
    ""E"",      # pycodestyle errors
    ""F"",      # pyflakes
    ""I"",      # isort
    ""UP"",     # pyupgrade
    ""B"",      # flake8-bugbear
    ""C4"",     # flake8-comprehensions
    ""T20"",    # flake8-print (no print statements)
    ""SIM"",    # flake8-simplify
    ""N"",      # pep8-naming
    ""Q"",      # flake8-quotes
    ""RUF"",    # Ruff-specific rules
    ""ASYNC"",  # flake8-async
    ""S"",      # flake8-bandit (security)
    ""PTH"",    # flake8-use-pathlib
    ""ERA"",    # eradicate (commented-out code)
    ""PL"",     # pylint
    ""PERF"",   # perflint (performance)
    ""ANN"",    # flake8-annotations
    ""ARG"",    # flake8-unused-arguments
    ""RET"",    # flake8-return
    ""TCH"",    # flake8-type-checking
]

ignore = [
    ""E501"",    # Line too long (formatter handles this)
    ""S603"",    # subprocess without shell=True (too strict)
    ""S607"",    # Starting a process with a partial path (too strict)
]

# Per-file ignores
[tool.ruff.lint.per-file-ignores]
""__init__.py"" = [
    ""F401"",    # Allow unused imports in __init__.py
]
""tests/**/*.py"" = [
    ""S101"",    # Allow assert in tests
    ""PLR2004"", # Allow magic values in tests
    ""ANN"",     # Don't require annotations in tests
]

[tool.ruff.lint.isort]
known-first-party = [""your_package_name""]  # CHANGE THIS
combine-as-imports = true
force-sort-within-sections = true

[tool.ruff.lint.pydocstyle]
convention = ""google""

[tool.ruff.lint.flake8-type-checking]
strict = true

[tool.ruff.format]
quote-style = ""double""
indent-style = ""space""
skip-magic-trailing-comma = false
line-ending = ""auto""

# ============================================================
# PYRIGHT CONFIGURATION - MAXIMUM STRICTNESS
# TypeScript strict mode equivalent
# ============================================================
[tool.pyright]
pythonVersion = ""3.12""
typeCheckingMode = ""strict""

# ============================================================
# IMPORT AND MODULE CHECKS
# ============================================================
reportMissingImports = true
reportMissingTypeStubs = true  # Stricter: require type stubs
reportUndefinedVariable = true
reportAssertAlwaysTrue = true
reportInvalidStringEscapeSequence = true

# ============================================================
# STRICT NULL SAFETY (like TS strictNullChecks)
# ============================================================
reportOptionalSubscript = true
reportOptionalMemberAccess = true
reportOptionalCall = true
reportOptionalIterable = true
reportOptionalContextManager = true
reportOptionalOperand = true

# ============================================================
# TYPE COMPLETENESS (like TS noImplicitAny + strictFunctionTypes)
# ============================================================
reportMissingParameterType = true
reportMissingTypeArgument = true
reportUnknownParameterType = true
reportUnknownLambdaType = true
reportUnknownArgumentType = true   # STRICT: Enable (can be noisy)
reportUnknownVariableType = true   # STRICT: Enable (can be noisy)
reportUnknownMemberType = true     # STRICT: Enable (can be noisy)
reportUntypedFunctionDecorator = true
reportUntypedClassDecorator = true
reportUntypedBaseClass = true
reportUntypedNamedTuple = true

# ============================================================
# CLASS AND INHERITANCE CHECKS
# ============================================================
reportIncompatibleMethodOverride = true
reportIncompatibleVariableOverride = true
reportInconsistentConstructor = true
reportUninitializedInstanceVariable = true
reportOverlappingOverload = true
reportMissingSuperCall = true  # STRICT: Enable

# ============================================================
# CODE QUALITY (like TS noUnusedLocals + noUnusedParameters)
# ============================================================
reportPrivateUsage = true
reportConstantRedefinition = true
reportInvalidStubStatement = true
reportIncompleteStub = true
reportUnsupportedDunderAll = true
reportUnusedClass = ""error""        # STRICT: Error instead of warning
reportUnusedFunction = ""error""     # STRICT: Error instead of warning
reportUnusedVariable = ""error""     # STRICT: Error instead of warning
reportUnusedImport = ""error""       # STRICT: Error instead of warning
reportDuplicateImport = ""error""    # STRICT: Error instead of warning

# ============================================================
# UNNECESSARY CODE DETECTION
# ============================================================
reportUnnecessaryIsInstance = ""error""         # STRICT: Error
reportUnnecessaryCast = ""error""               # STRICT: Error
reportUnnecessaryComparison = ""error""         # STRICT: Error
reportUnnecessaryContains = ""error""           # STRICT: Error
reportUnnecessaryTypeIgnoreComment = ""error""  # STRICT: Error

# ============================================================
# FUNCTION/METHOD SIGNATURE STRICTNESS
# ============================================================
reportGeneralTypeIssues = true
reportPropertyTypeMismatch = true
reportFunctionMemberAccess = true
reportCallInDefaultInitializer = true
reportImplicitStringConcatenation = true  # STRICT: Enable

# ============================================================
# ADDITIONAL STRICT CHECKS (Progressive Enhancement)
# ============================================================
reportImplicitOverride = true    # STRICT: Require @override decorator (Python 3.12+)
reportShadowedImports = true     # STRICT: Detect shadowed imports
reportDeprecated = ""warning""     # Warn on deprecated usage

# ============================================================
# ADDITIONAL TYPE CHECKS
# ============================================================
reportImportCycles = ""warning""

# ============================================================
# EXCLUSIONS
# ============================================================
exclude = [
    ""**/__pycache__"",
    ""**/node_modules"",
    "".git"",
    "".mypy_cache"",
    "".pyright_cache"",
    "".ruff_cache"",
    "".pytest_cache"",
    "".venv"",
    ""venv"",
    ""env"",
    ""logs"",
    ""output"",
    ""data"",
    ""build"",
    ""dist"",
    ""*.egg-info"",
]

venvPath = "".""
venv = "".venv""

# ============================================================
# PYTEST CONFIGURATION
# ============================================================
[tool.pytest.ini_options]
testpaths = [""tests""]
python_files = [""test_*.py"", ""*_test.py""]
python_classes = [""Test*""]
python_functions = [""test_*""]
addopts = [
    ""--strict-markers"",
    ""--strict-config"",
    ""--tb=short"",
    ""--cov=."",
    ""--cov-report=term-missing:skip-covered"",
    ""--cov-report=html"",
    ""--cov-report=xml"",
    ""--cov-fail-under=80"",  # STRICT: Require 80% coverage
]
markers = [
    ""slow: marks tests as slow (deselect with '-m \""not slow\""')"",
    ""integration: marks tests as integration tests"",
    ""unit: marks tests as unit tests"",
]

# ============================================================
# COVERAGE CONFIGURATION
# ============================================================
[tool.coverage.run]
source = ["".""]
branch = true  # STRICT: Enable branch coverage
omit = [
    ""*/tests/*"",
    ""*/test_*.py"",
    ""*/__pycache__/*"",
    ""*/.venv/*"",
    ""*/venv/*"",
    ""*/scripts/*"",
]

[tool.coverage.report]
precision = 2
show_missing = true
skip_covered = false
fail_under = 80  # STRICT: Require 80% coverage
exclude_lines = [
    ""pragma: no cover"",
    ""def __repr__"",
    ""raise AssertionError"",
    ""raise NotImplementedError"",
    ""if __name__ == .__main__.:"",
    ""if TYPE_CHECKING:"",
    ""@abstractmethod"",
    ""@overload"",
]

# ============================================================
# QUICK START GUIDE
# ============================================================
#
# 1. CREATE NEW PROJECT:
#    mkdir my-project && cd my-project
#    cp STRICT_PYPROJECT_TEMPLATE.toml pyproject.toml
#
# 2. CUSTOMIZE (REQUIRED):
#    - Change project.name to ""my-project""
#    - Change project.description
#    - Change project.authors
#    - Change tool.ruff.lint.isort.known-first-party to [""my_project""]
#
# 3. SETUP ENVIRONMENT:
#    uv venv
#    source .venv/bin/activate  # Linux/Mac
#    .venv\Scripts\activate     # Windows
#    uv pip install -e "".[dev]""
#
# 4. CREATE PROJECT STRUCTURE:
#    mkdir -p src/my_project tests
#    touch src/my_project/__init__.py
#    touch tests/__init__.py
#
# 5. CREATE .gitignore:
#    echo "".venv/
#    __pycache__/
#    *.py[cod]
#    .pytest_cache/
#    .ruff_cache/
#    .pyright_cache/
#    .coverage
#    htmlcov/
#    dist/
#    build/
#    *.egg-info/
#    .env
#    .DS_Store"" > .gitignore
#
# 6. DAILY WORKFLOW:
#    # Format code
#    uv run ruff format .
#
#    # Lint and auto-fix
#    uv run ruff check . --fix
#
#    # Type check (strict!)
#    uv run pyright
#
#    # Run tests with coverage
#    uv run pytest
#
#    # Full check (run before commit)
#    uv run ruff format . && uv run ruff check . && uv run pyright && uv run pytest
#
# 7. VS CODE SETUP (recommended):
#    Create .vscode/settings.json:
#    {
#      ""python.defaultInterpreterPath"": "".venv/bin/python"",
#      ""python.analysis.typeCheckingMode"": ""strict"",
#      ""python.analysis.autoImportCompletions"": true,
#      ""editor.formatOnSave"": true,
#      ""editor.codeActionsOnSave"": {
#        ""source.organizeImports"": true,
#        ""source.fixAll"": true
#      },
#      ""[python]"": {
#        ""editor.defaultFormatter"": ""charliermarsh.ruff""
#      },
#      ""ruff.enable"": true,
#      ""ruff.lint.enable"": true,
#      ""ruff.format.args"": [""--config"", ""pyproject.toml""]
#    }
#
# 8. GITHUB ACTIONS CI (optional):
#    Create .github/workflows/ci.yml:
#    name: CI
#    on: [push, pull_request]
#    jobs:
#      test:
#        runs-on: ubuntu-latest
#        steps:
#          - uses: actions/checkout@v4
#          - uses: astral-sh/setup-uv@v1
#          - run: uv pip install -e "".[dev]""
#          - run: uv run ruff format --check .
#          - run: uv run ruff check .
#          - run: uv run pyright
#          - run: uv run pytest
#
# ============================================================
# PYDANTIC V2 PATTERNS (IMPORTANT)
# ============================================================
#
# ‚úÖ CORRECT (Pydantic v2):
# from pydantic import BaseModel, field_validator, model_validator, ConfigDict
#
# class User(BaseModel):
#     model_config = ConfigDict(strict=True)
#     name: str
#     age: int
#
#     @field_validator('age')
#     @classmethod
#     def validate_age(cls, v: int) -> int:
#         if v < 0:
#             raise ValueError('age must be positive')
#         return v
#
#     @model_validator(mode='after')
#     def validate_model(self) -> 'User':
#         return self
#
# ‚ùå WRONG (Pydantic v1 - deprecated):
# class User(BaseModel):
#     class Config:
#         strict = True
#
#     @validator('age')
#     def validate_age(cls, v):
#         return v
#
# ============================================================
# STRICTNESS LEVELS
# ============================================================
#
# This template is at MAXIMUM strictness. To reduce:
#
# LEVEL 1 - Production Ready (Recommended):
#   - Keep all current settings
#   - This is the gold standard
#
# LEVEL 2 - Slightly Relaxed:
#   - reportUnknownArgumentType = false
#   - reportUnknownVariableType = false
#   - reportUnknownMemberType = false
#   - reportUnused* = ""warning"" (instead of ""error"")
#
# LEVEL 3 - Gradual Adoption:
#   - typeCheckingMode = ""standard""
#   - reportMissingSuperCall = false
#   - reportImplicitOverride = false
#
# ============================================================
# TROUBLESHOOTING
# ============================================================
#
# Q: Too many type errors from third-party libraries?
# A: Add to exclude list or set reportMissingTypeStubs = false
#
# Q: Pyright too slow?
# A: Add large directories to exclude list
#
# Q: Ruff ""ALL"" too strict?
# A: Replace ""ALL"" with specific rule codes (see template above)
#
# Q: Coverage failing?
# A: Reduce fail_under from 80 to 70 or 60
#
# Q: How to ignore specific errors temporarily?
# A: Use # type: ignore[error-code] or # noqa: RULE_CODE
#    But fix them eventually - strict mode means no ignores!
#

```

",0,9,2025-10-12 23:51:51,Ranteck,https://www.reddit.com/r/Python/comments/1o53ave/i_built_an_ultrastrict_typing_setup_in_python/
1o4wjlr,reddit,Pyautogui n√£o manipula o gerenciador de dom√≠nios do Windows por que?,"Estou tentando fazer um c√≥digo que abra aquela tela de onde se gerencia o dom√≠nio do Windows.  
L√° dentro o script dever√° colocar o hostname da m√°quina , mandar buscar a m√°quina , clicar em cima dela e coloc√°-la no GRUPO PC\_ESTADOS\_UNIDOS e depois mover a m√°quina para o UO Michigan depois o UO Detroit.

Ok, fiz o c√≥digo mas ao tentar mandar o texto do hostname usando uma imagem como referencia, o Python + Pyautogui at√© acha o campo, mas ao inv√©s de mandar o texto para o campo, ele manda para o console como se fosse um comando a ser executado. Ok, se voc√™ tenta executar o script com um click isso n√£o ocorre, porem n√£o manda texto nenhum e o c√≥digo para clicar no bot√£o buscar faz o bot√£o ser real√ßado porem ele n√£o clica, seja com o click direito ou esquerdo ou com ambos v√°rias vezes, simplesmente n√£o ocorre nada.  


Essa tela do windows √© aprova de automatiza√ß√£o?",0,4,2025-10-12 19:22:43,Gabriel_Cinzao,https://www.reddit.com/r/Python/comments/1o4wjlr/pyautogui_n√£o_manipula_o_gerenciador_de_dom√≠nios/
1o3uy4y,reddit,I made a Better Notepad alternative using PySide6,"# What My Project Does

ZenNotes is a minimalistic Notepad app with a sleek design inspired by the Fluent Design. It offers the familiar look of the Windows Notepad while having much more powerful features like Translate, TTS, etc.

# Target Audience

Anyone who uses Windows Notepad, or noepads in general

# Comparison¬†

The target competition is Windows Notepad. ZenNotes is like an ""extension"" of Windows Notepad, with similar looks but much more features, like TTS, Translate, etc.

# GitHub

[https://github.com/rohankishore/ZenNotes](https://github.com/rohankishore/ZenNotes)",45,21,2025-10-11 13:56:17,Specialist-Arachnid6,https://www.reddit.com/r/Python/comments/1o3uy4y/i_made_a_better_notepad_alternative_using_pyside6/
1o3sqqz,reddit,"Announcing html-to-markdown v2: Rust rewrite, full CommonMark 1.2 compliance, and hOCR support","Hi Pythonistas,

I'm glad to announce the v2 release of [html-to-markdown](https://github.com/Goldziher/html-to-markdown).

This library started life as a fork of `markdownify`, a Python library for converting HTML to Markdown. I forked it originally because I needed modern type hints, but then found myself rewriting the entire thing. Over time it became essential for [kreuzberg](https://github.com/Goldziher/kreuzberg), where it serves as a backbone for both html -> markdown and hOCR -> markdown.

I am working on Kreuzberg v4, which migrates much of it to Rust. This necessitated updating this component as well, which led to a full rewrite in Rust, offering improved performance, memory stability, and a more robust feature set.

v2  delivers Rust-backed HTML ‚Üí Markdown conversion with Python bindings, a CLI and a Rust crate. The rewrite makes this by far the most performance and complete solution for HTML to Markdown conversion in python. Here are some benchmarks:

Apple M4 ‚Ä¢ Real Wikipedia documents ‚Ä¢ `convert()` (Python)

| Document            | Size  | Latency | Throughput | Docs/sec |
| ------------------- | ----- | ------- | ---------- | -------- |
| Lists (Timeline)    | 129KB | 0.62ms  | 208‚ÄØMB/s   | 1,613    |
| Tables (Countries)  | 360KB | 2.02ms  | 178‚ÄØMB/s   | 495      |
| Mixed (Python wiki) | 656KB | 4.56ms  | 144‚ÄØMB/s   | 219      |

> V1 averaged ~2.5‚ÄØMB/s (Python/BeautifulSoup). V2‚Äôs Rust engine delivers 60‚Äì80x higher throughput.

The Python package still exposes `markdownify`-style calls via `html_to_markdown.v1_compat`, so migrations are relatively straightforward, although the v2 did introduce some breaking changes (see CHANGELOG.md for full details).

## Highlights

Here are the key highlights of the v2 release aside from the massive performance improvements:

- CommonMark-compliant defaults with explicit toggles when you need legacy behaviour.
- Inline image extraction (`convert_with_inline_images`) that captures data URI assets and inline SVGs with sizing and quota controls.
- Full hOCR 1.2 spec compliance, including hOCR table reconstruction and YAML frontmatter for metadata to keep OCR output structured.
- Memory is kept kept in check by dedicated harnesses: repeated conversions stay under 200‚ÄØMB RSS on multi-megabyte corpora.

## Target Audience
- Engineers replacing BeautifulSoup-based converters that fall apart on large documents or OCR outputs.
- Python, Rust, and CLI users who need identical Markdown from libraries, pipelines, and batch tools.
- Teams building document understanding stacks (including the kreuzberg ecosystem) that rely on tight memory behaviour and parallel throughput.
- OCR specialists who need to process hOCR efficiently.

## Comparison to Alternatives
- [`markdownify`](https://github.com/matthewwithanm/python-markdownify): the spiritual ancestor, but still Python + BeautifulSoup. html-to-markdown v2 keeps the API shims while delivering 60‚Äì80√ó more throughput, table-aware hOCR support, and deterministic memory usage across repeated conversions.
- [`html2text`](https://github.com/Alir3z4/html2text): solid for quick scripts, yet it lacks CommonMark compliance and tends to drift on complex tables and OCR layouts; it also allocates heavily under pressure because it was never built with long-running processes in mind.
- [`pandoc`](https://github.com/jgm/pandoc): extremely flexible (and amazing!), but large, much slower for pure HTML ‚Üí Markdown pipelines, and not embeddable in Python without subprocess juggling. html-to-markdown v2 offers a slim Rust core with direct bindings, so you keep the performance while staying in-process.

If you end up using the rewrite, a ‚≠êÔ∏è on the [repo](https://github.com/Goldziher/html-to-markdown) always makes yours truly happy!",53,5,2025-10-11 12:01:26,Goldziher,https://www.reddit.com/r/Python/comments/1o3sqqz/announcing_htmltomarkdown_v2_rust_rewrite_full/
1o41tgv,reddit,[FOSS] Flint: A 100% Config-Driven ETL Framework,"I'd like to share **Flint**, a configuration-driven ETL framework that lets you define complete data pipelines through JSON/YAML instead of code.

## What My Project Does

Flint transforms straightforward ETL workflows from programming tasks into declarative configuration. Define your sources, transformations (select, filter, join, cast, etc.), and destinations in JSON or YAML - the framework handles execution. The processing engine is abstracted away, currently supporting Apache Spark with Polars in development.

**It's not intended to replace all ETL development** - complex data engineering still needs custom code. Instead, it handles routine ETL tasks so engineers can focus on more interesting problems.

## Target Audience
- Data engineers tired of writing boilerplate for basic pipelines, so they ahve more time for more interesting programming tasks than straightforward ETL pipelines.
- Teams wanting standardized ETL patterns
- Organizations needing pipeline logic accessible to non-developers
- Projects requiring multi-engine flexibility

100% test coverage (unit + e2e), strong typing, extensive documentation with class and activity diagrams, and configurable alerts/hooks.

## Comparison

Unlike other transformation tools like DBT this one is configuration focused to reduce complexity and programming knowledge to make the boring ETL task simple, to keep more time for engineers for more intersting issues. This focuses on pure configuration without vendor lock-in as the backend key can be changed anytime with another implementation.

## Future expansion

The foundation is solid - now looking to expand with new engines, add tracing/metrics, migrate CLI to Click, move from azure devops CICD to github actions, extend Polars transformations, and more.

**[GitHub: config-driven-ETL-framework](https://github.com/krijnvanderburg/config-driven-ETL-framework)**. If you like the project idea then consider giving it a star, it means the world to get a project started from the ground.

```jsonc
{
    ""runtime"": {
        ""id"": ""customer-orders-pipeline"",
        ""description"": ""ETL pipeline for processing customer orders data"",
        ""enabled"": true,
        ""jobs"": [
            {
                ""id"": ""silver"",
                ""description"": ""Combine customer and order source data into a single dataset"",
                ""enabled"": true,
                ""engine_type"": ""spark"", // Specifies the processing engine to use
                ""extracts"": [
                    {
                        ""id"": ""extract-customers"",
                        ""extract_type"": ""file"", // Read from file system
                        ""data_format"": ""csv"", // CSV input format
                        ""location"": ""examples/join_select/customers/"", // Source directory
                        ""method"": ""batch"", // Process all files at once
                        ""options"": {
                            ""delimiter"": "","", // CSV delimiter character
                            ""header"": true, // First row contains column names
                            ""inferSchema"": false // Use provided schema instead of inferring
                        },
                        ""schema"": ""examples/join_select/customers_schema.json"" // Path to schema definition
                    }
                ],
                ""transforms"": [
                    {
                        ""id"": ""transform-join-orders"",
                        ""upstream_id"": ""extract-customers"", // First input dataset from extract stage
                        ""options"": {},
                        ""functions"": [
                            {""function_type"": ""join"", ""arguments"": {""other_upstream_id"": ""extract-orders"", ""on"": [""customer_id""], ""how"": ""inner""}},
                            {""function_type"": ""select"", ""arguments"": {""columns"": [""name"", ""email"", ""signup_date"", ""order_id"", ""order_date"", ""amount""]}}
                        ]
                    }
                ],
                ""loads"": [
                    {
                        ""id"": ""load-customer-orders"",
                        ""upstream_id"": ""transform-join-orders"", // Input dataset for this load
                        ""load_type"": ""file"", // Write to file system
                        ""data_format"": ""csv"", // Output as CSV
                        ""location"": ""examples/join_select/output"", // Output directory
                        ""method"": ""batch"", // Write all data at once
                        ""mode"": ""overwrite"", // Replace existing files if any
                        ""options"": {
                            ""header"": true // Include header row with column names
                        },
                        ""schema_export"": """" // No schema export
                    }
                ],
                ""hooks"": {
                    ""onStart"": [], // Actions to execute before pipeline starts
                    ""onFailure"": [], // Actions to execute if pipeline fails
                    ""onSuccess"": [],  // Actions to execute if pipeline succeeds
                    ""onFinally"": [] // Actions to execute after pipeline completes (success or failure)
                }
            }
        ]
    }
}
```",10,0,2025-10-11 18:42:21,TeamFlint,https://www.reddit.com/r/Python/comments/1o41tgv/foss_flint_a_100_configdriven_etl_framework/
1o4yx19,reddit,"HIRING: Scrape 300,000 PDFs and Archive to 128‚ÄØGB VERBATIM Discs","We are seeking an operator to extract approximately 300,000 book titles from AbeBooks.com, applying specific filtering parameters that will be provided.

Once the dataset is obtained, the corresponding PDF files should be retrieved from the Wayback Machine or Anna‚Äôs Archive, when available.
The estimated total storage requirement is around 4 TB. Data will be temporarily stored on a dedicated server during collection and subsequently transferred to 128 GB Verbatim or Panasonic optical discs for long-term preservation.


The objective is to ensure the archive‚Äôs readability and transferability for at least 100 years, relying solely on commercially available hardware and systems.",0,4,2025-10-12 20:54:09,Atronem,https://www.reddit.com/r/Python/comments/1o4yx19/hiring_scrape_300000_pdfs_and_archive_to_128_gb/
1o3r5tp,reddit,"I shared 300+ Python Data Science Videos on YouTube (Tutorials, Projects and Full Courses)","Hello, I am sharing free Python Data Science Tutorials for over 2 years on YouTube and I wanted to share my playlists. I believe they are great for learning the field, I am sharing them below. Thanks for reading!

Python Tutorials ->¬†[https://youtube.com/playlist?list=PLTsu3dft3CWgJrlcs\_IO1eif7myukPPKJ&si=fYIz2RLJV1dC6nT5](https://youtube.com/playlist?list=PLTsu3dft3CWgJrlcs_IO1eif7myukPPKJ&si=fYIz2RLJV1dC6nT5)

Data Science Full Courses & Projects:¬†[https://youtube.com/playlist?list=PLTsu3dft3CWiow7L7WrCd27ohlra\_5PGH](https://youtube.com/playlist?list=PLTsu3dft3CWiow7L7WrCd27ohlra_5PGH)

AI Tutorials (LangChain, LLMs & OpenAI API):¬†[https://youtube.com/playlist?list=PLTsu3dft3CWhAAPowINZa5cMZ5elpfrxW](https://youtube.com/playlist?list=PLTsu3dft3CWhAAPowINZa5cMZ5elpfrxW)

Machine Learning Tutorials:¬†[https://youtube.com/playlist?list=PLTsu3dft3CWhSJh3x5T6jqPWTTg2i6jp1](https://youtube.com/playlist?list=PLTsu3dft3CWhSJh3x5T6jqPWTTg2i6jp1)

Deep Learning Tutorials:¬†[https://youtube.com/playlist?list=PLTsu3dft3CWghrjn4PmFZlxVBileBpMjj](https://youtube.com/playlist?list=PLTsu3dft3CWghrjn4PmFZlxVBileBpMjj)

Natural Language Processing Tutorials:¬†[https://youtube.com/playlist?list=PLTsu3dft3CWjYPJi5RCCVAF6DxE28LoKD](https://youtube.com/playlist?list=PLTsu3dft3CWjYPJi5RCCVAF6DxE28LoKD)

Time Series Analysis Tutorials:¬†[https://youtube.com/playlist?list=PLTsu3dft3CWibrBga4nKVEl5NELXnZ402](https://youtube.com/playlist?list=PLTsu3dft3CWibrBga4nKVEl5NELXnZ402)

Streamlit Based Python Web App Development Tutorials:¬†[https://youtube.com/playlist?list=PLTsu3dft3CWhBViLMhL0Aqb75rkSz\_CL-](https://youtube.com/playlist?list=PLTsu3dft3CWhBViLMhL0Aqb75rkSz_CL-)

Data Cleaning Tutorials:¬†[https://youtube.com/playlist?list=PLTsu3dft3CWhOUPyXdLw8DGy\_1l2oK1yy](https://youtube.com/playlist?list=PLTsu3dft3CWhOUPyXdLw8DGy_1l2oK1yy)

Data Analysis Tutorials:¬†[https://youtube.com/playlist?list=PLTsu3dft3CWhwPJcaAc-k6a8vAqBx2\_0t](https://youtube.com/playlist?list=PLTsu3dft3CWhwPJcaAc-k6a8vAqBx2_0t)

End-to-End Data Science Projects:¬†[https://youtube.com/playlist?list=PLTsu3dft3CWg69zbIVUQtFSRx\_UV80OOg](https://youtube.com/playlist?list=PLTsu3dft3CWg69zbIVUQtFSRx_UV80OOg)",30,2,2025-10-11 10:24:12,onurbaltaci,https://www.reddit.com/r/Python/comments/1o3r5tp/i_shared_300_python_data_science_videos_on/
1o3s3yj,reddit,Feedback Request for API Key Management Library for FastAPI,"Hello,

In my work, I build many FastAPI applications, both internal and external, that expose endpoints to other product, business, and data teams, accessible via API keys. Each project eventually ended up with its own slightly different API key system, so I finally took the time to extract the common parts and combine them into a reusable library.

[https://github.com/Athroniaeth/fastapi-api-key](https://github.com/Athroniaeth/fastapi-api-key)

Before publishing it publicly (not yet on PyPI, and the mkdocs documentation is still local), I‚Äôd like to get feedback from people who have solved similar problems (or just see what they think).

The goal is to see if I can improve this project or if there are any major security flaws (which would be problematic for an API key system).

I built the library as follows:

* **Security-first**: secrets are hashed with a salt and a pepper, and never logged or returned after creation
* **Easy-to-use**: just inherited from the repository and use service
* **Prod-ready**: services and repositories are async, and battle-tested
* **Agnostic hasher**: you can use any async-compatible hashing strategy (default: Argon2)
* **Agnostic backend**: you can use any async-compatible database (default: SQLAlchemy)
* **Factory**: create a Typer, FastAPI router wired to api key systems (only SQLAlchemy for now)

**I‚Äôd love feedback on (but not limited to) the following:**

* Are there features you would expect that don‚Äôt exist?
* Does the SQLAlchemy Mixin approach seem good for handling custom field extensions?
* Do you see any potential flaws with the current hashing/peppering strategy?
* What do you think about the extras/packaging approach (‚Äúcore‚Äù, ‚Äúfastapi‚Äù, ‚Äúall‚Äù)?

Is there anything else I should add to make it more usable? If you want to browse the code, start with the preliminary README (which includes usage examples). There‚Äôs also mkdocs documentation with quickstarts and usage guides.",16,3,2025-10-11 11:24:01,__secondary__,https://www.reddit.com/r/Python/comments/1o3s3yj/feedback_request_for_api_key_management_library/
1o3vzbm,reddit,sdax - an API for asyncio for handling parallel tasks declaratively,"Parallel async¬†is fast, but managing failures and cleanup across¬†multiple dependent operations is hard.

sdax - (Structured Declarative Async eXecution) does all the heavy lifting. You just need to write the async functions and wire them into ""levels"".

I'm working on an extension to sdax for doing all the initialization using decorators - coming next.

Requires Python 3.11 or higher since it uses asyncio.TaskGroup and ExceptionGroup which were introduced in 3.11.

See: [https://pypi.org/project/sdax](https://pypi.org/project/sdax/), [https://github.com/owebeeone/sdax](https://github.com/owebeeone/sdax)",7,5,2025-10-11 14:43:02,GianniMariani,https://www.reddit.com/r/Python/comments/1o3vzbm/sdax_an_api_for_asyncio_for_handling_parallel/
1o3ijyt,reddit,How much Python do I really need to know to land my first dev job?,"Hey everyone,
I‚Äôve been working as a Data Analyst at an energy distribution company for about a year and a half. My long-term goal has always been to build the skills needed to transition into a developer role.
I feel like it‚Äôs finally time to sharpen my knowledge and make that pivot ‚Äî but honestly, I still feel like I know nothing, even though I‚Äôm a bit of a Swiss Army knife in my current job.
Here‚Äôs a quick overview of what I already know and where I‚Äôm at:
Several Python certificates (Coursera and Cisco).
Certified and experienced in SQL databases (DDL and DML).
Comfortable working with Linux systems.
Process automation experience using PDI Spoon and batch scripts.
Currently studying Data Analytics and Machine Learning with Python.
I haven‚Äôt worked with APIs or HTTP requests yet, and my English level is low, but I‚Äôm improving.
Where should I focus next? Do I need to go deeper in Python itself, or start learning web frameworks, APIs, or something else to move toward a dev job?",43,46,2025-10-11 02:09:54,Secure-Hornet7304,https://www.reddit.com/r/Python/comments/1o3ijyt/how_much_python_do_i_really_need_to_know_to_land/
1o2viq3,reddit,uv cheatsheet with most common/useful commands,"I've been having lots of fun using Astral's uv and also teaching it to friends and students, so I decided to create a cheatsheet with the most common/useful commands.

[uv cheatsheet with most common/useful commands](https://mathspp.com/blog/uv-cheatsheet)

I included sections about

 - project creation;
 - dependency management;
 - project lifecycle & versioning;
 - installing/working with tools;
 - working with scripts;
 - uv's interface for `pip` and `venv`; and
 - some meta & miscellaneous commands.

The link above takes you to a page with all these sections as regular tables and to high-resolution/print-quality downloadable files you can  get for yourself from the link above.

I hope this is helpful for you and if you have any feedback, I'm all ears!",397,73,2025-10-10 09:42:23,RojerGS,https://www.reddit.com/r/Python/comments/1o2viq3/uv_cheatsheet_with_most_commonuseful_commands/
1o3v4cs,reddit,Built an automated GitHub-RAG pipeline system with incremental sync,"**What My Project Does**

RAGIT is a fully automated RAG pipeline for GitHub repositories. Upload a repo and it handles collection, preprocessing, embedding, vector indexing, and incremental synchronization automatically. Context is locked to specific commits to avoid version confusion. When you ask questions, hybrid search finds relevant code with citations and answers consistently across multiple files.

**Target Audience**

Production-ready system for development teams working with large codebases. Built with microservices architecture (Gateway-Backend-Worker pattern) using PostgreSQL, Redis, and Milvus. Fully dockerized for easy deployment. Useful for legacy code analysis, project onboarding, and ongoing codebase understanding.

**Comparison**

Unlike manually copying code into ChatGPT/Claude which loses context and version tracking, RAGIT automates the entire pipeline and maintains commit-level consistency. Compared to other RAG frameworks that require manual chunking and indexing, RAGIT handles GitHub repos end-to-end with automatic sync when code changes. More reproducible and consistent than direct LLM usage.

Apache 2.0 licensed.

GitHub: https://github.com/Gyu-Chul/RAGIT
Demo: https://www.youtube.com/watch?v=VSBDDvj5_w4

Open to feedback.",1,0,2025-10-11 14:04:00,RecentHearing8646,https://www.reddit.com/r/Python/comments/1o3v4cs/built_an_automated_githubrag_pipeline_system_with/
1o3323m,reddit,PipeFunc: Build Lightning-Fast Pipelines with Python: DAGs Made Easy,"Hey r/Python!

I'm excited to share `pipefunc` ([github.com/pipefunc/pipefunc](https://github.com/pipefunc/pipefunc)), a Python library designed to make building and running complex computational workflows incredibly fast and easy. If you've ever dealt with intricate dependencies between functions, struggled with parallelization, or wished for a simpler way to create and manage DAG pipelines, `pipefunc` is here to help.

**What My Project Does:**

`pipefunc` empowers you to easily construct **Directed Acyclic Graph (DAG)** pipelines in Python. It handles:

1. **Automatic Dependency Resolution:**  `pipefunc` automatically determines the correct execution order of your functions, eliminating manual dependency management.
2. **Lightning-Fast Execution:** With minimal overhead (around **10 ¬µs per function call**), `pipefunc` ensures your pipelines run super fast.
3. **Effortless Parallelization:** `pipefunc` automatically parallelizes independent tasks, whether on your local machine or a SLURM cluster. It supports any `concurrent.futures.Executor`!
4. **Intuitive Visualization:** Generate interactive graphs to visualize your pipeline's structure and understand data flow.
5. **Simplified Parameter Sweeps:**  `pipefunc`'s `mapspec` feature lets you easily define and run N-dimensional parameter sweeps, which is perfect for scientific computing, simulations, and hyperparameter tuning.
6. **Resource Profiling:** Gain insights into your pipeline's performance with detailed CPU, memory, and timing reports.
7. **Caching:** Avoid redundant computations with multiple caching backends.
8. **Type Annotation Validation:** Ensures type consistency across your pipeline to catch errors early.
9. **Error Handling:** Includes an `ErrorSnapshot` feature to capture detailed information about errors, making debugging easier.

**Target Audience:**

`pipefunc` is ideal for:

*   **Scientific Computing:** Streamline simulations, data analysis, and complex computational workflows.
*   **Machine Learning:** Build robust and reproducible ML pipelines, including data preprocessing, model training, and evaluation.
*   **Data Engineering:** Create efficient ETL processes with automatic dependency management and parallel execution.
*   **HPC:** Run `pipefunc` on a SLURM cluster with minimal changes to your code.
*   **Anyone** working with interconnected functions who wants to improve code organization, performance, and maintainability.

`pipefunc` is designed to be flexible (great tool for prototyping and experimentation) and easy to adopt!

**Comparison:**

*  **vs. Hamilton:** Hamilton also compiles Python functions into
DAGs, but it centers on column-level DataFrame engineering, ships modifiers like @with_columns/@extract_columns, and offers built-in data/schema validation plus an optional UI for lineage and observability; pipefunc leans toward low-overhead scientific/HPC pipelines, executor-agnostic parallelism, and N-D sweeps via mapspecs.
*   **vs. Dask:** `pipefunc` offers a higher-level, more declarative way to define pipelines. It automatically manages task scheduling and execution based on your function definitions and `mapspec`s, without requiring you to write explicit parallel code.
*   **vs. Luigi/Airflow/Prefect/Kedro:** While those tools excel at ETL and event-driven workflows, `pipefunc` focuses on scientific computing, simulations, and computational workflows where fine-grained control over execution and resource allocation is crucial. Also, it's way easier to setup and develop with, with minimal dependencies!
*   **vs. Pandas:** You can easily combine `pipefunc` with `Pandas`! Use `pipefunc` to manage the execution of `Pandas` operations and parallelize your data processing pipelines. But it also works well with `Polars`, `Xarray`, and other libraries!
*   **vs. Joblib:** `pipefunc` offers several advantages over `Joblib`. `pipefunc` automatically determines the execution order of your functions, generates interactive visualizations of your pipeline, profiles resource usage, and supports multiple caching backends. Also, `pipefunc` allows you to specify the mapping between inputs and outputs using `mapspec`s, which enables complex map-reduce operations.

**Examples:**

**Simple Example:**

```python
from pipefunc import pipefunc, Pipeline

@pipefunc(output_name=""c"")
def add(a, b):
    return a + b

@pipefunc(output_name=""d"")
def multiply(b, c):
    return b * c

pipeline = Pipeline([add, multiply])
result = pipeline(""d"", a=2, b=3)  # Automatically executes 'add' first
print(result)  # Output: 15

pipeline.visualize() # Visualize the pipeline
```

**Parallel Example with `mapspec`:**

Parallelizes for all combinations of inputs `a` and `b` automatically!

```python
import numpy as np
from pipefunc import pipefunc, Pipeline
from pipefunc.map import load_outputs

@pipefunc(output_name=""c"", mapspec=""a[i], b[j] -> c[i, j]"")
def f(a: int, b: int):
    return a + b

@pipefunc(output_name=""mean"") # no mapspec, so receives 2D `c[:, :]`
def g(c: np.ndarray):
    return np.mean(c)

pipeline = Pipeline([f, g])
inputs = {""a"": [1, 2, 3], ""b"": [4, 5, 6]}
result_dict = pipeline.map(inputs, run_folder=""my_run_folder"", parallel=True)
result = load_outputs(""mean"", run_folder=""my_run_folder"") # can load now too
print(result)  # Output: 7.0
```

**Getting Started:**

*   **Docs:** [https://pipefunc.readthedocs.io/](https://pipefunc.readthedocs.io/)
*   **Source:** [https://github.com/pipefunc/pipefunc](https://github.com/pipefunc/pipefunc)

I'm exctited to hear your feedback and answer any questions you have. Give `pipefunc` a try and let me know how it can improve your workflows!
",58,14,2025-10-10 15:52:08,basnijholt,https://www.reddit.com/r/Python/comments/1o3323m/pipefunc_build_lightningfast_pipelines_with/
1o3qk1p,reddit,UV on termux Debian (android),"Anybody managed to build it? And if so, pretty please with chocolate chips, how? I've made the obvious attempts (pip install, cargo...) but no joy so far.",2,2,2025-10-11 09:45:27,DharmaBird,https://www.reddit.com/r/Python/comments/1o3qk1p/uv_on_termux_debian_android/
1o396tf,reddit,SPDL - Scalable and Performant Data Loading,"Hi Python community,

Inspired by recent showcases on pipeline libraries ([Pipevine](https://www.reddit.com/r/Python/comments/1o2n119/ergonomic_concurrency/), [pipefunc](https://www.reddit.com/r/Python/comments/1o3323m/pipefunc_build_lightningfast_pipelines_with/)), I‚Äôd like to share my project:¬†**SPDL (Scalable and Performant Data Loading)**. 

# What My Project Does

SPDL is designed to address the data loading bottleneck in machine learning (ML) and AI training pipelines. You break down data loading into discrete tasks with different constraints (network, CPU, GPU transfer etc) and construct a pipeline, and SPDL executes them efficiently. It features a task execution engine (pipeline abstraction) built on asyncio, alongside an independent I/O module for media processing. 

# Resources:

* **Repo:**¬†[https://github.com/facebookresearch/spdl](https://github.com/facebookresearch/spdl)
* **Documentation:**¬†[SPDL Docs](https://facebookresearch.github.io/spdl/main/)
* **PyPI:**
   * Install with `pip install spdl`
      * [spdl-core](https://pypi.org/project/spdl-core/) (no dependency)
      * [spdl-io](https://pypi.org/project/spdl-io/) (requires NumPy, and optionally PyTorch / Numba / Jax) 
* **arXiv:** [2504.20067](https://arxiv.org/abs/2504.20067)

# Target Audience

ML practitioners whose focus is model training rather than software engineering. It is production-ready.

# Core Principles

* **High Throughput & Efficiency:**¬†SPDL maximizes data loading speed and minimizes CPU/memory overhead to keep GPUs busy.
* **Flexibility:**¬†The pipeline abstraction is highly customizable, allowing users to tailor the structure to their environment, data, and requirements.
* **Observability:**¬†SPDL provides runtime statistics for each pipeline component, helping users identify bottlenecks and optimize performance.
* **Intuitive Construction:**¬†Pipelines are easy to build and reason about, with clear separation of stages and bounding factors.

# Architecture Overview

* **Pipeline Abstraction:**¬†With SPDL, you break down data loading into discrete tasks with different constraints (network, CPU, GPU transfer etc) and construct a pipeline that executes each task concurrently.
* **Multi-threading & Multi-processing:**¬†SPDL uses multi-threading by default for parallelism, with optional multi-processing for workloads that benefit from process isolation. In production, we‚Äôve successfully used multi-threading with Python 3.10 by composing functions that release the GIL. Support for InterpreterPoolExecutor in Python 3.14 is planned.
* **Async Event Loop:**¬†The task execution engine is built on an async event loop, supporting both async and regular functions.
* **Media I/O Module:**¬†Includes a high-performance I/O module for audio, video, and image processing, designed from scratch for maximum throughput. It also supports loading NumPy array fast from memory.
* **Non-invasive:** SPDL orchestrates the execution of given functions, and the only requirement for the function is that it is univariate function. No requirements to change your algorithms/business logic to pipelining it with SPDL.

# Monitoring & Optimization

SPDL exports detailed runtime statistics for each pipeline stage, making it easy to monitor throughput, resource usage, and identify bottlenecks. For more on production bottleneck analysis, see the¬†[Optimization Guide](https://l.facebook.com/l.php?u=https%3A%2F%2Ffacebookresearch.github.io%2Fspdl%2Fmain%2Foptimization_guide%2Fanalysis.html&h=AT3Hi60CVKm_FzR6YfXpfbCm4kDWAVz5144UjUlM7PbqiIaM-7yzNqESVRJqwnHieAIYd_BoPn5GkG8-t66ZfmbEbyS3hyMsNXu-CqwngZ5FVw1ZdbXwhRVG1xYKrE4d81n7m4rYPBbi2XQBwy898DT9nWE).

# Comparison

* Unlike previously shared projects, the feature set is more specific to ML efficiency. (though the pipeline abstraction is generic, and library is agnostic to ML framework)
* Supports single chain pipelining with different concurrency. Merging pipeline is also supported but not branching or general graph structure.",17,1,2025-10-10 19:38:53,moto900,https://www.reddit.com/r/Python/comments/1o396tf/spdl_scalable_and_performant_data_loading/
1o35xlh,reddit,EPUBLib - New python library for creating and editing EPUB3 files,"I wrote a python library to edit and create EPUB3 files.

* Repository:¬†[gitlab.com/joaoseckler/epublib](http://gitlab.com/joaoseckler/epublib)
* PyPi:¬†[pypi.org/project/epublib/](http://pypi.org/project/epublib/)
* Documentation:¬†[epub-lib.readthedocs.io/en/latest/](http://epub-lib.readthedocs.io/en/latest/)

Any suggestions and criticisms are welcome! And if you know any other places where people might be interested in this tool, please let me know.

**What My Project Does:**

It is a library for creating and editing EPUB documents according to the EPUB3 specification. Example from the [documentation](https://epub-lib.readthedocs.io/en/latest/index.html#basic-usage):

    from epublib import EPUB
    
    with EPUB(""book.epub"") as book:
        book.metadata.title = ""New title""
    
        for doc in book.documents:
            new_script = doc.soup.new_tag(""script"", attrs={""src"": ""../Misc/myscript.js""})
            doc.soup.head.append(new_script)
    
            new_heading = doc.soup.new_tag(""h1"", string=""New heading"")
            doc.soup.body.insert(0, new_heading)
    
        book.update_manifest_properties()
        book.write(""book-modified.epub"")

See the¬†[usage section¬†](https://epub-lib.readthedocs.io/en/latest/#basic-usage)of the documentation for a more usage examples.

**Target Audience:**

People working with publishing digital books using the EPUB format.

**Comparison:**

There is already an active python library called¬†[EbookLib](https://pypi.org/project/EbookLib/)¬†for handling EPUBs. A few things EPUBLib does differently:

1. Handles the EPUB non-intrusively, e.g. won't regenerate the package document/metadata before writing, can edit toc without recreating the entire navigation document;
2. Built-in XML parsing with BeautifulSoup;
3. Extra features: rename files, remove files, spine reordering etc;
4. Use nomenclature from the specification when possible (e.g. ""resource"" instead of ""item"").

",17,0,2025-10-10 17:37:48,joaoseckler,https://www.reddit.com/r/Python/comments/1o35xlh/epublib_new_python_library_for_creating_and/
1o4167n,reddit,Sell me (and my team) on UV,"I think UV is great so far, I only recently started using it. I would like to move myself and my team to using it as our official package manager, but I don‚Äôt really know the extent of why ‚Äúthis tool is better than venv/pip‚Äù. It was hard enough to convince them we should be using venv in the first place, but now I feel like I‚Äôm trying to introduce a tool that adds seemingly quite a bit more complexity.

Just curious on all the benefits and what I can say to encourage the movement.

Thanks!",0,22,2025-10-11 18:16:08,lukanixon,https://www.reddit.com/r/Python/comments/1o4167n/sell_me_and_my_team_on_uv/
1o2yh3k,reddit,Vision Agents 0.1,"First steps here, we've just released 0.1 of Vision Agents. [https://github.com/GetStream/Vision-Agents](https://github.com/GetStream/Vision-Agents)

**What My Project Does**

The idea is that it makes it super simple to build vision agents, combining fast models like Yolo with Gemini/Openai realtime. We're going for low latency & a completely open sdk. So you can use any vision model or video edge network. 

Here's an example of running live video through Yolo and then passing it to Gemini

    agent = Agent(
        edge=getstream.Edge(),
        agent_user=agent_user,
        instructions=""Read @golf_coach.md"",
        llm=openai.Realtime(fps=10),
        #llm=gemini.Realtime(fps=1), # Careful with FPS can get expensive
        processors=[ultralytics.YOLOPoseProcessor(model_path=""yolo11n-pose.pt"")],
    )

**Target Audience**¬†

Vision AI is like chatgpt in 2022. It's really fun to see how it works and what's possible. Anything from live coaching, to sports, to physical therapy, robotics, drones etc. But it's not production quality yet. Gemini and OpenAI both hallucinate a ton for vision AI. It seems close to being viable though, especially fun to have it describe your surroundings etc.

**Comparison**

Similar to Livekit Agents (livekit specific) and Pipecat (daily). We're going for open to all edge networks, low latency and with a focus on vision AI (voice works, but we're focused on live video)

This has been fun to work on with the team, finally at 0.1 :)



",18,2,2025-10-10 12:37:10,tschellenbach,https://www.reddit.com/r/Python/comments/1o2yh3k/vision_agents_01/
1o3ru8r,reddit,Intermediate-level project suggestions,"I need intermediate-level project ideas that I can do with Python. Other languages can be added to the project as well, that‚Äôs not a problem. They need to look good on GitHub and on my CV.",0,4,2025-10-11 11:07:39,learning_linuxsystem,https://www.reddit.com/r/Python/comments/1o3ru8r/intermediatelevel_project_suggestions/
1o2u6gy,reddit,Fiatlight: Instantly turn Python functions into interactive GUI apps or workflows,"**What Fiatlight Does**

[Fiatlight](https://pthom.github.io/fiatlight_doc) is a Python toolkit that lets you build interactive graphical applications by providing an *automatic user interface* for functions and dataclasses. It is published under the MIT license.

You may think of Fiatlight as *""ComfyUI for any type of data and functions""*: easy visual and interactive pipelines for any domain of interest. You do not have to write any UI code, and you can connect multiple functions to build workflows instantly: the outputs flow from one function to the next

Users can then adjust every parameter of the functions and save/reload their work. 

Fiatlight is built on top of Dear ImGui Bundle. It is very fast, and can provide feedback in real-time (at 120 FPS!). Since Dear ImGui Bundle is available via Pyodide, Fiatlight applications can be used locally or deployed as static web pages, without any server-side component.

As a prototyping tool, fiatlight does *not* provide full design control over the UI. It does however provide advanced viewer for many data types (standard python types, images, files, dataframes, matplotlib figures,  etc.), and is easily extensible.
 
*Links:*
- [Video tutorials](https://pthom.github.io/fiatlight_doc/flgt/video_tutorials.html)
- [Documentation](https://pthom.github.io/fiatlight_doc)
- [GitHub repo](https://github.com/pthom/fiatlight)


**Target Audience**

* Hobbyists wanting to create interactive applications quickly
* Educators and instructors needing interactive tools for teaching programming or algorithms
* Researchers who need shareable demos or visualizations of their work
* Developers who want to fine tune their algorithms, with visual feedback
* Library authors who want to showcase or demonstrate how to use and compose their functions
* Data scientists and analysts wanting instant GUI dashboards for exploring data


**Comparison**

* Broader scope than ComfyUI
* Often faster than streamlit or gradio (runs locally or serverless on a static web page)
* LabVIEW is famous for data acquisition, hardware integration, and quick GUI building, but is expensive and highly niche/proprietary
* Unreal Blueprints are widely used for visual scripting in games and rapid prototyping, but tightly coupled to Unreal Engine and less suitable for general Python/data workflows

**Example**

The example below showcases a simple pipeline where the user edits the input float value, and automatically sees the output of each function. Widgets for each parameter are generated according to type and customized with attributes.

```python
# Our functions
def float_source(x: float = 1.0) -> float:
    return x
def double(x: float = 1.0) -> float:
    return 2 * x

# Below, our GUI, where the user can edit the input for float_source, and see the output of both functions

import fiatlight as fl
# Set range for slider
fl.add_fiat_attributes(float_source, x__edit_type=""slider"", x__range=(0.0, 10.0))  

# Display a GUI for the composition of these two functions
fl.run([float_source, double])  
```
",22,0,2025-10-10 08:12:39,pstomi,https://www.reddit.com/r/Python/comments/1o2u6gy/fiatlight_instantly_turn_python_functions_into/
1o3h3uy,reddit,Saturday Daily Thread: Resource Request and Sharing! Daily Thread,"# Weekly Thread: Resource Request and Sharing üìö

Stumbled upon a useful Python resource? Or are you looking for a guide on a specific topic? Welcome to the Resource Request and Sharing thread!

## How it Works:

1. **Request**: Can't find a resource on a particular topic? Ask here!
2. **Share**: Found something useful? Share it with the community.
3. **Review**: Give or get opinions on Python resources you've used.

## Guidelines:

* Please include the type of resource (e.g., book, video, article) and the topic.
* Always be respectful when reviewing someone else's shared resource.

## Example Shares:

1. **Book**: [""Fluent Python""](https://www.amazon.com/Fluent-Python-Concise-Effective-Programming/dp/1491946008) \- Great for understanding Pythonic idioms.
2. **Video**: [Python Data Structures](https://www.youtube.com/watch?v=pkYVOmU3MgA) \- Excellent overview of Python's built-in data structures.
3. **Article**: [Understanding Python Decorators](https://realpython.com/primer-on-python-decorators/) \- A deep dive into decorators.

## Example Requests:

1. **Looking for**: Video tutorials on web scraping with Python.
2. **Need**: Book recommendations for Python machine learning.

Share the knowledge, enrich the community. Happy learning! üåü",1,1,2025-10-11 01:00:34,AutoModerator,https://www.reddit.com/r/Python/comments/1o3h3uy/saturday_daily_thread_resource_request_and/
1o3otup,reddit,Neend some career advice,I am bpharm 4 yr student and I wanted to work in the field of programming and development I basically have no knowledge about programming skills I am currently 22 yr should I pursue with programming or I should just stick to the pharmacy ,0,3,2025-10-11 07:54:33,Agreeable-Ad1713,https://www.reddit.com/r/Python/comments/1o3otup/neend_some_career_advice/
1o2n119,reddit,Ergonomic Concurrency,"**Project name:** Pipevine  
**Project link:** [https://github.com/arrno/pipevine](https://github.com/arrno/pipevine)

**What My Project Does**  
Pipevine is a lightweight async pipeline and worker-pool library for Python.  
It helps you compose concurrent dataflows with backpressure, retries, and cancellation.. without all the asyncio boilerplate.

**Target Audience**  
Developers who work with data pipelines, streaming, or CPU/IO-bound workloads in Python.  
It‚Äôs designed to be production-ready but lightweight enough for side projects and experimentation.

**How to Get Started**

    pip install pipevine

    import asyncio
    from pipevine import Pipeline, work_pool
    
    @work_pool(buffer=10, retries=3, num_workers=4)
    async def process_data(item, state):
        # Your processing logic here
        return item * 2
    
    @work_pool(buffer=5, retries=1)
    async def validate_data(item, state):
        if item < 0:
            raise ValueError(""Negative values not allowed"")
        return item
    
    # Create and run pipeline
    pipe = Pipeline(range(100)) >> process_data >> validate_data
    result = await pipe.run()
    

**Feedback Requested**  
I‚Äôd love thoughts on:

* API ergonomics (does it feel Pythonic?)
* Use cases where this could simplify your concurrency setup
* Naming and documentation clarity",25,15,2025-10-10 01:50:54,kwargs_,https://www.reddit.com/r/Python/comments/1o2n119/ergonomic_concurrency/
1o3luxp,reddit,Automating the Upgrade to Python 3.14,"I detailed the process I followed to get OpenAI‚Äôs codex cli  to upgrade a complex project with lots of dependencies to python 3.14 with uv:

https://x.com/doodlestein/status/1976478297744699771?s=46

Charlie Marsh retweeted it, so you can trust that it‚Äôs not a bunch of nonsense! Hope you guys find it useful.",0,5,2025-10-11 05:01:59,dicklesworth,https://www.reddit.com/r/Python/comments/1o3luxp/automating_the_upgrade_to_python_314/
1o24iwv,reddit,T Strings - Why there is no built in string rendering?,"I like the idea of T Strings and here is a toy example:

    name: str = 'Bob'
    age: int = 30
    template = t'Hello, {name}! You are {age} years old.'
    print (template.strings)
    print(template. interpolations)
    print(template. values)
    
    ('Hello, ', '! You are ', ' years old.')
    (Interpolation('Bob', 'name', None, ''), Interpolation(30, 'age', None, ''))
    ('Bob', 30)

But why isn't there a

`print(template.render)`

`# ‚Üí '`Hello, Bob! You are 30 years old.'",130,65,2025-10-09 13:25:45,UsernamesArentClever,https://www.reddit.com/r/Python/comments/1o24iwv/t_strings_why_there_is_no_built_in_string/
1o29byq,reddit,"Single Source of Truth - Generating ORM, REST, GQL, MCP, SDK and Tests from Pydantic","# What My Project Does

I built an extensible AGPL-3.0 Python server framework on FastAPI and SQLAlchemy after getting sick of writing the same thing 4+ times in different ways. It takes your Pydantic models and automatically generates:

* The ORM models with relationships
* The migrations
* FastAPI REST endpoints (CRUD - including batch, with relationship navigation and field specifiers)
* GraphQL schema via Strawberry (including nested relationships)
* MCP (Model Context Protocol) integration
* SDK for other projects
* Pytest tests for all of the above
* Coming Soon: **External API federation** from third-party APIs directly into your models (including **into the GQL schema**) - [early preview screenshot](https://imgur.com/a/Cem1FOT)

# Target Audience

Anyone who's also tired of writing the same thing 4 different ways and wants to ship ASAP.

# Comparison

Most tools solve one piece of this problem:

* `SQLModel` generates SQLAlchemy models from Pydantic but doesn't handle REST/GraphQL/tests
* `Strawberry/Graphene Extensions` generate GraphQL schemas but require separate REST endpoints and ORM definitions
* `FastAPI-utils/FastAPI-CRUD` generate REST endpoints but require manual GraphQL and testing setup
* `Hasura/PostGraphile` auto-generate GraphQL from databases but aren't Python-native and don't integrate with your existing Pydantic models

This framework generates all of it - ORM, REST, GraphQL, SDK, and tests - from a single Pydantic definition. The API federation feature also lets you integrate external APIs (Stripe, etc.) directly into your generated GraphQL schema, which most alternatives can't do.

# Links

Documentation available on GitHub and well-organized through Obsidian after cloning: [https://github.com/JamesonRGrieve/ServerFramework](https://github.com/JamesonRGrieve/ServerFramework)

I also built a NextJS companion front end that's designed to be similarly extensible.

[https://github.com/JamesonRGrieve/ClientFramework](https://github.com/JamesonRGrieve/ClientFramework)

Feedback and contributions welcome!",63,15,2025-10-09 16:41:09,ZephyrWarrior,https://www.reddit.com/r/Python/comments/1o29byq/single_source_of_truth_generating_orm_rest_gql/
1o2uzxf,reddit,Loadouts for Genshin Impact v0.1.11 is OUT NOW with support for Genshin Impact v6.0 Phase 2,"# About

This is a desktop application that allows travelers to manage their custom equipment of artifacts and weapons for playable characters and makes it convenient for travelers to calculate the associated statistics based on their equipment using the semantic understanding of how the gameplay works. Travelers can create their bespoke loadouts consisting of characters, artifacts and weapons and share them with their fellow travelers. Supported file formats include a human-readable¬†**Yet Another Markup Language (YAML)**¬†serialization format and a JSON-based¬†**Genshin Open Object Definition (GOOD)**¬†serialization format.

This project is currently in its beta phase and we are committed to delivering a quality experience with every release we make. If you are excited about the direction of this project and want to contribute to the efforts, we would greatly appreciate it if you help us boost the project visibility by¬†**starring the project repository**, address the releases by¬†**reporting the experienced errors**, choose the direction by¬†**proposing the intended features**, enhance the usability by¬†**documenting the project repository**, improve the codebase by¬†**opening the pull requests**¬†and finally, persist our efforts by¬†**sponsoring the development members**.

# Technologies

* Pydantic
* Pytesseract
* PySide6
* Pillow

# Updates

[Loadouts for Genshin Impact v0.1.11](https://gridhead.net/loadouts-for-genshin-impact-v0-1-11-released/) is OUT NOW with the addition of support for recently released artifacts like¬†*Night of the Sky's Unveiling*¬†and¬†*Silken Moon's Serenade*, recently released characters like¬†*Aino*,¬†*Lauma*¬†and¬†*Flins*¬†and for recently released weapons like¬†*Blackmarrow Lantern*,¬†*Bloodsoaked Ruins*,¬†*Etherlight Spindlelute*,¬†*Master Key*,¬†*Moonweaver's Dawn*,¬†*Nightweaver's Looking Glass*,¬†*Propsector's Shovel*,¬†*Serenity's Call*¬†and¬†*Snare Hook*¬†from¬†**Genshin Impact Luna I or v6.0 Phase 2**. Take this FREE and OPEN SOURCE application for a spin using the links below to manage the custom equipment of artifacts and weapons for the playable characters.

# Resources

* [Loadouts for Genshin Impact - GitHub](https://github.com/gridhead/gi-loadouts?ref=gridhead.net)
* [Loadouts for Genshin Impact - PyPI](https://pypi.org/project/gi-loadouts/?ref=gridhead.net)
* [Loadouts for Genshin Impact v0.1.11](https://github.com/gridhead/gi-loadouts/releases/tag/0.1.11?ref=gridhead.net)
   * [Executable for GNU/Linux distributions](https://github.com/gridhead/gi-loadouts/releases/download/0.1.11/gi-loadouts-0.1.11?ref=gridhead.net)
   * [Executable for Microsoft Windows](https://github.com/gridhead/gi-loadouts/releases/download/0.1.11/gi-loadouts-0.1.11.exe?ref=gridhead.net)

# Installation

Besides its availability as a¬†[*repository package on PyPI*](https://pypi.org/project/gi-loadouts/?ref=gridhead.net)¬†and as an¬†[*archived binary on PyInstaller*](https://github.com/gridhead/gi-loadouts/releases/tag/0.1.10?ref=gridhead.net), Loadouts for Genshin Impact is now available as an¬†[*installable package on Fedora Linux*](https://src.fedoraproject.org/rpms/gi-loadouts?ref=gridhead.net). Travelers using¬†[*Fedora Linux 42 and above*](https://bodhi.fedoraproject.org/updates/?search=gi-loadouts&user=t0xic0der&ref=gridhead.net)¬†can install the package on their operating system by executing the following command.

    $ sudo dnf install gi-loadouts --assumeyes --setopt=install_weak_deps=False

# Appeal

While allowing you to experiment with various builds and share them for later, Loadouts for Genshin Impact lets you take calculated risks by showing you the potential of your characters with certain artifacts and weapons equipped that you might not even own. Loadouts for Genshin Impact has been and always will be a free and open source software project, and we are committed to delivering a quality experience with every release we make.

# Disclaimer

With an extensive suite of over 1503 diverse functionality tests and impeccable 100% source code coverage, we proudly invite auditors and analysts from MiHoYo and other organizations to review our free and open source codebase. This thorough transparency underscores our unwavering commitment to maintaining the fairness and integrity of the game.

The users of this ecosystem application can have complete confidence that their accounts are safe from warnings, suspensions or terminations when using this project. The ecosystem application ensures complete compliance with the terms of services and the regulations regarding third-party software established by MiHoYo for Genshin Impact.

All rights to Genshin Impact assets used in this project are reserved by miHoYo Ltd. and Cognosphere Pte., Ltd. Other properties belong to their respective owners.",4,2,2025-10-10 09:07:25,t0xic0der,https://www.reddit.com/r/Python/comments/1o2uzxf/loadouts_for_genshin_impact_v0111_is_out_now_with/
1o2j714,reddit,New Stockdex release,"Hi reddit, 

i have released a new version of my open-source python package, Stockdex with new detailed documentation that you can find [here](https://ahnazary.github.io/stockdex/). I would love to hear your feedback and suggestions for future improvements.

# What my project does?

Stockdex is a Python package that provides a simple interface to get financial data from various sources in pandas DataFrames and Plotly figures. It supports multiple data sources including Yahoo Finance, Digrin, Finviz, Macrotrends, and JustETF (for EU ETFs). 

# Main differences with other packages

- Various data sources: Provides data from multiple sources (e.g. Yahoo Finance, Digrin, Finviz, Macrotrends, JustETF).
- Historical data: Provides a wide time range of data, e.g. Digrin and Macrotrends sources provide historical data in a span of years, unlike other packages like `yfinance` which only 4 - 5 years of historical data at max. 
- Numerous data categories: Stockdex provides financials criteria including financial statements, earnings, dividends, stock splits, list of key executives, major shareholders and more.
- Plotting capabilities (new feature): Plotting financial data using bar, line, and sankey plots. Detailed documentation with examples is available [here](https://ahnazary.github.io/stockdex/plots_and_figures.html).

# Installation

Simple pip install:

```bash
pip install stockdex -U
```

# Target audience

Anyone interested in financial data analysis.

[Github repo](https://github.com/ahnazary/stockdex)
[PyPI](https://pypi.org/project/stockdex/)",10,7,2025-10-09 22:57:47,nginx26,https://www.reddit.com/r/Python/comments/1o2j714/new_stockdex_release/
1o2lz3l,reddit,Friday Daily Thread: r/Python Meta and Free-Talk Fridays,"# Weekly Thread: Meta Discussions and Free Talk Friday üéôÔ∏è

Welcome to Free Talk Friday on /r/Python! This is the place to discuss the r/Python community (meta discussions), Python news, projects, or anything else Python-related!

## How it Works:

1. **Open Mic**: Share your thoughts, questions, or anything you'd like related to Python or the community.
2. **Community Pulse**: Discuss what you feel is working well or what could be improved in the /r/python community.
3. **News & Updates**: Keep up-to-date with the latest in Python and share any news you find interesting.

## Guidelines:

* All topics should be related to Python or the /r/python community.
* Be respectful and follow Reddit's [Code of Conduct](https://www.redditinc.com/policies/content-policy).

## Example Topics:

1. **New Python Release**: What do you think about the new features in Python 3.11?
2. **Community Events**: Any Python meetups or webinars coming up?
3. **Learning Resources**: Found a great Python tutorial? Share it here!
4. **Job Market**: How has Python impacted your career?
5. **Hot Takes**: Got a controversial Python opinion? Let's hear it!
6. **Community Ideas**: Something you'd like to see us do? tell us.

Let's keep the conversation going. Happy discussing! üåü",5,2,2025-10-10 01:01:00,AutoModerator,https://www.reddit.com/r/Python/comments/1o2lz3l/friday_daily_thread_rpython_meta_and_freetalk/
1o34d3a,reddit,Reflex Build Free Tier Is Back!,"A few days ago, **Reflex** re-introduced the **free tier** for their AI builder: **Reflex Build**.

[Reflex Build](https://build.reflex.dev/) is a powerful, Python-first AI app builder built on top of the Reflex framework. It generates **production-ready, enterprise-grade web apps** ‚Äî all in Python.

Whether you're building dashboards, internal tools, data viz apps, or just simple static pages, Reflex Build handles both **frontend and backend** in Python.

# Main Features

* **Plug-and-Play Integrations** Built-in support for popular tools like Databricks, Azure, Google Auth, and more ‚Äî no setup headaches.
* **Polished UI with Tailwind 4** Clean, responsive components out of the box, styled with the latest Tailwind CSS.
* **Private or Public Apps** Choose whether your apps are accessible to the world or kept private by default.
* **Fast, Tuned Agent Runtime** A finely optimized agent gets your app logic up and running instantly.
* **Built-In Testing** Ship with confidence using integrated testing tools for your app‚Äôs logic and behavior.
* **Customizable Themes** Use predefined themes or build your own to match your brand or aesthetic.
* **Markdown Support** Easily render rich content and documentation directly inside your apps.
* **Mobile-Ready by Default** Fully responsive layouts ensure your app looks great on all devices.

If you build something neat, share a screenshot or a link, I‚Äôd love to see what you're making.

",0,2,2025-10-10 16:39:41,None,https://www.reddit.com/r/Python/comments/1o34d3a/reflex_build_free_tier_is_back/
1o2t7zq,reddit,aiar: A pypi CLI tool for managing self-extracting archives suited to LLMs,"

Announcing the release of aiar, a command-line utility for packaging/extracting file collections via a single archive.

The primary use case is to simplify sending and receiving multi-file projects in text-only environments, particularly when interacting with LLMs. LLMs will find it particularly easy to create these files since there is no need to escape any characters. In particular, you don‚Äôt even need the aiar tool if you trust your LLM to generate the self-extracting script for you.

### **Key Features**

* **Self-Contained:** Archives contain both the extraction logic and data. No external tools like zip or tar are required to unpack.  
* **Multi-Format Output:** Generate self-extracting archives as Bash, Python, Node.js, or PowerShell scripts.  
* **LLM-Centric Design:** Includes a data-only ""bare"" (.aiar) format, which is a simple text specification for LLMs to generate without writing any code.  (Not that LLMs are able to easily create bash aiar files.)  
* **Extracting languages supported**: python, bash/zsh, nodejs and powershell and of course, no language ‚Äú.aiar‚Äù bare format which does not include the extraction code. Bare format files (as well as all the language specific archive formats) can be extracted using the aiar tool.

### **Usage**

**Installation:**

pip install aiar

**Creating an Archive:**

\# Create a self-extracting scripts  
aiar create \-o archive.py my\_stuff/  \# python

aiar create \-o archive.bash my\_stuff/ \# bash or zsh

aiar create \-o archive.ps1 my\_stuff/ \# powershell

**Extracting an Archive using the built in script:**

python archive.py \# python

bash archive.bash

powershell archive.ps1

\# Or, extract any format (including bare) with the tool  
aiar extract archive.py

Feedback and contributions are welcome.

**Links:**

* **PyPI:** [https://pypi.org/project/aiar/](https://pypi.org/project/aiar/)  
* **GitHub:** [https://github.com/owebeeone/aiar](https://github.com/owebeeone/aiar)",0,11,2025-10-10 07:13:13,GianniMariani,https://www.reddit.com/r/Python/comments/1o2t7zq/aiar_a_pypi_cli_tool_for_managing_selfextracting/
1o2frc2,reddit,"[Release] PyCopyX ‚Äî a Windows GUI around robocopy with precise selection, smart excludes","# What my project does

* Dual-pane GUI (Source/Destination) built with **PySide6**
* **Precise selection:** Ctrl-click and Shift-select in the Source pane
   * **Files only** ‚Üí `robocopy SRC DST file1 file2 ‚Ä¶ /LEV:1` (**no recursion**), so subfolders don‚Äôt sneak in
   * **Folders** ‚Üí `/E` (or **/MIR** in Mirror mode) per folder
* **Preview-first:** shows the exact `robocopy` command (with `/L`) plus the resolved **/XD** (dir excludes) and **/XF** (file masks)
* **Rock-solid excludes:** dir-name wildcards like `*env*` go to **/XD** *as-is* **and** are pre-expanded to absolute paths (defensive fallback if an environment is picky with wildcards). If `*Env` accidentally lands under file masks, PyCopyX also treats it as a dir-name glob and feeds it into **/XD**
* **Thread control:** sensible default **/MT:16**, clamped 1‚Ä¶128
* **Mirror safety:** Mirror is **folders-only**; if files are selected, it warns and aborts
* **Safe Delete:** optional Recycle Bin delete via **Send2Trash**

# Source Code

* **Repo:** [https://github.com/rozsit/116\_PyCopyX](https://github.com/rozsit/116_PyCopyX)
* **Signed .exe:** [https://github.com/rozsit/116\_PyCopyX/releases/tag/v1.0.0](https://github.com/rozsit/116_PyCopyX/releases/tag/v1.0.0) *Windows only (because* `robocopy`\*). Packaging via PyInstaller. License: Apache-2.0.\*

# Target Audience

* **Python developers** who need to copy/move/mirror **only parts** of a project tree while skipping virtualenvs, caches, and build artifacts
* **Windows users** wanting a predictable, GUI-driven front end for `robocopy`
* Teams handling **lots of small files** and wanting **multi-threaded** throughput with clear previews and safe defaults

# Why?

I often needed to copy/move/mirror only parts of a project tree‚Äîwithout dragging virtualenvs, caches, or build artifacts‚Äîand I wanted to see exactly what would happen before pressing ‚ÄúRun.‚Äù PyCopyX gives me that control while staying simple

# Typical excludes (just works)

* Virtual envs / caches / builds: `.venv`, `venv`, `__pycache__`, `.mypy_cache`, `.pytest_cache`, `.ruff_cache`, `build`, `dist`
* Catch-all for env-like names (any depth): `*env*`
* Git/IDE/Windows cruft: `.git`, `.idea`, `.vscode`, `Thumbs.db`, `desktop.ini`

>

# Roadmap / feedback

* Quick presets for common excludes, a TC-style **toggle selection** hotkey (Space), and QoL polish.
* Feedback welcome on edge cases (very long paths, locked files, Defender interaction) and real-world exclude patterns.

Issues/PRs welcome. Thanks! üôå",4,4,2025-10-09 20:44:15,rozsit,https://www.reddit.com/r/Python/comments/1o2frc2/release_pycopyx_a_windows_gui_around_robocopy/
1o1ipfo,reddit,Pydantic v2.12 release (Python 3.14),"[https://pydantic.dev/articles/pydantic-v2-12-release](https://pydantic.dev/articles/pydantic-v2-12-release)

* Support for Python 3.14
* New experimental `MISSING` sentinel
* Support for PEP 728 (`TypedDict` with `extra_items`)
* Preserve empty URL paths (`url_preserve_empty_path`)
* Control timestamp validation unit (`val_temporal_unit`)
* New `exclude_if` field option
* New `ensure_ascii` JSON serialization option
* Per-validation `extra` configuration
* Strict version check for `pydantic-core`
* JSON Schema improvements (regex for Decimal, custom titles, etc.)
* Only latest mypy version officially supported
* Slight validation performance improvement

",175,14,2025-10-08 19:26:53,__secondary__,https://www.reddit.com/r/Python/comments/1o1ipfo/pydantic_v212_release_python_314/
1o2pcg8,reddit,"pytrends not working, anyone same?","I tried to retrieve data from parents but found it not working. Is it still working? Has anyone used it recently?
Don‚Äôt know whether I should continue debugging the script.
",0,0,2025-10-10 03:42:40,No_Winner_3807,https://www.reddit.com/r/Python/comments/1o2pcg8/pytrends_not_working_anyone_same/
1o1ixgu,reddit,Good SQLBuilder for Python?,"Hello!  
I need to develop a small-medium forum with basic functionalities but I also need to make sure it supports DB swaps easily. I don't like to use ORMs because of their poor performance and I know SQL good enough not to care about it's conveinences. 

Many suggest SQLAlchemy Core but for 2 days I've been trying to read the official documentation. At first I thought ""woah, so much writing, must be very solid and straightforward"" only to realize I don't understand much of it. Or perhaps I don't have the patience.

Another alternative is PyPika which has a very small and clear documentation, easy to memorize the API after using it a few times and helps with translating an SQL query to multiple SQL dialects. 

Just curious, are there any other alternatives?  
Thanks!",28,37,2025-10-08 19:34:58,yughiro_destroyer,https://www.reddit.com/r/Python/comments/1o1ixgu/good_sqlbuilder_for_python/
1o1qqhu,reddit,Just launched a data dashboard showing when and how I take photos,"What My Project Does:

This dashboard connects to my personal photo gallery database and turns my photo uploads into interactive analytics. It visualizes:

- Daily photo activity
- Most used camera models
- Tag frequency and distribution
- Thumbnail previews of recent uploads

It updates automatically with cached data and can be manually refreshed. Built with Python, Streamlit, Plotly, and SQLAlchemy, it allows me to explore my photography data in a visually engaging way.


Target Audience:

This is mainly a personal project, but it‚Äôs designed to be production-ready ‚Äî anyone with a photo collection stored in Postgres could adapt it. It‚Äôs suitable for hobbyists, photographers, or developers exploring data storytelling with Streamlit dashboards.


Comparison:

Unlike basic photo galleries that only show images, this dashboard focuses on analytics and visualization. While platforms like Google Photos provide statistics, this project is:

Fully customizable

Open source (you can run or modify it yourself)

Designed for integrating custom metrics and tags

Built using Python/Streamlit, making it easy to expand with new charts or interactive components


üîó Live dashboard: https://a-k-holod-photo-stats.streamlit.app/

üì∑ Gallery: https://a-k-holod-gallery.vercel.app/

üíª Code: https://github.com/a-k-holod/photo-stats-dashboard


If you can't call 20 pictures gallery, then it's an album! ",9,0,2025-10-09 00:29:09,ANDZELEK,https://www.reddit.com/r/Python/comments/1o1qqhu/just_launched_a_data_dashboard_showing_when_and/
1o2gptj,reddit,Looking for *free* library or API to track market index,"I‚Äôm looking for a library or api, preferably an api that will let me look at the DWCF market index. I tried the yfinance library but the firewall at work is blocking it and not letting connect it to properly. I also tried the alpha vantage api but they do not have any data on DWCF. I also need historical data, like 20+ years worth :).

Is there anything available that someone can recommend?",0,5,2025-10-09 21:20:41,boyIDK,https://www.reddit.com/r/Python/comments/1o2gptj/looking_for_free_library_or_api_to_track_market/
1o1j2b3,reddit,"My project to learn descriptors, rich comparison functions, asyncio, and type hinting","[https://github.com/gdchinacat/reactions](https://github.com/gdchinacat/reactions)

I began this project a couple weeks ago based on an idea from another post (link below). I realized it would be a great way to learn some aspects of python I was not yet familiar with. 

The idea is that you can implement classes with fields and then specify conditions for when methods should be called in reaction to those field changing. For example:


    @dataclass
    class Counter:
        count: Field[int] = Field(-1)

        @ count >= 0
        async def loop(self, field, old, new):
                self.count += 1



When count is changed to non negative number it will start counting. Type annotations and some execution management code has been removed. For working examples see src/test/examples directory.

The code has liberal todos in it to expand the functionality, but the core of it is stable, so I thought it was time to release it.

Please let me know your thoughts, or feel free to ask questions about how it works or why I did things a certain way. Thanks!

The post that got me thinking about this: [https://www.reddit.com/r/Python/comments/1nmta0f/i\_built\_a\_full\_programming\_language\_interpreter/](https://www.reddit.com/r/Python/comments/1nmta0f/i_built_a_full_programming_language_interpreter/)",11,2,2025-10-08 19:39:50,gdchinacat,https://www.reddit.com/r/Python/comments/1o1j2b3/my_project_to_learn_descriptors_rich_comparison/
1o17ogm,reddit,TOML marries Argparse,"I wanted to share a small Python library I havee been working on that might help with managing ML experiment configurations.

Jump here directly to the repository: [https://github.com/florianmahner/tomlparse](https://github.com/florianmahner/tomlparse)

**What is it?**

tomlparse is a lightweight wrapper around Python's argparse that lets you use TOML files for configuration management while keeping all the benefits of argparse. It is designed to make hyperparameter management less painful for larger projects.

**Why TOML?**

If you've been using YAML or JSON for configs, TOML offers some nice advantages:

* Native support for dates, floats, integers, booleans, and arrays
* Clear, readable syntax without significant whitespace issues
* Official Python standard library support (tomllib in Python 3.11+)
* Comments that actually stay comments

**Key Features**

The library adds minimal overhead to your existing argparse workflow:

    import tomlparse
    
    parser = tomlparse.ArgumentParser()
    parser.add_argument(""--foo"", type=int, default=0)
    parser.add_argument(""--bar"", type=str, default="""")
    args = parser.parse_args()

Then run with:

    python experiment.py --config ""example.toml""

**What I find useful:**

1. **Table support** \- Organize configs into sections and switch between them easily
2. **Clear override hierarchy** \- CLI args > TOML table values > TOML root values > defaults
3. **Easy experiment tracking** \- Keep different TOML files for different experiment runs

**Example use case with tables:**

    # This is a TOML File
    # Parameters without a preceding [] are not part of a table (called root-table)
    foo = 10
    bar = ""hello""
    
    # These arguments are part of the table [general]
    [general]
    foo = 20
    
    # These arguments are part of the table [root]
    [root]
    bar = ""hey""

You can then specify which table to use:

    python experiment.py --config ""example.toml"" --table ""general""
    # Returns: {""foo"": 20, ""bar"": ""hello""}
    
    python experiment.py --config ""example.toml"" --table ""general"" --root-table ""root""
    # Returns: {""foo"": 20, ""bar"": ""hey""}

And you can always override from the command line:

    python experiment.py --config ""example.toml"" --table ""general"" --foo 100

**Install:**

    pip install tomlparse

**GitHub:** [https://github.com/florianmahner/tomlparse](https://github.com/florianmahner/tomlparse)

Would love to hear thoughts or feedback if anyone tries it out! It has been useful for my own work, but I am sure there are edge cases I haven't considered.

*Disclaimer: This is a personal project, not affiliated with any organization.*",38,14,2025-10-08 12:20:18,Prestigious-Nerve851,https://www.reddit.com/r/Python/comments/1o17ogm/toml_marries_argparse/
1o150hi,reddit,Use uv with Python 3.14 and IIS sites,"After the upgrade to Python 3.14, there's no longer the concept of a ""system-wide"" Python. Therefore, when you create a virtual environment, the hardlinks (if they are really hardlinks) point to `%LOCALAPPDATA%\Python\pythoncore-3.14-64\python.exe`. The problem is that if you have a virtual environment for an IIS website, e.g. spanandeggs.example.com, this will by default run with the virtual user IISAPPPOOL\spamandeggs.example.com. And that user most certainly doesn't have access to your personal `%LOCALAPPDATA%` directory. So, if you try to run the site, you'll get this error:

`did not find executable at '¬´%LOCALAPPDATA%¬ª\Python\pythoncore-3.14-64\python.exe': Access is denied.`

To make this work I've had to:

1. Download python to a separate directory (`uv python install 3.14 --install-dir C:\python\`)
2. Sync the virtual environment with the new Python version: `uv sync --upgrade --python C:\Python\cpython-3.14.0-windows-x86_64-none\`)

For completeness, where's an example web.config to make a site run natively under IIS (this assumes there's an app.py). I'm not 100% sure that all environment variables are required:

    <?xml version=""1.0"" encoding=""UTF-8""?>
    <configuration>
        <system.webServer>
            <modules runAllManagedModulesForAllRequests=""true"" />
            <handlers>
                <clear/>
                <add name=""httpPlatformHandler"" path=""*"" verb=""*"" modules=""httpPlatformHandler"" resourceType=""Unspecified"" requireAccess=""Script"" />
            </handlers>
            <httpPlatform processPath="".\.venv\Scripts\python.exe"" arguments=""-m flask run --port %HTTP_PLATFORM_PORT%"">
                <environmentVariables>
                    <environmentVariable name=""SERVER_PORT"" value=""%HTTP_PLATFORM_PORT%"" />
                    <environmentVariable name=""PYTHONPATH"" value=""."" />
                    <environmentVariable name=""PYTHONHOME"" value="""" />
                    <environmentVariable name=""VIRTUAL_ENV"" value="".venv"" />
                    <environmentVariable name=""PATH"" value="".venv\Scripts"" />
                </environmentVariables>
            </httpPlatform>
        </system.webServer>
    </configuration>",51,34,2025-10-08 09:36:50,gschizas,https://www.reddit.com/r/Python/comments/1o150hi/use_uv_with_python_314_and_iis_sites/
1o17iwq,reddit,Interesting discussion to shift Apache's Arrow release cycle forward to align with Python's release,"There's an interesting discussion in the PyArrow community about shifting their release cycle to better align with Python's annual release schedule. Currently, PyArrow often becomes the last major dependency to support new Python versions, with support arriving about a month after Python's stable release, which creates a bottleneck for the broader data engineering ecosystem.

The proposal suggests moving Arrow's feature freeze from early October to early August, shortly after Python's ABI-stable release candidate drops in late July, which would flip the timeline so PyArrow wheels are available around a month before Python's stable release rather than after.

[https://github.com/apache/arrow/issues/47700](https://github.com/apache/arrow/issues/47700)",31,2,2025-10-08 12:11:59,Balance-,https://www.reddit.com/r/Python/comments/1o17iwq/interesting_discussion_to_shift_apaches_arrow/
1o0gfp1,reddit,Python 3.14 Released,"https://docs.python.org/3.14/whatsnew/3.14.html

Interpreter improvements:

* PEP 649 and PEP 749: Deferred evaluation of annotations
* PEP 734: Multiple interpreters in the standard library
* PEP 750: Template strings
* PEP 758: Allow except and except* expressions without brackets
* PEP 765: Control flow in finally blocks
* PEP 768: Safe external debugger interface for CPython
* A new type of interpreter
* Free-threaded mode improvements
* Improved error messages
* Incremental garbage collection

Significant improvements in the standard library:

* PEP 784: Zstandard support in the standard library
* Asyncio introspection capabilities
* Concurrent safe warnings control
* Syntax highlighting in the default interactive shell, and color output in several standard library CLIs

C API improvements:

* PEP 741: Python configuration C API

Platform support:

* PEP 776: Emscripten is now an officially supported platform, at tier 3.

Release changes:

* PEP 779: Free-threaded Python is officially supported
* PEP 761: PGP signatures have been discontinued for official releases
* Windows and macOS binary releases now support the experimental just-in-time compiler
* Binary releases for Android are now provided",1084,103,2025-10-07 15:32:22,chinawcswing,https://www.reddit.com/r/Python/comments/1o0gfp1/python_314_released/
1o1rea5,reddit,"Thursday Daily Thread: Python Careers, Courses, and Furthering Education!","# Weekly Thread: Professional Use, Jobs, and Education üè¢

Welcome to this week's discussion on Python in the professional world! This is your spot to talk about job hunting, career growth, and educational resources in Python. Please note, this thread is **not for recruitment**.

---

## How it Works:

1. **Career Talk**: Discuss using Python in your job, or the job market for Python roles.
2. **Education Q&A**: Ask or answer questions about Python courses, certifications, and educational resources.
3. **Workplace Chat**: Share your experiences, challenges, or success stories about using Python professionally.

---

## Guidelines:

- This thread is **not for recruitment**. For job postings, please see r/PythonJobs or the recruitment thread in the sidebar.
- Keep discussions relevant to Python in the professional and educational context.
  
---

## Example Topics:

1. **Career Paths**: What kinds of roles are out there for Python developers?
2. **Certifications**: Are Python certifications worth it?
3. **Course Recommendations**: Any good advanced Python courses to recommend?
4. **Workplace Tools**: What Python libraries are indispensable in your professional work?
5. **Interview Tips**: What types of Python questions are commonly asked in interviews?

---

Let's help each other grow in our careers and education. Happy discussing! üåü",2,0,2025-10-09 01:00:33,AutoModerator,https://www.reddit.com/r/Python/comments/1o1rea5/thursday_daily_thread_python_careers_courses_and/
1o18p3a,reddit,Feature Store Summit - 2025 - Free and Online.,"**Hello Pytonistas !**  
  
We are organising the Feature Store Summit. An annual online event where we invite some of the most technical speakers from some of the world‚Äôs most advanced engineering teams to talk about their infrastructure for AI, ML and oftentime how this fits in the pythonic ecosystem.   
  
**Some of this year‚Äôs speakers are coming from:**  
Uber, Pinterest, Zalando, Lyft, Coinbase, Hopsworks and More!

**What to Expect:**  
üî• Real-Time Feature Engineering at scale  
üî•¬†Vector Databases & Generative AI in production  
üî•¬†The balance of Batch & Real-Time workflows  
üî•¬†Emerging trends driving the evolution of Feature Stores in 2025

**When:**  
üóìÔ∏è¬†October 14th  
‚è∞¬†Starting 8:30AM PT  
‚è∞ Starting 5:30PM CET  
  
Link;¬†[https://www.featurestoresummit.com/register](https://www.featurestoresummit.com/register?utm_source=reddit)

PS; it is free, online, and if you register you will be receiving the recorded talks afterward! 

  
",11,2,2025-10-08 13:11:06,logicalclocks,https://www.reddit.com/r/Python/comments/1o18p3a/feature_store_summit_2025_free_and_online/
